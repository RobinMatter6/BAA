nohup: ignoring input
Using GPU ID: 5
Using output folder /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min
WARNING:tensorflow:From script_train_fixed_params_isolated.py:115: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.

2024-12-23 20:27:10.143054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-23 20:27:12.381249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla M10 major: 5 minor: 0 memoryClockRate(GHz): 1.0325
pciBusID: 0000:b2:00.0
2024-12-23 20:27:12.381895: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-12-23 20:27:12.388697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-12-23 20:27:12.391874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-12-23 20:27:12.397377: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-12-23 20:27:12.418229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-12-23 20:27:12.421119: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-12-23 20:27:12.462462: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-12-23 20:27:13.396745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-12-23 20:27:13.398188: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-23 20:27:13.534643: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz
2024-12-23 20:27:13.634207: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47bf600 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-23 20:27:13.634344: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-23 20:27:14.849818: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b7260 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-23 20:27:14.849938: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla M10, Compute Capability 5.0
2024-12-23 20:27:14.855839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla M10 major: 5 minor: 0 memoryClockRate(GHz): 1.0325
pciBusID: 0000:b2:00.0
2024-12-23 20:27:14.856589: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-12-23 20:27:14.856808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-12-23 20:27:14.856990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-12-23 20:27:14.857159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-12-23 20:27:14.857317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-12-23 20:27:14.857482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-12-23 20:27:14.857643: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-12-23 20:27:14.859136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-12-23 20:27:14.859539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-12-23 20:27:14.860592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-23 20:27:14.860863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-23 20:27:14.861028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-12-23 20:27:14.886434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7692 MB memory) -> physical GPU (device: 0, name: Tesla M10, pci bus id: 0000:b2:00.0, compute capability: 5.0)
*** Training from defined parameters for visitors ***
Loading & splitting data...
Formatting train-valid-test splits.
Setting scalers with training data...
*** Loading hyperparameter manager ***
*** Running calibration ***
Params Selected:
dropout_rate: 0.3
hidden_layer_size: 160
learning_rate: 0.001
minibatch_size: 64
max_gradient_norm: 0.01
num_heads: 1
stack_size: 1
model_folder: /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed
2024-12-23 20:27:15.410552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla M10 major: 5 minor: 0 memoryClockRate(GHz): 1.0325
pciBusID: 0000:b2:00.0
2024-12-23 20:27:15.411114: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-12-23 20:27:15.411509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-12-23 20:27:15.411798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-12-23 20:27:15.412056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-12-23 20:27:15.412318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-12-23 20:27:15.412549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-12-23 20:27:15.412774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-12-23 20:27:15.414556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-12-23 20:27:15.414991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-23 20:27:15.415280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-23 20:27:15.415488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-12-23 20:27:15.417513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7692 MB memory) -> physical GPU (device: 0, name: Tesla M10, pci bus id: 0000:b2:00.0, compute capability: 5.0)
WARNING:tensorflow:From script_train_fixed_params_isolated.py:157: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

Resetting temp folder...
*** TemporalFusionTransformer params ***
# dropout_rate = 0.3
# hidden_layer_size = 160
# learning_rate = 0.001
# max_gradient_norm = 0.01
# minibatch_size = 64
# model_folder = /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed
# num_heads = 1
# stack_size = 1
# total_time_steps = 32
# num_encoder_steps = 24
# num_epochs = 100
# early_stopping_patience = 3
# multiprocessing_workers = 5
# column_definition = [('dummy_id', <DataTypes.REAL_VALUED: 0>, <InputTypes.ID: 4>), ('date', <DataTypes.DATE: 2>, <InputTypes.TIME: 5>), ('minute_of_hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('hour_of_day', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('week_of_year', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('month_of_year', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_month', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('Precipitation Duration', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('visitors', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('region', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>)]
# input_size = 9
# output_size = 1
# category_counts = [1]
# input_obs_loc = [7]
# static_input_loc = [8]
# known_regular_inputs = [0, 1, 2, 3, 4, 5, 6]
# known_categorical_inputs = [0]
WARNING:tensorflow:From /opt/BAA/TFT/libs/tft_model.py:1044: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /root/.pyenv/versions/3.7.12/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /root/.pyenv/versions/3.7.12/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /opt/BAA/TFT/libs/tft_model.py:947: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.

Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 9)]      0                                            
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           input_1[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32)]         0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
sequential (Sequential)         (None, 32, 160)      160         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 160)]        0           sequential[1][0]                 
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
flatten (Flatten)               (None, 160)          0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 160)          25760       flatten[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
activation (Activation)         (None, 160)          0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 1, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 160)          25760       activation[0][0]                 
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 1, 160)       0           dense_13[0][0]                   
__________________________________________________________________________________________________
dropout (Dropout)               (None, 160)          0           dense_10[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 1, 160)       25760       activation_2[0][0]               
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 1)            161         dropout[0][0]                    
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 1)            161         dropout[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 1, 160)       0           dense_14[0][0]                   
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 1)            161         flatten[0][0]                    
__________________________________________________________________________________________________
multiply (Multiply)             (None, 1)            0           dense_11[0][0]                   
                                                                 dense_12[0][0]                   
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 1, 160)       25760       dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 1, 160)       25760       dropout_1[0][0]                  
__________________________________________________________________________________________________
add (Add)                       (None, 1)            0           dense_8[0][0]                    
                                                                 multiply[0][0]                   
__________________________________________________________________________________________________
multiply_1 (Multiply)           (None, 1, 160)       0           dense_15[0][0]                   
                                                                 dense_16[0][0]                   
__________________________________________________________________________________________________
layer_normalization (LayerNorma (None, 1)            2           add[0][0]                        
__________________________________________________________________________________________________
add_1 (Add)                     (None, 1, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_1[0][0]                 
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 1)            0           layer_normalization[0][0]        
__________________________________________________________________________________________________
layer_normalization_1 (LayerNor (None, 1, 160)       320         add_1[0][0]                      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 1)]       0           activation_1[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_1[0][0]      
__________________________________________________________________________________________________
multiply_2 (Multiply)           (None, 1, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 160)]        0           multiply_2[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 160)          0           dense_17[0][0]                   
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 8)]      0           input_1[0][0]                    
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 160)          25760       activation_3[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 160)          0           dense_18[0][0]                   
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed (TimeDistribut (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 160)          25760       dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 160)          25760       dropout_2[0][0]                  
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160, 7)] 0           time_distributed_1[0][0]         
                                                                 time_distributed_2[0][0]         
                                                                 time_distributed_3[0][0]         
                                                                 time_distributed_4[0][0]         
                                                                 time_distributed_5[0][0]         
                                                                 time_distributed_6[0][0]         
                                                                 time_distributed_7[0][0]         
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160, 1)] 0           time_distributed[0][0]           
__________________________________________________________________________________________________
multiply_3 (Multiply)           (None, 160)          0           dense_19[0][0]                   
                                                                 dense_20[0][0]                   
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 7)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 1)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_2 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_3[0][0]                 
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 8)] 0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
layer_normalization_2 (LayerNor (None, 160)          320         add_2[0][0]                      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 1280)]   0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_2[0][0]      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160, 7)]  0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, 24, 160)      204960      tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, 1, 160)       25600       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 1120)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_2[0][0]      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           time_distributed_9[0][0]         
                                                                 time_distributed_10[0][0]        
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_47 (TimeDistri (None, 8, 160)       179360      tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_48 (TimeDistri (None, 1, 160)       25600       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_14 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_18 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_22 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_26 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_30 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_34 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_38 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_42 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           time_distributed_47[0][0]        
                                                                 time_distributed_48[0][0]        
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, 24, 160)      25760       activation_7[0][0]               
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 24, 160)      0           time_distributed_14[0][0]        
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 24, 160)      0           time_distributed_18[0][0]        
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 24, 160)      0           time_distributed_22[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 160)      0           time_distributed_26[0][0]        
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 24, 160)      0           time_distributed_30[0][0]        
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 24, 160)      0           time_distributed_34[0][0]        
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 24, 160)      0           time_distributed_38[0][0]        
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 24, 160)      0           time_distributed_42[0][0]        
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_52 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_56 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_60 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_64 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_68 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_72 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_76 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 160)      0           time_distributed_11[0][0]        
__________________________________________________________________________________________________
time_distributed_15 (TimeDistri (None, 24, 160)      25760       activation_9[0][0]               
__________________________________________________________________________________________________
time_distributed_19 (TimeDistri (None, 24, 160)      25760       activation_10[0][0]              
__________________________________________________________________________________________________
time_distributed_23 (TimeDistri (None, 24, 160)      25760       activation_11[0][0]              
__________________________________________________________________________________________________
time_distributed_27 (TimeDistri (None, 24, 160)      25760       activation_12[0][0]              
__________________________________________________________________________________________________
time_distributed_31 (TimeDistri (None, 24, 160)      25760       activation_13[0][0]              
__________________________________________________________________________________________________
time_distributed_35 (TimeDistri (None, 24, 160)      25760       activation_14[0][0]              
__________________________________________________________________________________________________
time_distributed_39 (TimeDistri (None, 24, 160)      25760       activation_15[0][0]              
__________________________________________________________________________________________________
time_distributed_43 (TimeDistri (None, 24, 160)      25760       activation_16[0][0]              
__________________________________________________________________________________________________
time_distributed_49 (TimeDistri (None, 8, 160)       25760       activation_17[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 160)       0           time_distributed_52[0][0]        
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 160)       0           time_distributed_56[0][0]        
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 160)       0           time_distributed_60[0][0]        
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 160)       0           time_distributed_64[0][0]        
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 160)       0           time_distributed_68[0][0]        
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 160)       0           time_distributed_72[0][0]        
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 160)       0           time_distributed_76[0][0]        
__________________________________________________________________________________________________
time_distributed_12 (TimeDistri (None, 24, 8)        1288        dropout_6[0][0]                  
__________________________________________________________________________________________________
time_distributed_13 (TimeDistri (None, 24, 8)        1288        dropout_6[0][0]                  
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 160)      0           time_distributed_15[0][0]        
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 160)      0           time_distributed_19[0][0]        
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 160)      0           time_distributed_23[0][0]        
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 160)      0           time_distributed_27[0][0]        
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 160)      0           time_distributed_31[0][0]        
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 160)      0           time_distributed_35[0][0]        
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 24, 160)      0           time_distributed_39[0][0]        
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 24, 160)      0           time_distributed_43[0][0]        
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 8, 160)       0           time_distributed_49[0][0]        
__________________________________________________________________________________________________
time_distributed_53 (TimeDistri (None, 8, 160)       25760       activation_19[0][0]              
__________________________________________________________________________________________________
time_distributed_57 (TimeDistri (None, 8, 160)       25760       activation_20[0][0]              
__________________________________________________________________________________________________
time_distributed_61 (TimeDistri (None, 8, 160)       25760       activation_21[0][0]              
__________________________________________________________________________________________________
time_distributed_65 (TimeDistri (None, 8, 160)       25760       activation_22[0][0]              
__________________________________________________________________________________________________
time_distributed_69 (TimeDistri (None, 8, 160)       25760       activation_23[0][0]              
__________________________________________________________________________________________________
time_distributed_73 (TimeDistri (None, 8, 160)       25760       activation_24[0][0]              
__________________________________________________________________________________________________
time_distributed_77 (TimeDistri (None, 8, 160)       25760       activation_25[0][0]              
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, 24, 8)        10248       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
multiply_7 (Multiply)           (None, 24, 8)        0           time_distributed_12[0][0]        
                                                                 time_distributed_13[0][0]        
__________________________________________________________________________________________________
time_distributed_16 (TimeDistri (None, 24, 160)      25760       dropout_7[0][0]                  
__________________________________________________________________________________________________
time_distributed_17 (TimeDistri (None, 24, 160)      25760       dropout_7[0][0]                  
__________________________________________________________________________________________________
time_distributed_20 (TimeDistri (None, 24, 160)      25760       dropout_8[0][0]                  
__________________________________________________________________________________________________
time_distributed_21 (TimeDistri (None, 24, 160)      25760       dropout_8[0][0]                  
__________________________________________________________________________________________________
time_distributed_24 (TimeDistri (None, 24, 160)      25760       dropout_9[0][0]                  
__________________________________________________________________________________________________
time_distributed_25 (TimeDistri (None, 24, 160)      25760       dropout_9[0][0]                  
__________________________________________________________________________________________________
time_distributed_28 (TimeDistri (None, 24, 160)      25760       dropout_10[0][0]                 
__________________________________________________________________________________________________
time_distributed_29 (TimeDistri (None, 24, 160)      25760       dropout_10[0][0]                 
__________________________________________________________________________________________________
time_distributed_32 (TimeDistri (None, 24, 160)      25760       dropout_11[0][0]                 
__________________________________________________________________________________________________
time_distributed_33 (TimeDistri (None, 24, 160)      25760       dropout_11[0][0]                 
__________________________________________________________________________________________________
time_distributed_36 (TimeDistri (None, 24, 160)      25760       dropout_12[0][0]                 
__________________________________________________________________________________________________
time_distributed_37 (TimeDistri (None, 24, 160)      25760       dropout_12[0][0]                 
__________________________________________________________________________________________________
time_distributed_40 (TimeDistri (None, 24, 160)      25760       dropout_13[0][0]                 
__________________________________________________________________________________________________
time_distributed_41 (TimeDistri (None, 24, 160)      25760       dropout_13[0][0]                 
__________________________________________________________________________________________________
time_distributed_44 (TimeDistri (None, 24, 160)      25760       dropout_14[0][0]                 
__________________________________________________________________________________________________
time_distributed_45 (TimeDistri (None, 24, 160)      25760       dropout_14[0][0]                 
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 160)          0           dense_25[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 160)          0           dense_29[0][0]                   
__________________________________________________________________________________________________
time_distributed_50 (TimeDistri (None, 8, 7)         1127        dropout_15[0][0]                 
__________________________________________________________________________________________________
time_distributed_51 (TimeDistri (None, 8, 7)         1127        dropout_15[0][0]                 
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 8, 160)       0           time_distributed_53[0][0]        
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 8, 160)       0           time_distributed_57[0][0]        
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 8, 160)       0           time_distributed_61[0][0]        
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 8, 160)       0           time_distributed_65[0][0]        
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, 8, 160)       0           time_distributed_69[0][0]        
__________________________________________________________________________________________________
dropout_21 (Dropout)            (None, 8, 160)       0           time_distributed_73[0][0]        
__________________________________________________________________________________________________
dropout_22 (Dropout)            (None, 8, 160)       0           time_distributed_77[0][0]        
__________________________________________________________________________________________________
add_6 (Add)                     (None, 24, 8)        0           time_distributed_8[0][0]         
                                                                 multiply_7[0][0]                 
__________________________________________________________________________________________________
multiply_8 (Multiply)           (None, 24, 160)      0           time_distributed_16[0][0]        
                                                                 time_distributed_17[0][0]        
__________________________________________________________________________________________________
multiply_9 (Multiply)           (None, 24, 160)      0           time_distributed_20[0][0]        
                                                                 time_distributed_21[0][0]        
__________________________________________________________________________________________________
multiply_10 (Multiply)          (None, 24, 160)      0           time_distributed_24[0][0]        
                                                                 time_distributed_25[0][0]        
__________________________________________________________________________________________________
multiply_11 (Multiply)          (None, 24, 160)      0           time_distributed_28[0][0]        
                                                                 time_distributed_29[0][0]        
__________________________________________________________________________________________________
multiply_12 (Multiply)          (None, 24, 160)      0           time_distributed_32[0][0]        
                                                                 time_distributed_33[0][0]        
__________________________________________________________________________________________________
multiply_13 (Multiply)          (None, 24, 160)      0           time_distributed_36[0][0]        
                                                                 time_distributed_37[0][0]        
__________________________________________________________________________________________________
multiply_14 (Multiply)          (None, 24, 160)      0           time_distributed_40[0][0]        
                                                                 time_distributed_41[0][0]        
__________________________________________________________________________________________________
multiply_15 (Multiply)          (None, 24, 160)      0           time_distributed_44[0][0]        
                                                                 time_distributed_45[0][0]        
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 160)          25760       activation_5[0][0]               
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 160)          25760       activation_6[0][0]               
__________________________________________________________________________________________________
time_distributed_46 (TimeDistri (None, 8, 7)         7847        tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
multiply_17 (Multiply)          (None, 8, 7)         0           time_distributed_50[0][0]        
                                                                 time_distributed_51[0][0]        
__________________________________________________________________________________________________
time_distributed_54 (TimeDistri (None, 8, 160)       25760       dropout_16[0][0]                 
__________________________________________________________________________________________________
time_distributed_55 (TimeDistri (None, 8, 160)       25760       dropout_16[0][0]                 
__________________________________________________________________________________________________
time_distributed_58 (TimeDistri (None, 8, 160)       25760       dropout_17[0][0]                 
__________________________________________________________________________________________________
time_distributed_59 (TimeDistri (None, 8, 160)       25760       dropout_17[0][0]                 
__________________________________________________________________________________________________
time_distributed_62 (TimeDistri (None, 8, 160)       25760       dropout_18[0][0]                 
__________________________________________________________________________________________________
time_distributed_63 (TimeDistri (None, 8, 160)       25760       dropout_18[0][0]                 
__________________________________________________________________________________________________
time_distributed_66 (TimeDistri (None, 8, 160)       25760       dropout_19[0][0]                 
__________________________________________________________________________________________________
time_distributed_67 (TimeDistri (None, 8, 160)       25760       dropout_19[0][0]                 
__________________________________________________________________________________________________
time_distributed_70 (TimeDistri (None, 8, 160)       25760       dropout_20[0][0]                 
__________________________________________________________________________________________________
time_distributed_71 (TimeDistri (None, 8, 160)       25760       dropout_20[0][0]                 
__________________________________________________________________________________________________
time_distributed_74 (TimeDistri (None, 8, 160)       25760       dropout_21[0][0]                 
__________________________________________________________________________________________________
time_distributed_75 (TimeDistri (None, 8, 160)       25760       dropout_21[0][0]                 
__________________________________________________________________________________________________
time_distributed_78 (TimeDistri (None, 8, 160)       25760       dropout_22[0][0]                 
__________________________________________________________________________________________________
time_distributed_79 (TimeDistri (None, 8, 160)       25760       dropout_22[0][0]                 
__________________________________________________________________________________________________
layer_normalization_6 (LayerNor (None, 24, 8)        16          add_6[0][0]                      
__________________________________________________________________________________________________
add_7 (Add)                     (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_8[0][0]                 
__________________________________________________________________________________________________
add_8 (Add)                     (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_9[0][0]                 
__________________________________________________________________________________________________
add_9 (Add)                     (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_10[0][0]                
__________________________________________________________________________________________________
add_10 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_11[0][0]                
__________________________________________________________________________________________________
add_11 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_12[0][0]                
__________________________________________________________________________________________________
add_12 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_13[0][0]                
__________________________________________________________________________________________________
add_13 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_14[0][0]                
__________________________________________________________________________________________________
add_14 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_15[0][0]                
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 160)          0           dense_26[0][0]                   
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 160)          0           dense_30[0][0]                   
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 7)         0           time_distributed_46[0][0]        
                                                                 multiply_17[0][0]                
__________________________________________________________________________________________________
multiply_18 (Multiply)          (None, 8, 160)       0           time_distributed_54[0][0]        
                                                                 time_distributed_55[0][0]        
__________________________________________________________________________________________________
multiply_19 (Multiply)          (None, 8, 160)       0           time_distributed_58[0][0]        
                                                                 time_distributed_59[0][0]        
__________________________________________________________________________________________________
multiply_20 (Multiply)          (None, 8, 160)       0           time_distributed_62[0][0]        
                                                                 time_distributed_63[0][0]        
__________________________________________________________________________________________________
multiply_21 (Multiply)          (None, 8, 160)       0           time_distributed_66[0][0]        
                                                                 time_distributed_67[0][0]        
__________________________________________________________________________________________________
multiply_22 (Multiply)          (None, 8, 160)       0           time_distributed_70[0][0]        
                                                                 time_distributed_71[0][0]        
__________________________________________________________________________________________________
multiply_23 (Multiply)          (None, 8, 160)       0           time_distributed_74[0][0]        
                                                                 time_distributed_75[0][0]        
__________________________________________________________________________________________________
multiply_24 (Multiply)          (None, 8, 160)       0           time_distributed_78[0][0]        
                                                                 time_distributed_79[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 8)        0           layer_normalization_6[0][0]      
__________________________________________________________________________________________________
layer_normalization_7 (LayerNor (None, 24, 160)      320         add_7[0][0]                      
__________________________________________________________________________________________________
layer_normalization_8 (LayerNor (None, 24, 160)      320         add_8[0][0]                      
__________________________________________________________________________________________________
layer_normalization_9 (LayerNor (None, 24, 160)      320         add_9[0][0]                      
__________________________________________________________________________________________________
layer_normalization_10 (LayerNo (None, 24, 160)      320         add_10[0][0]                     
__________________________________________________________________________________________________
layer_normalization_11 (LayerNo (None, 24, 160)      320         add_11[0][0]                     
__________________________________________________________________________________________________
layer_normalization_12 (LayerNo (None, 24, 160)      320         add_12[0][0]                     
__________________________________________________________________________________________________
layer_normalization_13 (LayerNo (None, 24, 160)      320         add_13[0][0]                     
__________________________________________________________________________________________________
layer_normalization_14 (LayerNo (None, 24, 160)      320         add_14[0][0]                     
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 160)          25760       dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 160)          25760       dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 160)          25760       dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 160)          25760       dropout_5[0][0]                  
__________________________________________________________________________________________________
layer_normalization_15 (LayerNo (None, 8, 7)         14          add_15[0][0]                     
__________________________________________________________________________________________________
add_16 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_18[0][0]                
__________________________________________________________________________________________________
add_17 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_19[0][0]                
__________________________________________________________________________________________________
add_18 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_20[0][0]                
__________________________________________________________________________________________________
add_19 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_21[0][0]                
__________________________________________________________________________________________________
add_20 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_22[0][0]                
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_23[0][0]                
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_24[0][0]                
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 1, 8)]   0           activation_8[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 8)] 0           layer_normalization_7[0][0]      
                                                                 layer_normalization_8[0][0]      
                                                                 layer_normalization_9[0][0]      
                                                                 layer_normalization_10[0][0]     
                                                                 layer_normalization_11[0][0]     
                                                                 layer_normalization_12[0][0]     
                                                                 layer_normalization_13[0][0]     
                                                                 layer_normalization_14[0][0]     
__________________________________________________________________________________________________
multiply_5 (Multiply)           (None, 160)          0           dense_27[0][0]                   
                                                                 dense_28[0][0]                   
__________________________________________________________________________________________________
multiply_6 (Multiply)           (None, 160)          0           dense_31[0][0]                   
                                                                 dense_32[0][0]                   
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 7)         0           layer_normalization_15[0][0]     
__________________________________________________________________________________________________
layer_normalization_16 (LayerNo (None, 8, 160)       320         add_16[0][0]                     
__________________________________________________________________________________________________
layer_normalization_17 (LayerNo (None, 8, 160)       320         add_17[0][0]                     
__________________________________________________________________________________________________
layer_normalization_18 (LayerNo (None, 8, 160)       320         add_18[0][0]                     
__________________________________________________________________________________________________
layer_normalization_19 (LayerNo (None, 8, 160)       320         add_19[0][0]                     
__________________________________________________________________________________________________
layer_normalization_20 (LayerNo (None, 8, 160)       320         add_20[0][0]                     
__________________________________________________________________________________________________
layer_normalization_21 (LayerNo (None, 8, 160)       320         add_21[0][0]                     
__________________________________________________________________________________________________
layer_normalization_22 (LayerNo (None, 8, 160)       320         add_22[0][0]                     
__________________________________________________________________________________________________
multiply_16 (Multiply)          (None, 24, 160, 8)   0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_4 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_5[0][0]                 
__________________________________________________________________________________________________
add_5 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_6[0][0]                 
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 1, 7)]    0           activation_18[0][0]              
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160, 7)]  0           layer_normalization_16[0][0]     
                                                                 layer_normalization_17[0][0]     
                                                                 layer_normalization_18[0][0]     
                                                                 layer_normalization_19[0][0]     
                                                                 layer_normalization_20[0][0]     
                                                                 layer_normalization_21[0][0]     
                                                                 layer_normalization_22[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           multiply_16[0][0]                
__________________________________________________________________________________________________
layer_normalization_4 (LayerNor (None, 160)          320         add_4[0][0]                      
__________________________________________________________________________________________________
layer_normalization_5 (LayerNor (None, 160)          320         add_5[0][0]                      
__________________________________________________________________________________________________
multiply_25 (Multiply)          (None, 8, 160, 7)    0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
cu_dnnlstm (CuDNNLSTM)          [(None, 24, 160), (N 206080      tf_op_layer_TemporalFusionTransfo
                                                                 layer_normalization_4[0][0]      
                                                                 layer_normalization_5[0][0]      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           multiply_25[0][0]                
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 160)          0           dense_21[0][0]                   
__________________________________________________________________________________________________
cu_dnnlstm_1 (CuDNNLSTM)        (None, 8, 160)       206080      tf_op_layer_TemporalFusionTransfo
                                                                 cu_dnnlstm[0][1]                 
                                                                 cu_dnnlstm[0][2]                 
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 160)          25760       activation_4[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160)]    0           cu_dnnlstm[0][0]                 
                                                                 cu_dnnlstm_1[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 160)          0           dense_22[0][0]                   
__________________________________________________________________________________________________
dropout_23 (Dropout)            (None, 32, 160)      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 160)          25760       dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 160)          25760       dropout_3[0][0]                  
__________________________________________________________________________________________________
time_distributed_80 (TimeDistri (None, 32, 160)      25760       dropout_23[0][0]                 
__________________________________________________________________________________________________
time_distributed_81 (TimeDistri (None, 32, 160)      25760       dropout_23[0][0]                 
__________________________________________________________________________________________________
multiply_4 (Multiply)           (None, 160)          0           dense_23[0][0]                   
                                                                 dense_24[0][0]                   
__________________________________________________________________________________________________
multiply_26 (Multiply)          (None, 32, 160)      0           time_distributed_80[0][0]        
                                                                 time_distributed_81[0][0]        
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160)]    0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_3 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_4[0][0]                 
__________________________________________________________________________________________________
add_23 (Add)                    (None, 32, 160)      0           multiply_26[0][0]                
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
layer_normalization_3 (LayerNor (None, 160)          320         add_3[0][0]                      
__________________________________________________________________________________________________
layer_normalization_23 (LayerNo (None, 32, 160)      320         add_23[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_3[0][0]      
__________________________________________________________________________________________________
time_distributed_82 (TimeDistri (None, 32, 160)      25760       layer_normalization_23[0][0]     
__________________________________________________________________________________________________
time_distributed_83 (TimeDistri (None, 1, 160)       25600       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160)]    0           time_distributed_82[0][0]        
                                                                 time_distributed_83[0][0]        
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 32, 160)      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_84 (TimeDistri (None, 32, 160)      25760       activation_26[0][0]              
__________________________________________________________________________________________________
dropout_24 (Dropout)            (None, 32, 160)      0           time_distributed_84[0][0]        
__________________________________________________________________________________________________
time_distributed_85 (TimeDistri (None, 32, 160)      25760       dropout_24[0][0]                 
__________________________________________________________________________________________________
time_distributed_86 (TimeDistri (None, 32, 160)      25760       dropout_24[0][0]                 
__________________________________________________________________________________________________
multiply_27 (Multiply)          (None, 32, 160)      0           time_distributed_85[0][0]        
                                                                 time_distributed_86[0][0]        
__________________________________________________________________________________________________
add_24 (Add)                    (None, 32, 160)      0           layer_normalization_23[0][0]     
                                                                 multiply_27[0][0]                
__________________________________________________________________________________________________
layer_normalization_24 (LayerNo (None, 32, 160)      320         add_24[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(3,)]               0           layer_normalization_24[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [()]                 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(3,)]               0           layer_normalization_24[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [()]                 0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(1,)]               0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(1,)]               0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(2,)]               0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, None)]       0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, None, None)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 32, 160)      25600       layer_normalization_24[0][0]     
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 32, 160)      25600       layer_normalization_24[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, None, None)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 32, 32)       0           dense_113[0][0]                  
                                                                 dense_114[0][0]                  
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, None, None)   0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_25 (Add)                    (None, 32, 32)       0           lambda[0][0]                     
                                                                 lambda_1[0][0]                   
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 32, 32)       0           add_25[0][0]                     
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 32, 32)       0           activation_27[0][0]              
__________________________________________________________________________________________________
dense_112 (Dense)               (None, 32, 160)      25600       layer_normalization_24[0][0]     
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 32, 160)      0           dropout_25[0][0]                 
                                                                 dense_112[0][0]                  
__________________________________________________________________________________________________
dropout_26 (Dropout)            (None, 32, 160)      0           lambda_2[0][0]                   
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 32, 160)      25600       dropout_26[0][0]                 
__________________________________________________________________________________________________
dropout_27 (Dropout)            (None, 32, 160)      0           dense_115[0][0]                  
__________________________________________________________________________________________________
dropout_28 (Dropout)            (None, 32, 160)      0           dropout_27[0][0]                 
__________________________________________________________________________________________________
time_distributed_87 (TimeDistri (None, 32, 160)      25760       dropout_28[0][0]                 
__________________________________________________________________________________________________
time_distributed_88 (TimeDistri (None, 32, 160)      25760       dropout_28[0][0]                 
__________________________________________________________________________________________________
multiply_28 (Multiply)          (None, 32, 160)      0           time_distributed_87[0][0]        
                                                                 time_distributed_88[0][0]        
__________________________________________________________________________________________________
add_26 (Add)                    (None, 32, 160)      0           multiply_28[0][0]                
                                                                 layer_normalization_24[0][0]     
__________________________________________________________________________________________________
layer_normalization_25 (LayerNo (None, 32, 160)      320         add_26[0][0]                     
__________________________________________________________________________________________________
time_distributed_89 (TimeDistri (None, 32, 160)      25760       layer_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 32, 160)      0           time_distributed_89[0][0]        
__________________________________________________________________________________________________
time_distributed_90 (TimeDistri (None, 32, 160)      25760       activation_28[0][0]              
__________________________________________________________________________________________________
dropout_29 (Dropout)            (None, 32, 160)      0           time_distributed_90[0][0]        
__________________________________________________________________________________________________
time_distributed_91 (TimeDistri (None, 32, 160)      25760       dropout_29[0][0]                 
__________________________________________________________________________________________________
time_distributed_92 (TimeDistri (None, 32, 160)      25760       dropout_29[0][0]                 
__________________________________________________________________________________________________
multiply_29 (Multiply)          (None, 32, 160)      0           time_distributed_91[0][0]        
                                                                 time_distributed_92[0][0]        
__________________________________________________________________________________________________
add_27 (Add)                    (None, 32, 160)      0           layer_normalization_25[0][0]     
                                                                 multiply_29[0][0]                
__________________________________________________________________________________________________
layer_normalization_26 (LayerNo (None, 32, 160)      320         add_27[0][0]                     
__________________________________________________________________________________________________
time_distributed_93 (TimeDistri (None, 32, 160)      25760       layer_normalization_26[0][0]     
__________________________________________________________________________________________________
time_distributed_94 (TimeDistri (None, 32, 160)      25760       layer_normalization_26[0][0]     
__________________________________________________________________________________________________
multiply_30 (Multiply)          (None, 32, 160)      0           time_distributed_93[0][0]        
                                                                 time_distributed_94[0][0]        
__________________________________________________________________________________________________
add_28 (Add)                    (None, 32, 160)      0           multiply_30[0][0]                
                                                                 layer_normalization_23[0][0]     
__________________________________________________________________________________________________
layer_normalization_27 (LayerNo (None, 32, 160)      320         add_28[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           layer_normalization_27[0][0]     
__________________________________________________________________________________________________
time_distributed_95 (TimeDistri (None, 8, 3)         483         tf_op_layer_TemporalFusionTransfo
==================================================================================================
Total params: 3,534,803
Trainable params: 3,534,803
Non-trainable params: 0
__________________________________________________________________________________________________
None
Cached data "train" updated
Cached data "valid" updated
*** Fitting TemporalFusionTransformer ***
Getting batched_data
Using cached training data
Using cached validation data
Using keras standard fit
WARNING:tensorflow:From /root/.pyenv/versions/3.7.12/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Train on 9568 samples, validate on 2711 samples
Epoch 1/100
2024-12-23 20:34:55.878898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-12-23 20:35:00.262232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-12-23 20:35:07.990306: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2024-12-23 20:35:07.990816: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.0'; dlerror: libcupti.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64:
2024-12-23 20:35:07.990874: W tensorflow/core/profiler/lib/profiler_session.cc:213] Encountered error while starting profiler: Unavailable: CUPTI error: CUPTI could not be loaded or symbol could not be found.
  64/9568 [..............................] - ETA: 5:43:02 - loss: 2.43372024-12-23 20:35:08.270944: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 0 kernel records, 0 memcpy records.
2024-12-23 20:35:08.271533: E tensorflow/core/platform/default/device_tracer.cc:70] CUPTI error: CUPTI could not be loaded or symbol could not be found.
 128/9568 [..............................] - ETA: 2:50:42 - loss: 1.9668 192/9568 [..............................] - ETA: 1:53:14 - loss: 1.7656 256/9568 [..............................] - ETA: 1:24:34 - loss: 1.6143 320/9568 [>.............................] - ETA: 1:07:27 - loss: 1.5006 384/9568 [>.............................] - ETA: 56:01 - loss: 1.3915   448/9568 [>.............................] - ETA: 47:45 - loss: 1.3021 512/9568 [>.............................] - ETA: 41:36 - loss: 1.2203 576/9568 [>.............................] - ETA: 36:47 - loss: 1.1668 640/9568 [=>............................] - ETA: 32:55 - loss: 1.1139 704/9568 [=>............................] - ETA: 29:45 - loss: 1.0662 768/9568 [=>............................] - ETA: 27:07 - loss: 1.0250 832/9568 [=>............................] - ETA: 24:53 - loss: 0.9946 896/9568 [=>............................] - ETA: 23:01 - loss: 0.9622 960/9568 [==>...........................] - ETA: 21:21 - loss: 0.93911024/9568 [==>...........................] - ETA: 19:57 - loss: 0.91671088/9568 [==>...........................] - ETA: 18:41 - loss: 0.89391152/9568 [==>...........................] - ETA: 17:33 - loss: 0.86981216/9568 [==>...........................] - ETA: 16:32 - loss: 0.85151280/9568 [===>..........................] - ETA: 15:36 - loss: 0.83081344/9568 [===>..........................] - ETA: 14:49 - loss: 0.81401408/9568 [===>..........................] - ETA: 14:04 - loss: 0.79901472/9568 [===>..........................] - ETA: 13:24 - loss: 0.78791536/9568 [===>..........................] - ETA: 12:47 - loss: 0.77401600/9568 [====>.........................] - ETA: 12:12 - loss: 0.76111664/9568 [====>.........................] - ETA: 11:41 - loss: 0.75261728/9568 [====>.........................] - ETA: 11:12 - loss: 0.74401792/9568 [====>.........................] - ETA: 10:45 - loss: 0.73371856/9568 [====>.........................] - ETA: 10:19 - loss: 0.72331920/9568 [=====>........................] - ETA: 9:55 - loss: 0.7144 1984/9568 [=====>........................] - ETA: 9:33 - loss: 0.70562048/9568 [=====>........................] - ETA: 9:12 - loss: 0.69632112/9568 [=====>........................] - ETA: 8:54 - loss: 0.68712176/9568 [=====>........................] - ETA: 8:35 - loss: 0.68022240/9568 [======>.......................] - ETA: 8:17 - loss: 0.67312304/9568 [======>.......................] - ETA: 8:01 - loss: 0.66672368/9568 [======>.......................] - ETA: 7:45 - loss: 0.66122432/9568 [======>.......................] - ETA: 7:30 - loss: 0.65462496/9568 [======>.......................] - ETA: 7:16 - loss: 0.64792560/9568 [=======>......................] - ETA: 7:03 - loss: 0.64072624/9568 [=======>......................] - ETA: 6:50 - loss: 0.63502688/9568 [=======>......................] - ETA: 6:38 - loss: 0.63072752/9568 [=======>......................] - ETA: 6:26 - loss: 0.62532816/9568 [=======>......................] - ETA: 6:15 - loss: 0.61922880/9568 [========>.....................] - ETA: 6:06 - loss: 0.61412944/9568 [========>.....................] - ETA: 5:56 - loss: 0.60873008/9568 [========>.....................] - ETA: 5:46 - loss: 0.60303072/9568 [========>.....................] - ETA: 5:37 - loss: 0.59743136/9568 [========>.....................] - ETA: 5:28 - loss: 0.59243200/9568 [=========>....................] - ETA: 5:18 - loss: 0.58703264/9568 [=========>....................] - ETA: 5:10 - loss: 0.58203328/9568 [=========>....................] - ETA: 5:02 - loss: 0.57823392/9568 [=========>....................] - ETA: 4:54 - loss: 0.57373456/9568 [=========>....................] - ETA: 4:46 - loss: 0.56833520/9568 [==========>...................] - ETA: 4:38 - loss: 0.56323584/9568 [==========>...................] - ETA: 4:31 - loss: 0.55893648/9568 [==========>...................] - ETA: 4:25 - loss: 0.55463712/9568 [==========>...................] - ETA: 4:18 - loss: 0.55013776/9568 [==========>...................] - ETA: 4:11 - loss: 0.54623840/9568 [===========>..................] - ETA: 4:05 - loss: 0.54193904/9568 [===========>..................] - ETA: 3:59 - loss: 0.53793968/9568 [===========>..................] - ETA: 3:53 - loss: 0.53524032/9568 [===========>..................] - ETA: 3:47 - loss: 0.53224096/9568 [===========>..................] - ETA: 3:41 - loss: 0.52914160/9568 [============>.................] - ETA: 3:36 - loss: 0.52564224/9568 [============>.................] - ETA: 3:31 - loss: 0.52214288/9568 [============>.................] - ETA: 3:26 - loss: 0.51944352/9568 [============>.................] - ETA: 3:21 - loss: 0.51614416/9568 [============>.................] - ETA: 3:15 - loss: 0.51364480/9568 [=============>................] - ETA: 3:11 - loss: 0.51064544/9568 [=============>................] - ETA: 3:06 - loss: 0.50774608/9568 [=============>................] - ETA: 3:01 - loss: 0.50484672/9568 [=============>................] - ETA: 2:57 - loss: 0.50214736/9568 [=============>................] - ETA: 2:53 - loss: 0.49924800/9568 [==============>...............] - ETA: 2:49 - loss: 0.49594864/9568 [==============>...............] - ETA: 2:45 - loss: 0.49384928/9568 [==============>...............] - ETA: 2:41 - loss: 0.49154992/9568 [==============>...............] - ETA: 2:36 - loss: 0.48955056/9568 [==============>...............] - ETA: 2:33 - loss: 0.48715120/9568 [===============>..............] - ETA: 2:29 - loss: 0.48435184/9568 [===============>..............] - ETA: 2:25 - loss: 0.48185248/9568 [===============>..............] - ETA: 2:22 - loss: 0.47955312/9568 [===============>..............] - ETA: 2:18 - loss: 0.47675376/9568 [===============>..............] - ETA: 2:15 - loss: 0.47455440/9568 [================>.............] - ETA: 2:11 - loss: 0.47195504/9568 [================>.............] - ETA: 2:08 - loss: 0.46965568/9568 [================>.............] - ETA: 2:05 - loss: 0.46765632/9568 [================>.............] - ETA: 2:02 - loss: 0.46595696/9568 [================>.............] - ETA: 1:58 - loss: 0.46325760/9568 [=================>............] - ETA: 1:55 - loss: 0.46215824/9568 [=================>............] - ETA: 1:53 - loss: 0.46075888/9568 [=================>............] - ETA: 1:50 - loss: 0.45895952/9568 [=================>............] - ETA: 1:47 - loss: 0.45726016/9568 [=================>............] - ETA: 1:44 - loss: 0.45546080/9568 [==================>...........] - ETA: 1:41 - loss: 0.45376144/9568 [==================>...........] - ETA: 1:38 - loss: 0.45206208/9568 [==================>...........] - ETA: 1:36 - loss: 0.45026272/9568 [==================>...........] - ETA: 1:33 - loss: 0.44846336/9568 [==================>...........] - ETA: 1:31 - loss: 0.44656400/9568 [===================>..........] - ETA: 1:28 - loss: 0.44456464/9568 [===================>..........] - ETA: 1:25 - loss: 0.44306528/9568 [===================>..........] - ETA: 1:23 - loss: 0.44076592/9568 [===================>..........] - ETA: 1:21 - loss: 0.43896656/9568 [===================>..........] - ETA: 1:18 - loss: 0.43776720/9568 [====================>.........] - ETA: 1:16 - loss: 0.43626784/9568 [====================>.........] - ETA: 1:14 - loss: 0.43426848/9568 [====================>.........] - ETA: 1:11 - loss: 0.43306912/9568 [====================>.........] - ETA: 1:09 - loss: 0.43186976/9568 [====================>.........] - ETA: 1:07 - loss: 0.43017040/9568 [=====================>........] - ETA: 1:05 - loss: 0.42837104/9568 [=====================>........] - ETA: 1:03 - loss: 0.42707168/9568 [=====================>........] - ETA: 1:01 - loss: 0.42567232/9568 [=====================>........] - ETA: 59s - loss: 0.4243 7296/9568 [=====================>........] - ETA: 57s - loss: 0.42317360/9568 [======================>.......] - ETA: 55s - loss: 0.42177424/9568 [======================>.......] - ETA: 53s - loss: 0.42057488/9568 [======================>.......] - ETA: 51s - loss: 0.41947552/9568 [======================>.......] - ETA: 49s - loss: 0.41867616/9568 [======================>.......] - ETA: 47s - loss: 0.41747680/9568 [=======================>......] - ETA: 45s - loss: 0.41627744/9568 [=======================>......] - ETA: 43s - loss: 0.41517808/9568 [=======================>......] - ETA: 42s - loss: 0.41347872/9568 [=======================>......] - ETA: 40s - loss: 0.41187936/9568 [=======================>......] - ETA: 38s - loss: 0.41078000/9568 [========================>.....] - ETA: 36s - loss: 0.40918064/9568 [========================>.....] - ETA: 35s - loss: 0.40778128/9568 [========================>.....] - ETA: 33s - loss: 0.40638192/9568 [========================>.....] - ETA: 31s - loss: 0.40548256/9568 [========================>.....] - ETA: 30s - loss: 0.40428320/9568 [=========================>....] - ETA: 28s - loss: 0.40308384/9568 [=========================>....] - ETA: 26s - loss: 0.40218448/9568 [=========================>....] - ETA: 25s - loss: 0.40108512/9568 [=========================>....] - ETA: 23s - loss: 0.39988576/9568 [=========================>....] - ETA: 22s - loss: 0.39878640/9568 [==========================>...] - ETA: 20s - loss: 0.39788704/9568 [==========================>...] - ETA: 19s - loss: 0.39678768/9568 [==========================>...] - ETA: 17s - loss: 0.39568832/9568 [==========================>...] - ETA: 16s - loss: 0.39498896/9568 [==========================>...] - ETA: 14s - loss: 0.39398960/9568 [===========================>..] - ETA: 13s - loss: 0.39299024/9568 [===========================>..] - ETA: 11s - loss: 0.39199088/9568 [===========================>..] - ETA: 10s - loss: 0.39109152/9568 [===========================>..] - ETA: 8s - loss: 0.3900 9216/9568 [===========================>..] - ETA: 7s - loss: 0.38899280/9568 [============================>.] - ETA: 6s - loss: 0.38809344/9568 [============================>.] - ETA: 4s - loss: 0.38759408/9568 [============================>.] - ETA: 3s - loss: 0.38659472/9568 [============================>.] - ETA: 2s - loss: 0.38579536/9568 [============================>.] - ETA: 0s - loss: 0.3847
Epoch 00001: val_loss improved from inf to 0.25508, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 243s 25ms/sample - loss: 0.3841 - val_loss: 0.2551
Epoch 2/100
  64/9568 [..............................] - ETA: 1:27 - loss: 0.2375 128/9568 [..............................] - ETA: 59s - loss: 0.2597  192/9568 [..............................] - ETA: 56s - loss: 0.2650 256/9568 [..............................] - ETA: 50s - loss: 0.2597 320/9568 [>.............................] - ETA: 47s - loss: 0.2514 384/9568 [>.............................] - ETA: 42s - loss: 0.2529 448/9568 [>.............................] - ETA: 43s - loss: 0.2531 512/9568 [>.............................] - ETA: 46s - loss: 0.2557 576/9568 [>.............................] - ETA: 46s - loss: 0.2556 640/9568 [=>............................] - ETA: 45s - loss: 0.2550 704/9568 [=>............................] - ETA: 43s - loss: 0.2532 768/9568 [=>............................] - ETA: 42s - loss: 0.2480 832/9568 [=>............................] - ETA: 41s - loss: 0.2508 896/9568 [=>............................] - ETA: 41s - loss: 0.2503 960/9568 [==>...........................] - ETA: 40s - loss: 0.25191024/9568 [==>...........................] - ETA: 40s - loss: 0.25091088/9568 [==>...........................] - ETA: 40s - loss: 0.25071152/9568 [==>...........................] - ETA: 42s - loss: 0.24971216/9568 [==>...........................] - ETA: 42s - loss: 0.24881280/9568 [===>..........................] - ETA: 42s - loss: 0.24991344/9568 [===>..........................] - ETA: 43s - loss: 0.24931408/9568 [===>..........................] - ETA: 42s - loss: 0.24791472/9568 [===>..........................] - ETA: 42s - loss: 0.24901536/9568 [===>..........................] - ETA: 41s - loss: 0.25021600/9568 [====>.........................] - ETA: 41s - loss: 0.24901664/9568 [====>.........................] - ETA: 40s - loss: 0.24681728/9568 [====>.........................] - ETA: 40s - loss: 0.24701792/9568 [====>.........................] - ETA: 40s - loss: 0.24721856/9568 [====>.........................] - ETA: 39s - loss: 0.24701920/9568 [=====>........................] - ETA: 38s - loss: 0.24641984/9568 [=====>........................] - ETA: 38s - loss: 0.24692048/9568 [=====>........................] - ETA: 38s - loss: 0.24662112/9568 [=====>........................] - ETA: 37s - loss: 0.24522176/9568 [=====>........................] - ETA: 37s - loss: 0.24402240/9568 [======>.......................] - ETA: 36s - loss: 0.24332304/9568 [======>.......................] - ETA: 36s - loss: 0.24332368/9568 [======>.......................] - ETA: 35s - loss: 0.24332432/9568 [======>.......................] - ETA: 34s - loss: 0.24252496/9568 [======>.......................] - ETA: 34s - loss: 0.24172560/9568 [=======>......................] - ETA: 34s - loss: 0.24062624/9568 [=======>......................] - ETA: 33s - loss: 0.24002688/9568 [=======>......................] - ETA: 34s - loss: 0.23952752/9568 [=======>......................] - ETA: 34s - loss: 0.23832816/9568 [=======>......................] - ETA: 34s - loss: 0.23792880/9568 [========>.....................] - ETA: 33s - loss: 0.23832944/9568 [========>.....................] - ETA: 33s - loss: 0.23843008/9568 [========>.....................] - ETA: 33s - loss: 0.23753072/9568 [========>.....................] - ETA: 33s - loss: 0.23843136/9568 [========>.....................] - ETA: 33s - loss: 0.23813200/9568 [=========>....................] - ETA: 32s - loss: 0.23893264/9568 [=========>....................] - ETA: 32s - loss: 0.23893328/9568 [=========>....................] - ETA: 32s - loss: 0.23843392/9568 [=========>....................] - ETA: 32s - loss: 0.23823456/9568 [=========>....................] - ETA: 32s - loss: 0.23843520/9568 [==========>...................] - ETA: 31s - loss: 0.23893584/9568 [==========>...................] - ETA: 31s - loss: 0.23893648/9568 [==========>...................] - ETA: 31s - loss: 0.23883712/9568 [==========>...................] - ETA: 31s - loss: 0.23853776/9568 [==========>...................] - ETA: 31s - loss: 0.23823840/9568 [===========>..................] - ETA: 30s - loss: 0.23763904/9568 [===========>..................] - ETA: 30s - loss: 0.23733968/9568 [===========>..................] - ETA: 30s - loss: 0.23724032/9568 [===========>..................] - ETA: 30s - loss: 0.23664096/9568 [===========>..................] - ETA: 30s - loss: 0.23624160/9568 [============>.................] - ETA: 30s - loss: 0.23564224/9568 [============>.................] - ETA: 29s - loss: 0.23484288/9568 [============>.................] - ETA: 29s - loss: 0.23394352/9568 [============>.................] - ETA: 28s - loss: 0.23314416/9568 [============>.................] - ETA: 28s - loss: 0.23264480/9568 [=============>................] - ETA: 28s - loss: 0.23194544/9568 [=============>................] - ETA: 27s - loss: 0.23254608/9568 [=============>................] - ETA: 27s - loss: 0.23204672/9568 [=============>................] - ETA: 27s - loss: 0.23154736/9568 [=============>................] - ETA: 26s - loss: 0.23094800/9568 [==============>...............] - ETA: 26s - loss: 0.23064864/9568 [==============>...............] - ETA: 25s - loss: 0.23024928/9568 [==============>...............] - ETA: 25s - loss: 0.22984992/9568 [==============>...............] - ETA: 25s - loss: 0.22915056/9568 [==============>...............] - ETA: 25s - loss: 0.22925120/9568 [===============>..............] - ETA: 24s - loss: 0.22865184/9568 [===============>..............] - ETA: 24s - loss: 0.22905248/9568 [===============>..............] - ETA: 23s - loss: 0.22865312/9568 [===============>..............] - ETA: 23s - loss: 0.22805376/9568 [===============>..............] - ETA: 23s - loss: 0.22795440/9568 [================>.............] - ETA: 22s - loss: 0.22765504/9568 [================>.............] - ETA: 22s - loss: 0.22795568/9568 [================>.............] - ETA: 22s - loss: 0.22775632/9568 [================>.............] - ETA: 21s - loss: 0.22755696/9568 [================>.............] - ETA: 21s - loss: 0.22775760/9568 [=================>............] - ETA: 20s - loss: 0.22725824/9568 [=================>............] - ETA: 20s - loss: 0.22705888/9568 [=================>............] - ETA: 20s - loss: 0.22645952/9568 [=================>............] - ETA: 19s - loss: 0.22626016/9568 [=================>............] - ETA: 19s - loss: 0.22606080/9568 [==================>...........] - ETA: 19s - loss: 0.22586144/9568 [==================>...........] - ETA: 19s - loss: 0.22536208/9568 [==================>...........] - ETA: 19s - loss: 0.22556272/9568 [==================>...........] - ETA: 18s - loss: 0.22536336/9568 [==================>...........] - ETA: 18s - loss: 0.22566400/9568 [===================>..........] - ETA: 17s - loss: 0.22536464/9568 [===================>..........] - ETA: 17s - loss: 0.22546528/9568 [===================>..........] - ETA: 17s - loss: 0.22536592/9568 [===================>..........] - ETA: 16s - loss: 0.22546656/9568 [===================>..........] - ETA: 16s - loss: 0.22516720/9568 [====================>.........] - ETA: 16s - loss: 0.22496784/9568 [====================>.........] - ETA: 15s - loss: 0.22476848/9568 [====================>.........] - ETA: 15s - loss: 0.22536912/9568 [====================>.........] - ETA: 15s - loss: 0.22516976/9568 [====================>.........] - ETA: 14s - loss: 0.22517040/9568 [=====================>........] - ETA: 14s - loss: 0.22507104/9568 [=====================>........] - ETA: 14s - loss: 0.22477168/9568 [=====================>........] - ETA: 13s - loss: 0.22477232/9568 [=====================>........] - ETA: 13s - loss: 0.22507296/9568 [=====================>........] - ETA: 12s - loss: 0.22457360/9568 [======================>.......] - ETA: 12s - loss: 0.22417424/9568 [======================>.......] - ETA: 12s - loss: 0.22387488/9568 [======================>.......] - ETA: 11s - loss: 0.22357552/9568 [======================>.......] - ETA: 11s - loss: 0.22317616/9568 [======================>.......] - ETA: 10s - loss: 0.22327680/9568 [=======================>......] - ETA: 10s - loss: 0.22297744/9568 [=======================>......] - ETA: 10s - loss: 0.22287808/9568 [=======================>......] - ETA: 9s - loss: 0.2224 7872/9568 [=======================>......] - ETA: 9s - loss: 0.22217936/9568 [=======================>......] - ETA: 9s - loss: 0.22178000/9568 [========================>.....] - ETA: 8s - loss: 0.22188064/9568 [========================>.....] - ETA: 8s - loss: 0.22168128/9568 [========================>.....] - ETA: 8s - loss: 0.22148192/9568 [========================>.....] - ETA: 7s - loss: 0.22138256/9568 [========================>.....] - ETA: 7s - loss: 0.22108320/9568 [=========================>....] - ETA: 7s - loss: 0.22078384/9568 [=========================>....] - ETA: 6s - loss: 0.22048448/9568 [=========================>....] - ETA: 6s - loss: 0.22038512/9568 [=========================>....] - ETA: 5s - loss: 0.22018576/9568 [=========================>....] - ETA: 5s - loss: 0.21998640/9568 [==========================>...] - ETA: 5s - loss: 0.21968704/9568 [==========================>...] - ETA: 4s - loss: 0.21938768/9568 [==========================>...] - ETA: 4s - loss: 0.21918832/9568 [==========================>...] - ETA: 4s - loss: 0.21928896/9568 [==========================>...] - ETA: 3s - loss: 0.21948960/9568 [===========================>..] - ETA: 3s - loss: 0.21939024/9568 [===========================>..] - ETA: 3s - loss: 0.21949088/9568 [===========================>..] - ETA: 2s - loss: 0.21939152/9568 [===========================>..] - ETA: 2s - loss: 0.21929216/9568 [===========================>..] - ETA: 1s - loss: 0.21929280/9568 [============================>.] - ETA: 1s - loss: 0.21959344/9568 [============================>.] - ETA: 1s - loss: 0.21959408/9568 [============================>.] - ETA: 0s - loss: 0.21949472/9568 [============================>.] - ETA: 0s - loss: 0.21929536/9568 [============================>.] - ETA: 0s - loss: 0.2190
Epoch 00002: val_loss improved from 0.25508 to 0.19733, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 61s 6ms/sample - loss: 0.2188 - val_loss: 0.1973
Epoch 3/100
  64/9568 [..............................] - ETA: 1:14 - loss: 0.1801 128/9568 [..............................] - ETA: 1:09 - loss: 0.1845 192/9568 [..............................] - ETA: 1:14 - loss: 0.2073 256/9568 [..............................] - ETA: 1:17 - loss: 0.2040 320/9568 [>.............................] - ETA: 1:17 - loss: 0.2015 384/9568 [>.............................] - ETA: 1:14 - loss: 0.2054 448/9568 [>.............................] - ETA: 1:14 - loss: 0.2104 512/9568 [>.............................] - ETA: 1:15 - loss: 0.2046 576/9568 [>.............................] - ETA: 1:13 - loss: 0.2055 640/9568 [=>............................] - ETA: 1:10 - loss: 0.2032 704/9568 [=>............................] - ETA: 1:09 - loss: 0.2052 768/9568 [=>............................] - ETA: 1:06 - loss: 0.2076 832/9568 [=>............................] - ETA: 1:05 - loss: 0.2075 896/9568 [=>............................] - ETA: 1:02 - loss: 0.2067 960/9568 [==>...........................] - ETA: 1:02 - loss: 0.20671024/9568 [==>...........................] - ETA: 1:00 - loss: 0.20951088/9568 [==>...........................] - ETA: 58s - loss: 0.2097 1152/9568 [==>...........................] - ETA: 58s - loss: 0.20831216/9568 [==>...........................] - ETA: 57s - loss: 0.20741280/9568 [===>..........................] - ETA: 55s - loss: 0.20541344/9568 [===>..........................] - ETA: 55s - loss: 0.20571408/9568 [===>..........................] - ETA: 55s - loss: 0.20511472/9568 [===>..........................] - ETA: 57s - loss: 0.20321536/9568 [===>..........................] - ETA: 58s - loss: 0.20211600/9568 [====>.........................] - ETA: 56s - loss: 0.20271664/9568 [====>.........................] - ETA: 55s - loss: 0.20191728/9568 [====>.........................] - ETA: 53s - loss: 0.20201792/9568 [====>.........................] - ETA: 52s - loss: 0.20051856/9568 [====>.........................] - ETA: 51s - loss: 0.19951920/9568 [=====>........................] - ETA: 50s - loss: 0.19851984/9568 [=====>........................] - ETA: 48s - loss: 0.19812048/9568 [=====>........................] - ETA: 47s - loss: 0.19762112/9568 [=====>........................] - ETA: 46s - loss: 0.19752176/9568 [=====>........................] - ETA: 46s - loss: 0.19662240/9568 [======>.......................] - ETA: 45s - loss: 0.19712304/9568 [======>.......................] - ETA: 45s - loss: 0.19712368/9568 [======>.......................] - ETA: 44s - loss: 0.19712432/9568 [======>.......................] - ETA: 44s - loss: 0.19672496/9568 [======>.......................] - ETA: 44s - loss: 0.19712560/9568 [=======>......................] - ETA: 44s - loss: 0.19672624/9568 [=======>......................] - ETA: 44s - loss: 0.19682688/9568 [=======>......................] - ETA: 44s - loss: 0.19782752/9568 [=======>......................] - ETA: 43s - loss: 0.19842816/9568 [=======>......................] - ETA: 42s - loss: 0.19952880/9568 [========>.....................] - ETA: 41s - loss: 0.19872944/9568 [========>.....................] - ETA: 41s - loss: 0.19903008/9568 [========>.....................] - ETA: 40s - loss: 0.19903072/9568 [========>.....................] - ETA: 39s - loss: 0.19873136/9568 [========>.....................] - ETA: 39s - loss: 0.19913200/9568 [=========>....................] - ETA: 38s - loss: 0.19973264/9568 [=========>....................] - ETA: 38s - loss: 0.19963328/9568 [=========>....................] - ETA: 37s - loss: 0.19933392/9568 [=========>....................] - ETA: 36s - loss: 0.19873456/9568 [=========>....................] - ETA: 36s - loss: 0.19883520/9568 [==========>...................] - ETA: 35s - loss: 0.19883584/9568 [==========>...................] - ETA: 34s - loss: 0.19903648/9568 [==========>...................] - ETA: 34s - loss: 0.19833712/9568 [==========>...................] - ETA: 34s - loss: 0.19793776/9568 [==========>...................] - ETA: 33s - loss: 0.19743840/9568 [===========>..................] - ETA: 33s - loss: 0.19703904/9568 [===========>..................] - ETA: 32s - loss: 0.19713968/9568 [===========>..................] - ETA: 32s - loss: 0.19834032/9568 [===========>..................] - ETA: 31s - loss: 0.19794096/9568 [===========>..................] - ETA: 31s - loss: 0.19734160/9568 [============>.................] - ETA: 31s - loss: 0.19764224/9568 [============>.................] - ETA: 30s - loss: 0.19824288/9568 [============>.................] - ETA: 30s - loss: 0.19834352/9568 [============>.................] - ETA: 30s - loss: 0.19814416/9568 [============>.................] - ETA: 30s - loss: 0.19804480/9568 [=============>................] - ETA: 29s - loss: 0.19844544/9568 [=============>................] - ETA: 29s - loss: 0.19854608/9568 [=============>................] - ETA: 29s - loss: 0.19804672/9568 [=============>................] - ETA: 28s - loss: 0.19814736/9568 [=============>................] - ETA: 28s - loss: 0.19784800/9568 [==============>...............] - ETA: 28s - loss: 0.19814864/9568 [==============>...............] - ETA: 27s - loss: 0.19834928/9568 [==============>...............] - ETA: 27s - loss: 0.19854992/9568 [==============>...............] - ETA: 27s - loss: 0.19815056/9568 [==============>...............] - ETA: 27s - loss: 0.19775120/9568 [===============>..............] - ETA: 26s - loss: 0.19775184/9568 [===============>..............] - ETA: 26s - loss: 0.19735248/9568 [===============>..............] - ETA: 25s - loss: 0.19695312/9568 [===============>..............] - ETA: 25s - loss: 0.19675376/9568 [===============>..............] - ETA: 25s - loss: 0.19645440/9568 [================>.............] - ETA: 24s - loss: 0.19635504/9568 [================>.............] - ETA: 24s - loss: 0.19615568/9568 [================>.............] - ETA: 23s - loss: 0.19595632/9568 [================>.............] - ETA: 23s - loss: 0.19605696/9568 [================>.............] - ETA: 23s - loss: 0.19565760/9568 [=================>............] - ETA: 22s - loss: 0.19545824/9568 [=================>............] - ETA: 22s - loss: 0.19515888/9568 [=================>............] - ETA: 21s - loss: 0.19495952/9568 [=================>............] - ETA: 21s - loss: 0.19466016/9568 [=================>............] - ETA: 21s - loss: 0.19416080/9568 [==================>...........] - ETA: 20s - loss: 0.19386144/9568 [==================>...........] - ETA: 20s - loss: 0.19356208/9568 [==================>...........] - ETA: 20s - loss: 0.19346272/9568 [==================>...........] - ETA: 19s - loss: 0.19366336/9568 [==================>...........] - ETA: 19s - loss: 0.19366400/9568 [===================>..........] - ETA: 19s - loss: 0.19336464/9568 [===================>..........] - ETA: 18s - loss: 0.19306528/9568 [===================>..........] - ETA: 18s - loss: 0.19266592/9568 [===================>..........] - ETA: 18s - loss: 0.19256656/9568 [===================>..........] - ETA: 17s - loss: 0.19246720/9568 [====================>.........] - ETA: 17s - loss: 0.19246784/9568 [====================>.........] - ETA: 17s - loss: 0.19206848/9568 [====================>.........] - ETA: 16s - loss: 0.19176912/9568 [====================>.........] - ETA: 16s - loss: 0.19176976/9568 [====================>.........] - ETA: 15s - loss: 0.19177040/9568 [=====================>........] - ETA: 15s - loss: 0.19197104/9568 [=====================>........] - ETA: 15s - loss: 0.19157168/9568 [=====================>........] - ETA: 14s - loss: 0.19187232/9568 [=====================>........] - ETA: 14s - loss: 0.19197296/9568 [=====================>........] - ETA: 14s - loss: 0.19167360/9568 [======================>.......] - ETA: 13s - loss: 0.19137424/9568 [======================>.......] - ETA: 13s - loss: 0.19137488/9568 [======================>.......] - ETA: 12s - loss: 0.19127552/9568 [======================>.......] - ETA: 12s - loss: 0.19117616/9568 [======================>.......] - ETA: 12s - loss: 0.19107680/9568 [=======================>......] - ETA: 11s - loss: 0.19097744/9568 [=======================>......] - ETA: 11s - loss: 0.19097808/9568 [=======================>......] - ETA: 10s - loss: 0.19087872/9568 [=======================>......] - ETA: 10s - loss: 0.19087936/9568 [=======================>......] - ETA: 10s - loss: 0.19108000/9568 [========================>.....] - ETA: 9s - loss: 0.1908 8064/9568 [========================>.....] - ETA: 9s - loss: 0.19118128/9568 [========================>.....] - ETA: 8s - loss: 0.19128192/9568 [========================>.....] - ETA: 8s - loss: 0.19108256/9568 [========================>.....] - ETA: 8s - loss: 0.19098320/9568 [=========================>....] - ETA: 7s - loss: 0.19108384/9568 [=========================>....] - ETA: 7s - loss: 0.19078448/9568 [=========================>....] - ETA: 6s - loss: 0.19068512/9568 [=========================>....] - ETA: 6s - loss: 0.19058576/9568 [=========================>....] - ETA: 6s - loss: 0.19048640/9568 [==========================>...] - ETA: 5s - loss: 0.19048704/9568 [==========================>...] - ETA: 5s - loss: 0.19038768/9568 [==========================>...] - ETA: 4s - loss: 0.19028832/9568 [==========================>...] - ETA: 4s - loss: 0.19008896/9568 [==========================>...] - ETA: 4s - loss: 0.19018960/9568 [===========================>..] - ETA: 3s - loss: 0.19059024/9568 [===========================>..] - ETA: 3s - loss: 0.19029088/9568 [===========================>..] - ETA: 2s - loss: 0.19019152/9568 [===========================>..] - ETA: 2s - loss: 0.18989216/9568 [===========================>..] - ETA: 2s - loss: 0.18979280/9568 [============================>.] - ETA: 1s - loss: 0.18979344/9568 [============================>.] - ETA: 1s - loss: 0.18979408/9568 [============================>.] - ETA: 0s - loss: 0.18969472/9568 [============================>.] - ETA: 0s - loss: 0.18969536/9568 [============================>.] - ETA: 0s - loss: 0.1897
Epoch 00003: val_loss improved from 0.19733 to 0.16702, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 64s 7ms/sample - loss: 0.1896 - val_loss: 0.1670
Epoch 4/100
  64/9568 [..............................] - ETA: 29s - loss: 0.1676 128/9568 [..............................] - ETA: 42s - loss: 0.1809 192/9568 [..............................] - ETA: 45s - loss: 0.1886 256/9568 [..............................] - ETA: 40s - loss: 0.1910 320/9568 [>.............................] - ETA: 39s - loss: 0.1878 384/9568 [>.............................] - ETA: 39s - loss: 0.1866 448/9568 [>.............................] - ETA: 40s - loss: 0.1891 512/9568 [>.............................] - ETA: 39s - loss: 0.1868 576/9568 [>.............................] - ETA: 40s - loss: 0.1871 640/9568 [=>............................] - ETA: 38s - loss: 0.1864 704/9568 [=>............................] - ETA: 42s - loss: 0.1845 768/9568 [=>............................] - ETA: 43s - loss: 0.1815 832/9568 [=>............................] - ETA: 44s - loss: 0.1792 896/9568 [=>............................] - ETA: 44s - loss: 0.1775 960/9568 [==>...........................] - ETA: 45s - loss: 0.17881024/9568 [==>...........................] - ETA: 44s - loss: 0.17841088/9568 [==>...........................] - ETA: 46s - loss: 0.17831152/9568 [==>...........................] - ETA: 48s - loss: 0.18141216/9568 [==>...........................] - ETA: 47s - loss: 0.18031280/9568 [===>..........................] - ETA: 48s - loss: 0.18301344/9568 [===>..........................] - ETA: 47s - loss: 0.18351408/9568 [===>..........................] - ETA: 47s - loss: 0.18191472/9568 [===>..........................] - ETA: 46s - loss: 0.18111536/9568 [===>..........................] - ETA: 46s - loss: 0.18171600/9568 [====>.........................] - ETA: 46s - loss: 0.18181664/9568 [====>.........................] - ETA: 47s - loss: 0.18151728/9568 [====>.........................] - ETA: 49s - loss: 0.18061792/9568 [====>.........................] - ETA: 48s - loss: 0.17951856/9568 [====>.........................] - ETA: 48s - loss: 0.17921920/9568 [=====>........................] - ETA: 47s - loss: 0.17841984/9568 [=====>........................] - ETA: 47s - loss: 0.17912048/9568 [=====>........................] - ETA: 46s - loss: 0.17882112/9568 [=====>........................] - ETA: 46s - loss: 0.17992176/9568 [=====>........................] - ETA: 46s - loss: 0.17922240/9568 [======>.......................] - ETA: 46s - loss: 0.17832304/9568 [======>.......................] - ETA: 46s - loss: 0.17722368/9568 [======>.......................] - ETA: 45s - loss: 0.17772432/9568 [======>.......................] - ETA: 44s - loss: 0.17692496/9568 [======>.......................] - ETA: 44s - loss: 0.17902560/9568 [=======>......................] - ETA: 44s - loss: 0.17932624/9568 [=======>......................] - ETA: 43s - loss: 0.17942688/9568 [=======>......................] - ETA: 43s - loss: 0.17962752/9568 [=======>......................] - ETA: 42s - loss: 0.17982816/9568 [=======>......................] - ETA: 42s - loss: 0.17972880/9568 [========>.....................] - ETA: 42s - loss: 0.17922944/9568 [========>.....................] - ETA: 42s - loss: 0.17963008/9568 [========>.....................] - ETA: 41s - loss: 0.17993072/9568 [========>.....................] - ETA: 41s - loss: 0.18013136/9568 [========>.....................] - ETA: 40s - loss: 0.17953200/9568 [=========>....................] - ETA: 39s - loss: 0.17993264/9568 [=========>....................] - ETA: 39s - loss: 0.18003328/9568 [=========>....................] - ETA: 38s - loss: 0.18013392/9568 [=========>....................] - ETA: 37s - loss: 0.18003456/9568 [=========>....................] - ETA: 37s - loss: 0.17953520/9568 [==========>...................] - ETA: 37s - loss: 0.17933584/9568 [==========>...................] - ETA: 37s - loss: 0.17953648/9568 [==========>...................] - ETA: 36s - loss: 0.17983712/9568 [==========>...................] - ETA: 36s - loss: 0.17993776/9568 [==========>...................] - ETA: 36s - loss: 0.17993840/9568 [===========>..................] - ETA: 36s - loss: 0.18023904/9568 [===========>..................] - ETA: 35s - loss: 0.18033968/9568 [===========>..................] - ETA: 35s - loss: 0.18094032/9568 [===========>..................] - ETA: 34s - loss: 0.18054096/9568 [===========>..................] - ETA: 34s - loss: 0.18024160/9568 [============>.................] - ETA: 33s - loss: 0.18024224/9568 [============>.................] - ETA: 33s - loss: 0.17984288/9568 [============>.................] - ETA: 32s - loss: 0.18004352/9568 [============>.................] - ETA: 31s - loss: 0.17964416/9568 [============>.................] - ETA: 31s - loss: 0.17924480/9568 [=============>................] - ETA: 30s - loss: 0.17934544/9568 [=============>................] - ETA: 30s - loss: 0.17914608/9568 [=============>................] - ETA: 29s - loss: 0.17884672/9568 [=============>................] - ETA: 29s - loss: 0.17904736/9568 [=============>................] - ETA: 29s - loss: 0.17874800/9568 [==============>...............] - ETA: 29s - loss: 0.17924864/9568 [==============>...............] - ETA: 29s - loss: 0.17914928/9568 [==============>...............] - ETA: 28s - loss: 0.17894992/9568 [==============>...............] - ETA: 28s - loss: 0.17925056/9568 [==============>...............] - ETA: 27s - loss: 0.17945120/9568 [===============>..............] - ETA: 27s - loss: 0.17975184/9568 [===============>..............] - ETA: 26s - loss: 0.17955248/9568 [===============>..............] - ETA: 26s - loss: 0.17935312/9568 [===============>..............] - ETA: 25s - loss: 0.17965376/9568 [===============>..............] - ETA: 25s - loss: 0.17975440/9568 [================>.............] - ETA: 24s - loss: 0.18045504/9568 [================>.............] - ETA: 24s - loss: 0.18065568/9568 [================>.............] - ETA: 24s - loss: 0.18025632/9568 [================>.............] - ETA: 23s - loss: 0.17995696/9568 [================>.............] - ETA: 23s - loss: 0.18005760/9568 [=================>............] - ETA: 23s - loss: 0.18005824/9568 [=================>............] - ETA: 22s - loss: 0.18065888/9568 [=================>............] - ETA: 22s - loss: 0.18095952/9568 [=================>............] - ETA: 21s - loss: 0.18066016/9568 [=================>............] - ETA: 21s - loss: 0.18116080/9568 [==================>...........] - ETA: 21s - loss: 0.18086144/9568 [==================>...........] - ETA: 20s - loss: 0.18086208/9568 [==================>...........] - ETA: 20s - loss: 0.18126272/9568 [==================>...........] - ETA: 19s - loss: 0.18086336/9568 [==================>...........] - ETA: 19s - loss: 0.18066400/9568 [===================>..........] - ETA: 19s - loss: 0.18086464/9568 [===================>..........] - ETA: 18s - loss: 0.18076528/9568 [===================>..........] - ETA: 18s - loss: 0.18066592/9568 [===================>..........] - ETA: 17s - loss: 0.18066656/9568 [===================>..........] - ETA: 17s - loss: 0.18066720/9568 [====================>.........] - ETA: 16s - loss: 0.18056784/9568 [====================>.........] - ETA: 16s - loss: 0.18036848/9568 [====================>.........] - ETA: 16s - loss: 0.18056912/9568 [====================>.........] - ETA: 15s - loss: 0.18026976/9568 [====================>.........] - ETA: 15s - loss: 0.18017040/9568 [=====================>........] - ETA: 15s - loss: 0.17987104/9568 [=====================>........] - ETA: 14s - loss: 0.17977168/9568 [=====================>........] - ETA: 14s - loss: 0.17957232/9568 [=====================>........] - ETA: 13s - loss: 0.17947296/9568 [=====================>........] - ETA: 13s - loss: 0.17927360/9568 [======================>.......] - ETA: 13s - loss: 0.17937424/9568 [======================>.......] - ETA: 12s - loss: 0.17927488/9568 [======================>.......] - ETA: 12s - loss: 0.17937552/9568 [======================>.......] - ETA: 12s - loss: 0.17947616/9568 [======================>.......] - ETA: 11s - loss: 0.17937680/9568 [=======================>......] - ETA: 11s - loss: 0.17937744/9568 [=======================>......] - ETA: 10s - loss: 0.17917808/9568 [=======================>......] - ETA: 10s - loss: 0.17917872/9568 [=======================>......] - ETA: 10s - loss: 0.17907936/9568 [=======================>......] - ETA: 9s - loss: 0.1792 8000/9568 [========================>.....] - ETA: 9s - loss: 0.17908064/9568 [========================>.....] - ETA: 9s - loss: 0.17888128/9568 [========================>.....] - ETA: 8s - loss: 0.17888192/9568 [========================>.....] - ETA: 8s - loss: 0.17898256/9568 [========================>.....] - ETA: 7s - loss: 0.17868320/9568 [=========================>....] - ETA: 7s - loss: 0.17918384/9568 [=========================>....] - ETA: 7s - loss: 0.17938448/9568 [=========================>....] - ETA: 6s - loss: 0.17958512/9568 [=========================>....] - ETA: 6s - loss: 0.17948576/9568 [=========================>....] - ETA: 6s - loss: 0.17928640/9568 [==========================>...] - ETA: 5s - loss: 0.17898704/9568 [==========================>...] - ETA: 5s - loss: 0.17908768/9568 [==========================>...] - ETA: 4s - loss: 0.17918832/9568 [==========================>...] - ETA: 4s - loss: 0.17918896/9568 [==========================>...] - ETA: 4s - loss: 0.17918960/9568 [===========================>..] - ETA: 3s - loss: 0.17919024/9568 [===========================>..] - ETA: 3s - loss: 0.17929088/9568 [===========================>..] - ETA: 2s - loss: 0.17919152/9568 [===========================>..] - ETA: 2s - loss: 0.17919216/9568 [===========================>..] - ETA: 2s - loss: 0.17919280/9568 [============================>.] - ETA: 1s - loss: 0.17889344/9568 [============================>.] - ETA: 1s - loss: 0.17869408/9568 [============================>.] - ETA: 0s - loss: 0.17869472/9568 [============================>.] - ETA: 0s - loss: 0.17859536/9568 [============================>.] - ETA: 0s - loss: 0.1785
Epoch 00004: val_loss did not improve from 0.16702
9568/9568 [==============================] - 64s 7ms/sample - loss: 0.1787 - val_loss: 0.1739
Epoch 5/100
  64/9568 [..............................] - ETA: 1:01 - loss: 0.1559 128/9568 [..............................] - ETA: 53s - loss: 0.1896  192/9568 [..............................] - ETA: 56s - loss: 0.1773 256/9568 [..............................] - ETA: 51s - loss: 0.1799 320/9568 [>.............................] - ETA: 47s - loss: 0.1801 384/9568 [>.............................] - ETA: 47s - loss: 0.1776 448/9568 [>.............................] - ETA: 48s - loss: 0.1783 512/9568 [>.............................] - ETA: 47s - loss: 0.1767 576/9568 [>.............................] - ETA: 47s - loss: 0.1787 640/9568 [=>............................] - ETA: 46s - loss: 0.1778 704/9568 [=>............................] - ETA: 48s - loss: 0.1775 768/9568 [=>............................] - ETA: 46s - loss: 0.1756 832/9568 [=>............................] - ETA: 47s - loss: 0.1757 896/9568 [=>............................] - ETA: 48s - loss: 0.1758 960/9568 [==>...........................] - ETA: 48s - loss: 0.17661024/9568 [==>...........................] - ETA: 48s - loss: 0.17781088/9568 [==>...........................] - ETA: 47s - loss: 0.17801152/9568 [==>...........................] - ETA: 47s - loss: 0.18111216/9568 [==>...........................] - ETA: 46s - loss: 0.18161280/9568 [===>..........................] - ETA: 46s - loss: 0.18171344/9568 [===>..........................] - ETA: 45s - loss: 0.18101408/9568 [===>..........................] - ETA: 45s - loss: 0.18061472/9568 [===>..........................] - ETA: 44s - loss: 0.18071536/9568 [===>..........................] - ETA: 43s - loss: 0.17951600/9568 [====>.........................] - ETA: 43s - loss: 0.17881664/9568 [====>.........................] - ETA: 43s - loss: 0.17951728/9568 [====>.........................] - ETA: 42s - loss: 0.17821792/9568 [====>.........................] - ETA: 41s - loss: 0.17681856/9568 [====>.........................] - ETA: 40s - loss: 0.17571920/9568 [=====>........................] - ETA: 40s - loss: 0.17661984/9568 [=====>........................] - ETA: 39s - loss: 0.17562048/9568 [=====>........................] - ETA: 38s - loss: 0.17432112/9568 [=====>........................] - ETA: 38s - loss: 0.17402176/9568 [=====>........................] - ETA: 37s - loss: 0.17332240/9568 [======>.......................] - ETA: 37s - loss: 0.17342304/9568 [======>.......................] - ETA: 37s - loss: 0.17322368/9568 [======>.......................] - ETA: 36s - loss: 0.17382432/9568 [======>.......................] - ETA: 36s - loss: 0.17332496/9568 [======>.......................] - ETA: 35s - loss: 0.17262560/9568 [=======>......................] - ETA: 34s - loss: 0.17202624/9568 [=======>......................] - ETA: 34s - loss: 0.17172688/9568 [=======>......................] - ETA: 33s - loss: 0.17192752/9568 [=======>......................] - ETA: 33s - loss: 0.17152816/9568 [=======>......................] - ETA: 33s - loss: 0.17192880/9568 [========>.....................] - ETA: 32s - loss: 0.17172944/9568 [========>.....................] - ETA: 32s - loss: 0.17143008/9568 [========>.....................] - ETA: 31s - loss: 0.17113072/9568 [========>.....................] - ETA: 31s - loss: 0.17123136/9568 [========>.....................] - ETA: 31s - loss: 0.17103200/9568 [=========>....................] - ETA: 31s - loss: 0.17093264/9568 [=========>....................] - ETA: 31s - loss: 0.17123328/9568 [=========>....................] - ETA: 31s - loss: 0.17083392/9568 [=========>....................] - ETA: 30s - loss: 0.17043456/9568 [=========>....................] - ETA: 30s - loss: 0.17023520/9568 [==========>...................] - ETA: 30s - loss: 0.17033584/9568 [==========>...................] - ETA: 29s - loss: 0.16983648/9568 [==========>...................] - ETA: 29s - loss: 0.17033712/9568 [==========>...................] - ETA: 29s - loss: 0.17003776/9568 [==========>...................] - ETA: 29s - loss: 0.17003840/9568 [===========>..................] - ETA: 29s - loss: 0.16973904/9568 [===========>..................] - ETA: 29s - loss: 0.16933968/9568 [===========>..................] - ETA: 28s - loss: 0.16884032/9568 [===========>..................] - ETA: 29s - loss: 0.16834096/9568 [===========>..................] - ETA: 29s - loss: 0.16844160/9568 [============>.................] - ETA: 28s - loss: 0.16814224/9568 [============>.................] - ETA: 28s - loss: 0.16794288/9568 [============>.................] - ETA: 28s - loss: 0.16744352/9568 [============>.................] - ETA: 28s - loss: 0.16724416/9568 [============>.................] - ETA: 27s - loss: 0.16724480/9568 [=============>................] - ETA: 27s - loss: 0.16694544/9568 [=============>................] - ETA: 27s - loss: 0.16724608/9568 [=============>................] - ETA: 27s - loss: 0.16694672/9568 [=============>................] - ETA: 27s - loss: 0.16664736/9568 [=============>................] - ETA: 27s - loss: 0.16634800/9568 [==============>...............] - ETA: 26s - loss: 0.16614864/9568 [==============>...............] - ETA: 26s - loss: 0.16604928/9568 [==============>...............] - ETA: 26s - loss: 0.16624992/9568 [==============>...............] - ETA: 26s - loss: 0.16665056/9568 [==============>...............] - ETA: 25s - loss: 0.16685120/9568 [===============>..............] - ETA: 25s - loss: 0.16695184/9568 [===============>..............] - ETA: 25s - loss: 0.16695248/9568 [===============>..............] - ETA: 25s - loss: 0.16685312/9568 [===============>..............] - ETA: 24s - loss: 0.16645376/9568 [===============>..............] - ETA: 24s - loss: 0.16665440/9568 [================>.............] - ETA: 23s - loss: 0.16755504/9568 [================>.............] - ETA: 23s - loss: 0.16735568/9568 [================>.............] - ETA: 23s - loss: 0.16755632/9568 [================>.............] - ETA: 22s - loss: 0.16725696/9568 [================>.............] - ETA: 22s - loss: 0.16705760/9568 [=================>............] - ETA: 22s - loss: 0.16735824/9568 [=================>............] - ETA: 21s - loss: 0.16735888/9568 [=================>............] - ETA: 21s - loss: 0.16745952/9568 [=================>............] - ETA: 21s - loss: 0.16786016/9568 [=================>............] - ETA: 20s - loss: 0.16766080/9568 [==================>...........] - ETA: 20s - loss: 0.16746144/9568 [==================>...........] - ETA: 19s - loss: 0.16716208/9568 [==================>...........] - ETA: 19s - loss: 0.16726272/9568 [==================>...........] - ETA: 19s - loss: 0.16716336/9568 [==================>...........] - ETA: 18s - loss: 0.16696400/9568 [===================>..........] - ETA: 18s - loss: 0.16686464/9568 [===================>..........] - ETA: 18s - loss: 0.16716528/9568 [===================>..........] - ETA: 17s - loss: 0.16696592/9568 [===================>..........] - ETA: 17s - loss: 0.16676656/9568 [===================>..........] - ETA: 16s - loss: 0.16696720/9568 [====================>.........] - ETA: 16s - loss: 0.16706784/9568 [====================>.........] - ETA: 16s - loss: 0.16726848/9568 [====================>.........] - ETA: 15s - loss: 0.16816912/9568 [====================>.........] - ETA: 15s - loss: 0.16816976/9568 [====================>.........] - ETA: 15s - loss: 0.16807040/9568 [=====================>........] - ETA: 14s - loss: 0.16807104/9568 [=====================>........] - ETA: 14s - loss: 0.16797168/9568 [=====================>........] - ETA: 13s - loss: 0.16817232/9568 [=====================>........] - ETA: 13s - loss: 0.16817296/9568 [=====================>........] - ETA: 13s - loss: 0.16817360/9568 [======================>.......] - ETA: 12s - loss: 0.16817424/9568 [======================>.......] - ETA: 12s - loss: 0.16827488/9568 [======================>.......] - ETA: 12s - loss: 0.16797552/9568 [======================>.......] - ETA: 11s - loss: 0.16787616/9568 [======================>.......] - ETA: 11s - loss: 0.16777680/9568 [=======================>......] - ETA: 11s - loss: 0.16837744/9568 [=======================>......] - ETA: 10s - loss: 0.16827808/9568 [=======================>......] - ETA: 10s - loss: 0.16867872/9568 [=======================>......] - ETA: 9s - loss: 0.1686 7936/9568 [=======================>......] - ETA: 9s - loss: 0.16868000/9568 [========================>.....] - ETA: 9s - loss: 0.16848064/9568 [========================>.....] - ETA: 8s - loss: 0.16848128/9568 [========================>.....] - ETA: 8s - loss: 0.16838192/9568 [========================>.....] - ETA: 7s - loss: 0.16828256/9568 [========================>.....] - ETA: 7s - loss: 0.16828320/9568 [=========================>....] - ETA: 7s - loss: 0.16808384/9568 [=========================>....] - ETA: 6s - loss: 0.16808448/9568 [=========================>....] - ETA: 6s - loss: 0.16798512/9568 [=========================>....] - ETA: 6s - loss: 0.16798576/9568 [=========================>....] - ETA: 5s - loss: 0.16778640/9568 [==========================>...] - ETA: 5s - loss: 0.16798704/9568 [==========================>...] - ETA: 5s - loss: 0.16808768/9568 [==========================>...] - ETA: 4s - loss: 0.16788832/9568 [==========================>...] - ETA: 4s - loss: 0.16768896/9568 [==========================>...] - ETA: 3s - loss: 0.16768960/9568 [===========================>..] - ETA: 3s - loss: 0.16749024/9568 [===========================>..] - ETA: 3s - loss: 0.16749088/9568 [===========================>..] - ETA: 2s - loss: 0.16729152/9568 [===========================>..] - ETA: 2s - loss: 0.16709216/9568 [===========================>..] - ETA: 1s - loss: 0.16719280/9568 [============================>.] - ETA: 1s - loss: 0.16739344/9568 [============================>.] - ETA: 1s - loss: 0.16749408/9568 [============================>.] - ETA: 0s - loss: 0.16739472/9568 [============================>.] - ETA: 0s - loss: 0.16739536/9568 [============================>.] - ETA: 0s - loss: 0.1672
Epoch 00005: val_loss improved from 0.16702 to 0.16231, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 61s 6ms/sample - loss: 0.1671 - val_loss: 0.1623
Epoch 6/100
  64/9568 [..............................] - ETA: 43s - loss: 0.1511 128/9568 [..............................] - ETA: 42s - loss: 0.1537 192/9568 [..............................] - ETA: 46s - loss: 0.1665 256/9568 [..............................] - ETA: 47s - loss: 0.1636 320/9568 [>.............................] - ETA: 49s - loss: 0.1633 384/9568 [>.............................] - ETA: 47s - loss: 0.1635 448/9568 [>.............................] - ETA: 53s - loss: 0.1622 512/9568 [>.............................] - ETA: 57s - loss: 0.1626 576/9568 [>.............................] - ETA: 53s - loss: 0.1650 640/9568 [=>............................] - ETA: 53s - loss: 0.1665 704/9568 [=>............................] - ETA: 53s - loss: 0.1666 768/9568 [=>............................] - ETA: 51s - loss: 0.1696 832/9568 [=>............................] - ETA: 50s - loss: 0.1696 896/9568 [=>............................] - ETA: 51s - loss: 0.1706 960/9568 [==>...........................] - ETA: 54s - loss: 0.17041024/9568 [==>...........................] - ETA: 55s - loss: 0.17071088/9568 [==>...........................] - ETA: 55s - loss: 0.17211152/9568 [==>...........................] - ETA: 56s - loss: 0.17121216/9568 [==>...........................] - ETA: 57s - loss: 0.17131280/9568 [===>..........................] - ETA: 58s - loss: 0.17091344/9568 [===>..........................] - ETA: 59s - loss: 0.17201408/9568 [===>..........................] - ETA: 58s - loss: 0.17301472/9568 [===>..........................] - ETA: 58s - loss: 0.17331536/9568 [===>..........................] - ETA: 56s - loss: 0.17221600/9568 [====>.........................] - ETA: 55s - loss: 0.17171664/9568 [====>.........................] - ETA: 54s - loss: 0.17191728/9568 [====>.........................] - ETA: 54s - loss: 0.17201792/9568 [====>.........................] - ETA: 53s - loss: 0.17121856/9568 [====>.........................] - ETA: 52s - loss: 0.17061920/9568 [=====>........................] - ETA: 51s - loss: 0.16961984/9568 [=====>........................] - ETA: 50s - loss: 0.16892048/9568 [=====>........................] - ETA: 49s - loss: 0.16832112/9568 [=====>........................] - ETA: 48s - loss: 0.16782176/9568 [=====>........................] - ETA: 48s - loss: 0.16712240/9568 [======>.......................] - ETA: 48s - loss: 0.16622304/9568 [======>.......................] - ETA: 48s - loss: 0.16672368/9568 [======>.......................] - ETA: 49s - loss: 0.16592432/9568 [======>.......................] - ETA: 48s - loss: 0.16562496/9568 [======>.......................] - ETA: 47s - loss: 0.16522560/9568 [=======>......................] - ETA: 46s - loss: 0.16502624/9568 [=======>......................] - ETA: 46s - loss: 0.16462688/9568 [=======>......................] - ETA: 45s - loss: 0.16522752/9568 [=======>......................] - ETA: 45s - loss: 0.16492816/9568 [=======>......................] - ETA: 44s - loss: 0.16452880/9568 [========>.....................] - ETA: 43s - loss: 0.16392944/9568 [========>.....................] - ETA: 42s - loss: 0.16373008/9568 [========>.....................] - ETA: 41s - loss: 0.16363072/9568 [========>.....................] - ETA: 41s - loss: 0.16333136/9568 [========>.....................] - ETA: 40s - loss: 0.16353200/9568 [=========>....................] - ETA: 40s - loss: 0.16343264/9568 [=========>....................] - ETA: 40s - loss: 0.16273328/9568 [=========>....................] - ETA: 39s - loss: 0.16243392/9568 [=========>....................] - ETA: 39s - loss: 0.16283456/9568 [=========>....................] - ETA: 38s - loss: 0.16263520/9568 [==========>...................] - ETA: 37s - loss: 0.16263584/9568 [==========>...................] - ETA: 37s - loss: 0.16303648/9568 [==========>...................] - ETA: 36s - loss: 0.16283712/9568 [==========>...................] - ETA: 36s - loss: 0.16283776/9568 [==========>...................] - ETA: 35s - loss: 0.16293840/9568 [===========>..................] - ETA: 34s - loss: 0.16333904/9568 [===========>..................] - ETA: 34s - loss: 0.16303968/9568 [===========>..................] - ETA: 33s - loss: 0.16294032/9568 [===========>..................] - ETA: 33s - loss: 0.16244096/9568 [===========>..................] - ETA: 33s - loss: 0.16244160/9568 [============>.................] - ETA: 32s - loss: 0.16214224/9568 [============>.................] - ETA: 32s - loss: 0.16184288/9568 [============>.................] - ETA: 31s - loss: 0.16174352/9568 [============>.................] - ETA: 31s - loss: 0.16164416/9568 [============>.................] - ETA: 30s - loss: 0.16224480/9568 [=============>................] - ETA: 30s - loss: 0.16224544/9568 [=============>................] - ETA: 30s - loss: 0.16224608/9568 [=============>................] - ETA: 29s - loss: 0.16254672/9568 [=============>................] - ETA: 29s - loss: 0.16234736/9568 [=============>................] - ETA: 28s - loss: 0.16244800/9568 [==============>...............] - ETA: 28s - loss: 0.16214864/9568 [==============>...............] - ETA: 27s - loss: 0.16184928/9568 [==============>...............] - ETA: 27s - loss: 0.16184992/9568 [==============>...............] - ETA: 27s - loss: 0.16205056/9568 [==============>...............] - ETA: 27s - loss: 0.16195120/9568 [===============>..............] - ETA: 26s - loss: 0.16215184/9568 [===============>..............] - ETA: 26s - loss: 0.16215248/9568 [===============>..............] - ETA: 25s - loss: 0.16215312/9568 [===============>..............] - ETA: 25s - loss: 0.16185376/9568 [===============>..............] - ETA: 25s - loss: 0.16225440/9568 [================>.............] - ETA: 25s - loss: 0.16195504/9568 [================>.............] - ETA: 25s - loss: 0.16225568/9568 [================>.............] - ETA: 24s - loss: 0.16195632/9568 [================>.............] - ETA: 24s - loss: 0.16195696/9568 [================>.............] - ETA: 24s - loss: 0.16195760/9568 [=================>............] - ETA: 23s - loss: 0.16215824/9568 [=================>............] - ETA: 23s - loss: 0.16235888/9568 [=================>............] - ETA: 23s - loss: 0.16255952/9568 [=================>............] - ETA: 22s - loss: 0.16256016/9568 [=================>............] - ETA: 22s - loss: 0.16256080/9568 [==================>...........] - ETA: 21s - loss: 0.16246144/9568 [==================>...........] - ETA: 21s - loss: 0.16246208/9568 [==================>...........] - ETA: 21s - loss: 0.16236272/9568 [==================>...........] - ETA: 21s - loss: 0.16246336/9568 [==================>...........] - ETA: 20s - loss: 0.16246400/9568 [===================>..........] - ETA: 20s - loss: 0.16256464/9568 [===================>..........] - ETA: 20s - loss: 0.16236528/9568 [===================>..........] - ETA: 19s - loss: 0.16216592/9568 [===================>..........] - ETA: 19s - loss: 0.16266656/9568 [===================>..........] - ETA: 18s - loss: 0.16226720/9568 [====================>.........] - ETA: 18s - loss: 0.16206784/9568 [====================>.........] - ETA: 18s - loss: 0.16186848/9568 [====================>.........] - ETA: 17s - loss: 0.16216912/9568 [====================>.........] - ETA: 17s - loss: 0.16186976/9568 [====================>.........] - ETA: 16s - loss: 0.16167040/9568 [=====================>........] - ETA: 16s - loss: 0.16167104/9568 [=====================>........] - ETA: 15s - loss: 0.16167168/9568 [=====================>........] - ETA: 15s - loss: 0.16177232/9568 [=====================>........] - ETA: 14s - loss: 0.16177296/9568 [=====================>........] - ETA: 14s - loss: 0.16157360/9568 [======================>.......] - ETA: 14s - loss: 0.16137424/9568 [======================>.......] - ETA: 13s - loss: 0.16157488/9568 [======================>.......] - ETA: 13s - loss: 0.16147552/9568 [======================>.......] - ETA: 12s - loss: 0.16157616/9568 [======================>.......] - ETA: 12s - loss: 0.16147680/9568 [=======================>......] - ETA: 12s - loss: 0.16137744/9568 [=======================>......] - ETA: 11s - loss: 0.16137808/9568 [=======================>......] - ETA: 11s - loss: 0.16137872/9568 [=======================>......] - ETA: 10s - loss: 0.16157936/9568 [=======================>......] - ETA: 10s - loss: 0.16148000/9568 [========================>.....] - ETA: 9s - loss: 0.1615 8064/9568 [========================>.....] - ETA: 9s - loss: 0.16168128/9568 [========================>.....] - ETA: 9s - loss: 0.16148192/9568 [========================>.....] - ETA: 8s - loss: 0.16138256/9568 [========================>.....] - ETA: 8s - loss: 0.16158320/9568 [=========================>....] - ETA: 7s - loss: 0.16178384/9568 [=========================>....] - ETA: 7s - loss: 0.16168448/9568 [=========================>....] - ETA: 7s - loss: 0.16158512/9568 [=========================>....] - ETA: 6s - loss: 0.16228576/9568 [=========================>....] - ETA: 6s - loss: 0.16288640/9568 [==========================>...] - ETA: 5s - loss: 0.16288704/9568 [==========================>...] - ETA: 5s - loss: 0.16288768/9568 [==========================>...] - ETA: 4s - loss: 0.16278832/9568 [==========================>...] - ETA: 4s - loss: 0.16288896/9568 [==========================>...] - ETA: 4s - loss: 0.16268960/9568 [===========================>..] - ETA: 3s - loss: 0.16259024/9568 [===========================>..] - ETA: 3s - loss: 0.16259088/9568 [===========================>..] - ETA: 2s - loss: 0.16259152/9568 [===========================>..] - ETA: 2s - loss: 0.16279216/9568 [===========================>..] - ETA: 2s - loss: 0.16279280/9568 [============================>.] - ETA: 1s - loss: 0.16259344/9568 [============================>.] - ETA: 1s - loss: 0.16239408/9568 [============================>.] - ETA: 1s - loss: 0.16229472/9568 [============================>.] - ETA: 0s - loss: 0.16219536/9568 [============================>.] - ETA: 0s - loss: 0.1622
Epoch 00006: val_loss improved from 0.16231 to 0.16174, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 66s 7ms/sample - loss: 0.1621 - val_loss: 0.1617
Epoch 7/100
  64/9568 [..............................] - ETA: 51s - loss: 0.1467 128/9568 [..............................] - ETA: 53s - loss: 0.1537 192/9568 [..............................] - ETA: 52s - loss: 0.1492 256/9568 [..............................] - ETA: 1:02 - loss: 0.1506 320/9568 [>.............................] - ETA: 1:03 - loss: 0.1458 384/9568 [>.............................] - ETA: 1:01 - loss: 0.1507 448/9568 [>.............................] - ETA: 57s - loss: 0.1488  512/9568 [>.............................] - ETA: 56s - loss: 0.1468 576/9568 [>.............................] - ETA: 58s - loss: 0.1528 640/9568 [=>............................] - ETA: 56s - loss: 0.1507 704/9568 [=>............................] - ETA: 55s - loss: 0.1527 768/9568 [=>............................] - ETA: 53s - loss: 0.1523 832/9568 [=>............................] - ETA: 52s - loss: 0.1519 896/9568 [=>............................] - ETA: 52s - loss: 0.1532 960/9568 [==>...........................] - ETA: 51s - loss: 0.15601024/9568 [==>...........................] - ETA: 51s - loss: 0.15531088/9568 [==>...........................] - ETA: 51s - loss: 0.15451152/9568 [==>...........................] - ETA: 49s - loss: 0.15661216/9568 [==>...........................] - ETA: 48s - loss: 0.15701280/9568 [===>..........................] - ETA: 48s - loss: 0.15721344/9568 [===>..........................] - ETA: 47s - loss: 0.15651408/9568 [===>..........................] - ETA: 46s - loss: 0.15601472/9568 [===>..........................] - ETA: 46s - loss: 0.15631536/9568 [===>..........................] - ETA: 46s - loss: 0.15581600/9568 [====>.........................] - ETA: 46s - loss: 0.15471664/9568 [====>.........................] - ETA: 46s - loss: 0.15451728/9568 [====>.........................] - ETA: 45s - loss: 0.15461792/9568 [====>.........................] - ETA: 44s - loss: 0.15431856/9568 [====>.........................] - ETA: 44s - loss: 0.15411920/9568 [=====>........................] - ETA: 44s - loss: 0.15521984/9568 [=====>........................] - ETA: 44s - loss: 0.15512048/9568 [=====>........................] - ETA: 43s - loss: 0.15492112/9568 [=====>........................] - ETA: 44s - loss: 0.15522176/9568 [=====>........................] - ETA: 43s - loss: 0.15612240/9568 [======>.......................] - ETA: 42s - loss: 0.15572304/9568 [======>.......................] - ETA: 43s - loss: 0.15512368/9568 [======>.......................] - ETA: 43s - loss: 0.15552432/9568 [======>.......................] - ETA: 43s - loss: 0.15552496/9568 [======>.......................] - ETA: 43s - loss: 0.15582560/9568 [=======>......................] - ETA: 43s - loss: 0.15622624/9568 [=======>......................] - ETA: 43s - loss: 0.15672688/9568 [=======>......................] - ETA: 43s - loss: 0.15652752/9568 [=======>......................] - ETA: 43s - loss: 0.15632816/9568 [=======>......................] - ETA: 43s - loss: 0.15602880/9568 [========>.....................] - ETA: 43s - loss: 0.15572944/9568 [========>.....................] - ETA: 43s - loss: 0.15613008/9568 [========>.....................] - ETA: 42s - loss: 0.15603072/9568 [========>.....................] - ETA: 42s - loss: 0.15563136/9568 [========>.....................] - ETA: 42s - loss: 0.15553200/9568 [=========>....................] - ETA: 41s - loss: 0.15513264/9568 [=========>....................] - ETA: 41s - loss: 0.15503328/9568 [=========>....................] - ETA: 40s - loss: 0.15473392/9568 [=========>....................] - ETA: 40s - loss: 0.15483456/9568 [=========>....................] - ETA: 39s - loss: 0.15443520/9568 [==========>...................] - ETA: 39s - loss: 0.15443584/9568 [==========>...................] - ETA: 39s - loss: 0.15423648/9568 [==========>...................] - ETA: 38s - loss: 0.15443712/9568 [==========>...................] - ETA: 38s - loss: 0.15423776/9568 [==========>...................] - ETA: 37s - loss: 0.15373840/9568 [===========>..................] - ETA: 38s - loss: 0.15333904/9568 [===========>..................] - ETA: 37s - loss: 0.15383968/9568 [===========>..................] - ETA: 37s - loss: 0.15364032/9568 [===========>..................] - ETA: 36s - loss: 0.15394096/9568 [===========>..................] - ETA: 36s - loss: 0.15394160/9568 [============>.................] - ETA: 35s - loss: 0.15404224/9568 [============>.................] - ETA: 35s - loss: 0.15364288/9568 [============>.................] - ETA: 34s - loss: 0.15384352/9568 [============>.................] - ETA: 34s - loss: 0.15374416/9568 [============>.................] - ETA: 33s - loss: 0.15354480/9568 [=============>................] - ETA: 33s - loss: 0.15354544/9568 [=============>................] - ETA: 32s - loss: 0.15334608/9568 [=============>................] - ETA: 31s - loss: 0.15364672/9568 [=============>................] - ETA: 31s - loss: 0.15394736/9568 [=============>................] - ETA: 30s - loss: 0.15394800/9568 [==============>...............] - ETA: 30s - loss: 0.15394864/9568 [==============>...............] - ETA: 29s - loss: 0.15384928/9568 [==============>...............] - ETA: 29s - loss: 0.15394992/9568 [==============>...............] - ETA: 28s - loss: 0.15405056/9568 [==============>...............] - ETA: 28s - loss: 0.15375120/9568 [===============>..............] - ETA: 27s - loss: 0.15365184/9568 [===============>..............] - ETA: 27s - loss: 0.15355248/9568 [===============>..............] - ETA: 26s - loss: 0.15345312/9568 [===============>..............] - ETA: 26s - loss: 0.15335376/9568 [===============>..............] - ETA: 25s - loss: 0.15305440/9568 [================>.............] - ETA: 25s - loss: 0.15305504/9568 [================>.............] - ETA: 24s - loss: 0.15325568/9568 [================>.............] - ETA: 24s - loss: 0.15365632/9568 [================>.............] - ETA: 23s - loss: 0.15385696/9568 [================>.............] - ETA: 23s - loss: 0.15415760/9568 [=================>............] - ETA: 23s - loss: 0.15395824/9568 [=================>............] - ETA: 22s - loss: 0.15415888/9568 [=================>............] - ETA: 22s - loss: 0.15395952/9568 [=================>............] - ETA: 21s - loss: 0.15366016/9568 [=================>............] - ETA: 21s - loss: 0.15376080/9568 [==================>...........] - ETA: 20s - loss: 0.15346144/9568 [==================>...........] - ETA: 20s - loss: 0.15316208/9568 [==================>...........] - ETA: 20s - loss: 0.15326272/9568 [==================>...........] - ETA: 19s - loss: 0.15316336/9568 [==================>...........] - ETA: 19s - loss: 0.15306400/9568 [===================>..........] - ETA: 18s - loss: 0.15316464/9568 [===================>..........] - ETA: 18s - loss: 0.15326528/9568 [===================>..........] - ETA: 18s - loss: 0.15306592/9568 [===================>..........] - ETA: 17s - loss: 0.15296656/9568 [===================>..........] - ETA: 17s - loss: 0.15296720/9568 [====================>.........] - ETA: 17s - loss: 0.15256784/9568 [====================>.........] - ETA: 16s - loss: 0.15266848/9568 [====================>.........] - ETA: 16s - loss: 0.15276912/9568 [====================>.........] - ETA: 16s - loss: 0.15266976/9568 [====================>.........] - ETA: 15s - loss: 0.15257040/9568 [=====================>........] - ETA: 15s - loss: 0.15247104/9568 [=====================>........] - ETA: 14s - loss: 0.15297168/9568 [=====================>........] - ETA: 14s - loss: 0.15297232/9568 [=====================>........] - ETA: 14s - loss: 0.15297296/9568 [=====================>........] - ETA: 13s - loss: 0.15287360/9568 [======================>.......] - ETA: 13s - loss: 0.15357424/9568 [======================>.......] - ETA: 13s - loss: 0.15357488/9568 [======================>.......] - ETA: 12s - loss: 0.15387552/9568 [======================>.......] - ETA: 12s - loss: 0.15377616/9568 [======================>.......] - ETA: 11s - loss: 0.15377680/9568 [=======================>......] - ETA: 11s - loss: 0.15437744/9568 [=======================>......] - ETA: 11s - loss: 0.15437808/9568 [=======================>......] - ETA: 10s - loss: 0.15437872/9568 [=======================>......] - ETA: 10s - loss: 0.15457936/9568 [=======================>......] - ETA: 9s - loss: 0.1545 8000/9568 [========================>.....] - ETA: 9s - loss: 0.15458064/9568 [========================>.....] - ETA: 9s - loss: 0.15448128/9568 [========================>.....] - ETA: 8s - loss: 0.15438192/9568 [========================>.....] - ETA: 8s - loss: 0.15438256/9568 [========================>.....] - ETA: 8s - loss: 0.15438320/9568 [=========================>....] - ETA: 7s - loss: 0.15438384/9568 [=========================>....] - ETA: 7s - loss: 0.15458448/9568 [=========================>....] - ETA: 6s - loss: 0.15448512/9568 [=========================>....] - ETA: 6s - loss: 0.15448576/9568 [=========================>....] - ETA: 6s - loss: 0.15458640/9568 [==========================>...] - ETA: 5s - loss: 0.15478704/9568 [==========================>...] - ETA: 5s - loss: 0.15488768/9568 [==========================>...] - ETA: 4s - loss: 0.15498832/9568 [==========================>...] - ETA: 4s - loss: 0.15488896/9568 [==========================>...] - ETA: 4s - loss: 0.15478960/9568 [===========================>..] - ETA: 3s - loss: 0.15469024/9568 [===========================>..] - ETA: 3s - loss: 0.15469088/9568 [===========================>..] - ETA: 2s - loss: 0.15459152/9568 [===========================>..] - ETA: 2s - loss: 0.15439216/9568 [===========================>..] - ETA: 2s - loss: 0.15429280/9568 [============================>.] - ETA: 1s - loss: 0.15419344/9568 [============================>.] - ETA: 1s - loss: 0.15409408/9568 [============================>.] - ETA: 0s - loss: 0.15399472/9568 [============================>.] - ETA: 0s - loss: 0.15399536/9568 [============================>.] - ETA: 0s - loss: 0.1539
Epoch 00007: val_loss improved from 0.16174 to 0.15707, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 64s 7ms/sample - loss: 0.1539 - val_loss: 0.1571
Epoch 8/100
  64/9568 [..............................] - ETA: 1:05 - loss: 0.1368 128/9568 [..............................] - ETA: 56s - loss: 0.1347  192/9568 [..............................] - ETA: 58s - loss: 0.1368 256/9568 [..............................] - ETA: 50s - loss: 0.1411 320/9568 [>.............................] - ETA: 49s - loss: 0.1494 384/9568 [>.............................] - ETA: 46s - loss: 0.1593 448/9568 [>.............................] - ETA: 46s - loss: 0.1557 512/9568 [>.............................] - ETA: 46s - loss: 0.1570 576/9568 [>.............................] - ETA: 45s - loss: 0.1608 640/9568 [=>............................] - ETA: 44s - loss: 0.1580 704/9568 [=>............................] - ETA: 42s - loss: 0.1562 768/9568 [=>............................] - ETA: 44s - loss: 0.1548 832/9568 [=>............................] - ETA: 48s - loss: 0.1559 896/9568 [=>............................] - ETA: 47s - loss: 0.1552 960/9568 [==>...........................] - ETA: 47s - loss: 0.15351024/9568 [==>...........................] - ETA: 48s - loss: 0.15331088/9568 [==>...........................] - ETA: 47s - loss: 0.15501152/9568 [==>...........................] - ETA: 46s - loss: 0.15771216/9568 [==>...........................] - ETA: 44s - loss: 0.15721280/9568 [===>..........................] - ETA: 43s - loss: 0.15631344/9568 [===>..........................] - ETA: 43s - loss: 0.15541408/9568 [===>..........................] - ETA: 45s - loss: 0.15781472/9568 [===>..........................] - ETA: 46s - loss: 0.15911536/9568 [===>..........................] - ETA: 45s - loss: 0.15861600/9568 [====>.........................] - ETA: 45s - loss: 0.15741664/9568 [====>.........................] - ETA: 44s - loss: 0.15731728/9568 [====>.........................] - ETA: 44s - loss: 0.15651792/9568 [====>.........................] - ETA: 43s - loss: 0.15611856/9568 [====>.........................] - ETA: 42s - loss: 0.15561920/9568 [=====>........................] - ETA: 42s - loss: 0.15551984/9568 [=====>........................] - ETA: 41s - loss: 0.15502048/9568 [=====>........................] - ETA: 42s - loss: 0.15522112/9568 [=====>........................] - ETA: 41s - loss: 0.15562176/9568 [=====>........................] - ETA: 42s - loss: 0.15482240/9568 [======>.......................] - ETA: 41s - loss: 0.15462304/9568 [======>.......................] - ETA: 41s - loss: 0.15432368/9568 [======>.......................] - ETA: 40s - loss: 0.15402432/9568 [======>.......................] - ETA: 39s - loss: 0.15342496/9568 [======>.......................] - ETA: 38s - loss: 0.15272560/9568 [=======>......................] - ETA: 37s - loss: 0.15232624/9568 [=======>......................] - ETA: 36s - loss: 0.15252688/9568 [=======>......................] - ETA: 36s - loss: 0.15262752/9568 [=======>......................] - ETA: 35s - loss: 0.15262816/9568 [=======>......................] - ETA: 35s - loss: 0.15232880/9568 [========>.....................] - ETA: 35s - loss: 0.15212944/9568 [========>.....................] - ETA: 34s - loss: 0.15233008/9568 [========>.....................] - ETA: 34s - loss: 0.15223072/9568 [========>.....................] - ETA: 34s - loss: 0.15223136/9568 [========>.....................] - ETA: 33s - loss: 0.15193200/9568 [=========>....................] - ETA: 33s - loss: 0.15193264/9568 [=========>....................] - ETA: 33s - loss: 0.15203328/9568 [=========>....................] - ETA: 32s - loss: 0.15163392/9568 [=========>....................] - ETA: 33s - loss: 0.15203456/9568 [=========>....................] - ETA: 33s - loss: 0.15233520/9568 [==========>...................] - ETA: 32s - loss: 0.15273584/9568 [==========>...................] - ETA: 32s - loss: 0.15263648/9568 [==========>...................] - ETA: 32s - loss: 0.15313712/9568 [==========>...................] - ETA: 32s - loss: 0.15283776/9568 [==========>...................] - ETA: 32s - loss: 0.15293840/9568 [===========>..................] - ETA: 31s - loss: 0.15273904/9568 [===========>..................] - ETA: 31s - loss: 0.15293968/9568 [===========>..................] - ETA: 31s - loss: 0.15314032/9568 [===========>..................] - ETA: 30s - loss: 0.15324096/9568 [===========>..................] - ETA: 30s - loss: 0.15334160/9568 [============>.................] - ETA: 30s - loss: 0.15344224/9568 [============>.................] - ETA: 30s - loss: 0.15314288/9568 [============>.................] - ETA: 29s - loss: 0.15284352/9568 [============>.................] - ETA: 29s - loss: 0.15254416/9568 [============>.................] - ETA: 28s - loss: 0.15274480/9568 [=============>................] - ETA: 28s - loss: 0.15304544/9568 [=============>................] - ETA: 28s - loss: 0.15304608/9568 [=============>................] - ETA: 28s - loss: 0.15304672/9568 [=============>................] - ETA: 28s - loss: 0.15284736/9568 [=============>................] - ETA: 27s - loss: 0.15274800/9568 [==============>...............] - ETA: 27s - loss: 0.15274864/9568 [==============>...............] - ETA: 27s - loss: 0.15284928/9568 [==============>...............] - ETA: 27s - loss: 0.15284992/9568 [==============>...............] - ETA: 26s - loss: 0.15295056/9568 [==============>...............] - ETA: 26s - loss: 0.15275120/9568 [===============>..............] - ETA: 26s - loss: 0.15265184/9568 [===============>..............] - ETA: 26s - loss: 0.15245248/9568 [===============>..............] - ETA: 25s - loss: 0.15225312/9568 [===============>..............] - ETA: 25s - loss: 0.15225376/9568 [===============>..............] - ETA: 24s - loss: 0.15205440/9568 [================>.............] - ETA: 24s - loss: 0.15225504/9568 [================>.............] - ETA: 23s - loss: 0.15225568/9568 [================>.............] - ETA: 23s - loss: 0.15215632/9568 [================>.............] - ETA: 23s - loss: 0.15175696/9568 [================>.............] - ETA: 22s - loss: 0.15165760/9568 [=================>............] - ETA: 22s - loss: 0.15175824/9568 [=================>............] - ETA: 21s - loss: 0.15165888/9568 [=================>............] - ETA: 21s - loss: 0.15135952/9568 [=================>............] - ETA: 21s - loss: 0.15146016/9568 [=================>............] - ETA: 21s - loss: 0.15116080/9568 [==================>...........] - ETA: 20s - loss: 0.15126144/9568 [==================>...........] - ETA: 20s - loss: 0.15126208/9568 [==================>...........] - ETA: 20s - loss: 0.15106272/9568 [==================>...........] - ETA: 19s - loss: 0.15106336/9568 [==================>...........] - ETA: 19s - loss: 0.15096400/9568 [===================>..........] - ETA: 18s - loss: 0.15086464/9568 [===================>..........] - ETA: 18s - loss: 0.15066528/9568 [===================>..........] - ETA: 17s - loss: 0.15056592/9568 [===================>..........] - ETA: 17s - loss: 0.15036656/9568 [===================>..........] - ETA: 17s - loss: 0.15036720/9568 [====================>.........] - ETA: 16s - loss: 0.15026784/9568 [====================>.........] - ETA: 16s - loss: 0.15006848/9568 [====================>.........] - ETA: 16s - loss: 0.15006912/9568 [====================>.........] - ETA: 15s - loss: 0.14986976/9568 [====================>.........] - ETA: 15s - loss: 0.14967040/9568 [=====================>........] - ETA: 15s - loss: 0.14997104/9568 [=====================>........] - ETA: 14s - loss: 0.14977168/9568 [=====================>........] - ETA: 14s - loss: 0.14947232/9568 [=====================>........] - ETA: 14s - loss: 0.14937296/9568 [=====================>........] - ETA: 13s - loss: 0.14927360/9568 [======================>.......] - ETA: 13s - loss: 0.14927424/9568 [======================>.......] - ETA: 12s - loss: 0.14907488/9568 [======================>.......] - ETA: 12s - loss: 0.14887552/9568 [======================>.......] - ETA: 12s - loss: 0.14867616/9568 [======================>.......] - ETA: 11s - loss: 0.14887680/9568 [=======================>......] - ETA: 11s - loss: 0.14887744/9568 [=======================>......] - ETA: 10s - loss: 0.14867808/9568 [=======================>......] - ETA: 10s - loss: 0.14857872/9568 [=======================>......] - ETA: 10s - loss: 0.14857936/9568 [=======================>......] - ETA: 9s - loss: 0.1486 8000/9568 [========================>.....] - ETA: 9s - loss: 0.14858064/9568 [========================>.....] - ETA: 8s - loss: 0.14848128/9568 [========================>.....] - ETA: 8s - loss: 0.14828192/9568 [========================>.....] - ETA: 8s - loss: 0.14838256/9568 [========================>.....] - ETA: 7s - loss: 0.14838320/9568 [=========================>....] - ETA: 7s - loss: 0.14828384/9568 [=========================>....] - ETA: 7s - loss: 0.14808448/9568 [=========================>....] - ETA: 6s - loss: 0.14818512/9568 [=========================>....] - ETA: 6s - loss: 0.14818576/9568 [=========================>....] - ETA: 5s - loss: 0.14808640/9568 [==========================>...] - ETA: 5s - loss: 0.14798704/9568 [==========================>...] - ETA: 5s - loss: 0.14778768/9568 [==========================>...] - ETA: 4s - loss: 0.14768832/9568 [==========================>...] - ETA: 4s - loss: 0.14778896/9568 [==========================>...] - ETA: 3s - loss: 0.14788960/9568 [===========================>..] - ETA: 3s - loss: 0.14779024/9568 [===========================>..] - ETA: 3s - loss: 0.14769088/9568 [===========================>..] - ETA: 2s - loss: 0.14769152/9568 [===========================>..] - ETA: 2s - loss: 0.14769216/9568 [===========================>..] - ETA: 2s - loss: 0.14769280/9568 [============================>.] - ETA: 1s - loss: 0.14769344/9568 [============================>.] - ETA: 1s - loss: 0.14759408/9568 [============================>.] - ETA: 0s - loss: 0.14749472/9568 [============================>.] - ETA: 0s - loss: 0.14739536/9568 [============================>.] - ETA: 0s - loss: 0.1474
Epoch 00008: val_loss did not improve from 0.15707
9568/9568 [==============================] - 61s 6ms/sample - loss: 0.1475 - val_loss: 0.1610
Epoch 9/100
  64/9568 [..............................] - ETA: 1:11 - loss: 0.1359 128/9568 [..............................] - ETA: 1:13 - loss: 0.1317 192/9568 [..............................] - ETA: 1:12 - loss: 0.1353 256/9568 [..............................] - ETA: 1:06 - loss: 0.1428 320/9568 [>.............................] - ETA: 1:05 - loss: 0.1480 384/9568 [>.............................] - ETA: 1:04 - loss: 0.1462 448/9568 [>.............................] - ETA: 1:05 - loss: 0.1463 512/9568 [>.............................] - ETA: 1:05 - loss: 0.1511 576/9568 [>.............................] - ETA: 1:08 - loss: 0.1511 640/9568 [=>............................] - ETA: 1:09 - loss: 0.1502 704/9568 [=>............................] - ETA: 1:08 - loss: 0.1480 768/9568 [=>............................] - ETA: 1:05 - loss: 0.1489 832/9568 [=>............................] - ETA: 1:06 - loss: 0.1495 896/9568 [=>............................] - ETA: 1:06 - loss: 0.1499 960/9568 [==>...........................] - ETA: 1:03 - loss: 0.14951024/9568 [==>...........................] - ETA: 1:01 - loss: 0.14801088/9568 [==>...........................] - ETA: 59s - loss: 0.1463 1152/9568 [==>...........................] - ETA: 58s - loss: 0.14671216/9568 [==>...........................] - ETA: 55s - loss: 0.14611280/9568 [===>..........................] - ETA: 54s - loss: 0.14571344/9568 [===>..........................] - ETA: 53s - loss: 0.14531408/9568 [===>..........................] - ETA: 52s - loss: 0.14581472/9568 [===>..........................] - ETA: 52s - loss: 0.14551536/9568 [===>..........................] - ETA: 52s - loss: 0.14501600/9568 [====>.........................] - ETA: 53s - loss: 0.14481664/9568 [====>.........................] - ETA: 54s - loss: 0.14471728/9568 [====>.........................] - ETA: 55s - loss: 0.14421792/9568 [====>.........................] - ETA: 55s - loss: 0.14521856/9568 [====>.........................] - ETA: 55s - loss: 0.14421920/9568 [=====>........................] - ETA: 53s - loss: 0.14391984/9568 [=====>........................] - ETA: 52s - loss: 0.14372048/9568 [=====>........................] - ETA: 51s - loss: 0.14362112/9568 [=====>........................] - ETA: 51s - loss: 0.14382176/9568 [=====>........................] - ETA: 49s - loss: 0.14382240/9568 [======>.......................] - ETA: 49s - loss: 0.14362304/9568 [======>.......................] - ETA: 48s - loss: 0.14302368/9568 [======>.......................] - ETA: 47s - loss: 0.14302432/9568 [======>.......................] - ETA: 46s - loss: 0.14322496/9568 [======>.......................] - ETA: 47s - loss: 0.14282560/9568 [=======>......................] - ETA: 46s - loss: 0.14292624/9568 [=======>......................] - ETA: 45s - loss: 0.14272688/9568 [=======>......................] - ETA: 45s - loss: 0.14222752/9568 [=======>......................] - ETA: 44s - loss: 0.14202816/9568 [=======>......................] - ETA: 44s - loss: 0.14192880/9568 [========>.....................] - ETA: 44s - loss: 0.14172944/9568 [========>.....................] - ETA: 43s - loss: 0.14153008/9568 [========>.....................] - ETA: 42s - loss: 0.14173072/9568 [========>.....................] - ETA: 42s - loss: 0.14183136/9568 [========>.....................] - ETA: 41s - loss: 0.14163200/9568 [=========>....................] - ETA: 40s - loss: 0.14143264/9568 [=========>....................] - ETA: 39s - loss: 0.14153328/9568 [=========>....................] - ETA: 39s - loss: 0.14143392/9568 [=========>....................] - ETA: 38s - loss: 0.14143456/9568 [=========>....................] - ETA: 37s - loss: 0.14183520/9568 [==========>...................] - ETA: 36s - loss: 0.14163584/9568 [==========>...................] - ETA: 36s - loss: 0.14243648/9568 [==========>...................] - ETA: 35s - loss: 0.14273712/9568 [==========>...................] - ETA: 35s - loss: 0.14263776/9568 [==========>...................] - ETA: 35s - loss: 0.14253840/9568 [===========>..................] - ETA: 34s - loss: 0.14273904/9568 [===========>..................] - ETA: 34s - loss: 0.14253968/9568 [===========>..................] - ETA: 33s - loss: 0.14234032/9568 [===========>..................] - ETA: 33s - loss: 0.14224096/9568 [===========>..................] - ETA: 32s - loss: 0.14224160/9568 [============>.................] - ETA: 32s - loss: 0.14234224/9568 [============>.................] - ETA: 31s - loss: 0.14244288/9568 [============>.................] - ETA: 31s - loss: 0.14284352/9568 [============>.................] - ETA: 30s - loss: 0.14264416/9568 [============>.................] - ETA: 30s - loss: 0.14264480/9568 [=============>................] - ETA: 30s - loss: 0.14254544/9568 [=============>................] - ETA: 29s - loss: 0.14254608/9568 [=============>................] - ETA: 29s - loss: 0.14244672/9568 [=============>................] - ETA: 29s - loss: 0.14244736/9568 [=============>................] - ETA: 28s - loss: 0.14224800/9568 [==============>...............] - ETA: 28s - loss: 0.14214864/9568 [==============>...............] - ETA: 27s - loss: 0.14254928/9568 [==============>...............] - ETA: 27s - loss: 0.14234992/9568 [==============>...............] - ETA: 26s - loss: 0.14205056/9568 [==============>...............] - ETA: 26s - loss: 0.14185120/9568 [===============>..............] - ETA: 26s - loss: 0.14155184/9568 [===============>..............] - ETA: 25s - loss: 0.14125248/9568 [===============>..............] - ETA: 25s - loss: 0.14145312/9568 [===============>..............] - ETA: 25s - loss: 0.14135376/9568 [===============>..............] - ETA: 25s - loss: 0.14145440/9568 [================>.............] - ETA: 24s - loss: 0.14135504/9568 [================>.............] - ETA: 24s - loss: 0.14155568/9568 [================>.............] - ETA: 23s - loss: 0.14135632/9568 [================>.............] - ETA: 23s - loss: 0.14125696/9568 [================>.............] - ETA: 23s - loss: 0.14105760/9568 [=================>............] - ETA: 22s - loss: 0.14085824/9568 [=================>............] - ETA: 22s - loss: 0.14075888/9568 [=================>............] - ETA: 22s - loss: 0.14085952/9568 [=================>............] - ETA: 21s - loss: 0.14066016/9568 [=================>............] - ETA: 21s - loss: 0.14066080/9568 [==================>...........] - ETA: 21s - loss: 0.14056144/9568 [==================>...........] - ETA: 21s - loss: 0.14076208/9568 [==================>...........] - ETA: 20s - loss: 0.14106272/9568 [==================>...........] - ETA: 20s - loss: 0.14106336/9568 [==================>...........] - ETA: 20s - loss: 0.14096400/9568 [===================>..........] - ETA: 19s - loss: 0.14076464/9568 [===================>..........] - ETA: 19s - loss: 0.14076528/9568 [===================>..........] - ETA: 18s - loss: 0.14086592/9568 [===================>..........] - ETA: 18s - loss: 0.14136656/9568 [===================>..........] - ETA: 18s - loss: 0.14126720/9568 [====================>.........] - ETA: 17s - loss: 0.14116784/9568 [====================>.........] - ETA: 17s - loss: 0.14116848/9568 [====================>.........] - ETA: 16s - loss: 0.14106912/9568 [====================>.........] - ETA: 16s - loss: 0.14106976/9568 [====================>.........] - ETA: 16s - loss: 0.14107040/9568 [=====================>........] - ETA: 15s - loss: 0.14097104/9568 [=====================>........] - ETA: 15s - loss: 0.14107168/9568 [=====================>........] - ETA: 14s - loss: 0.14117232/9568 [=====================>........] - ETA: 14s - loss: 0.14117296/9568 [=====================>........] - ETA: 14s - loss: 0.14107360/9568 [======================>.......] - ETA: 13s - loss: 0.14087424/9568 [======================>.......] - ETA: 13s - loss: 0.14067488/9568 [======================>.......] - ETA: 12s - loss: 0.14077552/9568 [======================>.......] - ETA: 12s - loss: 0.14077616/9568 [======================>.......] - ETA: 11s - loss: 0.14077680/9568 [=======================>......] - ETA: 11s - loss: 0.14087744/9568 [=======================>......] - ETA: 11s - loss: 0.14077808/9568 [=======================>......] - ETA: 10s - loss: 0.14077872/9568 [=======================>......] - ETA: 10s - loss: 0.14077936/9568 [=======================>......] - ETA: 9s - loss: 0.1406 8000/9568 [========================>.....] - ETA: 9s - loss: 0.14058064/9568 [========================>.....] - ETA: 9s - loss: 0.14038128/9568 [========================>.....] - ETA: 8s - loss: 0.14028192/9568 [========================>.....] - ETA: 8s - loss: 0.14038256/9568 [========================>.....] - ETA: 8s - loss: 0.14038320/9568 [=========================>....] - ETA: 7s - loss: 0.14058384/9568 [=========================>....] - ETA: 7s - loss: 0.14058448/9568 [=========================>....] - ETA: 6s - loss: 0.14078512/9568 [=========================>....] - ETA: 6s - loss: 0.14088576/9568 [=========================>....] - ETA: 6s - loss: 0.14088640/9568 [==========================>...] - ETA: 5s - loss: 0.14098704/9568 [==========================>...] - ETA: 5s - loss: 0.14088768/9568 [==========================>...] - ETA: 4s - loss: 0.14088832/9568 [==========================>...] - ETA: 4s - loss: 0.14088896/9568 [==========================>...] - ETA: 4s - loss: 0.14078960/9568 [===========================>..] - ETA: 3s - loss: 0.14069024/9568 [===========================>..] - ETA: 3s - loss: 0.14069088/9568 [===========================>..] - ETA: 2s - loss: 0.14079152/9568 [===========================>..] - ETA: 2s - loss: 0.14079216/9568 [===========================>..] - ETA: 2s - loss: 0.14079280/9568 [============================>.] - ETA: 1s - loss: 0.14069344/9568 [============================>.] - ETA: 1s - loss: 0.14069408/9568 [============================>.] - ETA: 0s - loss: 0.14059472/9568 [============================>.] - ETA: 0s - loss: 0.14049536/9568 [============================>.] - ETA: 0s - loss: 0.1405
Epoch 00009: val_loss improved from 0.15707 to 0.15439, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 63s 7ms/sample - loss: 0.1405 - val_loss: 0.1544
Epoch 10/100
  64/9568 [..............................] - ETA: 54s - loss: 0.1271 128/9568 [..............................] - ETA: 40s - loss: 0.1234 192/9568 [..............................] - ETA: 34s - loss: 0.1240 256/9568 [..............................] - ETA: 46s - loss: 0.1284 320/9568 [>.............................] - ETA: 54s - loss: 0.1284 384/9568 [>.............................] - ETA: 52s - loss: 0.1300 448/9568 [>.............................] - ETA: 50s - loss: 0.1300 512/9568 [>.............................] - ETA: 49s - loss: 0.1298 576/9568 [>.............................] - ETA: 48s - loss: 0.1303 640/9568 [=>............................] - ETA: 46s - loss: 0.1292 704/9568 [=>............................] - ETA: 45s - loss: 0.1313 768/9568 [=>............................] - ETA: 46s - loss: 0.1316 832/9568 [=>............................] - ETA: 48s - loss: 0.1346 896/9568 [=>............................] - ETA: 50s - loss: 0.1341 960/9568 [==>...........................] - ETA: 49s - loss: 0.13451024/9568 [==>...........................] - ETA: 48s - loss: 0.13591088/9568 [==>...........................] - ETA: 46s - loss: 0.13761152/9568 [==>...........................] - ETA: 47s - loss: 0.13781216/9568 [==>...........................] - ETA: 46s - loss: 0.13751280/9568 [===>..........................] - ETA: 47s - loss: 0.13731344/9568 [===>..........................] - ETA: 47s - loss: 0.13771408/9568 [===>..........................] - ETA: 47s - loss: 0.13831472/9568 [===>..........................] - ETA: 47s - loss: 0.13971536/9568 [===>..........................] - ETA: 48s - loss: 0.14021600/9568 [====>.........................] - ETA: 49s - loss: 0.14021664/9568 [====>.........................] - ETA: 49s - loss: 0.13961728/9568 [====>.........................] - ETA: 47s - loss: 0.13971792/9568 [====>.........................] - ETA: 47s - loss: 0.14021856/9568 [====>.........................] - ETA: 47s - loss: 0.14121920/9568 [=====>........................] - ETA: 47s - loss: 0.14111984/9568 [=====>........................] - ETA: 48s - loss: 0.14062048/9568 [=====>........................] - ETA: 47s - loss: 0.13982112/9568 [=====>........................] - ETA: 47s - loss: 0.14002176/9568 [=====>........................] - ETA: 47s - loss: 0.13982240/9568 [======>.......................] - ETA: 46s - loss: 0.13952304/9568 [======>.......................] - ETA: 46s - loss: 0.13942368/9568 [======>.......................] - ETA: 46s - loss: 0.13922432/9568 [======>.......................] - ETA: 45s - loss: 0.13902496/9568 [======>.......................] - ETA: 45s - loss: 0.13912560/9568 [=======>......................] - ETA: 44s - loss: 0.13942624/9568 [=======>......................] - ETA: 44s - loss: 0.14062688/9568 [=======>......................] - ETA: 44s - loss: 0.14072752/9568 [=======>......................] - ETA: 44s - loss: 0.14062816/9568 [=======>......................] - ETA: 43s - loss: 0.14082880/9568 [========>.....................] - ETA: 43s - loss: 0.14052944/9568 [========>.....................] - ETA: 43s - loss: 0.14003008/9568 [========>.....................] - ETA: 42s - loss: 0.13963072/9568 [========>.....................] - ETA: 42s - loss: 0.13943136/9568 [========>.....................] - ETA: 41s - loss: 0.13933200/9568 [=========>....................] - ETA: 40s - loss: 0.13943264/9568 [=========>....................] - ETA: 40s - loss: 0.14013328/9568 [=========>....................] - ETA: 39s - loss: 0.14013392/9568 [=========>....................] - ETA: 39s - loss: 0.14013456/9568 [=========>....................] - ETA: 38s - loss: 0.14013520/9568 [==========>...................] - ETA: 38s - loss: 0.14043584/9568 [==========>...................] - ETA: 38s - loss: 0.14133648/9568 [==========>...................] - ETA: 38s - loss: 0.14123712/9568 [==========>...................] - ETA: 38s - loss: 0.14113776/9568 [==========>...................] - ETA: 37s - loss: 0.14123840/9568 [===========>..................] - ETA: 37s - loss: 0.14113904/9568 [===========>..................] - ETA: 36s - loss: 0.14103968/9568 [===========>..................] - ETA: 36s - loss: 0.14104032/9568 [===========>..................] - ETA: 35s - loss: 0.14074096/9568 [===========>..................] - ETA: 34s - loss: 0.14094160/9568 [============>.................] - ETA: 34s - loss: 0.14094224/9568 [============>.................] - ETA: 33s - loss: 0.14074288/9568 [============>.................] - ETA: 33s - loss: 0.14034352/9568 [============>.................] - ETA: 32s - loss: 0.14004416/9568 [============>.................] - ETA: 32s - loss: 0.14004480/9568 [=============>................] - ETA: 31s - loss: 0.14014544/9568 [=============>................] - ETA: 31s - loss: 0.13994608/9568 [=============>................] - ETA: 31s - loss: 0.14034672/9568 [=============>................] - ETA: 30s - loss: 0.13994736/9568 [=============>................] - ETA: 30s - loss: 0.13984800/9568 [==============>...............] - ETA: 29s - loss: 0.13954864/9568 [==============>...............] - ETA: 29s - loss: 0.13944928/9568 [==============>...............] - ETA: 29s - loss: 0.13914992/9568 [==============>...............] - ETA: 28s - loss: 0.13895056/9568 [==============>...............] - ETA: 28s - loss: 0.13885120/9568 [===============>..............] - ETA: 27s - loss: 0.13885184/9568 [===============>..............] - ETA: 27s - loss: 0.13895248/9568 [===============>..............] - ETA: 26s - loss: 0.13875312/9568 [===============>..............] - ETA: 26s - loss: 0.13895376/9568 [===============>..............] - ETA: 26s - loss: 0.13905440/9568 [================>.............] - ETA: 25s - loss: 0.13915504/9568 [================>.............] - ETA: 25s - loss: 0.13915568/9568 [================>.............] - ETA: 24s - loss: 0.13905632/9568 [================>.............] - ETA: 24s - loss: 0.13915696/9568 [================>.............] - ETA: 24s - loss: 0.13895760/9568 [=================>............] - ETA: 23s - loss: 0.13875824/9568 [=================>............] - ETA: 23s - loss: 0.13855888/9568 [=================>............] - ETA: 22s - loss: 0.13835952/9568 [=================>............] - ETA: 22s - loss: 0.13826016/9568 [=================>............] - ETA: 21s - loss: 0.13806080/9568 [==================>...........] - ETA: 21s - loss: 0.13816144/9568 [==================>...........] - ETA: 21s - loss: 0.13826208/9568 [==================>...........] - ETA: 20s - loss: 0.13826272/9568 [==================>...........] - ETA: 20s - loss: 0.13806336/9568 [==================>...........] - ETA: 19s - loss: 0.13806400/9568 [===================>..........] - ETA: 19s - loss: 0.13806464/9568 [===================>..........] - ETA: 19s - loss: 0.13796528/9568 [===================>..........] - ETA: 18s - loss: 0.13786592/9568 [===================>..........] - ETA: 18s - loss: 0.13816656/9568 [===================>..........] - ETA: 17s - loss: 0.13806720/9568 [====================>.........] - ETA: 17s - loss: 0.13806784/9568 [====================>.........] - ETA: 17s - loss: 0.13786848/9568 [====================>.........] - ETA: 16s - loss: 0.13806912/9568 [====================>.........] - ETA: 16s - loss: 0.13796976/9568 [====================>.........] - ETA: 16s - loss: 0.13817040/9568 [=====================>........] - ETA: 15s - loss: 0.13827104/9568 [=====================>........] - ETA: 15s - loss: 0.13847168/9568 [=====================>........] - ETA: 14s - loss: 0.13827232/9568 [=====================>........] - ETA: 14s - loss: 0.13837296/9568 [=====================>........] - ETA: 14s - loss: 0.13827360/9568 [======================>.......] - ETA: 13s - loss: 0.13817424/9568 [======================>.......] - ETA: 13s - loss: 0.13817488/9568 [======================>.......] - ETA: 12s - loss: 0.13817552/9568 [======================>.......] - ETA: 12s - loss: 0.13817616/9568 [======================>.......] - ETA: 12s - loss: 0.13797680/9568 [=======================>......] - ETA: 11s - loss: 0.13797744/9568 [=======================>......] - ETA: 11s - loss: 0.13777808/9568 [=======================>......] - ETA: 10s - loss: 0.13777872/9568 [=======================>......] - ETA: 10s - loss: 0.13767936/9568 [=======================>......] - ETA: 10s - loss: 0.13788000/9568 [========================>.....] - ETA: 9s - loss: 0.1379 8064/9568 [========================>.....] - ETA: 9s - loss: 0.13788128/9568 [========================>.....] - ETA: 8s - loss: 0.13788192/9568 [========================>.....] - ETA: 8s - loss: 0.13768256/9568 [========================>.....] - ETA: 8s - loss: 0.13768320/9568 [=========================>....] - ETA: 7s - loss: 0.13758384/9568 [=========================>....] - ETA: 7s - loss: 0.13748448/9568 [=========================>....] - ETA: 6s - loss: 0.13748512/9568 [=========================>....] - ETA: 6s - loss: 0.13738576/9568 [=========================>....] - ETA: 6s - loss: 0.13728640/9568 [==========================>...] - ETA: 5s - loss: 0.13728704/9568 [==========================>...] - ETA: 5s - loss: 0.13738768/9568 [==========================>...] - ETA: 4s - loss: 0.13738832/9568 [==========================>...] - ETA: 4s - loss: 0.13718896/9568 [==========================>...] - ETA: 4s - loss: 0.13708960/9568 [===========================>..] - ETA: 3s - loss: 0.13729024/9568 [===========================>..] - ETA: 3s - loss: 0.13729088/9568 [===========================>..] - ETA: 2s - loss: 0.13719152/9568 [===========================>..] - ETA: 2s - loss: 0.13719216/9568 [===========================>..] - ETA: 2s - loss: 0.13709280/9568 [============================>.] - ETA: 1s - loss: 0.13709344/9568 [============================>.] - ETA: 1s - loss: 0.13719408/9568 [============================>.] - ETA: 0s - loss: 0.13739472/9568 [============================>.] - ETA: 0s - loss: 0.13739536/9568 [============================>.] - ETA: 0s - loss: 0.1372
Epoch 00010: val_loss did not improve from 0.15439
9568/9568 [==============================] - 63s 7ms/sample - loss: 0.1372 - val_loss: 0.1548
Epoch 11/100
  64/9568 [..............................] - ETA: 46s - loss: 0.1324 128/9568 [..............................] - ETA: 56s - loss: 0.1280 192/9568 [..............................] - ETA: 1:00 - loss: 0.1337 256/9568 [..............................] - ETA: 58s - loss: 0.1317  320/9568 [>.............................] - ETA: 57s - loss: 0.1290 384/9568 [>.............................] - ETA: 59s - loss: 0.1293 448/9568 [>.............................] - ETA: 55s - loss: 0.1295 512/9568 [>.............................] - ETA: 54s - loss: 0.1328 576/9568 [>.............................] - ETA: 56s - loss: 0.1326 640/9568 [=>............................] - ETA: 55s - loss: 0.1338 704/9568 [=>............................] - ETA: 55s - loss: 0.1322 768/9568 [=>............................] - ETA: 53s - loss: 0.1307 832/9568 [=>............................] - ETA: 51s - loss: 0.1307 896/9568 [=>............................] - ETA: 50s - loss: 0.1287 960/9568 [==>...........................] - ETA: 48s - loss: 0.13021024/9568 [==>...........................] - ETA: 47s - loss: 0.13181088/9568 [==>...........................] - ETA: 45s - loss: 0.13241152/9568 [==>...........................] - ETA: 45s - loss: 0.13151216/9568 [==>...........................] - ETA: 44s - loss: 0.13141280/9568 [===>..........................] - ETA: 44s - loss: 0.13081344/9568 [===>..........................] - ETA: 43s - loss: 0.13101408/9568 [===>..........................] - ETA: 42s - loss: 0.13091472/9568 [===>..........................] - ETA: 42s - loss: 0.13131536/9568 [===>..........................] - ETA: 41s - loss: 0.13141600/9568 [====>.........................] - ETA: 40s - loss: 0.13161664/9568 [====>.........................] - ETA: 39s - loss: 0.13141728/9568 [====>.........................] - ETA: 39s - loss: 0.13091792/9568 [====>.........................] - ETA: 39s - loss: 0.13131856/9568 [====>.........................] - ETA: 38s - loss: 0.13121920/9568 [=====>........................] - ETA: 38s - loss: 0.13091984/9568 [=====>........................] - ETA: 37s - loss: 0.13122048/9568 [=====>........................] - ETA: 36s - loss: 0.13102112/9568 [=====>........................] - ETA: 35s - loss: 0.13142176/9568 [=====>........................] - ETA: 35s - loss: 0.13192240/9568 [======>.......................] - ETA: 34s - loss: 0.13252304/9568 [======>.......................] - ETA: 35s - loss: 0.13202368/9568 [======>.......................] - ETA: 34s - loss: 0.13252432/9568 [======>.......................] - ETA: 34s - loss: 0.13232496/9568 [======>.......................] - ETA: 34s - loss: 0.13242560/9568 [=======>......................] - ETA: 34s - loss: 0.13192624/9568 [=======>......................] - ETA: 33s - loss: 0.13202688/9568 [=======>......................] - ETA: 33s - loss: 0.13182752/9568 [=======>......................] - ETA: 33s - loss: 0.13162816/9568 [=======>......................] - ETA: 33s - loss: 0.13232880/9568 [========>.....................] - ETA: 33s - loss: 0.13202944/9568 [========>.....................] - ETA: 33s - loss: 0.13203008/9568 [========>.....................] - ETA: 32s - loss: 0.13163072/9568 [========>.....................] - ETA: 32s - loss: 0.13193136/9568 [========>.....................] - ETA: 32s - loss: 0.13203200/9568 [=========>....................] - ETA: 31s - loss: 0.13213264/9568 [=========>....................] - ETA: 31s - loss: 0.13213328/9568 [=========>....................] - ETA: 31s - loss: 0.13203392/9568 [=========>....................] - ETA: 31s - loss: 0.13203456/9568 [=========>....................] - ETA: 31s - loss: 0.13213520/9568 [==========>...................] - ETA: 31s - loss: 0.13213584/9568 [==========>...................] - ETA: 31s - loss: 0.13213648/9568 [==========>...................] - ETA: 31s - loss: 0.13253712/9568 [==========>...................] - ETA: 30s - loss: 0.13273776/9568 [==========>...................] - ETA: 31s - loss: 0.13243840/9568 [===========>..................] - ETA: 31s - loss: 0.13243904/9568 [===========>..................] - ETA: 31s - loss: 0.13263968/9568 [===========>..................] - ETA: 31s - loss: 0.13274032/9568 [===========>..................] - ETA: 31s - loss: 0.13354096/9568 [===========>..................] - ETA: 31s - loss: 0.13374160/9568 [============>.................] - ETA: 30s - loss: 0.13394224/9568 [============>.................] - ETA: 30s - loss: 0.13384288/9568 [============>.................] - ETA: 30s - loss: 0.13394352/9568 [============>.................] - ETA: 30s - loss: 0.13384416/9568 [============>.................] - ETA: 29s - loss: 0.13394480/9568 [=============>................] - ETA: 29s - loss: 0.13404544/9568 [=============>................] - ETA: 29s - loss: 0.13374608/9568 [=============>................] - ETA: 29s - loss: 0.13364672/9568 [=============>................] - ETA: 28s - loss: 0.13364736/9568 [=============>................] - ETA: 28s - loss: 0.13324800/9568 [==============>...............] - ETA: 28s - loss: 0.13314864/9568 [==============>...............] - ETA: 27s - loss: 0.13324928/9568 [==============>...............] - ETA: 27s - loss: 0.13294992/9568 [==============>...............] - ETA: 27s - loss: 0.13305056/9568 [==============>...............] - ETA: 26s - loss: 0.13285120/9568 [===============>..............] - ETA: 26s - loss: 0.13285184/9568 [===============>..............] - ETA: 25s - loss: 0.13275248/9568 [===============>..............] - ETA: 25s - loss: 0.13315312/9568 [===============>..............] - ETA: 24s - loss: 0.13295376/9568 [===============>..............] - ETA: 24s - loss: 0.13285440/9568 [================>.............] - ETA: 23s - loss: 0.13285504/9568 [================>.............] - ETA: 23s - loss: 0.13275568/9568 [================>.............] - ETA: 23s - loss: 0.13285632/9568 [================>.............] - ETA: 23s - loss: 0.13275696/9568 [================>.............] - ETA: 23s - loss: 0.13265760/9568 [=================>............] - ETA: 22s - loss: 0.13245824/9568 [=================>............] - ETA: 22s - loss: 0.13255888/9568 [=================>............] - ETA: 21s - loss: 0.13275952/9568 [=================>............] - ETA: 21s - loss: 0.13286016/9568 [=================>............] - ETA: 20s - loss: 0.13266080/9568 [==================>...........] - ETA: 20s - loss: 0.13276144/9568 [==================>...........] - ETA: 20s - loss: 0.13266208/9568 [==================>...........] - ETA: 19s - loss: 0.13256272/9568 [==================>...........] - ETA: 19s - loss: 0.13296336/9568 [==================>...........] - ETA: 18s - loss: 0.13276400/9568 [===================>..........] - ETA: 18s - loss: 0.13286464/9568 [===================>..........] - ETA: 18s - loss: 0.13276528/9568 [===================>..........] - ETA: 18s - loss: 0.13276592/9568 [===================>..........] - ETA: 17s - loss: 0.13306656/9568 [===================>..........] - ETA: 17s - loss: 0.13316720/9568 [====================>.........] - ETA: 16s - loss: 0.13306784/9568 [====================>.........] - ETA: 16s - loss: 0.13306848/9568 [====================>.........] - ETA: 16s - loss: 0.13306912/9568 [====================>.........] - ETA: 15s - loss: 0.13306976/9568 [====================>.........] - ETA: 15s - loss: 0.13307040/9568 [=====================>........] - ETA: 14s - loss: 0.13297104/9568 [=====================>........] - ETA: 14s - loss: 0.13317168/9568 [=====================>........] - ETA: 14s - loss: 0.13327232/9568 [=====================>........] - ETA: 13s - loss: 0.13327296/9568 [=====================>........] - ETA: 13s - loss: 0.13327360/9568 [======================>.......] - ETA: 12s - loss: 0.13317424/9568 [======================>.......] - ETA: 12s - loss: 0.13307488/9568 [======================>.......] - ETA: 12s - loss: 0.13297552/9568 [======================>.......] - ETA: 11s - loss: 0.13317616/9568 [======================>.......] - ETA: 11s - loss: 0.13337680/9568 [=======================>......] - ETA: 10s - loss: 0.13317744/9568 [=======================>......] - ETA: 10s - loss: 0.13317808/9568 [=======================>......] - ETA: 10s - loss: 0.13307872/9568 [=======================>......] - ETA: 9s - loss: 0.1330 7936/9568 [=======================>......] - ETA: 9s - loss: 0.13308000/9568 [========================>.....] - ETA: 9s - loss: 0.13308064/9568 [========================>.....] - ETA: 8s - loss: 0.13308128/9568 [========================>.....] - ETA: 8s - loss: 0.13288192/9568 [========================>.....] - ETA: 7s - loss: 0.13278256/9568 [========================>.....] - ETA: 7s - loss: 0.13288320/9568 [=========================>....] - ETA: 7s - loss: 0.13288384/9568 [=========================>....] - ETA: 6s - loss: 0.13268448/9568 [=========================>....] - ETA: 6s - loss: 0.13328512/9568 [=========================>....] - ETA: 5s - loss: 0.13328576/9568 [=========================>....] - ETA: 5s - loss: 0.13348640/9568 [==========================>...] - ETA: 5s - loss: 0.13348704/9568 [==========================>...] - ETA: 4s - loss: 0.13368768/9568 [==========================>...] - ETA: 4s - loss: 0.13358832/9568 [==========================>...] - ETA: 4s - loss: 0.13358896/9568 [==========================>...] - ETA: 3s - loss: 0.13358960/9568 [===========================>..] - ETA: 3s - loss: 0.13349024/9568 [===========================>..] - ETA: 3s - loss: 0.13349088/9568 [===========================>..] - ETA: 2s - loss: 0.13339152/9568 [===========================>..] - ETA: 2s - loss: 0.13339216/9568 [===========================>..] - ETA: 1s - loss: 0.13339280/9568 [============================>.] - ETA: 1s - loss: 0.13329344/9568 [============================>.] - ETA: 1s - loss: 0.13319408/9568 [============================>.] - ETA: 0s - loss: 0.13319472/9568 [============================>.] - ETA: 0s - loss: 0.13339536/9568 [============================>.] - ETA: 0s - loss: 0.1334
Epoch 00011: val_loss improved from 0.15439 to 0.15422, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 61s 6ms/sample - loss: 0.1335 - val_loss: 0.1542
Epoch 12/100
  64/9568 [..............................] - ETA: 53s - loss: 0.1285 128/9568 [..............................] - ETA: 58s - loss: 0.1228 192/9568 [..............................] - ETA: 49s - loss: 0.1269 256/9568 [..............................] - ETA: 51s - loss: 0.1241 320/9568 [>.............................] - ETA: 50s - loss: 0.1288 384/9568 [>.............................] - ETA: 47s - loss: 0.1286 448/9568 [>.............................] - ETA: 46s - loss: 0.1285 512/9568 [>.............................] - ETA: 45s - loss: 0.1275 576/9568 [>.............................] - ETA: 46s - loss: 0.1260 640/9568 [=>............................] - ETA: 48s - loss: 0.1267 704/9568 [=>............................] - ETA: 50s - loss: 0.1261 768/9568 [=>............................] - ETA: 50s - loss: 0.1258 832/9568 [=>............................] - ETA: 53s - loss: 0.1263 896/9568 [=>............................] - ETA: 55s - loss: 0.1287 960/9568 [==>...........................] - ETA: 54s - loss: 0.12801024/9568 [==>...........................] - ETA: 53s - loss: 0.12751088/9568 [==>...........................] - ETA: 52s - loss: 0.12701152/9568 [==>...........................] - ETA: 51s - loss: 0.12681216/9568 [==>...........................] - ETA: 51s - loss: 0.12651280/9568 [===>..........................] - ETA: 51s - loss: 0.12701344/9568 [===>..........................] - ETA: 50s - loss: 0.12721408/9568 [===>..........................] - ETA: 50s - loss: 0.12751472/9568 [===>..........................] - ETA: 51s - loss: 0.12701536/9568 [===>..........................] - ETA: 51s - loss: 0.12651600/9568 [====>.........................] - ETA: 51s - loss: 0.12671664/9568 [====>.........................] - ETA: 50s - loss: 0.12741728/9568 [====>.........................] - ETA: 49s - loss: 0.12751792/9568 [====>.........................] - ETA: 48s - loss: 0.12861856/9568 [====>.........................] - ETA: 48s - loss: 0.12851920/9568 [=====>........................] - ETA: 47s - loss: 0.12831984/9568 [=====>........................] - ETA: 46s - loss: 0.12912048/9568 [=====>........................] - ETA: 46s - loss: 0.12982112/9568 [=====>........................] - ETA: 46s - loss: 0.12972176/9568 [=====>........................] - ETA: 45s - loss: 0.12922240/9568 [======>.......................] - ETA: 44s - loss: 0.12892304/9568 [======>.......................] - ETA: 43s - loss: 0.12882368/9568 [======>.......................] - ETA: 43s - loss: 0.12902432/9568 [======>.......................] - ETA: 43s - loss: 0.13002496/9568 [======>.......................] - ETA: 42s - loss: 0.12942560/9568 [=======>......................] - ETA: 41s - loss: 0.12962624/9568 [=======>......................] - ETA: 41s - loss: 0.13052688/9568 [=======>......................] - ETA: 40s - loss: 0.13092752/9568 [=======>......................] - ETA: 39s - loss: 0.13072816/9568 [=======>......................] - ETA: 39s - loss: 0.13162880/9568 [========>.....................] - ETA: 38s - loss: 0.13162944/9568 [========>.....................] - ETA: 37s - loss: 0.13153008/9568 [========>.....................] - ETA: 37s - loss: 0.13173072/9568 [========>.....................] - ETA: 36s - loss: 0.13233136/9568 [========>.....................] - ETA: 35s - loss: 0.13213200/9568 [=========>....................] - ETA: 35s - loss: 0.13203264/9568 [=========>....................] - ETA: 34s - loss: 0.13173328/9568 [=========>....................] - ETA: 34s - loss: 0.13193392/9568 [=========>....................] - ETA: 33s - loss: 0.13203456/9568 [=========>....................] - ETA: 32s - loss: 0.13193520/9568 [==========>...................] - ETA: 32s - loss: 0.13143584/9568 [==========>...................] - ETA: 32s - loss: 0.13153648/9568 [==========>...................] - ETA: 31s - loss: 0.13143712/9568 [==========>...................] - ETA: 31s - loss: 0.13113776/9568 [==========>...................] - ETA: 31s - loss: 0.13103840/9568 [===========>..................] - ETA: 31s - loss: 0.13113904/9568 [===========>..................] - ETA: 30s - loss: 0.13133968/9568 [===========>..................] - ETA: 30s - loss: 0.13114032/9568 [===========>..................] - ETA: 29s - loss: 0.13104096/9568 [===========>..................] - ETA: 29s - loss: 0.13084160/9568 [============>.................] - ETA: 29s - loss: 0.13094224/9568 [============>.................] - ETA: 28s - loss: 0.13094288/9568 [============>.................] - ETA: 28s - loss: 0.13084352/9568 [============>.................] - ETA: 27s - loss: 0.13064416/9568 [============>.................] - ETA: 27s - loss: 0.13044480/9568 [=============>................] - ETA: 26s - loss: 0.13054544/9568 [=============>................] - ETA: 26s - loss: 0.13044608/9568 [=============>................] - ETA: 26s - loss: 0.13034672/9568 [=============>................] - ETA: 25s - loss: 0.13014736/9568 [=============>................] - ETA: 25s - loss: 0.13004800/9568 [==============>...............] - ETA: 25s - loss: 0.13004864/9568 [==============>...............] - ETA: 24s - loss: 0.12994928/9568 [==============>...............] - ETA: 24s - loss: 0.12994992/9568 [==============>...............] - ETA: 24s - loss: 0.12975056/9568 [==============>...............] - ETA: 23s - loss: 0.12985120/9568 [===============>..............] - ETA: 23s - loss: 0.12965184/9568 [===============>..............] - ETA: 23s - loss: 0.12955248/9568 [===============>..............] - ETA: 23s - loss: 0.12945312/9568 [===============>..............] - ETA: 22s - loss: 0.12975376/9568 [===============>..............] - ETA: 22s - loss: 0.13035440/9568 [================>.............] - ETA: 22s - loss: 0.13025504/9568 [================>.............] - ETA: 21s - loss: 0.13025568/9568 [================>.............] - ETA: 21s - loss: 0.13015632/9568 [================>.............] - ETA: 21s - loss: 0.12995696/9568 [================>.............] - ETA: 20s - loss: 0.12995760/9568 [=================>............] - ETA: 20s - loss: 0.12995824/9568 [=================>............] - ETA: 20s - loss: 0.12985888/9568 [=================>............] - ETA: 19s - loss: 0.12995952/9568 [=================>............] - ETA: 19s - loss: 0.12976016/9568 [=================>............] - ETA: 19s - loss: 0.12976080/9568 [==================>...........] - ETA: 18s - loss: 0.12986144/9568 [==================>...........] - ETA: 18s - loss: 0.13016208/9568 [==================>...........] - ETA: 18s - loss: 0.13006272/9568 [==================>...........] - ETA: 17s - loss: 0.13016336/9568 [==================>...........] - ETA: 17s - loss: 0.13016400/9568 [===================>..........] - ETA: 17s - loss: 0.13016464/9568 [===================>..........] - ETA: 17s - loss: 0.13006528/9568 [===================>..........] - ETA: 16s - loss: 0.12996592/9568 [===================>..........] - ETA: 16s - loss: 0.12996656/9568 [===================>..........] - ETA: 16s - loss: 0.12996720/9568 [====================>.........] - ETA: 15s - loss: 0.12976784/9568 [====================>.........] - ETA: 15s - loss: 0.12976848/9568 [====================>.........] - ETA: 15s - loss: 0.12976912/9568 [====================>.........] - ETA: 14s - loss: 0.12966976/9568 [====================>.........] - ETA: 14s - loss: 0.12967040/9568 [=====================>........] - ETA: 14s - loss: 0.12957104/9568 [=====================>........] - ETA: 13s - loss: 0.12947168/9568 [=====================>........] - ETA: 13s - loss: 0.12937232/9568 [=====================>........] - ETA: 12s - loss: 0.12927296/9568 [=====================>........] - ETA: 12s - loss: 0.12917360/9568 [======================>.......] - ETA: 12s - loss: 0.12937424/9568 [======================>.......] - ETA: 12s - loss: 0.12937488/9568 [======================>.......] - ETA: 11s - loss: 0.12947552/9568 [======================>.......] - ETA: 11s - loss: 0.12947616/9568 [======================>.......] - ETA: 10s - loss: 0.12937680/9568 [=======================>......] - ETA: 10s - loss: 0.12957744/9568 [=======================>......] - ETA: 10s - loss: 0.12957808/9568 [=======================>......] - ETA: 9s - loss: 0.1294 7872/9568 [=======================>......] - ETA: 9s - loss: 0.12937936/9568 [=======================>......] - ETA: 9s - loss: 0.12938000/9568 [========================>.....] - ETA: 8s - loss: 0.12928064/9568 [========================>.....] - ETA: 8s - loss: 0.12928128/9568 [========================>.....] - ETA: 8s - loss: 0.12938192/9568 [========================>.....] - ETA: 7s - loss: 0.12948256/9568 [========================>.....] - ETA: 7s - loss: 0.12938320/9568 [=========================>....] - ETA: 6s - loss: 0.12948384/9568 [=========================>....] - ETA: 6s - loss: 0.12938448/9568 [=========================>....] - ETA: 6s - loss: 0.12928512/9568 [=========================>....] - ETA: 5s - loss: 0.12958576/9568 [=========================>....] - ETA: 5s - loss: 0.12948640/9568 [==========================>...] - ETA: 5s - loss: 0.12978704/9568 [==========================>...] - ETA: 4s - loss: 0.12978768/9568 [==========================>...] - ETA: 4s - loss: 0.12968832/9568 [==========================>...] - ETA: 4s - loss: 0.12968896/9568 [==========================>...] - ETA: 3s - loss: 0.12978960/9568 [===========================>..] - ETA: 3s - loss: 0.12989024/9568 [===========================>..] - ETA: 2s - loss: 0.13019088/9568 [===========================>..] - ETA: 2s - loss: 0.13019152/9568 [===========================>..] - ETA: 2s - loss: 0.13019216/9568 [===========================>..] - ETA: 1s - loss: 0.13009280/9568 [============================>.] - ETA: 1s - loss: 0.13019344/9568 [============================>.] - ETA: 1s - loss: 0.13029408/9568 [============================>.] - ETA: 0s - loss: 0.13039472/9568 [============================>.] - ETA: 0s - loss: 0.13029536/9568 [============================>.] - ETA: 0s - loss: 0.1301
Epoch 00012: val_loss did not improve from 0.15422
9568/9568 [==============================] - 55s 6ms/sample - loss: 0.1301 - val_loss: 0.1641
Epoch 13/100
  64/9568 [..............................] - ETA: 49s - loss: 0.1318 128/9568 [..............................] - ETA: 39s - loss: 0.1464 192/9568 [..............................] - ETA: 37s - loss: 0.1412 256/9568 [..............................] - ETA: 38s - loss: 0.1430 320/9568 [>.............................] - ETA: 39s - loss: 0.1413 384/9568 [>.............................] - ETA: 41s - loss: 0.1418 448/9568 [>.............................] - ETA: 42s - loss: 0.1397 512/9568 [>.............................] - ETA: 40s - loss: 0.1367 576/9568 [>.............................] - ETA: 40s - loss: 0.1352 640/9568 [=>............................] - ETA: 41s - loss: 0.1335 704/9568 [=>............................] - ETA: 45s - loss: 0.1324 768/9568 [=>............................] - ETA: 46s - loss: 0.1306 832/9568 [=>............................] - ETA: 45s - loss: 0.1309 896/9568 [=>............................] - ETA: 44s - loss: 0.1304 960/9568 [==>...........................] - ETA: 44s - loss: 0.12961024/9568 [==>...........................] - ETA: 44s - loss: 0.12831088/9568 [==>...........................] - ETA: 44s - loss: 0.12801152/9568 [==>...........................] - ETA: 45s - loss: 0.12791216/9568 [==>...........................] - ETA: 46s - loss: 0.13031280/9568 [===>..........................] - ETA: 45s - loss: 0.13141344/9568 [===>..........................] - ETA: 45s - loss: 0.13161408/9568 [===>..........................] - ETA: 45s - loss: 0.13141472/9568 [===>..........................] - ETA: 45s - loss: 0.13121536/9568 [===>..........................] - ETA: 45s - loss: 0.13031600/9568 [====>.........................] - ETA: 44s - loss: 0.13191664/9568 [====>.........................] - ETA: 44s - loss: 0.13181728/9568 [====>.........................] - ETA: 45s - loss: 0.13161792/9568 [====>.........................] - ETA: 45s - loss: 0.13191856/9568 [====>.........................] - ETA: 44s - loss: 0.13141920/9568 [=====>........................] - ETA: 43s - loss: 0.13191984/9568 [=====>........................] - ETA: 43s - loss: 0.13132048/9568 [=====>........................] - ETA: 42s - loss: 0.13092112/9568 [=====>........................] - ETA: 41s - loss: 0.13092176/9568 [=====>........................] - ETA: 40s - loss: 0.13072240/9568 [======>.......................] - ETA: 40s - loss: 0.13062304/9568 [======>.......................] - ETA: 39s - loss: 0.13052368/9568 [======>.......................] - ETA: 38s - loss: 0.13092432/9568 [======>.......................] - ETA: 38s - loss: 0.13072496/9568 [======>.......................] - ETA: 38s - loss: 0.13032560/9568 [=======>......................] - ETA: 37s - loss: 0.12992624/9568 [=======>......................] - ETA: 37s - loss: 0.12962688/9568 [=======>......................] - ETA: 36s - loss: 0.12972752/9568 [=======>......................] - ETA: 35s - loss: 0.12992816/9568 [=======>......................] - ETA: 35s - loss: 0.12972880/9568 [========>.....................] - ETA: 34s - loss: 0.12912944/9568 [========>.....................] - ETA: 34s - loss: 0.12883008/9568 [========>.....................] - ETA: 34s - loss: 0.12863072/9568 [========>.....................] - ETA: 34s - loss: 0.12883136/9568 [========>.....................] - ETA: 34s - loss: 0.12883200/9568 [=========>....................] - ETA: 34s - loss: 0.12893264/9568 [=========>....................] - ETA: 34s - loss: 0.12903328/9568 [=========>....................] - ETA: 33s - loss: 0.12893392/9568 [=========>....................] - ETA: 33s - loss: 0.12893456/9568 [=========>....................] - ETA: 33s - loss: 0.12943520/9568 [==========>...................] - ETA: 32s - loss: 0.12963584/9568 [==========>...................] - ETA: 32s - loss: 0.12973648/9568 [==========>...................] - ETA: 31s - loss: 0.12983712/9568 [==========>...................] - ETA: 31s - loss: 0.12953776/9568 [==========>...................] - ETA: 31s - loss: 0.12953840/9568 [===========>..................] - ETA: 30s - loss: 0.12993904/9568 [===========>..................] - ETA: 30s - loss: 0.13013968/9568 [===========>..................] - ETA: 29s - loss: 0.12994032/9568 [===========>..................] - ETA: 29s - loss: 0.12974096/9568 [===========>..................] - ETA: 28s - loss: 0.12964160/9568 [============>.................] - ETA: 28s - loss: 0.12934224/9568 [============>.................] - ETA: 27s - loss: 0.12934288/9568 [============>.................] - ETA: 27s - loss: 0.12924352/9568 [============>.................] - ETA: 26s - loss: 0.12914416/9568 [============>.................] - ETA: 26s - loss: 0.12884480/9568 [=============>................] - ETA: 25s - loss: 0.12874544/9568 [=============>................] - ETA: 25s - loss: 0.12854608/9568 [=============>................] - ETA: 25s - loss: 0.12864672/9568 [=============>................] - ETA: 25s - loss: 0.12844736/9568 [=============>................] - ETA: 25s - loss: 0.12874800/9568 [==============>...............] - ETA: 24s - loss: 0.12864864/9568 [==============>...............] - ETA: 24s - loss: 0.12854928/9568 [==============>...............] - ETA: 24s - loss: 0.12884992/9568 [==============>...............] - ETA: 23s - loss: 0.12885056/9568 [==============>...............] - ETA: 23s - loss: 0.12875120/9568 [===============>..............] - ETA: 23s - loss: 0.12855184/9568 [===============>..............] - ETA: 22s - loss: 0.12835248/9568 [===============>..............] - ETA: 22s - loss: 0.12815312/9568 [===============>..............] - ETA: 21s - loss: 0.12825376/9568 [===============>..............] - ETA: 21s - loss: 0.12815440/9568 [================>.............] - ETA: 21s - loss: 0.12815504/9568 [================>.............] - ETA: 20s - loss: 0.12795568/9568 [================>.............] - ETA: 20s - loss: 0.12805632/9568 [================>.............] - ETA: 19s - loss: 0.12795696/9568 [================>.............] - ETA: 19s - loss: 0.12775760/9568 [=================>............] - ETA: 19s - loss: 0.12795824/9568 [=================>............] - ETA: 19s - loss: 0.12775888/9568 [=================>............] - ETA: 18s - loss: 0.12765952/9568 [=================>............] - ETA: 18s - loss: 0.12756016/9568 [=================>............] - ETA: 18s - loss: 0.12746080/9568 [==================>...........] - ETA: 17s - loss: 0.12726144/9568 [==================>...........] - ETA: 17s - loss: 0.12726208/9568 [==================>...........] - ETA: 17s - loss: 0.12706272/9568 [==================>...........] - ETA: 16s - loss: 0.12716336/9568 [==================>...........] - ETA: 16s - loss: 0.12706400/9568 [===================>..........] - ETA: 15s - loss: 0.12716464/9568 [===================>..........] - ETA: 15s - loss: 0.12716528/9568 [===================>..........] - ETA: 15s - loss: 0.12706592/9568 [===================>..........] - ETA: 14s - loss: 0.12696656/9568 [===================>..........] - ETA: 14s - loss: 0.12686720/9568 [====================>.........] - ETA: 14s - loss: 0.12686784/9568 [====================>.........] - ETA: 13s - loss: 0.12686848/9568 [====================>.........] - ETA: 13s - loss: 0.12686912/9568 [====================>.........] - ETA: 13s - loss: 0.12686976/9568 [====================>.........] - ETA: 13s - loss: 0.12697040/9568 [=====================>........] - ETA: 12s - loss: 0.12687104/9568 [=====================>........] - ETA: 12s - loss: 0.12687168/9568 [=====================>........] - ETA: 12s - loss: 0.12677232/9568 [=====================>........] - ETA: 11s - loss: 0.12687296/9568 [=====================>........] - ETA: 11s - loss: 0.12677360/9568 [======================>.......] - ETA: 11s - loss: 0.12677424/9568 [======================>.......] - ETA: 10s - loss: 0.12667488/9568 [======================>.......] - ETA: 10s - loss: 0.12657552/9568 [======================>.......] - ETA: 10s - loss: 0.12637616/9568 [======================>.......] - ETA: 9s - loss: 0.1263 7680/9568 [=======================>......] - ETA: 9s - loss: 0.12637744/9568 [=======================>......] - ETA: 9s - loss: 0.12647808/9568 [=======================>......] - ETA: 8s - loss: 0.12637872/9568 [=======================>......] - ETA: 8s - loss: 0.12627936/9568 [=======================>......] - ETA: 8s - loss: 0.12628000/9568 [========================>.....] - ETA: 7s - loss: 0.12618064/9568 [========================>.....] - ETA: 7s - loss: 0.12638128/9568 [========================>.....] - ETA: 7s - loss: 0.12638192/9568 [========================>.....] - ETA: 7s - loss: 0.12628256/9568 [========================>.....] - ETA: 6s - loss: 0.12628320/9568 [=========================>....] - ETA: 6s - loss: 0.12628384/9568 [=========================>....] - ETA: 6s - loss: 0.12618448/9568 [=========================>....] - ETA: 5s - loss: 0.12608512/9568 [=========================>....] - ETA: 5s - loss: 0.12608576/9568 [=========================>....] - ETA: 5s - loss: 0.12608640/9568 [==========================>...] - ETA: 4s - loss: 0.12598704/9568 [==========================>...] - ETA: 4s - loss: 0.12598768/9568 [==========================>...] - ETA: 4s - loss: 0.12598832/9568 [==========================>...] - ETA: 3s - loss: 0.12588896/9568 [==========================>...] - ETA: 3s - loss: 0.12588960/9568 [===========================>..] - ETA: 3s - loss: 0.12599024/9568 [===========================>..] - ETA: 2s - loss: 0.12599088/9568 [===========================>..] - ETA: 2s - loss: 0.12599152/9568 [===========================>..] - ETA: 2s - loss: 0.12589216/9568 [===========================>..] - ETA: 1s - loss: 0.12579280/9568 [============================>.] - ETA: 1s - loss: 0.12579344/9568 [============================>.] - ETA: 1s - loss: 0.12559408/9568 [============================>.] - ETA: 0s - loss: 0.12549472/9568 [============================>.] - ETA: 0s - loss: 0.12579536/9568 [============================>.] - ETA: 0s - loss: 0.1257
Epoch 00013: val_loss improved from 0.15422 to 0.15199, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 52s 5ms/sample - loss: 0.1257 - val_loss: 0.1520
Epoch 14/100
  64/9568 [..............................] - ETA: 53s - loss: 0.1475 128/9568 [..............................] - ETA: 44s - loss: 0.1313 192/9568 [..............................] - ETA: 41s - loss: 0.1255 256/9568 [..............................] - ETA: 44s - loss: 0.1234 320/9568 [>.............................] - ETA: 44s - loss: 0.1219 384/9568 [>.............................] - ETA: 45s - loss: 0.1196 448/9568 [>.............................] - ETA: 44s - loss: 0.1228 512/9568 [>.............................] - ETA: 44s - loss: 0.1223 576/9568 [>.............................] - ETA: 45s - loss: 0.1225 640/9568 [=>............................] - ETA: 43s - loss: 0.1226 704/9568 [=>............................] - ETA: 43s - loss: 0.1221 768/9568 [=>............................] - ETA: 42s - loss: 0.1229 832/9568 [=>............................] - ETA: 41s - loss: 0.1233 896/9568 [=>............................] - ETA: 40s - loss: 0.1232 960/9568 [==>...........................] - ETA: 38s - loss: 0.12221024/9568 [==>...........................] - ETA: 37s - loss: 0.12181088/9568 [==>...........................] - ETA: 36s - loss: 0.12231152/9568 [==>...........................] - ETA: 35s - loss: 0.12211216/9568 [==>...........................] - ETA: 35s - loss: 0.12321280/9568 [===>..........................] - ETA: 34s - loss: 0.12301344/9568 [===>..........................] - ETA: 34s - loss: 0.12291408/9568 [===>..........................] - ETA: 34s - loss: 0.12261472/9568 [===>..........................] - ETA: 34s - loss: 0.12281536/9568 [===>..........................] - ETA: 34s - loss: 0.12291600/9568 [====>.........................] - ETA: 34s - loss: 0.12301664/9568 [====>.........................] - ETA: 34s - loss: 0.12341728/9568 [====>.........................] - ETA: 34s - loss: 0.12351792/9568 [====>.........................] - ETA: 34s - loss: 0.12351856/9568 [====>.........................] - ETA: 33s - loss: 0.12451920/9568 [=====>........................] - ETA: 33s - loss: 0.12421984/9568 [=====>........................] - ETA: 33s - loss: 0.12442048/9568 [=====>........................] - ETA: 33s - loss: 0.12532112/9568 [=====>........................] - ETA: 33s - loss: 0.12512176/9568 [=====>........................] - ETA: 32s - loss: 0.12542240/9568 [======>.......................] - ETA: 32s - loss: 0.12532304/9568 [======>.......................] - ETA: 31s - loss: 0.12532368/9568 [======>.......................] - ETA: 31s - loss: 0.12522432/9568 [======>.......................] - ETA: 31s - loss: 0.12522496/9568 [======>.......................] - ETA: 30s - loss: 0.12512560/9568 [=======>......................] - ETA: 30s - loss: 0.12492624/9568 [=======>......................] - ETA: 30s - loss: 0.12522688/9568 [=======>......................] - ETA: 30s - loss: 0.12532752/9568 [=======>......................] - ETA: 31s - loss: 0.12552816/9568 [=======>......................] - ETA: 31s - loss: 0.12542880/9568 [========>.....................] - ETA: 31s - loss: 0.12512944/9568 [========>.....................] - ETA: 31s - loss: 0.12503008/9568 [========>.....................] - ETA: 31s - loss: 0.12563072/9568 [========>.....................] - ETA: 30s - loss: 0.12543136/9568 [========>.....................] - ETA: 30s - loss: 0.12563200/9568 [=========>....................] - ETA: 30s - loss: 0.12523264/9568 [=========>....................] - ETA: 30s - loss: 0.12523328/9568 [=========>....................] - ETA: 30s - loss: 0.12513392/9568 [=========>....................] - ETA: 30s - loss: 0.12513456/9568 [=========>....................] - ETA: 29s - loss: 0.12533520/9568 [==========>...................] - ETA: 29s - loss: 0.12523584/9568 [==========>...................] - ETA: 28s - loss: 0.12513648/9568 [==========>...................] - ETA: 28s - loss: 0.12523712/9568 [==========>...................] - ETA: 28s - loss: 0.12503776/9568 [==========>...................] - ETA: 28s - loss: 0.12503840/9568 [===========>..................] - ETA: 27s - loss: 0.12513904/9568 [===========>..................] - ETA: 27s - loss: 0.12513968/9568 [===========>..................] - ETA: 27s - loss: 0.12504032/9568 [===========>..................] - ETA: 26s - loss: 0.12504096/9568 [===========>..................] - ETA: 26s - loss: 0.12474160/9568 [============>.................] - ETA: 26s - loss: 0.12514224/9568 [============>.................] - ETA: 26s - loss: 0.12524288/9568 [============>.................] - ETA: 25s - loss: 0.12504352/9568 [============>.................] - ETA: 25s - loss: 0.12524416/9568 [============>.................] - ETA: 25s - loss: 0.12514480/9568 [=============>................] - ETA: 24s - loss: 0.12564544/9568 [=============>................] - ETA: 24s - loss: 0.12554608/9568 [=============>................] - ETA: 23s - loss: 0.12544672/9568 [=============>................] - ETA: 23s - loss: 0.12554736/9568 [=============>................] - ETA: 23s - loss: 0.12564800/9568 [==============>...............] - ETA: 23s - loss: 0.12554864/9568 [==============>...............] - ETA: 23s - loss: 0.12554928/9568 [==============>...............] - ETA: 23s - loss: 0.12554992/9568 [==============>...............] - ETA: 22s - loss: 0.12525056/9568 [==============>...............] - ETA: 22s - loss: 0.12515120/9568 [===============>..............] - ETA: 21s - loss: 0.12495184/9568 [===============>..............] - ETA: 21s - loss: 0.12515248/9568 [===============>..............] - ETA: 21s - loss: 0.12515312/9568 [===============>..............] - ETA: 20s - loss: 0.12525376/9568 [===============>..............] - ETA: 20s - loss: 0.12515440/9568 [================>.............] - ETA: 20s - loss: 0.12515504/9568 [================>.............] - ETA: 19s - loss: 0.12525568/9568 [================>.............] - ETA: 19s - loss: 0.12525632/9568 [================>.............] - ETA: 19s - loss: 0.12535696/9568 [================>.............] - ETA: 19s - loss: 0.12525760/9568 [=================>............] - ETA: 18s - loss: 0.12525824/9568 [=================>............] - ETA: 18s - loss: 0.12495888/9568 [=================>............] - ETA: 17s - loss: 0.12495952/9568 [=================>............] - ETA: 17s - loss: 0.12496016/9568 [=================>............] - ETA: 17s - loss: 0.12486080/9568 [==================>...........] - ETA: 16s - loss: 0.12466144/9568 [==================>...........] - ETA: 16s - loss: 0.12446208/9568 [==================>...........] - ETA: 16s - loss: 0.12446272/9568 [==================>...........] - ETA: 15s - loss: 0.12436336/9568 [==================>...........] - ETA: 15s - loss: 0.12436400/9568 [===================>..........] - ETA: 15s - loss: 0.12446464/9568 [===================>..........] - ETA: 15s - loss: 0.12426528/9568 [===================>..........] - ETA: 14s - loss: 0.12426592/9568 [===================>..........] - ETA: 14s - loss: 0.12406656/9568 [===================>..........] - ETA: 14s - loss: 0.12406720/9568 [====================>.........] - ETA: 13s - loss: 0.12396784/9568 [====================>.........] - ETA: 13s - loss: 0.12396848/9568 [====================>.........] - ETA: 13s - loss: 0.12386912/9568 [====================>.........] - ETA: 12s - loss: 0.12386976/9568 [====================>.........] - ETA: 12s - loss: 0.12387040/9568 [=====================>........] - ETA: 12s - loss: 0.12387104/9568 [=====================>........] - ETA: 11s - loss: 0.12377168/9568 [=====================>........] - ETA: 11s - loss: 0.12367232/9568 [=====================>........] - ETA: 11s - loss: 0.12357296/9568 [=====================>........] - ETA: 10s - loss: 0.12377360/9568 [======================>.......] - ETA: 10s - loss: 0.12367424/9568 [======================>.......] - ETA: 10s - loss: 0.12357488/9568 [======================>.......] - ETA: 9s - loss: 0.1235 7552/9568 [======================>.......] - ETA: 9s - loss: 0.12357616/9568 [======================>.......] - ETA: 9s - loss: 0.12357680/9568 [=======================>......] - ETA: 9s - loss: 0.12337744/9568 [=======================>......] - ETA: 8s - loss: 0.12337808/9568 [=======================>......] - ETA: 8s - loss: 0.12347872/9568 [=======================>......] - ETA: 8s - loss: 0.12327936/9568 [=======================>......] - ETA: 7s - loss: 0.12348000/9568 [========================>.....] - ETA: 7s - loss: 0.12358064/9568 [========================>.....] - ETA: 7s - loss: 0.12368128/9568 [========================>.....] - ETA: 6s - loss: 0.12388192/9568 [========================>.....] - ETA: 6s - loss: 0.12398256/9568 [========================>.....] - ETA: 6s - loss: 0.12388320/9568 [=========================>....] - ETA: 5s - loss: 0.12398384/9568 [=========================>....] - ETA: 5s - loss: 0.12398448/9568 [=========================>....] - ETA: 5s - loss: 0.12418512/9568 [=========================>....] - ETA: 5s - loss: 0.12428576/9568 [=========================>....] - ETA: 4s - loss: 0.12418640/9568 [==========================>...] - ETA: 4s - loss: 0.12418704/9568 [==========================>...] - ETA: 4s - loss: 0.12418768/9568 [==========================>...] - ETA: 3s - loss: 0.12448832/9568 [==========================>...] - ETA: 3s - loss: 0.12458896/9568 [==========================>...] - ETA: 3s - loss: 0.12458960/9568 [===========================>..] - ETA: 2s - loss: 0.12469024/9568 [===========================>..] - ETA: 2s - loss: 0.12459088/9568 [===========================>..] - ETA: 2s - loss: 0.12459152/9568 [===========================>..] - ETA: 2s - loss: 0.12469216/9568 [===========================>..] - ETA: 1s - loss: 0.12459280/9568 [============================>.] - ETA: 1s - loss: 0.12449344/9568 [============================>.] - ETA: 1s - loss: 0.12449408/9568 [============================>.] - ETA: 0s - loss: 0.12439472/9568 [============================>.] - ETA: 0s - loss: 0.12439536/9568 [============================>.] - ETA: 0s - loss: 0.1242
Epoch 00014: val_loss did not improve from 0.15199
9568/9568 [==============================] - 50s 5ms/sample - loss: 0.1241 - val_loss: 0.1538
Epoch 15/100
  64/9568 [..............................] - ETA: 1:22 - loss: 0.1175 128/9568 [..............................] - ETA: 1:12 - loss: 0.1212 192/9568 [..............................] - ETA: 1:02 - loss: 0.1321 256/9568 [..............................] - ETA: 59s - loss: 0.1334  320/9568 [>.............................] - ETA: 58s - loss: 0.1307 384/9568 [>.............................] - ETA: 55s - loss: 0.1279 448/9568 [>.............................] - ETA: 54s - loss: 0.1265 512/9568 [>.............................] - ETA: 53s - loss: 0.1246 576/9568 [>.............................] - ETA: 52s - loss: 0.1229 640/9568 [=>............................] - ETA: 50s - loss: 0.1219 704/9568 [=>............................] - ETA: 51s - loss: 0.1218 768/9568 [=>............................] - ETA: 50s - loss: 0.1210 832/9568 [=>............................] - ETA: 49s - loss: 0.1212 896/9568 [=>............................] - ETA: 47s - loss: 0.1227 960/9568 [==>...........................] - ETA: 45s - loss: 0.12211024/9568 [==>...........................] - ETA: 45s - loss: 0.12161088/9568 [==>...........................] - ETA: 47s - loss: 0.12081152/9568 [==>...........................] - ETA: 47s - loss: 0.12041216/9568 [==>...........................] - ETA: 47s - loss: 0.12191280/9568 [===>..........................] - ETA: 46s - loss: 0.12121344/9568 [===>..........................] - ETA: 44s - loss: 0.12121408/9568 [===>..........................] - ETA: 43s - loss: 0.12071472/9568 [===>..........................] - ETA: 42s - loss: 0.12041536/9568 [===>..........................] - ETA: 42s - loss: 0.12051600/9568 [====>.........................] - ETA: 43s - loss: 0.12061664/9568 [====>.........................] - ETA: 42s - loss: 0.12011728/9568 [====>.........................] - ETA: 41s - loss: 0.12001792/9568 [====>.........................] - ETA: 40s - loss: 0.12021856/9568 [====>.........................] - ETA: 40s - loss: 0.12071920/9568 [=====>........................] - ETA: 40s - loss: 0.12041984/9568 [=====>........................] - ETA: 40s - loss: 0.12052048/9568 [=====>........................] - ETA: 40s - loss: 0.12092112/9568 [=====>........................] - ETA: 40s - loss: 0.12142176/9568 [=====>........................] - ETA: 39s - loss: 0.12112240/9568 [======>.......................] - ETA: 38s - loss: 0.12092304/9568 [======>.......................] - ETA: 38s - loss: 0.12042368/9568 [======>.......................] - ETA: 37s - loss: 0.12042432/9568 [======>.......................] - ETA: 36s - loss: 0.12022496/9568 [======>.......................] - ETA: 36s - loss: 0.12012560/9568 [=======>......................] - ETA: 35s - loss: 0.12012624/9568 [=======>......................] - ETA: 35s - loss: 0.12022688/9568 [=======>......................] - ETA: 35s - loss: 0.12002752/9568 [=======>......................] - ETA: 35s - loss: 0.11992816/9568 [=======>......................] - ETA: 34s - loss: 0.11992880/9568 [========>.....................] - ETA: 33s - loss: 0.11992944/9568 [========>.....................] - ETA: 33s - loss: 0.11963008/9568 [========>.....................] - ETA: 32s - loss: 0.11993072/9568 [========>.....................] - ETA: 32s - loss: 0.11963136/9568 [========>.....................] - ETA: 31s - loss: 0.11933200/9568 [=========>....................] - ETA: 30s - loss: 0.11913264/9568 [=========>....................] - ETA: 30s - loss: 0.11883328/9568 [=========>....................] - ETA: 30s - loss: 0.11933392/9568 [=========>....................] - ETA: 29s - loss: 0.11943456/9568 [=========>....................] - ETA: 29s - loss: 0.11933520/9568 [==========>...................] - ETA: 28s - loss: 0.11923584/9568 [==========>...................] - ETA: 28s - loss: 0.11933648/9568 [==========>...................] - ETA: 27s - loss: 0.11943712/9568 [==========>...................] - ETA: 27s - loss: 0.11933776/9568 [==========>...................] - ETA: 26s - loss: 0.11963840/9568 [===========>..................] - ETA: 26s - loss: 0.11973904/9568 [===========>..................] - ETA: 26s - loss: 0.11993968/9568 [===========>..................] - ETA: 25s - loss: 0.11984032/9568 [===========>..................] - ETA: 25s - loss: 0.11984096/9568 [===========>..................] - ETA: 25s - loss: 0.12014160/9568 [============>.................] - ETA: 25s - loss: 0.12034224/9568 [============>.................] - ETA: 25s - loss: 0.12014288/9568 [============>.................] - ETA: 24s - loss: 0.11994352/9568 [============>.................] - ETA: 24s - loss: 0.12004416/9568 [============>.................] - ETA: 24s - loss: 0.11994480/9568 [=============>................] - ETA: 24s - loss: 0.11974544/9568 [=============>................] - ETA: 23s - loss: 0.12014608/9568 [=============>................] - ETA: 23s - loss: 0.12024672/9568 [=============>................] - ETA: 22s - loss: 0.12014736/9568 [=============>................] - ETA: 22s - loss: 0.12034800/9568 [==============>...............] - ETA: 22s - loss: 0.12044864/9568 [==============>...............] - ETA: 21s - loss: 0.12034928/9568 [==============>...............] - ETA: 21s - loss: 0.12024992/9568 [==============>...............] - ETA: 21s - loss: 0.12025056/9568 [==============>...............] - ETA: 20s - loss: 0.12005120/9568 [===============>..............] - ETA: 20s - loss: 0.11995184/9568 [===============>..............] - ETA: 20s - loss: 0.11975248/9568 [===============>..............] - ETA: 19s - loss: 0.11965312/9568 [===============>..............] - ETA: 19s - loss: 0.11975376/9568 [===============>..............] - ETA: 19s - loss: 0.11965440/9568 [================>.............] - ETA: 19s - loss: 0.11965504/9568 [================>.............] - ETA: 19s - loss: 0.12015568/9568 [================>.............] - ETA: 18s - loss: 0.12005632/9568 [================>.............] - ETA: 18s - loss: 0.12015696/9568 [================>.............] - ETA: 18s - loss: 0.12005760/9568 [=================>............] - ETA: 17s - loss: 0.12005824/9568 [=================>............] - ETA: 17s - loss: 0.12005888/9568 [=================>............] - ETA: 17s - loss: 0.12005952/9568 [=================>............] - ETA: 17s - loss: 0.12006016/9568 [=================>............] - ETA: 16s - loss: 0.12056080/9568 [==================>...........] - ETA: 16s - loss: 0.12056144/9568 [==================>...........] - ETA: 16s - loss: 0.12056208/9568 [==================>...........] - ETA: 15s - loss: 0.12056272/9568 [==================>...........] - ETA: 15s - loss: 0.12036336/9568 [==================>...........] - ETA: 15s - loss: 0.12036400/9568 [===================>..........] - ETA: 14s - loss: 0.12046464/9568 [===================>..........] - ETA: 14s - loss: 0.12036528/9568 [===================>..........] - ETA: 14s - loss: 0.12036592/9568 [===================>..........] - ETA: 14s - loss: 0.12046656/9568 [===================>..........] - ETA: 13s - loss: 0.12046720/9568 [====================>.........] - ETA: 13s - loss: 0.12046784/9568 [====================>.........] - ETA: 13s - loss: 0.12046848/9568 [====================>.........] - ETA: 12s - loss: 0.12036912/9568 [====================>.........] - ETA: 12s - loss: 0.12026976/9568 [====================>.........] - ETA: 12s - loss: 0.12027040/9568 [=====================>........] - ETA: 11s - loss: 0.12027104/9568 [=====================>........] - ETA: 11s - loss: 0.12037168/9568 [=====================>........] - ETA: 11s - loss: 0.12037232/9568 [=====================>........] - ETA: 11s - loss: 0.12047296/9568 [=====================>........] - ETA: 10s - loss: 0.12047360/9568 [======================>.......] - ETA: 10s - loss: 0.12047424/9568 [======================>.......] - ETA: 10s - loss: 0.12047488/9568 [======================>.......] - ETA: 9s - loss: 0.1203 7552/9568 [======================>.......] - ETA: 9s - loss: 0.12047616/9568 [======================>.......] - ETA: 9s - loss: 0.12047680/9568 [=======================>......] - ETA: 9s - loss: 0.12047744/9568 [=======================>......] - ETA: 8s - loss: 0.12047808/9568 [=======================>......] - ETA: 8s - loss: 0.12037872/9568 [=======================>......] - ETA: 8s - loss: 0.12037936/9568 [=======================>......] - ETA: 7s - loss: 0.12058000/9568 [========================>.....] - ETA: 7s - loss: 0.12048064/9568 [========================>.....] - ETA: 7s - loss: 0.12048128/9568 [========================>.....] - ETA: 6s - loss: 0.12038192/9568 [========================>.....] - ETA: 6s - loss: 0.12028256/9568 [========================>.....] - ETA: 6s - loss: 0.12018320/9568 [=========================>....] - ETA: 6s - loss: 0.12008384/9568 [=========================>....] - ETA: 5s - loss: 0.12008448/9568 [=========================>....] - ETA: 5s - loss: 0.11998512/9568 [=========================>....] - ETA: 5s - loss: 0.11998576/9568 [=========================>....] - ETA: 4s - loss: 0.11998640/9568 [==========================>...] - ETA: 4s - loss: 0.11988704/9568 [==========================>...] - ETA: 4s - loss: 0.11978768/9568 [==========================>...] - ETA: 3s - loss: 0.11988832/9568 [==========================>...] - ETA: 3s - loss: 0.11998896/9568 [==========================>...] - ETA: 3s - loss: 0.11998960/9568 [===========================>..] - ETA: 2s - loss: 0.11999024/9568 [===========================>..] - ETA: 2s - loss: 0.11999088/9568 [===========================>..] - ETA: 2s - loss: 0.12019152/9568 [===========================>..] - ETA: 1s - loss: 0.12009216/9568 [===========================>..] - ETA: 1s - loss: 0.12009280/9568 [============================>.] - ETA: 1s - loss: 0.12009344/9568 [============================>.] - ETA: 1s - loss: 0.12009408/9568 [============================>.] - ETA: 0s - loss: 0.11999472/9568 [============================>.] - ETA: 0s - loss: 0.11999536/9568 [============================>.] - ETA: 0s - loss: 0.1198
Epoch 00015: val_loss did not improve from 0.15199
9568/9568 [==============================] - 48s 5ms/sample - loss: 0.1198 - val_loss: 0.1585
Epoch 16/100
  64/9568 [..............................] - ETA: 38s - loss: 0.1195 128/9568 [..............................] - ETA: 42s - loss: 0.1372 192/9568 [..............................] - ETA: 42s - loss: 0.1346 256/9568 [..............................] - ETA: 44s - loss: 0.1311 320/9568 [>.............................] - ETA: 41s - loss: 0.1257 384/9568 [>.............................] - ETA: 39s - loss: 0.1236 448/9568 [>.............................] - ETA: 40s - loss: 0.1214 512/9568 [>.............................] - ETA: 41s - loss: 0.1197 576/9568 [>.............................] - ETA: 39s - loss: 0.1192 640/9568 [=>............................] - ETA: 37s - loss: 0.1174 704/9568 [=>............................] - ETA: 35s - loss: 0.1161 768/9568 [=>............................] - ETA: 34s - loss: 0.1159 832/9568 [=>............................] - ETA: 34s - loss: 0.1150 896/9568 [=>............................] - ETA: 33s - loss: 0.1145 960/9568 [==>...........................] - ETA: 34s - loss: 0.11401024/9568 [==>...........................] - ETA: 34s - loss: 0.11611088/9568 [==>...........................] - ETA: 33s - loss: 0.11611152/9568 [==>...........................] - ETA: 35s - loss: 0.11691216/9568 [==>...........................] - ETA: 37s - loss: 0.11861280/9568 [===>..........................] - ETA: 37s - loss: 0.11811344/9568 [===>..........................] - ETA: 37s - loss: 0.11801408/9568 [===>..........................] - ETA: 36s - loss: 0.11821472/9568 [===>..........................] - ETA: 36s - loss: 0.11761536/9568 [===>..........................] - ETA: 37s - loss: 0.11801600/9568 [====>.........................] - ETA: 38s - loss: 0.11781664/9568 [====>.........................] - ETA: 38s - loss: 0.11751728/9568 [====>.........................] - ETA: 38s - loss: 0.11701792/9568 [====>.........................] - ETA: 37s - loss: 0.11681856/9568 [====>.........................] - ETA: 37s - loss: 0.11681920/9568 [=====>........................] - ETA: 37s - loss: 0.11661984/9568 [=====>........................] - ETA: 37s - loss: 0.11632048/9568 [=====>........................] - ETA: 36s - loss: 0.11622112/9568 [=====>........................] - ETA: 36s - loss: 0.11592176/9568 [=====>........................] - ETA: 35s - loss: 0.11622240/9568 [======>.......................] - ETA: 35s - loss: 0.11622304/9568 [======>.......................] - ETA: 34s - loss: 0.11592368/9568 [======>.......................] - ETA: 34s - loss: 0.11592432/9568 [======>.......................] - ETA: 34s - loss: 0.11552496/9568 [======>.......................] - ETA: 33s - loss: 0.11572560/9568 [=======>......................] - ETA: 33s - loss: 0.11602624/9568 [=======>......................] - ETA: 33s - loss: 0.11602688/9568 [=======>......................] - ETA: 32s - loss: 0.11602752/9568 [=======>......................] - ETA: 32s - loss: 0.11602816/9568 [=======>......................] - ETA: 31s - loss: 0.11612880/9568 [========>.....................] - ETA: 31s - loss: 0.11622944/9568 [========>.....................] - ETA: 30s - loss: 0.11653008/9568 [========>.....................] - ETA: 30s - loss: 0.11663072/9568 [========>.....................] - ETA: 30s - loss: 0.11643136/9568 [========>.....................] - ETA: 30s - loss: 0.11653200/9568 [=========>....................] - ETA: 29s - loss: 0.11633264/9568 [=========>....................] - ETA: 29s - loss: 0.11633328/9568 [=========>....................] - ETA: 28s - loss: 0.11623392/9568 [=========>....................] - ETA: 28s - loss: 0.11623456/9568 [=========>....................] - ETA: 28s - loss: 0.11663520/9568 [==========>...................] - ETA: 27s - loss: 0.11723584/9568 [==========>...................] - ETA: 27s - loss: 0.11723648/9568 [==========>...................] - ETA: 26s - loss: 0.11733712/9568 [==========>...................] - ETA: 26s - loss: 0.11733776/9568 [==========>...................] - ETA: 26s - loss: 0.11733840/9568 [===========>..................] - ETA: 25s - loss: 0.11723904/9568 [===========>..................] - ETA: 25s - loss: 0.11763968/9568 [===========>..................] - ETA: 25s - loss: 0.11774032/9568 [===========>..................] - ETA: 24s - loss: 0.11794096/9568 [===========>..................] - ETA: 24s - loss: 0.11824160/9568 [============>.................] - ETA: 24s - loss: 0.11824224/9568 [============>.................] - ETA: 24s - loss: 0.11854288/9568 [============>.................] - ETA: 24s - loss: 0.11844352/9568 [============>.................] - ETA: 23s - loss: 0.11854416/9568 [============>.................] - ETA: 23s - loss: 0.11844480/9568 [=============>................] - ETA: 23s - loss: 0.11844544/9568 [=============>................] - ETA: 22s - loss: 0.11834608/9568 [=============>................] - ETA: 22s - loss: 0.11814672/9568 [=============>................] - ETA: 22s - loss: 0.11794736/9568 [=============>................] - ETA: 21s - loss: 0.11814800/9568 [==============>...............] - ETA: 21s - loss: 0.11804864/9568 [==============>...............] - ETA: 21s - loss: 0.11814928/9568 [==============>...............] - ETA: 21s - loss: 0.11824992/9568 [==============>...............] - ETA: 21s - loss: 0.11865056/9568 [==============>...............] - ETA: 20s - loss: 0.11875120/9568 [===============>..............] - ETA: 20s - loss: 0.11875184/9568 [===============>..............] - ETA: 19s - loss: 0.11865248/9568 [===============>..............] - ETA: 19s - loss: 0.11855312/9568 [===============>..............] - ETA: 19s - loss: 0.11845376/9568 [===============>..............] - ETA: 19s - loss: 0.11845440/9568 [================>.............] - ETA: 18s - loss: 0.11845504/9568 [================>.............] - ETA: 18s - loss: 0.11855568/9568 [================>.............] - ETA: 17s - loss: 0.11855632/9568 [================>.............] - ETA: 17s - loss: 0.11865696/9568 [================>.............] - ETA: 17s - loss: 0.11855760/9568 [=================>............] - ETA: 17s - loss: 0.11845824/9568 [=================>............] - ETA: 17s - loss: 0.11835888/9568 [=================>............] - ETA: 16s - loss: 0.11835952/9568 [=================>............] - ETA: 16s - loss: 0.11836016/9568 [=================>............] - ETA: 16s - loss: 0.11826080/9568 [==================>...........] - ETA: 15s - loss: 0.11836144/9568 [==================>...........] - ETA: 15s - loss: 0.11836208/9568 [==================>...........] - ETA: 15s - loss: 0.11826272/9568 [==================>...........] - ETA: 14s - loss: 0.11826336/9568 [==================>...........] - ETA: 14s - loss: 0.11816400/9568 [===================>..........] - ETA: 14s - loss: 0.11816464/9568 [===================>..........] - ETA: 14s - loss: 0.11806528/9568 [===================>..........] - ETA: 13s - loss: 0.11796592/9568 [===================>..........] - ETA: 13s - loss: 0.11786656/9568 [===================>..........] - ETA: 13s - loss: 0.11786720/9568 [====================>.........] - ETA: 12s - loss: 0.11786784/9568 [====================>.........] - ETA: 12s - loss: 0.11786848/9568 [====================>.........] - ETA: 12s - loss: 0.11786912/9568 [====================>.........] - ETA: 11s - loss: 0.11776976/9568 [====================>.........] - ETA: 11s - loss: 0.11777040/9568 [=====================>........] - ETA: 11s - loss: 0.11787104/9568 [=====================>........] - ETA: 11s - loss: 0.11777168/9568 [=====================>........] - ETA: 10s - loss: 0.11777232/9568 [=====================>........] - ETA: 10s - loss: 0.11767296/9568 [=====================>........] - ETA: 10s - loss: 0.11767360/9568 [======================>.......] - ETA: 10s - loss: 0.11757424/9568 [======================>.......] - ETA: 9s - loss: 0.1175 7488/9568 [======================>.......] - ETA: 9s - loss: 0.11747552/9568 [======================>.......] - ETA: 9s - loss: 0.11737616/9568 [======================>.......] - ETA: 8s - loss: 0.11717680/9568 [=======================>......] - ETA: 8s - loss: 0.11717744/9568 [=======================>......] - ETA: 8s - loss: 0.11727808/9568 [=======================>......] - ETA: 8s - loss: 0.11747872/9568 [=======================>......] - ETA: 7s - loss: 0.11747936/9568 [=======================>......] - ETA: 7s - loss: 0.11738000/9568 [========================>.....] - ETA: 7s - loss: 0.11768064/9568 [========================>.....] - ETA: 6s - loss: 0.11778128/9568 [========================>.....] - ETA: 6s - loss: 0.11778192/9568 [========================>.....] - ETA: 6s - loss: 0.11768256/9568 [========================>.....] - ETA: 6s - loss: 0.11788320/9568 [=========================>....] - ETA: 5s - loss: 0.11788384/9568 [=========================>....] - ETA: 5s - loss: 0.11788448/9568 [=========================>....] - ETA: 5s - loss: 0.11778512/9568 [=========================>....] - ETA: 4s - loss: 0.11768576/9568 [=========================>....] - ETA: 4s - loss: 0.11768640/9568 [==========================>...] - ETA: 4s - loss: 0.11758704/9568 [==========================>...] - ETA: 3s - loss: 0.11748768/9568 [==========================>...] - ETA: 3s - loss: 0.11758832/9568 [==========================>...] - ETA: 3s - loss: 0.11758896/9568 [==========================>...] - ETA: 3s - loss: 0.11758960/9568 [===========================>..] - ETA: 2s - loss: 0.11759024/9568 [===========================>..] - ETA: 2s - loss: 0.11749088/9568 [===========================>..] - ETA: 2s - loss: 0.11749152/9568 [===========================>..] - ETA: 1s - loss: 0.11769216/9568 [===========================>..] - ETA: 1s - loss: 0.11769280/9568 [============================>.] - ETA: 1s - loss: 0.11779344/9568 [============================>.] - ETA: 1s - loss: 0.11779408/9568 [============================>.] - ETA: 0s - loss: 0.11779472/9568 [============================>.] - ETA: 0s - loss: 0.11769536/9568 [============================>.] - ETA: 0s - loss: 0.1176
Epoch 00016: val_loss did not improve from 0.15199
9568/9568 [==============================] - 48s 5ms/sample - loss: 0.1177 - val_loss: 0.1619
Epoch 00016: early stopping
Cannot load from /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed/tmp, skipping ...
Using cached validation data
  32/2711 [..............................] - ETA: 2s - loss: 0.1387  96/2711 [>.............................] - ETA: 2s - loss: 0.1645 160/2711 [>.............................] - ETA: 2s - loss: 0.1659 192/2711 [=>............................] - ETA: 2s - loss: 0.1764 224/2711 [=>............................] - ETA: 3s - loss: 0.1669 256/2711 [=>............................] - ETA: 3s - loss: 0.1634 320/2711 [==>...........................] - ETA: 3s - loss: 0.1514 352/2711 [==>...........................] - ETA: 4s - loss: 0.1490 416/2711 [===>..........................] - ETA: 4s - loss: 0.1416 448/2711 [===>..........................] - ETA: 4s - loss: 0.1418 480/2711 [====>.........................] - ETA: 4s - loss: 0.1372 512/2711 [====>.........................] - ETA: 4s - loss: 0.1347 544/2711 [=====>........................] - ETA: 4s - loss: 0.1350 608/2711 [=====>........................] - ETA: 4s - loss: 0.1386 640/2711 [======>.......................] - ETA: 4s - loss: 0.1375 672/2711 [======>.......................] - ETA: 4s - loss: 0.1364 736/2711 [=======>......................] - ETA: 4s - loss: 0.1354 768/2711 [=======>......................] - ETA: 4s - loss: 0.1361 832/2711 [========>.....................] - ETA: 3s - loss: 0.1398 864/2711 [========>.....................] - ETA: 3s - loss: 0.1404 896/2711 [========>.....................] - ETA: 3s - loss: 0.1403 960/2711 [=========>....................] - ETA: 3s - loss: 0.13811024/2711 [==========>...................] - ETA: 3s - loss: 0.13961088/2711 [===========>..................] - ETA: 3s - loss: 0.14291120/2711 [===========>..................] - ETA: 3s - loss: 0.14451184/2711 [============>.................] - ETA: 2s - loss: 0.14481248/2711 [============>.................] - ETA: 2s - loss: 0.14291312/2711 [=============>................] - ETA: 2s - loss: 0.14231344/2711 [=============>................] - ETA: 2s - loss: 0.14221408/2711 [==============>...............] - ETA: 2s - loss: 0.14281472/2711 [===============>..............] - ETA: 2s - loss: 0.14301504/2711 [===============>..............] - ETA: 2s - loss: 0.14271568/2711 [================>.............] - ETA: 2s - loss: 0.14191632/2711 [=================>............] - ETA: 1s - loss: 0.14211696/2711 [=================>............] - ETA: 1s - loss: 0.14181760/2711 [==================>...........] - ETA: 1s - loss: 0.14221824/2711 [===================>..........] - ETA: 1s - loss: 0.14211888/2711 [===================>..........] - ETA: 1s - loss: 0.14181920/2711 [====================>.........] - ETA: 1s - loss: 0.14131952/2711 [====================>.........] - ETA: 1s - loss: 0.14171984/2711 [====================>.........] - ETA: 1s - loss: 0.14122016/2711 [=====================>........] - ETA: 1s - loss: 0.14042048/2711 [=====================>........] - ETA: 1s - loss: 0.14262080/2711 [======================>.......] - ETA: 1s - loss: 0.14552144/2711 [======================>.......] - ETA: 0s - loss: 0.14482208/2711 [=======================>......] - ETA: 0s - loss: 0.14392272/2711 [========================>.....] - ETA: 0s - loss: 0.14482336/2711 [========================>.....] - ETA: 0s - loss: 0.14442400/2711 [=========================>....] - ETA: 0s - loss: 0.15422464/2711 [==========================>...] - ETA: 0s - loss: 0.16372528/2711 [==========================>...] - ETA: 0s - loss: 0.16202592/2711 [===========================>..] - ETA: 0s - loss: 0.16322656/2711 [============================>.] - ETA: 0s - loss: 0.16302688/2711 [============================>.] - ETA: 0s - loss: 0.16212711/2711 [==============================] - 4s 2ms/sample - loss: 0.1619
Optimal model found, updating
WARNING:tensorflow:From /opt/BAA/TFT/libs/utils.py:173: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /opt/BAA/TFT/libs/utils.py:173: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /opt/BAA/TFT/libs/utils.py:174: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

Model saved to: /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed/TemporalFusionTransformer.ckpt
*** Running tests ***
2024-12-23 20:51:55.128633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla M10 major: 5 minor: 0 memoryClockRate(GHz): 1.0325
pciBusID: 0000:b2:00.0
2024-12-23 20:51:55.131917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-12-23 20:51:55.135646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-12-23 20:51:55.143974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-12-23 20:51:55.144674: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-12-23 20:51:55.145145: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-12-23 20:51:55.145949: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-12-23 20:51:55.146273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-12-23 20:51:55.159011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-12-23 20:51:55.160288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-23 20:51:55.161472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-23 20:51:55.164913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-12-23 20:51:55.254289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7692 MB memory) -> physical GPU (device: 0, name: Tesla M10, pci bus id: 0000:b2:00.0, compute capability: 5.0)
Resetting temp folder...
*** TemporalFusionTransformer params ***
# dropout_rate = 0.3
# hidden_layer_size = 160
# learning_rate = 0.001
# max_gradient_norm = 0.01
# minibatch_size = 64
# model_folder = /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed
# num_heads = 1
# stack_size = 1
# total_time_steps = 32
# num_encoder_steps = 24
# num_epochs = 100
# early_stopping_patience = 3
# multiprocessing_workers = 5
# column_definition = [('dummy_id', <DataTypes.REAL_VALUED: 0>, <InputTypes.ID: 4>), ('date', <DataTypes.DATE: 2>, <InputTypes.TIME: 5>), ('minute_of_hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('hour_of_day', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('week_of_year', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('month_of_year', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_month', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('Precipitation Duration', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('visitors', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('region', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>)]
# input_size = 9
# output_size = 1
# category_counts = [1]
# input_obs_loc = [7]
# static_input_loc = [8]
# known_regular_inputs = [0, 1, 2, 3, 4, 5, 6]
# known_categorical_inputs = [0]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 9)]      0                                            
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           input_1[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32)]         0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
sequential (Sequential)         (None, 32, 160)      160         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 160)]        0           sequential[1][0]                 
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
flatten (Flatten)               (None, 160)          0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 160)          25760       flatten[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
activation (Activation)         (None, 160)          0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 1, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 160)          25760       activation[0][0]                 
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 1, 160)       0           dense_13[0][0]                   
__________________________________________________________________________________________________
dropout (Dropout)               (None, 160)          0           dense_10[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 1, 160)       25760       activation_2[0][0]               
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 1)            161         dropout[0][0]                    
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 1)            161         dropout[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 1, 160)       0           dense_14[0][0]                   
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 1)            161         flatten[0][0]                    
__________________________________________________________________________________________________
multiply (Multiply)             (None, 1)            0           dense_11[0][0]                   
                                                                 dense_12[0][0]                   
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 1, 160)       25760       dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 1, 160)       25760       dropout_1[0][0]                  
__________________________________________________________________________________________________
add (Add)                       (None, 1)            0           dense_8[0][0]                    
                                                                 multiply[0][0]                   
__________________________________________________________________________________________________
multiply_1 (Multiply)           (None, 1, 160)       0           dense_15[0][0]                   
                                                                 dense_16[0][0]                   
__________________________________________________________________________________________________
layer_normalization (LayerNorma (None, 1)            2           add[0][0]                        
__________________________________________________________________________________________________
add_1 (Add)                     (None, 1, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_1[0][0]                 
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 1)            0           layer_normalization[0][0]        
__________________________________________________________________________________________________
layer_normalization_1 (LayerNor (None, 1, 160)       320         add_1[0][0]                      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 1)]       0           activation_1[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_1[0][0]      
__________________________________________________________________________________________________
multiply_2 (Multiply)           (None, 1, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 160)]        0           multiply_2[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 160)          0           dense_17[0][0]                   
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 8)]      0           input_1[0][0]                    
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 160)          25760       activation_3[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 160)          0           dense_18[0][0]                   
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed (TimeDistribut (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 160)          25760       dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 160)          25760       dropout_2[0][0]                  
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160, 7)] 0           time_distributed_1[0][0]         
                                                                 time_distributed_2[0][0]         
                                                                 time_distributed_3[0][0]         
                                                                 time_distributed_4[0][0]         
                                                                 time_distributed_5[0][0]         
                                                                 time_distributed_6[0][0]         
                                                                 time_distributed_7[0][0]         
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160, 1)] 0           time_distributed[0][0]           
__________________________________________________________________________________________________
multiply_3 (Multiply)           (None, 160)          0           dense_19[0][0]                   
                                                                 dense_20[0][0]                   
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 7)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 1)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_2 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_3[0][0]                 
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 8)] 0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
layer_normalization_2 (LayerNor (None, 160)          320         add_2[0][0]                      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 1280)]   0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_2[0][0]      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160, 7)]  0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, 24, 160)      204960      tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, 1, 160)       25600       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 1120)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_2[0][0]      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           time_distributed_9[0][0]         
                                                                 time_distributed_10[0][0]        
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_47 (TimeDistri (None, 8, 160)       179360      tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_48 (TimeDistri (None, 1, 160)       25600       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_14 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_18 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_22 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_26 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_30 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_34 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_38 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_42 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           time_distributed_47[0][0]        
                                                                 time_distributed_48[0][0]        
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, 24, 160)      25760       activation_7[0][0]               
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 24, 160)      0           time_distributed_14[0][0]        
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 24, 160)      0           time_distributed_18[0][0]        
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 24, 160)      0           time_distributed_22[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 160)      0           time_distributed_26[0][0]        
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 24, 160)      0           time_distributed_30[0][0]        
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 24, 160)      0           time_distributed_34[0][0]        
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 24, 160)      0           time_distributed_38[0][0]        
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 24, 160)      0           time_distributed_42[0][0]        
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_52 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_56 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_60 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_64 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_68 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_72 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_76 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 160)      0           time_distributed_11[0][0]        
__________________________________________________________________________________________________
time_distributed_15 (TimeDistri (None, 24, 160)      25760       activation_9[0][0]               
__________________________________________________________________________________________________
time_distributed_19 (TimeDistri (None, 24, 160)      25760       activation_10[0][0]              
__________________________________________________________________________________________________
time_distributed_23 (TimeDistri (None, 24, 160)      25760       activation_11[0][0]              
__________________________________________________________________________________________________
time_distributed_27 (TimeDistri (None, 24, 160)      25760       activation_12[0][0]              
__________________________________________________________________________________________________
time_distributed_31 (TimeDistri (None, 24, 160)      25760       activation_13[0][0]              
__________________________________________________________________________________________________
time_distributed_35 (TimeDistri (None, 24, 160)      25760       activation_14[0][0]              
__________________________________________________________________________________________________
time_distributed_39 (TimeDistri (None, 24, 160)      25760       activation_15[0][0]              
__________________________________________________________________________________________________
time_distributed_43 (TimeDistri (None, 24, 160)      25760       activation_16[0][0]              
__________________________________________________________________________________________________
time_distributed_49 (TimeDistri (None, 8, 160)       25760       activation_17[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 160)       0           time_distributed_52[0][0]        
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 160)       0           time_distributed_56[0][0]        
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 160)       0           time_distributed_60[0][0]        
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 160)       0           time_distributed_64[0][0]        
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 160)       0           time_distributed_68[0][0]        
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 160)       0           time_distributed_72[0][0]        
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 160)       0           time_distributed_76[0][0]        
__________________________________________________________________________________________________
time_distributed_12 (TimeDistri (None, 24, 8)        1288        dropout_6[0][0]                  
__________________________________________________________________________________________________
time_distributed_13 (TimeDistri (None, 24, 8)        1288        dropout_6[0][0]                  
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 160)      0           time_distributed_15[0][0]        
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 160)      0           time_distributed_19[0][0]        
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 160)      0           time_distributed_23[0][0]        
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 160)      0           time_distributed_27[0][0]        
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 160)      0           time_distributed_31[0][0]        
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 160)      0           time_distributed_35[0][0]        
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 24, 160)      0           time_distributed_39[0][0]        
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 24, 160)      0           time_distributed_43[0][0]        
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 8, 160)       0           time_distributed_49[0][0]        
__________________________________________________________________________________________________
time_distributed_53 (TimeDistri (None, 8, 160)       25760       activation_19[0][0]              
__________________________________________________________________________________________________
time_distributed_57 (TimeDistri (None, 8, 160)       25760       activation_20[0][0]              
__________________________________________________________________________________________________
time_distributed_61 (TimeDistri (None, 8, 160)       25760       activation_21[0][0]              
__________________________________________________________________________________________________
time_distributed_65 (TimeDistri (None, 8, 160)       25760       activation_22[0][0]              
__________________________________________________________________________________________________
time_distributed_69 (TimeDistri (None, 8, 160)       25760       activation_23[0][0]              
__________________________________________________________________________________________________
time_distributed_73 (TimeDistri (None, 8, 160)       25760       activation_24[0][0]              
__________________________________________________________________________________________________
time_distributed_77 (TimeDistri (None, 8, 160)       25760       activation_25[0][0]              
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, 24, 8)        10248       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
multiply_7 (Multiply)           (None, 24, 8)        0           time_distributed_12[0][0]        
                                                                 time_distributed_13[0][0]        
__________________________________________________________________________________________________
time_distributed_16 (TimeDistri (None, 24, 160)      25760       dropout_7[0][0]                  
__________________________________________________________________________________________________
time_distributed_17 (TimeDistri (None, 24, 160)      25760       dropout_7[0][0]                  
__________________________________________________________________________________________________
time_distributed_20 (TimeDistri (None, 24, 160)      25760       dropout_8[0][0]                  
__________________________________________________________________________________________________
time_distributed_21 (TimeDistri (None, 24, 160)      25760       dropout_8[0][0]                  
__________________________________________________________________________________________________
time_distributed_24 (TimeDistri (None, 24, 160)      25760       dropout_9[0][0]                  
__________________________________________________________________________________________________
time_distributed_25 (TimeDistri (None, 24, 160)      25760       dropout_9[0][0]                  
__________________________________________________________________________________________________
time_distributed_28 (TimeDistri (None, 24, 160)      25760       dropout_10[0][0]                 
__________________________________________________________________________________________________
time_distributed_29 (TimeDistri (None, 24, 160)      25760       dropout_10[0][0]                 
__________________________________________________________________________________________________
time_distributed_32 (TimeDistri (None, 24, 160)      25760       dropout_11[0][0]                 
__________________________________________________________________________________________________
time_distributed_33 (TimeDistri (None, 24, 160)      25760       dropout_11[0][0]                 
__________________________________________________________________________________________________
time_distributed_36 (TimeDistri (None, 24, 160)      25760       dropout_12[0][0]                 
__________________________________________________________________________________________________
time_distributed_37 (TimeDistri (None, 24, 160)      25760       dropout_12[0][0]                 
__________________________________________________________________________________________________
time_distributed_40 (TimeDistri (None, 24, 160)      25760       dropout_13[0][0]                 
__________________________________________________________________________________________________
time_distributed_41 (TimeDistri (None, 24, 160)      25760       dropout_13[0][0]                 
__________________________________________________________________________________________________
time_distributed_44 (TimeDistri (None, 24, 160)      25760       dropout_14[0][0]                 
__________________________________________________________________________________________________
time_distributed_45 (TimeDistri (None, 24, 160)      25760       dropout_14[0][0]                 
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 160)          0           dense_25[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 160)          0           dense_29[0][0]                   
__________________________________________________________________________________________________
time_distributed_50 (TimeDistri (None, 8, 7)         1127        dropout_15[0][0]                 
__________________________________________________________________________________________________
time_distributed_51 (TimeDistri (None, 8, 7)         1127        dropout_15[0][0]                 
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 8, 160)       0           time_distributed_53[0][0]        
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 8, 160)       0           time_distributed_57[0][0]        
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 8, 160)       0           time_distributed_61[0][0]        
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 8, 160)       0           time_distributed_65[0][0]        
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, 8, 160)       0           time_distributed_69[0][0]        
__________________________________________________________________________________________________
dropout_21 (Dropout)            (None, 8, 160)       0           time_distributed_73[0][0]        
__________________________________________________________________________________________________
dropout_22 (Dropout)            (None, 8, 160)       0           time_distributed_77[0][0]        
__________________________________________________________________________________________________
add_6 (Add)                     (None, 24, 8)        0           time_distributed_8[0][0]         
                                                                 multiply_7[0][0]                 
__________________________________________________________________________________________________
multiply_8 (Multiply)           (None, 24, 160)      0           time_distributed_16[0][0]        
                                                                 time_distributed_17[0][0]        
__________________________________________________________________________________________________
multiply_9 (Multiply)           (None, 24, 160)      0           time_distributed_20[0][0]        
                                                                 time_distributed_21[0][0]        
__________________________________________________________________________________________________
multiply_10 (Multiply)          (None, 24, 160)      0           time_distributed_24[0][0]        
                                                                 time_distributed_25[0][0]        
__________________________________________________________________________________________________
multiply_11 (Multiply)          (None, 24, 160)      0           time_distributed_28[0][0]        
                                                                 time_distributed_29[0][0]        
__________________________________________________________________________________________________
multiply_12 (Multiply)          (None, 24, 160)      0           time_distributed_32[0][0]        
                                                                 time_distributed_33[0][0]        
__________________________________________________________________________________________________
multiply_13 (Multiply)          (None, 24, 160)      0           time_distributed_36[0][0]        
                                                                 time_distributed_37[0][0]        
__________________________________________________________________________________________________
multiply_14 (Multiply)          (None, 24, 160)      0           time_distributed_40[0][0]        
                                                                 time_distributed_41[0][0]        
__________________________________________________________________________________________________
multiply_15 (Multiply)          (None, 24, 160)      0           time_distributed_44[0][0]        
                                                                 time_distributed_45[0][0]        
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 160)          25760       activation_5[0][0]               
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 160)          25760       activation_6[0][0]               
__________________________________________________________________________________________________
time_distributed_46 (TimeDistri (None, 8, 7)         7847        tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
multiply_17 (Multiply)          (None, 8, 7)         0           time_distributed_50[0][0]        
                                                                 time_distributed_51[0][0]        
__________________________________________________________________________________________________
time_distributed_54 (TimeDistri (None, 8, 160)       25760       dropout_16[0][0]                 
__________________________________________________________________________________________________
time_distributed_55 (TimeDistri (None, 8, 160)       25760       dropout_16[0][0]                 
__________________________________________________________________________________________________
time_distributed_58 (TimeDistri (None, 8, 160)       25760       dropout_17[0][0]                 
__________________________________________________________________________________________________
time_distributed_59 (TimeDistri (None, 8, 160)       25760       dropout_17[0][0]                 
__________________________________________________________________________________________________
time_distributed_62 (TimeDistri (None, 8, 160)       25760       dropout_18[0][0]                 
__________________________________________________________________________________________________
time_distributed_63 (TimeDistri (None, 8, 160)       25760       dropout_18[0][0]                 
__________________________________________________________________________________________________
time_distributed_66 (TimeDistri (None, 8, 160)       25760       dropout_19[0][0]                 
__________________________________________________________________________________________________
time_distributed_67 (TimeDistri (None, 8, 160)       25760       dropout_19[0][0]                 
__________________________________________________________________________________________________
time_distributed_70 (TimeDistri (None, 8, 160)       25760       dropout_20[0][0]                 
__________________________________________________________________________________________________
time_distributed_71 (TimeDistri (None, 8, 160)       25760       dropout_20[0][0]                 
__________________________________________________________________________________________________
time_distributed_74 (TimeDistri (None, 8, 160)       25760       dropout_21[0][0]                 
__________________________________________________________________________________________________
time_distributed_75 (TimeDistri (None, 8, 160)       25760       dropout_21[0][0]                 
__________________________________________________________________________________________________
time_distributed_78 (TimeDistri (None, 8, 160)       25760       dropout_22[0][0]                 
__________________________________________________________________________________________________
time_distributed_79 (TimeDistri (None, 8, 160)       25760       dropout_22[0][0]                 
__________________________________________________________________________________________________
layer_normalization_6 (LayerNor (None, 24, 8)        16          add_6[0][0]                      
__________________________________________________________________________________________________
add_7 (Add)                     (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_8[0][0]                 
__________________________________________________________________________________________________
add_8 (Add)                     (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_9[0][0]                 
__________________________________________________________________________________________________
add_9 (Add)                     (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_10[0][0]                
__________________________________________________________________________________________________
add_10 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_11[0][0]                
__________________________________________________________________________________________________
add_11 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_12[0][0]                
__________________________________________________________________________________________________
add_12 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_13[0][0]                
__________________________________________________________________________________________________
add_13 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_14[0][0]                
__________________________________________________________________________________________________
add_14 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_15[0][0]                
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 160)          0           dense_26[0][0]                   
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 160)          0           dense_30[0][0]                   
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 7)         0           time_distributed_46[0][0]        
                                                                 multiply_17[0][0]                
__________________________________________________________________________________________________
multiply_18 (Multiply)          (None, 8, 160)       0           time_distributed_54[0][0]        
                                                                 time_distributed_55[0][0]        
__________________________________________________________________________________________________
multiply_19 (Multiply)          (None, 8, 160)       0           time_distributed_58[0][0]        
                                                                 time_distributed_59[0][0]        
__________________________________________________________________________________________________
multiply_20 (Multiply)          (None, 8, 160)       0           time_distributed_62[0][0]        
                                                                 time_distributed_63[0][0]        
__________________________________________________________________________________________________
multiply_21 (Multiply)          (None, 8, 160)       0           time_distributed_66[0][0]        
                                                                 time_distributed_67[0][0]        
__________________________________________________________________________________________________
multiply_22 (Multiply)          (None, 8, 160)       0           time_distributed_70[0][0]        
                                                                 time_distributed_71[0][0]        
__________________________________________________________________________________________________
multiply_23 (Multiply)          (None, 8, 160)       0           time_distributed_74[0][0]        
                                                                 time_distributed_75[0][0]        
__________________________________________________________________________________________________
multiply_24 (Multiply)          (None, 8, 160)       0           time_distributed_78[0][0]        
                                                                 time_distributed_79[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 8)        0           layer_normalization_6[0][0]      
__________________________________________________________________________________________________
layer_normalization_7 (LayerNor (None, 24, 160)      320         add_7[0][0]                      
__________________________________________________________________________________________________
layer_normalization_8 (LayerNor (None, 24, 160)      320         add_8[0][0]                      
__________________________________________________________________________________________________
layer_normalization_9 (LayerNor (None, 24, 160)      320         add_9[0][0]                      
__________________________________________________________________________________________________
layer_normalization_10 (LayerNo (None, 24, 160)      320         add_10[0][0]                     
__________________________________________________________________________________________________
layer_normalization_11 (LayerNo (None, 24, 160)      320         add_11[0][0]                     
__________________________________________________________________________________________________
layer_normalization_12 (LayerNo (None, 24, 160)      320         add_12[0][0]                     
__________________________________________________________________________________________________
layer_normalization_13 (LayerNo (None, 24, 160)      320         add_13[0][0]                     
__________________________________________________________________________________________________
layer_normalization_14 (LayerNo (None, 24, 160)      320         add_14[0][0]                     
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 160)          25760       dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 160)          25760       dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 160)          25760       dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 160)          25760       dropout_5[0][0]                  
__________________________________________________________________________________________________
layer_normalization_15 (LayerNo (None, 8, 7)         14          add_15[0][0]                     
__________________________________________________________________________________________________
add_16 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_18[0][0]                
__________________________________________________________________________________________________
add_17 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_19[0][0]                
__________________________________________________________________________________________________
add_18 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_20[0][0]                
__________________________________________________________________________________________________
add_19 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_21[0][0]                
__________________________________________________________________________________________________
add_20 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_22[0][0]                
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_23[0][0]                
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_24[0][0]                
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 1, 8)]   0           activation_8[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 8)] 0           layer_normalization_7[0][0]      
                                                                 layer_normalization_8[0][0]      
                                                                 layer_normalization_9[0][0]      
                                                                 layer_normalization_10[0][0]     
                                                                 layer_normalization_11[0][0]     
                                                                 layer_normalization_12[0][0]     
                                                                 layer_normalization_13[0][0]     
                                                                 layer_normalization_14[0][0]     
__________________________________________________________________________________________________
multiply_5 (Multiply)           (None, 160)          0           dense_27[0][0]                   
                                                                 dense_28[0][0]                   
__________________________________________________________________________________________________
multiply_6 (Multiply)           (None, 160)          0           dense_31[0][0]                   
                                                                 dense_32[0][0]                   
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 7)         0           layer_normalization_15[0][0]     
__________________________________________________________________________________________________
layer_normalization_16 (LayerNo (None, 8, 160)       320         add_16[0][0]                     
__________________________________________________________________________________________________
layer_normalization_17 (LayerNo (None, 8, 160)       320         add_17[0][0]                     
__________________________________________________________________________________________________
layer_normalization_18 (LayerNo (None, 8, 160)       320         add_18[0][0]                     
__________________________________________________________________________________________________
layer_normalization_19 (LayerNo (None, 8, 160)       320         add_19[0][0]                     
__________________________________________________________________________________________________
layer_normalization_20 (LayerNo (None, 8, 160)       320         add_20[0][0]                     
__________________________________________________________________________________________________
layer_normalization_21 (LayerNo (None, 8, 160)       320         add_21[0][0]                     
__________________________________________________________________________________________________
layer_normalization_22 (LayerNo (None, 8, 160)       320         add_22[0][0]                     
__________________________________________________________________________________________________
multiply_16 (Multiply)          (None, 24, 160, 8)   0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_4 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_5[0][0]                 
__________________________________________________________________________________________________
add_5 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_6[0][0]                 
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 1, 7)]    0           activation_18[0][0]              
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160, 7)]  0           layer_normalization_16[0][0]     
                                                                 layer_normalization_17[0][0]     
                                                                 layer_normalization_18[0][0]     
                                                                 layer_normalization_19[0][0]     
                                                                 layer_normalization_20[0][0]     
                                                                 layer_normalization_21[0][0]     
                                                                 layer_normalization_22[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           multiply_16[0][0]                
__________________________________________________________________________________________________
layer_normalization_4 (LayerNor (None, 160)          320         add_4[0][0]                      
__________________________________________________________________________________________________
layer_normalization_5 (LayerNor (None, 160)          320         add_5[0][0]                      
__________________________________________________________________________________________________
multiply_25 (Multiply)          (None, 8, 160, 7)    0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
cu_dnnlstm (CuDNNLSTM)          [(None, 24, 160), (N 206080      tf_op_layer_TemporalFusionTransfo
                                                                 layer_normalization_4[0][0]      
                                                                 layer_normalization_5[0][0]      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           multiply_25[0][0]                
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 160)          0           dense_21[0][0]                   
__________________________________________________________________________________________________
cu_dnnlstm_1 (CuDNNLSTM)        (None, 8, 160)       206080      tf_op_layer_TemporalFusionTransfo
                                                                 cu_dnnlstm[0][1]                 
                                                                 cu_dnnlstm[0][2]                 
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 160)          25760       activation_4[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160)]    0           cu_dnnlstm[0][0]                 
                                                                 cu_dnnlstm_1[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 160)          0           dense_22[0][0]                   
__________________________________________________________________________________________________
dropout_23 (Dropout)            (None, 32, 160)      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 160)          25760       dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 160)          25760       dropout_3[0][0]                  
__________________________________________________________________________________________________
time_distributed_80 (TimeDistri (None, 32, 160)      25760       dropout_23[0][0]                 
__________________________________________________________________________________________________
time_distributed_81 (TimeDistri (None, 32, 160)      25760       dropout_23[0][0]                 
__________________________________________________________________________________________________
multiply_4 (Multiply)           (None, 160)          0           dense_23[0][0]                   
                                                                 dense_24[0][0]                   
__________________________________________________________________________________________________
multiply_26 (Multiply)          (None, 32, 160)      0           time_distributed_80[0][0]        
                                                                 time_distributed_81[0][0]        
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160)]    0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_3 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_4[0][0]                 
__________________________________________________________________________________________________
add_23 (Add)                    (None, 32, 160)      0           multiply_26[0][0]                
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
layer_normalization_3 (LayerNor (None, 160)          320         add_3[0][0]                      
__________________________________________________________________________________________________
layer_normalization_23 (LayerNo (None, 32, 160)      320         add_23[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_3[0][0]      
__________________________________________________________________________________________________
time_distributed_82 (TimeDistri (None, 32, 160)      25760       layer_normalization_23[0][0]     
__________________________________________________________________________________________________
time_distributed_83 (TimeDistri (None, 1, 160)       25600       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160)]    0           time_distributed_82[0][0]        
                                                                 time_distributed_83[0][0]        
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 32, 160)      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_84 (TimeDistri (None, 32, 160)      25760       activation_26[0][0]              
__________________________________________________________________________________________________
dropout_24 (Dropout)            (None, 32, 160)      0           time_distributed_84[0][0]        
__________________________________________________________________________________________________
time_distributed_85 (TimeDistri (None, 32, 160)      25760       dropout_24[0][0]                 
__________________________________________________________________________________________________
time_distributed_86 (TimeDistri (None, 32, 160)      25760       dropout_24[0][0]                 
__________________________________________________________________________________________________
multiply_27 (Multiply)          (None, 32, 160)      0           time_distributed_85[0][0]        
                                                                 time_distributed_86[0][0]        
__________________________________________________________________________________________________
add_24 (Add)                    (None, 32, 160)      0           layer_normalization_23[0][0]     
                                                                 multiply_27[0][0]                
__________________________________________________________________________________________________
layer_normalization_24 (LayerNo (None, 32, 160)      320         add_24[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(3,)]               0           layer_normalization_24[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [()]                 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(3,)]               0           layer_normalization_24[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [()]                 0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(1,)]               0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(1,)]               0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(2,)]               0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, None)]       0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, None, None)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 32, 160)      25600       layer_normalization_24[0][0]     
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 32, 160)      25600       layer_normalization_24[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, None, None)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 32, 32)       0           dense_113[0][0]                  
                                                                 dense_114[0][0]                  
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, None, None)   0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_25 (Add)                    (None, 32, 32)       0           lambda[0][0]                     
                                                                 lambda_1[0][0]                   
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 32, 32)       0           add_25[0][0]                     
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 32, 32)       0           activation_27[0][0]              
__________________________________________________________________________________________________
dense_112 (Dense)               (None, 32, 160)      25600       layer_normalization_24[0][0]     
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 32, 160)      0           dropout_25[0][0]                 
                                                                 dense_112[0][0]                  
__________________________________________________________________________________________________
dropout_26 (Dropout)            (None, 32, 160)      0           lambda_2[0][0]                   
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 32, 160)      25600       dropout_26[0][0]                 
__________________________________________________________________________________________________
dropout_27 (Dropout)            (None, 32, 160)      0           dense_115[0][0]                  
__________________________________________________________________________________________________
dropout_28 (Dropout)            (None, 32, 160)      0           dropout_27[0][0]                 
__________________________________________________________________________________________________
time_distributed_87 (TimeDistri (None, 32, 160)      25760       dropout_28[0][0]                 
__________________________________________________________________________________________________
time_distributed_88 (TimeDistri (None, 32, 160)      25760       dropout_28[0][0]                 
__________________________________________________________________________________________________
multiply_28 (Multiply)          (None, 32, 160)      0           time_distributed_87[0][0]        
                                                                 time_distributed_88[0][0]        
__________________________________________________________________________________________________
add_26 (Add)                    (None, 32, 160)      0           multiply_28[0][0]                
                                                                 layer_normalization_24[0][0]     
__________________________________________________________________________________________________
layer_normalization_25 (LayerNo (None, 32, 160)      320         add_26[0][0]                     
__________________________________________________________________________________________________
time_distributed_89 (TimeDistri (None, 32, 160)      25760       layer_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 32, 160)      0           time_distributed_89[0][0]        
__________________________________________________________________________________________________
time_distributed_90 (TimeDistri (None, 32, 160)      25760       activation_28[0][0]              
__________________________________________________________________________________________________
dropout_29 (Dropout)            (None, 32, 160)      0           time_distributed_90[0][0]        
__________________________________________________________________________________________________
time_distributed_91 (TimeDistri (None, 32, 160)      25760       dropout_29[0][0]                 
__________________________________________________________________________________________________
time_distributed_92 (TimeDistri (None, 32, 160)      25760       dropout_29[0][0]                 
__________________________________________________________________________________________________
multiply_29 (Multiply)          (None, 32, 160)      0           time_distributed_91[0][0]        
                                                                 time_distributed_92[0][0]        
__________________________________________________________________________________________________
add_27 (Add)                    (None, 32, 160)      0           layer_normalization_25[0][0]     
                                                                 multiply_29[0][0]                
__________________________________________________________________________________________________
layer_normalization_26 (LayerNo (None, 32, 160)      320         add_27[0][0]                     
__________________________________________________________________________________________________
time_distributed_93 (TimeDistri (None, 32, 160)      25760       layer_normalization_26[0][0]     
__________________________________________________________________________________________________
time_distributed_94 (TimeDistri (None, 32, 160)      25760       layer_normalization_26[0][0]     
__________________________________________________________________________________________________
multiply_30 (Multiply)          (None, 32, 160)      0           time_distributed_93[0][0]        
                                                                 time_distributed_94[0][0]        
__________________________________________________________________________________________________
add_28 (Add)                    (None, 32, 160)      0           multiply_30[0][0]                
                                                                 layer_normalization_23[0][0]     
__________________________________________________________________________________________________
layer_normalization_27 (LayerNo (None, 32, 160)      320         add_28[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           layer_normalization_27[0][0]     
__________________________________________________________________________________________________
time_distributed_95 (TimeDistri (None, 8, 3)         483         tf_op_layer_TemporalFusionTransfo
==================================================================================================
Total params: 3,534,803
Trainable params: 3,534,803
Non-trainable params: 0
__________________________________________________________________________________________________
None
Loading model from /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed/TemporalFusionTransformer.ckpt
tensor_name:  TemporalFusionTransformer/cu_dnnlstm/bias
[0.05885702 0.00192912 0.03149243 ... 0.0277706  0.01126425 0.00706575]
tensor_name:  TemporalFusionTransformer/cu_dnnlstm/kernel
[[ 0.00167706 -0.02888612 -0.07398848 ... -0.14946505  0.04595786
   0.23005597]
 [ 0.00985879 -0.07592117  0.0139452  ... -0.01736646  0.01769915
  -0.04467985]
 [ 0.10909189 -0.04129439  0.0161266  ... -0.05869312  0.06015863
  -0.06080863]
 ...
 [ 0.0895818  -0.01010847  0.06085191 ... -0.02794878  0.2636785
   0.02073093]
 [ 0.02327269 -0.00941504  0.01732354 ...  0.06715667  0.1478615
  -0.09126383]
 [-0.07185182  0.00768186  0.04782503 ...  0.08809163  0.0443568
   0.02815444]]
tensor_name:  TemporalFusionTransformer/cu_dnnlstm/recurrent_kernel
[[ 0.00946168 -0.00866132  0.05997617 ... -0.08761999  0.00985809
  -0.1153173 ]
 [-0.00237667 -0.05314063 -0.03614016 ... -0.00309081 -0.05379777
  -0.10493657]
 [-0.10553337  0.07522567 -0.00405387 ... -0.06158578 -0.07879864
  -0.09757494]
 ...
 [-0.04016227  0.00940893 -0.05957895 ...  0.02026873 -0.04761871
   0.13621189]
 [-0.17407027  0.16481149 -0.00332485 ...  0.01110149 -0.0297294
   0.01283444]
 [-0.0481886  -0.00603438 -0.02146239 ...  0.03518774 -0.02607763
   0.01360997]]
tensor_name:  TemporalFusionTransformer/cu_dnnlstm_1/bias
[-0.00778743 -0.01112121 -0.01376002 ... -0.02827872  0.02374495
  0.00530256]
tensor_name:  TemporalFusionTransformer/cu_dnnlstm_1/kernel
[[ 0.06305395 -0.02535732  0.02057783 ...  0.02373539  0.11367036
  -0.02495812]
 [-0.03065175  0.01089652 -0.01516341 ...  0.03453453 -0.03555375
  -0.04118426]
 [ 0.084562   -0.12635903 -0.09570441 ... -0.06824017  0.10141447
  -0.03130382]
 ...
 [-0.03102591  0.02594646 -0.06540868 ... -0.01867605 -0.05276379
  -0.06268099]
 [-0.04126848 -0.11396684 -0.09003442 ... -0.10399803 -0.04562325
  -0.09262006]
 [ 0.01633488 -0.0382482   0.06319074 ... -0.02888192 -0.04296586
  -0.01307754]]
tensor_name:  TemporalFusionTransformer/cu_dnnlstm_1/recurrent_kernel
[[ 0.12752545 -0.02687594  0.0400101  ...  0.04046494  0.00926566
  -0.03974913]
 [ 0.08455991  0.07467029 -0.09216198 ...  0.02581784  0.09924988
  -0.05934387]
 [ 0.06498076 -0.16541564 -0.00131233 ... -0.01746507  0.01678254
  -0.05392901]
 ...
 [ 0.06252454  0.11003604 -0.0115315  ... -0.11854664  0.00695179
  -0.06782122]
 [ 0.03150696 -0.19783321 -0.13365456 ... -0.05573049 -0.07809726
  -0.10923697]
 [-0.01371662 -0.08789495  0.02412319 ...  0.0051601   0.09627491
   0.06330878]]
tensor_name:  TemporalFusionTransformer/dense_10/bias
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
tensor_name:  TemporalFusionTransformer/dense_10/kernel
[[ 0.12635115  0.06337725  0.10214809 ... -0.04678428  0.06844848
  -0.12905373]
 [-0.04842158 -0.05553076  0.08292629 ... -0.05056182  0.11810505
  -0.10768306]
 [-0.031059    0.1034469  -0.13477    ... -0.13567698  0.03273404
  -0.03796177]
 ...
 [-0.07262021  0.00778604 -0.10969674 ...  0.11584073 -0.10274493
   0.06777929]
 [-0.13179794  0.12084678  0.04583105 ...  0.13116118  0.08362147
  -0.08833936]
 [ 0.06131953  0.11363384  0.08943075 ...  0.0760943   0.09056777
  -0.08433102]]
tensor_name:  TemporalFusionTransformer/dense_11/bias
[0.]
tensor_name:  TemporalFusionTransformer/dense_11/kernel
[[-0.05396824]
 [ 0.12208673]
 [ 0.17129263]
 [ 0.06962129]
 [-0.11524922]
 [-0.18749814]
 [ 0.03371654]
 [ 0.12700355]
 [-0.00422652]
 [ 0.12268168]
 [ 0.19043031]
 [-0.13795635]
 [ 0.13418311]
 [ 0.1355736 ]
 [ 0.12786755]
 [-0.11768712]
 [ 0.14626709]
 [-0.18451396]
 [-0.17121981]
 [ 0.07596639]
 [ 0.14476949]
 [ 0.04580577]
 [ 0.02973351]
 [-0.03794609]
 [-0.02160066]
 [-0.11758163]
 [ 0.14008343]
 [ 0.07248926]
 [-0.18731113]
 [-0.0771945 ]
 [-0.09835608]
 [-0.16135623]
 [ 0.09143314]
 [ 0.00391069]
 [ 0.1146715 ]
 [ 0.07363895]
 [ 0.0182799 ]
 [ 0.04224063]
 [-0.10194049]
 [ 0.04914458]
 [ 0.05473733]
 [-0.10564912]
 [-0.09022182]
 [-0.18332505]
 [ 0.01683983]
 [ 0.16317683]
 [-0.01480065]
 [ 0.0475298 ]
 [-0.05460694]
 [ 0.04686192]
 [-0.13711292]
 [-0.01101415]
 [ 0.00953856]
 [ 0.02752118]
 [ 0.09295782]
 [ 0.0513258 ]
 [ 0.05040316]
 [ 0.0521335 ]
 [-0.00040637]
 [-0.04795927]
 [ 0.12439278]
 [ 0.0206849 ]
 [ 0.01460914]
 [ 0.1687442 ]
 [ 0.10639825]
 [-0.08547816]
 [-0.07205823]
 [-0.16445634]
 [ 0.05222662]
 [ 0.13044685]
 [-0.03116067]
 [ 0.17632008]
 [-0.09050916]
 [-0.06740308]
 [ 0.1423068 ]
 [-0.09159837]
 [-0.05268742]
 [ 0.10470936]
 [ 0.00988269]
 [-0.09968669]
 [-0.17779268]
 [-0.02491675]
 [-0.03508002]
 [-0.03993174]
 [ 0.04338576]
 [ 0.05130339]
 [ 0.14397374]
 [-0.04818343]
 [-0.0168536 ]
 [-0.15124506]
 [-0.02148409]
 [ 0.09132719]
 [ 0.06679881]
 [-0.13036957]
 [ 0.12458411]
 [ 0.02958967]
 [ 0.16804218]
 [ 0.08694854]
 [-0.18768623]
 [ 0.08613062]
 [ 0.10410565]
 [ 0.1763418 ]
 [ 0.0489144 ]
 [ 0.11177182]
 [-0.047648  ]
 [ 0.1679407 ]
 [-0.06881382]
 [-0.09796505]
 [ 0.14577538]
 [ 0.12824816]
 [-0.17245497]
 [-0.09839299]
 [ 0.13833773]
 [-0.05586152]
 [-0.1299313 ]
 [ 0.03811133]
 [ 0.18761832]
 [-0.10765636]
 [-0.18989623]
 [ 0.18920219]
 [-0.08221045]
 [ 0.10097155]
 [-0.0871448 ]
 [ 0.07199159]
 [ 0.00110725]
 [ 0.10085782]
 [-0.18748699]
 [ 0.07306483]
 [-0.103765  ]
 [-0.03152433]
 [ 0.15529427]
 [-0.02922137]
 [ 0.08771589]
 [-0.06830367]
 [-0.05619939]
 [ 0.1152612 ]
 [-0.12431817]
 [ 0.03526546]
 [ 0.0624302 ]
 [-0.12145582]
 [ 0.03937203]
 [ 0.1708261 ]
 [-0.04071465]
 [ 0.03041638]
 [ 0.1672732 ]
 [-0.13432683]
 [ 0.18212989]
 [ 0.17379332]
 [-0.12007762]
 [ 0.08163923]
 [-0.18476492]
 [-0.03037451]
 [-0.12037398]
 [ 0.15109533]
 [-0.14787586]
 [ 0.14436886]
 [ 0.08771801]
 [ 0.00833811]
 [-0.12848195]
 [-0.18823537]]
tensor_name:  TemporalFusionTransformer/dense_112/kernel
[[ 0.0656864  -0.09995673 -0.10474832 ... -0.02113487  0.12962323
  -0.08262789]
 [ 0.06722874  0.0462884   0.01335255 ...  0.08677033 -0.10919878
   0.10280065]
 [-0.0300188   0.07973015 -0.13890964 ...  0.0494994   0.08140735
  -0.04669301]
 ...
 [ 0.00554499  0.09750144  0.11001408 ...  0.08009478 -0.0465539
  -0.0180143 ]
 [ 0.05080296 -0.11105509  0.06449199 ...  0.02403296 -0.04172276
  -0.02218484]
 [ 0.01882849 -0.09402958 -0.08322981 ... -0.03119395  0.08634467
  -0.04951679]]
tensor_name:  TemporalFusionTransformer/dense_113/kernel
[[ 0.05320194 -0.03513477  0.01364278 ...  0.02358451 -0.04714017
  -0.10496338]
 [ 0.092485   -0.05764206  0.05985571 ...  0.0212514   0.11973427
   0.09765052]
 [ 0.03071298  0.02555454 -0.10182176 ...  0.12351499  0.03804418
   0.05809193]
 ...
 [-0.08523416  0.12249903  0.08151401 ... -0.0958929   0.1189032
   0.02451796]
 [ 0.02432169 -0.1273408   0.05572354 ... -0.10559887 -0.09357204
   0.16563566]
 [ 0.11981755  0.09692008 -0.09853049 ...  0.11091853 -0.12320157
   0.07547554]]
tensor_name:  TemporalFusionTransformer/dense_114/kernel
[[-0.0520336   0.10854039  0.13061897 ...  0.00166524  0.09981926
  -0.11101525]
 [ 0.1141304   0.08127765 -0.07306974 ...  0.05568783 -0.04113714
   0.0023652 ]
 [ 0.05924077 -0.11100116 -0.04755518 ... -0.0446784   0.11482831
  -0.03532813]
 ...
 [ 0.01969329 -0.01277919 -0.02996111 ...  0.05638009 -0.01115221
   0.04146135]
 [ 0.17042938  0.02091214 -0.11075869 ...  0.11534962  0.05864855
  -0.08432622]
 [-0.06986681  0.09209947  0.10194577 ... -0.11414515 -0.03946612
  -0.05033567]]
tensor_name:  TemporalFusionTransformer/dense_115/kernel
[[-0.02300425 -0.07892753 -0.07300053 ... -0.00120203 -0.02905556
  -0.11455756]
 [ 0.14556962 -0.04339426 -0.00803749 ...  0.06708298  0.01749205
   0.03974219]
 [ 0.14059189  0.05240053 -0.05306006 ... -0.08296845 -0.0101192
  -0.08392823]
 ...
 [ 0.07081757  0.0384688   0.10869943 ...  0.03242602  0.02338547
  -0.04440355]
 [-0.04956509 -0.01547151 -0.04524171 ... -0.03335559 -0.06997127
   0.03262265]
 [-0.00675963 -0.0442776   0.02182089 ... -0.08860648  0.07593041
  -0.02437673]]
tensor_name:  TemporalFusionTransformer/dense_12/bias
[0.]
tensor_name:  TemporalFusionTransformer/dense_12/kernel
[[-0.0172601 ]
 [-0.15923819]
 [ 0.09637433]
 [ 0.05550519]
 [ 0.06361344]
 [ 0.01796964]
 [ 0.13329014]
 [-0.05256757]
 [-0.08032132]
 [-0.1741611 ]
 [ 0.04507662]
 [-0.15210749]
 [ 0.14196333]
 [ 0.02431381]
 [ 0.02725676]
 [-0.05085795]
 [-0.04405904]
 [ 0.08297774]
 [ 0.181734  ]
 [-0.09926855]
 [-0.01246226]
 [-0.17938206]
 [-0.07649739]
 [-0.15066029]
 [ 0.13994533]
 [-0.10058286]
 [ 0.00026773]
 [-0.16917309]
 [ 0.03345917]
 [-0.08778138]
 [ 0.17214373]
 [-0.04793139]
 [-0.12593557]
 [ 0.14923838]
 [ 0.18359745]
 [-0.17623125]
 [-0.16007845]
 [-0.09420095]
 [-0.1608475 ]
 [-0.02892178]
 [-0.03929336]
 [ 0.18801057]
 [ 0.05136828]
 [ 0.16570196]
 [ 0.10638338]
 [ 0.01763728]
 [-0.14045818]
 [-0.02445571]
 [ 0.08776486]
 [-0.02434437]
 [ 0.06204215]
 [ 0.19303128]
 [-0.06333461]
 [ 0.07792628]
 [-0.13550675]
 [-0.01241149]
 [ 0.06641871]
 [ 0.03065006]
 [ 0.08578348]
 [ 0.11163577]
 [ 0.16948763]
 [ 0.06816536]
 [-0.01197517]
 [-0.1905185 ]
 [-0.16853106]
 [-0.0936242 ]
 [ 0.0606581 ]
 [ 0.08308637]
 [-0.12289127]
 [ 0.19039279]
 [ 0.11971745]
 [ 0.14597628]
 [-0.13934344]
 [ 0.06871349]
 [ 0.06958589]
 [-0.13225345]
 [-0.03540464]
 [ 0.00393687]
 [ 0.02018565]
 [ 0.07483277]
 [-0.17720388]
 [ 0.11904374]
 [-0.09407374]
 [-0.12962703]
 [ 0.1097607 ]
 [ 0.09652397]
 [-0.06322838]
 [-0.09581361]
 [ 0.02840018]
 [-0.03979026]
 [ 0.11223957]
 [ 0.12121654]
 [-0.17697084]
 [ 0.02088432]
 [-0.10030942]
 [ 0.08014452]
 [-0.15595898]
 [-0.07876665]
 [ 0.0625439 ]
 [-0.07137622]
 [ 0.06025898]
 [-0.16389607]
 [ 0.0838353 ]
 [-0.15910509]
 [ 0.05210055]
 [ 0.14026755]
 [-0.0230329 ]
 [-0.09821068]
 [-0.18467352]
 [ 0.18057072]
 [-0.05451585]
 [-0.17371538]
 [ 0.0955883 ]
 [ 0.00180095]
 [-0.17072761]
 [ 0.0236873 ]
 [-0.07297852]
 [-0.0228534 ]
 [ 0.06761032]
 [-0.05426534]
 [-0.12682483]
 [-0.11023054]
 [ 0.0036772 ]
 [ 0.18734357]
 [-0.12062118]
 [ 0.04955439]
 [-0.13109674]
 [-0.12281303]
 [-0.12248192]
 [-0.04984224]
 [-0.11427522]
 [ 0.10464731]
 [-0.09220987]
 [-0.01155593]
 [-0.01276028]
 [ 0.04123314]
 [ 0.18484074]
 [ 0.16183889]
 [-0.11363159]
 [-0.13716626]
 [-0.12853222]
 [ 0.05584499]
 [-0.00582306]
 [-0.17132723]
 [-0.18890588]
 [ 0.02152975]
 [ 0.01629646]
 [-0.1890336 ]
 [-0.0516222 ]
 [-0.05695993]
 [ 0.12153062]
 [-0.13367924]
 [-0.06627221]
 [-0.0859184 ]
 [-0.1300334 ]
 [-0.13792224]
 [-0.18070586]
 [ 0.021668  ]
 [ 0.16250843]
 [-0.10576971]]
tensor_name:  TemporalFusionTransformer/dense_13/bias
[ 0.00886424  0.00708033 -0.0059369  -0.01018396 -0.00501965  0.00246427
 -0.00446282 -0.00946876  0.00790204 -0.0072786   0.01109929 -0.00131957
 -0.00397159  0.00849157 -0.00112441 -0.00171046 -0.00086266 -0.00121344
 -0.00247652  0.00687996  0.0138344   0.00369242  0.00448739 -0.00299185
  0.00100622 -0.00661814  0.01747276 -0.00231895 -0.00423738  0.00086961
  0.0037159  -0.00813684 -0.00117887 -0.00215557  0.00855548 -0.01047102
  0.00604831  0.01191851 -0.00387542  0.00314084  0.00078088 -0.00379869
 -0.00755649  0.0051494  -0.01567568 -0.01547292  0.00221786  0.01036217
  0.00768857  0.00041742 -0.0071308  -0.01586883  0.00210427 -0.00579334
  0.00411106  0.00302954  0.00664243  0.01632336 -0.00519169  0.00828296
  0.00652422  0.00259984  0.00670107  0.00241531  0.00602094  0.00318127
 -0.00523807 -0.00089333 -0.00226483  0.01166819 -0.0026524  -0.00465785
  0.00322779  0.00138191  0.01320926  0.00596288  0.00315687 -0.01283476
 -0.00168324 -0.00346493 -0.00502611  0.00739699  0.00896964 -0.02481393
 -0.01808328 -0.00199559 -0.00076269  0.00270478  0.00260968  0.00678393
  0.01294309 -0.00349723  0.00444577  0.00496915  0.0041853  -0.00779035
  0.00328173  0.00160182  0.03004134 -0.00090223  0.00263527 -0.00766956
 -0.02212784 -0.00345179 -0.00508784 -0.00526713 -0.00565306 -0.01415423
  0.00497167 -0.00248983 -0.00819413 -0.01304154  0.00432154  0.00514902
  0.01249743  0.00700269 -0.01571495  0.00944117  0.01130414  0.01948435
  0.00363539  0.01651203  0.00436007  0.01395907  0.02529639 -0.00619468
  0.01313326 -0.00535443  0.01408711  0.00175421 -0.01301789  0.01157016
 -0.0014095  -0.01480949 -0.01946228 -0.01243834 -0.00574827 -0.01143921
  0.01222215  0.00523654  0.02671741  0.00093544  0.00609314 -0.01586592
  0.00698666  0.01910116  0.0137643   0.00324498  0.00073892  0.00397728
  0.00030162  0.00493556  0.01616867  0.00048685 -0.00061015  0.02193365
  0.00554051 -0.00967375 -0.01384072  0.00875975]
tensor_name:  TemporalFusionTransformer/dense_13/kernel
[[-0.12290154 -0.10640772 -0.06167762 ...  0.02674756  0.04667176
   0.01920966]
 [ 0.02278199  0.00918564  0.12048441 ... -0.08449066  0.05409371
  -0.04977943]
 [-0.00445238  0.11578504 -0.04567841 ... -0.11417351  0.09311313
  -0.10819963]
 ...
 [ 0.04652847  0.00124064  0.06084982 ... -0.1327112   0.10551473
   0.04216494]
 [ 0.06837602 -0.04140187  0.1340229  ... -0.01559388 -0.06241878
  -0.08919267]
 [ 0.02917173  0.03837654 -0.04836779 ...  0.06011497  0.09205721
   0.11288099]]
tensor_name:  TemporalFusionTransformer/dense_14/bias
[-0.01126108 -0.01329419  0.01927249 -0.00106512 -0.00156008  0.01557127
  0.00515277  0.02962886 -0.01673744  0.0116822  -0.00893395 -0.02669556
  0.00033459 -0.0090039   0.00764441 -0.01908935 -0.00381053  0.00427102
  0.00091766 -0.0184959   0.00856852  0.01727545 -0.00200774 -0.00873217
  0.00882056  0.01202765 -0.00382807  0.01586511 -0.01173411 -0.00521141
 -0.03005635  0.00030617 -0.03135862  0.01435236 -0.00598479  0.00929681
  0.00885285  0.00063557  0.02250791  0.02414939  0.01039976  0.00813113
  0.00685815  0.00430485  0.0257882   0.01423328  0.00680686  0.00589789
 -0.00341087  0.00903751 -0.0034123   0.00194409  0.0122004   0.01895869
 -0.00194944  0.00361969 -0.01126572 -0.0051434   0.00169827 -0.00284345
  0.00697369 -0.01939477  0.01673864 -0.0022149  -0.00458839 -0.01746758
  0.00205639  0.00453338 -0.00668554 -0.00160919  0.00851611  0.00840144
 -0.00763519 -0.00156535  0.00359726 -0.00557094  0.01962412  0.00033984
 -0.02015972  0.00627681 -0.00641122  0.01894142  0.00124881 -0.01424259
  0.01080115 -0.0022421   0.02699667 -0.00718668  0.00288188  0.01815738
 -0.00277094  0.00183136 -0.01330024 -0.00071649 -0.01413372 -0.00257665
 -0.00016135 -0.01131379  0.01053393 -0.00861131  0.01720007 -0.02185308
 -0.01421134  0.01108108  0.01890657 -0.00515625 -0.02710362  0.0038677
  0.00594104 -0.00326688 -0.00858817 -0.00700065 -0.01272858 -0.00991596
 -0.01913105  0.00426222  0.00985022  0.00868196  0.01395062  0.02269685
  0.00771627  0.00884871 -0.00781898  0.00087395 -0.00414812 -0.00628438
  0.00797539 -0.00669727  0.01223525 -0.00648127 -0.00793465  0.00062341
  0.00050295 -0.01769968 -0.01404052 -0.00553815  0.02163552  0.01666334
  0.00507494 -0.01307623  0.02986547  0.00294418  0.00101354  0.00621371
 -0.0007631  -0.00400088 -0.01808622 -0.01967785  0.02680584  0.00732252
  0.01293608  0.01858146 -0.0057878   0.01216858 -0.00091397 -0.00160147
  0.00130488  0.00185199  0.00768223  0.0308884 ]
tensor_name:  TemporalFusionTransformer/dense_14/kernel
[[ 0.14363159  0.00358291  0.01756766 ...  0.01456847 -0.0043702
  -0.00605846]
 [-0.13944052 -0.04735094  0.029654   ...  0.05307576 -0.0536369
  -0.10816339]
 [ 0.00490289 -0.03378037 -0.03215558 ...  0.10040777  0.05806908
  -0.11805468]
 ...
 [-0.0644208   0.00856119 -0.02958797 ...  0.01711967 -0.00670705
  -0.02695088]
 [ 0.00217674 -0.07435025 -0.1291082  ... -0.13341027 -0.13457109
  -0.132804  ]
 [ 0.09470221  0.06301567 -0.10543657 ... -0.05811659 -0.05840407
   0.08430479]]
tensor_name:  TemporalFusionTransformer/dense_15/bias
[-1.20268501e-02 -6.20607892e-03  8.29097722e-03 -1.82560086e-02
 -3.92349670e-03 -7.48342078e-04  1.28061213e-02 -4.88396641e-03
  2.24227197e-02  2.25510797e-03 -1.06912954e-02 -8.83953739e-03
  1.44923944e-02  4.45211232e-02 -1.11294016e-02  1.16837081e-02
 -1.97308119e-02 -5.47166774e-03  5.99580538e-03  3.12875421e-03
 -1.68357557e-03 -4.25570831e-03 -2.82699871e-03 -9.16377362e-03
 -7.25960650e-04  1.84330326e-02 -1.30720623e-02 -8.21753405e-03
  2.76231151e-02  7.24019902e-03 -1.56568072e-03 -1.25697104e-03
 -5.45914704e-03  1.31586092e-02 -1.25528090e-02 -2.14030910e-02
 -1.37570938e-02  1.01723010e-03 -2.24280749e-02  2.08999440e-02
  1.36505980e-02  2.07754760e-03  6.06475049e-04  1.19868421e-03
 -3.63923283e-03 -1.95672014e-03 -8.66080914e-03  6.13390992e-04
  1.21853629e-03  2.74964655e-03 -2.52993871e-03  2.41573751e-02
  2.19330806e-02  1.83056332e-02  4.28492902e-03  1.00729475e-03
  2.17646733e-03  5.12105413e-03 -8.75608902e-03 -5.57451509e-03
  4.78601595e-03  3.09794862e-03 -1.22808665e-02  1.00194775e-02
 -8.76982044e-03  1.61978044e-02 -9.42519680e-03 -4.91110794e-03
 -1.83073822e-02 -2.48249178e-03  1.01618702e-03  4.45198920e-03
 -1.85270014e-03 -1.80984084e-02 -1.79570518e-03  3.93751040e-02
 -1.20807504e-02  6.47913618e-03 -6.56836014e-03  5.43421553e-03
  1.00050122e-02  1.26553047e-02 -1.17424633e-02  1.17510669e-02
 -3.48083209e-03 -1.59025681e-03  7.80683430e-03 -4.65234101e-04
 -4.87857126e-03  2.04163007e-02 -1.94107052e-02  2.33903229e-05
  5.60096139e-03  8.31906591e-03 -4.66934871e-03 -2.73997802e-02
  4.03268775e-03  1.93556007e-02 -7.83956330e-03 -1.53858345e-02
 -4.51516174e-03  9.01770871e-03  1.20935775e-03  1.65678822e-02
 -2.06175074e-03 -9.78591968e-04 -8.81423522e-03 -4.69202250e-02
 -2.06582132e-03  4.42256033e-02 -8.60672165e-03 -2.71066721e-03
 -9.74852964e-03 -3.16197537e-02 -4.30853665e-03 -1.76603184e-03
  8.46946426e-03  8.91690375e-04  8.70284438e-03 -3.77974729e-03
  3.11629963e-03  1.99569762e-03 -5.75672276e-03 -8.73474497e-03
 -8.68347380e-03  6.23747567e-03  2.31157728e-02  3.52308787e-02
  2.25062412e-03 -6.34085713e-03 -2.92773684e-03 -7.27366889e-03
  1.16229784e-02  2.22518481e-03  7.46513950e-03  1.43587636e-03
  4.29613609e-03 -1.11233313e-02  8.82946234e-03  9.73471254e-03
 -9.60170943e-03 -1.06302090e-04  1.18447663e-02 -5.95834386e-03
 -3.13345231e-02  1.47675176e-03 -8.90544616e-03 -2.46669468e-03
 -3.69063243e-02  2.21698312e-03  8.50387383e-03  2.02395860e-03
  1.25168147e-03 -1.62327047e-02 -1.09234673e-03 -1.52668683e-03
  5.36433794e-03  1.87180284e-02 -3.55605222e-03 -2.24695285e-03]
tensor_name:  TemporalFusionTransformer/dense_15/kernel
[[-0.03098452 -0.06350241 -0.09220456 ... -0.02143712 -0.09095944
  -0.08453459]
 [ 0.07823577  0.09546651  0.00284181 ... -0.08324362  0.01674752
  -0.07137059]
 [-0.0554846   0.06976672 -0.00712552 ...  0.03919835 -0.0602029
   0.07168226]
 ...
 [-0.06034673 -0.04099774  0.06161992 ...  0.09180124  0.11754189
  -0.06015336]
 [ 0.04256289  0.00306227  0.01849365 ... -0.0797571  -0.01786827
   0.05554255]
 [-0.14198099  0.10880199 -0.07442762 ...  0.04996779  0.04448004
  -0.07777866]]
tensor_name:  TemporalFusionTransformer/dense_16/bias
[-0.003005   -0.00965933 -0.00576883 -0.00020254 -0.00267328 -0.01260137
 -0.0105259  -0.01713294  0.01107483  0.00236306 -0.01057805 -0.00721955
  0.00946764  0.02123008 -0.01138521 -0.0094244   0.00637123 -0.00203813
 -0.00672372 -0.01138612 -0.01649378 -0.01459298 -0.00376293 -0.00342083
 -0.02195407  0.00401184 -0.01329859 -0.01230095  0.02084439 -0.01167507
 -0.00644967 -0.00961933 -0.01163854  0.00165214  0.0033022   0.00754049
 -0.00392208 -0.01425243  0.00603816 -0.00381113  0.00171777 -0.00599011
 -0.0100905  -0.00143165 -0.00456526 -0.02083418 -0.00595118 -0.01463885
 -0.00181939 -0.00602651  0.00163219  0.0176216   0.00848129  0.00285683
 -0.01595293 -0.0186987   0.0003818  -0.00900686  0.00141181 -0.0089843
 -0.01019068  0.00076449 -0.00379089 -0.00606324 -0.00545241 -0.00425684
 -0.01941603 -0.00475901  0.00833978 -0.00308882 -0.00754147 -0.00730177
  0.00193792 -0.00252123  0.00074273  0.01490863 -0.00446359 -0.00819155
 -0.00020616 -0.00727438 -0.01053013  0.00231555  0.00352479 -0.00095958
 -0.01063653 -0.01656351 -0.0102353  -0.01143784 -0.01614613 -0.00424542
  0.00856939 -0.00997074 -0.00106521 -0.00156601 -0.01233245  0.0146149
 -0.00628508  0.00705366  0.00626054 -0.01924106 -0.01796283 -0.00616179
  0.00466567  0.01074632 -0.02194064 -0.0141217  -0.00520656  0.02779711
 -0.0088794   0.03534261 -0.00297828 -0.00104912 -0.01256404  0.01840654
 -0.01729627 -0.02151181  0.00133189  0.0088097  -0.010046   -0.00144964
 -0.00419438 -0.00322679 -0.02007125  0.00925935 -0.02356546 -0.00590522
 -0.01364642  0.0291235  -0.01107457 -0.00556669 -0.00747447 -0.00543797
 -0.00019595 -0.01248903 -0.01110674 -0.00959539 -0.01350243 -0.02633776
 -0.01040302  0.00531864 -0.0226814  -0.00887854 -0.00934661 -0.01022038
  0.01796397 -0.001252   -0.01452891 -0.00526558  0.03335528 -0.00419099
 -0.0038295  -0.00078329 -0.01697395  0.0058628  -0.02712359 -0.01644449
 -0.00676403  0.00305992 -0.01004748 -0.01062222]
tensor_name:  TemporalFusionTransformer/dense_16/kernel
[[ 0.09760541 -0.07160813 -0.03652263 ... -0.09434717  0.03719059
   0.00587581]
 [ 0.1242156  -0.08475813  0.07581369 ... -0.03702337 -0.03753101
  -0.02240665]
 [-0.13995247 -0.12813973  0.0852028  ... -0.0961622   0.05687367
  -0.15097947]
 ...
 [-0.07271262  0.10762053  0.07867877 ...  0.04645178  0.03103533
   0.10730696]
 [ 0.05829692  0.08501382 -0.04663441 ...  0.06459218  0.11158468
   0.1064871 ]
 [-0.08458962 -0.16002734  0.03185558 ...  0.06872679 -0.05201874
  -0.10357648]]
tensor_name:  TemporalFusionTransformer/dense_17/bias
[-1.4381650e-02  5.1357076e-03 -6.0676006e-03  1.5859075e-02
 -2.8824548e-03 -4.0392741e-03 -9.7489785e-03 -1.5226077e-02
 -3.1679368e-03 -1.1031153e-02 -1.1069692e-02  1.0473683e-03
  2.6129166e-05 -9.9007739e-03 -3.3612503e-03  2.1284400e-02
  7.4648242e-03 -3.6644125e-03 -7.6472820e-03  1.6912250e-03
  6.7809843e-03  2.0645778e-03 -8.2891602e-03  3.4735468e-03
 -8.7091717e-04  3.5920311e-03 -1.6230224e-02  3.4520908e-03
 -6.9636772e-03 -1.5895741e-02 -1.3593059e-02 -2.4125797e-03
 -2.9805284e-03  9.9228171e-04 -1.3787225e-02 -6.9038360e-03
 -2.1861591e-03  6.5601557e-03  1.5973963e-03  1.6827159e-02
  3.8232091e-03 -1.7477445e-02  1.8552773e-02 -4.4852421e-03
  3.0232593e-02 -3.3851163e-03 -3.9132098e-03  5.7495418e-03
 -4.8832195e-03  5.8393441e-03  1.3859664e-03 -1.0925833e-02
 -2.6124297e-03  6.2905760e-03  3.1741303e-03 -3.9311307e-03
 -6.5964001e-04  2.1905972e-02  5.1617548e-03 -1.1479630e-03
 -1.3113394e-02 -6.6591478e-03 -1.0136209e-02 -4.0015529e-04
  2.0213103e-02 -1.2800431e-02  2.8836972e-04  1.2895530e-02
 -3.0617758e-03 -4.3277540e-03  1.0912887e-02 -5.1726354e-03
 -5.3647393e-03 -1.0874346e-02 -1.1522396e-02 -9.6292631e-04
 -5.3615030e-03 -1.2100053e-02  1.9186139e-03 -1.4595468e-02
  3.0924862e-03 -1.1339775e-02 -7.7129994e-03  2.3403249e-03
 -9.8771174e-03 -3.2137469e-03 -1.1692240e-03  5.5628433e-03
  9.5784673e-03 -7.1289609e-03  3.6015410e-03 -1.1820972e-02
 -3.7042692e-04 -5.5392152e-03 -1.2085810e-02  1.1054690e-02
 -1.2495363e-02 -1.2941818e-02 -5.5603744e-03 -8.3484072e-03
  1.3607196e-03 -1.1841699e-02  1.2310480e-02 -9.4339615e-03
 -1.1251166e-03  8.9428399e-04 -1.4837807e-02  1.0308616e-03
  7.4487273e-03  7.9102265e-03 -3.0872377e-03 -9.5240241e-03
 -4.0159910e-03 -3.5689874e-03 -1.6094960e-02 -1.6378891e-02
  6.1114049e-03  8.3904583e-03  8.4047029e-03 -2.4535074e-03
  1.2090395e-03 -3.7622410e-03 -1.4663606e-02  3.0720106e-04
  1.9739572e-02  9.8877065e-03  2.5982462e-04  1.3959612e-02
 -7.6498329e-03 -1.8169647e-02  7.6858643e-03 -7.2914306e-03
 -1.1586039e-03 -1.3450833e-02  3.1256103e-03 -5.8881328e-03
  6.9846930e-03 -5.5577699e-03 -1.2401284e-02  7.0029353e-03
 -4.4008479e-03  7.5633707e-04 -1.5189578e-02  7.8771630e-04
 -3.2312169e-03 -2.7810221e-03  3.0675773e-03 -5.4656190e-04
 -5.2627241e-03  1.2098435e-02 -1.1610214e-02  1.6284389e-02
  4.8036827e-03 -1.0610448e-02  1.0448440e-02 -1.5557661e-02
 -8.2814787e-04  1.5376345e-02  4.8800143e-03  5.1479293e-03]
tensor_name:  TemporalFusionTransformer/dense_17/kernel
[[-0.06537632 -0.0854219   0.0546315  ...  0.11338542  0.04154333
  -0.04589787]
 [ 0.05325933  0.12097424 -0.06028049 ... -0.01930769  0.13661405
  -0.00152647]
 [ 0.08587687 -0.02392375  0.00802367 ...  0.00598582  0.08327449
   0.13180919]
 ...
 [-0.04908082 -0.10988539 -0.04830707 ... -0.04819847  0.10701223
  -0.10134904]
 [ 0.09812377 -0.03110401  0.02677084 ...  0.07617686 -0.12804495
   0.09985047]
 [-0.08184788  0.04713317  0.10981285 ... -0.02173866 -0.06796489
   0.10797275]]
tensor_name:  TemporalFusionTransformer/dense_18/bias
[ 0.01866166 -0.02216432 -0.00124964 -0.01525051 -0.01297431  0.0069093
 -0.00827492  0.01442418 -0.00134913 -0.00751495  0.00114355 -0.02031128
  0.01574693  0.00260025 -0.0258414   0.00190068  0.00540055  0.00164605
 -0.01675901 -0.00770449 -0.02468695  0.00875818 -0.01518826  0.01343874
 -0.00685718  0.01268378 -0.00502116 -0.00707567  0.01780279  0.00993121
  0.00414485 -0.01156795 -0.02000397  0.00671071  0.00023224  0.00824362
 -0.00042856  0.02278151  0.01381296  0.01148932  0.00586399  0.00170264
  0.00264518 -0.00062533  0.01506518 -0.00115425 -0.01429689  0.00691256
 -0.01017045  0.01143742 -0.0157615   0.00905415  0.00197426 -0.00604865
 -0.00685867 -0.00071951  0.00295388  0.01786351 -0.00781095 -0.01255727
  0.01033761  0.00871022  0.03207495  0.00379787 -0.01139814  0.00509137
  0.00784916 -0.01472935  0.01816059 -0.00384915 -0.00166329 -0.01580722
 -0.01098393 -0.00714074  0.0117476   0.00769932  0.01203716  0.0147353
  0.00529929  0.00554196 -0.00853862  0.01321201 -0.01694017 -0.00424206
 -0.00441101  0.00047547 -0.01278515 -0.01332053  0.01388644  0.01714807
  0.01733563  0.00374326  0.01944616  0.00401757 -0.00500132 -0.02321021
 -0.00092665  0.00451051 -0.00145412  0.00274833 -0.0033041  -0.00504119
 -0.00742405 -0.01557578  0.01804167 -0.0077511   0.00568436 -0.00850715
  0.02077971 -0.01811349  0.00203101  0.00456807  0.01492544  0.0174133
 -0.00491556  0.01298267 -0.00708304  0.01230642  0.00201858  0.02362541
  0.00772916 -0.01060009  0.00085085  0.01416523 -0.02725097 -0.00366759
 -0.02697865 -0.01080884 -0.01708937  0.00101746 -0.02694168 -0.00612803
  0.00579886 -0.00205853 -0.00745538 -0.00200732 -0.01942662 -0.01569528
  0.0092027   0.01396166  0.0237238   0.00243398 -0.0033366   0.00663696
 -0.00594706 -0.00848105 -0.01065097 -0.00610842  0.02028256  0.01230573
  0.01022666  0.01780877 -0.00885062  0.00089637  0.00500558  0.00486243
  0.021552   -0.01012945  0.00287682 -0.01278048]
tensor_name:  TemporalFusionTransformer/dense_18/kernel
[[-0.01105282 -0.02943118 -0.09072997 ... -0.03895043 -0.11633734
   0.00716898]
 [-0.09433545 -0.15290366  0.07115152 ...  0.10443025 -0.03679764
   0.03828997]
 [-0.05372584 -0.07388298 -0.02990684 ...  0.069564    0.0722148
  -0.08952715]
 ...
 [ 0.04836957 -0.02589991  0.02089189 ...  0.03877402 -0.06832771
   0.05629723]
 [ 0.16267522 -0.14583963  0.09000573 ... -0.1655262   0.15444459
  -0.07657614]
 [-0.0676213   0.13170576 -0.05745174 ...  0.00096208  0.01958812
   0.03838682]]
tensor_name:  TemporalFusionTransformer/dense_19/bias
[-0.01279654  0.00249254  0.00148106 -0.01298165 -0.00347886 -0.01098827
  0.00375481 -0.01061761  0.01813125  0.00294477 -0.01087355 -0.01471774
  0.02656567  0.03118434  0.00920977  0.00791046 -0.00932293 -0.00504515
  0.01382423  0.00800669  0.01041113 -0.00676793 -0.00906072 -0.00691809
  0.0095888   0.0093471  -0.02435173  0.00538703  0.00863591 -0.00114756
 -0.00785719  0.00730153 -0.00507371  0.00865305  0.00771517 -0.00657653
 -0.00476902 -0.00617579 -0.02585779  0.00260726  0.00789792  0.0116397
  0.00450638  0.00344069 -0.00329399 -0.00175691 -0.00624495  0.00900081
 -0.00743309 -0.00048386 -0.00381445  0.00338506 -0.00463621  0.00074479
 -0.00639648 -0.00217552 -0.00271821  0.00533277  0.00245836 -0.01210324
 -0.00139193 -0.00913407 -0.00128495  0.00449536  0.00340879  0.021065
 -0.01078945  0.00401308 -0.01828885 -0.00102223  0.00776502  0.00079942
  0.0263229  -0.03067195 -0.00341108  0.03734803 -0.00478186  0.00647681
 -0.0043959   0.00951006  0.00746448  0.00500761 -0.01685242  0.00545743
 -0.00808097 -0.00060702 -0.00067495  0.00315032  0.00226298  0.00435355
 -0.018972    0.00318549 -0.00032366  0.00632093  0.00253647 -0.02332517
 -0.00731545  0.02348229 -0.00580542 -0.01072455 -0.00071258 -0.0021909
  0.00826691  0.00518534 -0.00414789 -0.00418192 -0.00199379 -0.04976102
 -0.00160287  0.03319515 -0.00059147 -0.01497511 -0.00957474 -0.02223769
 -0.0007033  -0.00017737  0.00593089 -0.00207273  0.00011797  0.00560934
  0.00611182  0.01663961 -0.00755985 -0.0055344   0.01081207  0.00075945
 -0.00126828 -0.00269489 -0.00599061 -0.00373971 -0.00323432  0.00477847
  0.00124822 -0.00688315  0.00874213  0.0020916  -0.01117059 -0.0054327
 -0.00817748  0.00752611 -0.01587239 -0.00225477 -0.00140648 -0.00476359
 -0.0372086   0.00134976  0.00427371 -0.00908768 -0.01352278 -0.00764434
  0.01312624  0.00056974  0.00399731 -0.0075316  -0.00326583 -0.00718084
  0.00848264  0.00175092  0.00357278  0.00323292]
tensor_name:  TemporalFusionTransformer/dense_19/kernel
[[-0.03018693 -0.00756925  0.06392767 ... -0.06712919  0.01815058
   0.02864826]
 [-0.09825292  0.12047615  0.0892631  ... -0.11451092 -0.10609083
   0.06852209]
 [ 0.05391731 -0.0095798  -0.08212459 ...  0.09817974  0.04353518
  -0.10324876]
 ...
 [-0.05500159  0.10564948  0.10889082 ... -0.05547327 -0.06806275
   0.02114879]
 [-0.11807788  0.06763332  0.11959343 ... -0.06797736  0.10452744
   0.0639547 ]
 [ 0.05758486  0.03564307 -0.01266177 ... -0.06528714  0.1028033
  -0.03777039]]
tensor_name:  TemporalFusionTransformer/dense_20/bias
[-1.23256305e-02 -1.03166979e-02 -1.11560235e-02 -1.01496261e-02
 -9.68268048e-03  9.83390398e-03 -3.06810681e-02 -3.08286143e-03
  7.25149177e-03  3.03042005e-03 -1.67955998e-02  1.18186353e-02
 -2.01035920e-03  5.21074794e-03  1.06017878e-02 -2.89782113e-03
 -1.53759238e-03  1.64977729e-03 -1.66497156e-02 -2.81243818e-03
 -4.21428541e-03 -1.10904463e-02 -7.19109084e-05 -4.46678046e-03
  1.73017790e-04  1.29163526e-02  1.31934891e-02 -4.34073852e-03
 -1.73175223e-02 -2.87503377e-03 -4.11263853e-03 -3.29819368e-03
 -1.30540654e-02 -7.96840340e-03  3.86441918e-03  5.80314547e-03
 -8.02058075e-03 -1.41122704e-02  1.68033708e-02 -5.99336950e-03
 -1.83305005e-03  1.27645843e-02  4.53754421e-03  1.10833673e-03
 -5.94731094e-03  2.11285846e-03  3.41251283e-03  4.12586778e-05
  1.54785858e-03 -1.29589522e-02 -7.50729698e-04 -9.37003829e-03
  6.23599626e-03 -1.78103354e-02 -1.54608546e-03  1.24149667e-02
 -1.75741538e-02 -9.17927269e-03 -1.80625077e-02  7.76071148e-03
 -1.18104899e-02 -5.49954642e-03 -1.87502448e-02 -2.38287472e-03
 -9.33175255e-03  2.91458089e-02 -6.25153631e-03 -2.35999795e-03
  1.95278134e-02 -1.14028296e-02  3.64654954e-03 -3.63105047e-03
  1.03780590e-02  3.44972983e-02 -1.15274210e-02  6.80904649e-03
  7.78222969e-03 -1.06800199e-02  5.65502036e-04  1.12044644e-02
 -9.54480655e-03 -1.22465910e-02  2.50323284e-02  4.18500323e-03
 -1.64752230e-02 -1.17150284e-02 -7.00979913e-03  8.32127873e-03
  2.07179040e-03 -1.53411869e-02  1.83475558e-02 -5.24021173e-03
 -1.41079035e-02  1.62259780e-03 -3.78541939e-04  1.46398339e-02
 -1.84146352e-02  7.73427542e-03  4.38961573e-03 -8.65106750e-03
 -8.70094821e-03 -8.77757557e-03 -9.10037104e-03 -1.93543837e-03
  4.51756222e-03 -1.32077802e-02 -1.05883405e-02  2.06711031e-02
 -7.16867298e-03  1.05202207e-02  5.99636172e-04  1.63032226e-02
 -1.30122658e-02  1.37095088e-02 -2.28722598e-02  4.04395582e-03
 -1.46359140e-02  1.02329312e-03 -6.14089519e-03  1.65696209e-03
 -1.55527163e-02  1.39370272e-02 -1.02493996e-02  3.52719589e-03
 -1.37507701e-02 -3.29618133e-03  2.13016872e-03 -8.27856362e-03
  3.29652312e-03 -1.70370210e-02 -2.58413292e-02 -1.16706723e-02
  1.40573399e-03 -1.15590729e-02 -7.76860910e-03  1.66316261e-03
 -1.33699998e-02 -2.32642540e-03 -2.14218613e-04 -1.75482535e-03
 -1.29850139e-03 -1.01985922e-02 -8.28292500e-03 -1.65283028e-02
  7.92230759e-03 -1.16911568e-02 -1.67692676e-02 -1.64192822e-02
 -1.60158239e-02 -1.01306364e-02 -1.23435184e-02 -3.41687519e-05
  2.80856248e-03 -2.61836220e-03 -9.40897223e-03 -2.67978776e-02
  6.51692320e-03 -1.42517062e-02 -2.29473878e-03 -7.99631234e-03]
tensor_name:  TemporalFusionTransformer/dense_20/kernel
[[-0.11426858 -0.13758875 -0.08010473 ... -0.07023744 -0.05669001
   0.10241209]
 [ 0.04854808  0.00653345 -0.00333716 ... -0.02913967 -0.08579637
   0.13074434]
 [ 0.12263703  0.1218475  -0.10245456 ...  0.06684414 -0.08066556
  -0.11894321]
 ...
 [ 0.06137052  0.05324844 -0.1038928  ...  0.02126858  0.0179868
   0.1291722 ]
 [-0.03292302 -0.14240117  0.09807824 ...  0.02730743 -0.00176811
  -0.02466287]
 [-0.12810752  0.04960285 -0.05091567 ... -0.00696811  0.06676697
   0.05606203]]
tensor_name:  TemporalFusionTransformer/dense_21/bias
[-7.6648598e-03 -4.6133748e-03 -9.1558590e-04  1.3108737e-03
  1.6914470e-03  6.0790754e-04  6.1401990e-03 -4.4137631e-03
  6.3825595e-05  1.8318517e-03 -6.8400125e-03 -2.0956662e-03
 -8.4757647e-03 -5.7166624e-03 -8.7743513e-03 -2.4754270e-03
  2.8693466e-03  1.6103947e-03  6.0166917e-03  5.9392420e-05
  6.5315114e-03 -2.1297925e-03  1.1706809e-02 -8.2656406e-03
 -6.1656552e-04 -7.6592417e-04  7.7813501e-03  1.7912438e-03
  4.9217152e-03  1.1213926e-02 -8.8340519e-03  1.3645219e-03
 -8.1892805e-03 -1.1835660e-02 -4.7577345e-03  2.2176524e-04
 -1.3300933e-02  6.9174846e-03 -5.1156431e-04 -9.8700877e-03
 -3.3522707e-03  1.5432774e-03 -8.7914243e-03  6.2949387e-03
  4.2636613e-03  1.3203665e-03 -6.2708925e-03 -7.6074866e-03
  6.3124797e-03  9.6138017e-03 -8.3014416e-03 -4.3046391e-03
 -9.7399568e-03 -1.4824028e-03  1.1474632e-03 -9.0434458e-03
  2.4273247e-03  2.5015529e-03  6.0020699e-03 -8.9188330e-03
 -5.9467587e-03 -7.4087679e-03  5.3545875e-03 -2.3777012e-03
 -2.2490462e-03  1.6918245e-03  6.2660924e-03  1.4526984e-03
  1.0693690e-03 -9.9389872e-05 -2.0276212e-04  5.2525202e-04
 -2.1111425e-03 -3.0578955e-04 -7.4819876e-03 -1.2075488e-03
  6.3835440e-04 -4.2794389e-03 -2.2664897e-03  2.4396474e-02
 -8.4988438e-03 -8.2356120e-03 -5.2498374e-03 -9.2204497e-04
 -1.3107463e-02 -5.0651981e-04  1.5366331e-02 -6.8439369e-04
  4.0245354e-03  5.9159491e-03 -1.8820856e-03  5.7644006e-03
  1.2686269e-02  1.8700622e-03  8.3719855e-03  6.4241006e-03
 -3.8106070e-04  8.3486550e-03 -6.5639573e-03  2.3334362e-03
 -3.8767182e-03 -1.5534154e-03 -7.0192665e-03  8.2326597e-03
 -1.9434233e-03  7.2090661e-05 -7.6779732e-03  2.2664669e-03
  9.0455096e-03 -1.8247043e-03 -6.0472321e-03  1.1163010e-03
 -5.1781368e-03  1.0110048e-02  2.1255668e-03 -1.3900308e-03
  1.5674462e-03 -3.6515133e-03 -1.2395749e-03 -9.0008080e-03
 -1.4098105e-03  3.0787820e-03 -4.3523527e-04 -7.5422404e-03
  2.2896424e-04 -5.5895168e-03 -9.3089677e-03 -4.5329290e-03
  5.9344308e-03 -1.6980508e-02 -8.9988130e-04  7.7825445e-03
  6.7116660e-03 -6.4413338e-03  9.7711813e-03  4.5376639e-03
 -9.0209432e-03 -2.5987490e-03 -1.2310481e-03 -6.5278972e-04
 -7.4334028e-03 -1.0619900e-03 -3.2729602e-03 -1.0070781e-02
  1.9052710e-02  6.1023207e-03  1.2661137e-02  6.8205800e-03
 -2.8144813e-03 -1.5893786e-03  5.5923108e-03  1.4578332e-02
 -4.9009859e-03  8.4636770e-03 -5.2205683e-03  1.5183804e-03
  5.2525960e-03  8.8047357e-03  4.4019404e-03 -3.7094650e-03]
tensor_name:  TemporalFusionTransformer/dense_21/kernel
[[ 0.05657168  0.01615525 -0.10426109 ... -0.14015044  0.07906108
   0.14254612]
 [ 0.1281988  -0.03094064  0.00686492 ... -0.11247552 -0.04561466
   0.11501612]
 [ 0.05893293  0.04694203  0.03199652 ...  0.10739034  0.07827628
  -0.08986966]
 ...
 [-0.07647175  0.05522222  0.03805305 ... -0.07140303  0.1328103
  -0.14275233]
 [ 0.07504255  0.0457108  -0.09198762 ...  0.12927765  0.05503302
   0.12287842]
 [-0.02065168 -0.12882724 -0.09119205 ... -0.07712141 -0.06637791
   0.08798365]]
tensor_name:  TemporalFusionTransformer/dense_22/bias
[-9.68684535e-03 -1.05036655e-02 -2.26920005e-03 -9.63098742e-03
 -5.18769631e-03 -4.31582070e-04  1.14748040e-02  2.92926421e-03
  1.34840878e-02  1.99075211e-02  9.85611416e-03 -7.78474659e-03
 -8.26022681e-03 -6.84491126e-03 -7.39805261e-03  2.83909123e-03
 -2.10840325e-03  4.29521693e-04 -9.53695644e-03  9.25995293e-04
 -6.44079736e-03 -4.99258377e-03 -5.34708332e-03 -1.61463872e-03
  6.85896259e-03  4.58272127e-03 -1.88002014e-03  6.15716027e-03
 -5.42864809e-03  8.83853994e-04 -4.94018495e-05  8.15871451e-03
  8.70044110e-04 -2.63740472e-03 -1.41712802e-03 -3.31635377e-03
 -8.98399949e-03  1.10169211e-02  1.37407035e-02  1.49661908e-03
 -9.53390449e-03 -2.62551522e-03 -1.19802617e-02  4.46104212e-03
 -1.19914962e-02 -1.69300358e-03 -6.37580082e-03  8.44965689e-04
 -5.70370350e-03  1.16718365e-02  6.91389618e-03 -2.26291854e-06
  2.00455985e-03 -2.57780333e-03 -5.40201599e-03 -2.47541186e-03
  1.50576783e-02  7.09602889e-03 -1.32509572e-02  2.68169749e-03
  8.37350823e-03  6.22136844e-03 -3.44379991e-03  8.79536197e-03
  1.72533491e-03 -1.04730207e-04  1.83278159e-03  7.52132433e-03
  5.61711844e-03 -3.75726470e-03  9.07529052e-03 -5.02515538e-03
  1.49218505e-02 -5.47436299e-04  2.87291384e-03 -6.40166271e-03
 -9.67098586e-03  1.67128518e-02  1.29435095e-03  1.50756066e-04
  8.48907325e-03 -3.77261732e-03  9.12033487e-03  9.71779693e-03
 -5.15105855e-03  5.21402154e-03 -4.30322019e-04  4.45949426e-03
  1.39711481e-02 -2.89615546e-03  3.21883545e-03  6.24484383e-03
  6.72539510e-03 -4.77237580e-03  1.82199804e-03 -2.28638854e-03
 -4.77176858e-03  5.99471340e-03 -4.88127815e-03 -5.65591408e-03
 -9.20742226e-04 -1.89067842e-03 -2.64695343e-02  2.01301603e-03
 -4.48811147e-03  8.65172036e-03  9.82890138e-04 -5.24995499e-04
  4.49878769e-03 -5.65501023e-03  1.68332905e-02 -8.75349797e-04
 -6.88066939e-03 -6.28371583e-03  9.80549213e-03  7.00824847e-03
  1.90952662e-02  1.21575058e-03 -1.00260519e-03  5.04907966e-03
  8.40733107e-03 -6.85001537e-03 -7.44085992e-03 -7.43542053e-03
 -1.16451951e-02 -8.95949267e-03  1.65461078e-02  6.14373712e-03
  1.43170659e-03  3.35730682e-03 -5.40655199e-03 -6.99327374e-03
  2.27313139e-03  4.69409674e-03 -1.06763153e-03  6.50471402e-03
 -1.11712702e-03 -6.58210227e-03  1.48565052e-02 -6.86601270e-03
 -1.19166216e-02  3.26022995e-03 -3.12399189e-03  4.62185452e-03
  4.98003280e-03 -5.49897877e-03  1.13354726e-02 -5.29261166e-03
  4.31180140e-03 -6.75097760e-03 -6.90536713e-03  2.75661447e-03
 -4.98482538e-03 -6.12670742e-03  8.27569398e-04 -7.94332416e-04
  1.00164246e-02  5.51229350e-05  4.76273661e-03 -6.77197939e-03]
tensor_name:  TemporalFusionTransformer/dense_22/kernel
[[ 0.04917829  0.04458081 -0.03716093 ... -0.08079959 -0.12397112
  -0.10028575]
 [-0.0464889   0.01475179 -0.12638873 ... -0.00643859 -0.09779242
  -0.03446507]
 [-0.06508398  0.11876111 -0.02209121 ...  0.02795353 -0.08200735
  -0.11014238]
 ...
 [-0.11741496 -0.135694    0.06313396 ...  0.02422615  0.05031538
  -0.00630999]
 [-0.01550342 -0.06824619 -0.03548556 ...  0.11369354 -0.05847647
  -0.02003474]
 [ 0.05273804 -0.0267691   0.08083251 ... -0.07395544 -0.13052529
   0.13041113]]
tensor_name:  TemporalFusionTransformer/dense_23/bias
[ 7.71359168e-03 -9.27925576e-03 -4.52941796e-03  2.01853085e-03
 -7.47583946e-03  2.01084744e-03  4.70822863e-03 -3.74740362e-03
  6.16467977e-03  5.90794813e-03 -3.89703899e-03 -2.43094291e-05
  4.82422486e-03  1.55997705e-02  4.72555077e-03 -7.37971859e-03
 -2.55308580e-03 -5.49521390e-03  4.76838136e-03  4.91612731e-03
  4.16840008e-03 -1.48786406e-03 -3.49478191e-03 -7.00374134e-04
 -7.97909964e-03 -1.12218619e-03 -4.47097793e-03 -9.11502866e-04
  1.52374646e-02  1.55973667e-03 -2.37379014e-03 -3.26837762e-03
 -2.97952513e-03 -6.97173877e-04 -1.22475997e-02 -8.20131681e-04
 -1.02466727e-02 -2.03619921e-03 -5.90656325e-03  1.40647753e-03
  9.23756324e-03  2.29185564e-03 -7.37823313e-03  7.54798530e-03
 -2.30589052e-04 -6.73234323e-03  3.04353028e-03 -2.97669391e-03
  7.95178115e-03 -4.83356044e-03  7.17465300e-03  1.65927410e-03
  1.86824016e-02  1.40986254e-03  2.47372867e-04  1.29827997e-03
 -6.81070983e-03 -6.46421744e-04  5.44545474e-03  1.00408513e-02
 -5.96716860e-03  8.98986962e-03 -7.71491788e-03 -6.56015880e-04
 -2.32393388e-03  6.78442375e-05  6.75048726e-03 -2.92482623e-03
  1.85588002e-03  3.59823648e-03 -4.78420267e-03 -1.30771264e-03
  2.03278824e-03  8.31895974e-04 -2.27966788e-03  7.08232773e-03
  2.56278028e-04 -2.22953246e-03 -4.51887073e-03  4.32574609e-03
 -2.22277245e-03  6.36019325e-03  2.63845245e-03 -1.87676959e-03
 -5.27891284e-03  6.96293404e-03  2.81365828e-05  3.43699963e-03
  4.42604098e-04  1.38302310e-03 -1.11786602e-02  4.43437882e-03
  5.58953546e-03  5.13913855e-03  5.76717593e-03 -7.26089533e-03
  8.85069277e-03 -7.56234210e-03 -4.60302411e-03  4.80708806e-03
 -1.11296885e-02  4.75617172e-03  1.99360261e-03  1.14184571e-02
  1.84756122e-03  3.08883656e-03 -1.62204392e-02  4.85301903e-03
 -1.40037304e-02  1.58978589e-02  3.33967060e-03 -6.06432045e-03
 -3.00533976e-03  3.90516152e-03 -7.61342561e-03 -2.17841845e-03
 -6.44115312e-03 -5.85588021e-03  3.60320578e-03  1.02188159e-02
 -5.00156777e-03  4.20901086e-03  2.31184065e-03 -1.15025118e-02
  1.79983804e-03 -2.50713457e-03  8.45333445e-04  1.43991867e-02
 -3.29681602e-03  3.77208169e-04 -2.36983222e-04 -3.24469921e-03
 -3.82464356e-03  2.47592363e-03  2.09411094e-03  1.27793690e-02
 -1.56188966e-03  6.77646091e-03  5.66149037e-03 -4.64575645e-03
 -2.80693267e-03 -1.36258823e-04  4.68529761e-05  2.69205379e-03
  5.20985574e-03 -5.59300510e-03  4.00822656e-03 -8.11403710e-03
 -4.54911590e-03 -9.81791969e-03 -7.07390206e-03  5.91339835e-04
  4.38016187e-03 -5.10700140e-03  1.43803982e-03 -4.15368751e-03
 -1.09771611e-02 -1.38640776e-03 -1.00057770e-03 -2.68209539e-03]
tensor_name:  TemporalFusionTransformer/dense_23/kernel
[[-0.07915851  0.09617262  0.00846682 ... -0.09538013 -0.1490517
   0.09239566]
 [-0.11552066  0.09039125 -0.12434442 ... -0.02184848  0.12025096
  -0.02501812]
 [ 0.11996467 -0.11439773 -0.08100293 ...  0.04989411 -0.11727189
   0.05041331]
 ...
 [ 0.03766814  0.07675872  0.00598003 ...  0.1108693   0.08818756
  -0.06671312]
 [-0.0565448   0.09917118  0.05948805 ... -0.0444303  -0.02827616
  -0.08645604]
 [-0.09930742 -0.109086    0.04184054 ... -0.1326195   0.02116999
   0.05478465]]
tensor_name:  TemporalFusionTransformer/dense_24/bias
[-2.57523824e-03  5.67306625e-03 -4.51949984e-03 -2.24536704e-03
  7.39625981e-03  6.90719287e-04  3.71824531e-03 -1.04668643e-02
  4.80242586e-03 -1.02737285e-02 -1.57239027e-02 -3.19541257e-04
 -1.11505082e-02  1.32399229e-02  3.53203597e-03 -1.58939306e-02
 -1.24177721e-03 -6.70897309e-03 -7.92031921e-03 -5.85395424e-03
 -8.31343140e-03 -3.88438092e-03  1.62576174e-03  1.87840045e-03
  1.06029231e-02 -1.16062174e-02 -2.88562267e-03 -3.78036895e-03
  5.64355962e-03 -4.73540230e-03 -5.76546183e-03 -8.15617293e-03
 -6.86039403e-03 -9.12939478e-03  1.10048801e-02 -2.75645696e-04
 -5.23661869e-03  1.03970896e-03  5.22216200e-04 -1.24385757e-02
  1.04778511e-02 -1.52932166e-03  4.02744813e-03  3.25795077e-03
 -9.33478586e-03 -5.43050515e-03 -1.04271676e-02  2.88644782e-03
 -1.23569649e-03 -5.61189745e-03 -5.78062143e-03 -1.15531567e-03
  1.47087304e-02 -5.38436882e-03 -1.74090378e-02 -2.43202224e-03
  5.68485260e-03 -1.01509690e-02 -2.83804792e-03  8.04140233e-03
 -7.68072298e-03  2.73001986e-03  1.42035584e-04 -1.14833098e-02
  4.20153281e-03 -9.17874929e-03  1.83155353e-03  6.70295581e-03
  3.13911471e-03 -4.84680757e-03  7.34031852e-03  6.02735905e-03
 -1.00846905e-02 -8.16969853e-03  5.43958135e-03 -6.07654685e-03
 -3.63024254e-03 -4.22036648e-03 -1.82399573e-03 -6.05927221e-03
  3.51331057e-03 -9.67821945e-03 -8.70254007e-04 -5.60780475e-03
 -4.44873527e-04 -8.41708761e-03 -5.12421038e-03 -1.30097708e-02
 -6.85262866e-03  3.69391358e-03  8.04338139e-03 -8.59517240e-05
  1.30485365e-04 -3.80448735e-04 -4.90854634e-03 -9.09478310e-03
 -1.03528099e-02  2.56261230e-03 -6.54401351e-03 -3.13595450e-03
  6.31563505e-03  1.16287230e-03 -5.34260739e-03  4.20531817e-03
  2.81940517e-03  3.47698876e-03  9.82167386e-03 -5.69723407e-03
  1.25683323e-02  1.01999491e-02 -1.32235158e-02  2.55108601e-03
 -9.33799660e-04 -4.72470513e-03  1.32798858e-03  3.64901358e-03
  3.88737838e-03 -1.05886208e-02 -1.98842119e-03  5.44209033e-03
 -1.29996222e-02 -4.26721759e-03  2.03262176e-03 -7.84150977e-03
 -4.91744513e-03 -1.27762393e-03  4.00921766e-04  1.96075048e-02
  3.88345495e-03 -1.69652002e-03  8.67720053e-04 -2.16732049e-04
 -1.90785504e-03  7.60774303e-04  4.39385325e-03  1.12214675e-02
 -7.22077396e-03 -1.29137319e-02  6.27077417e-03 -7.46668410e-03
 -1.30674466e-02 -2.97207432e-03  3.00153112e-03 -8.53911042e-03
 -7.10226828e-03 -5.27516799e-03 -3.49186826e-03  1.10861082e-02
  6.76146592e-04 -9.04603582e-03 -7.01881526e-03 -1.08327428e-02
 -1.15557620e-02 -7.27330474e-03 -5.58166765e-04  9.66224878e-04
  5.78163378e-03 -5.50671713e-03 -2.62463978e-03 -2.40443111e-03]
tensor_name:  TemporalFusionTransformer/dense_24/kernel
[[-0.10231971 -0.09527954 -0.11778963 ... -0.05182911  0.06946418
  -0.0041478 ]
 [ 0.03418838 -0.12767953 -0.12515464 ...  0.08604706 -0.06663154
   0.00683443]
 [-0.11998066 -0.07490154  0.12032212 ... -0.03697257  0.08816993
  -0.12424635]
 ...
 [-0.08618184 -0.0958489  -0.09858478 ... -0.04860016  0.00735964
   0.0400805 ]
 [ 0.11311907 -0.04863563  0.0987113  ... -0.01881105  0.11943322
  -0.08371161]
 [ 0.10811636  0.00511341  0.04780121 ... -0.01607447 -0.13242455
   0.00181801]]
tensor_name:  TemporalFusionTransformer/dense_25/bias
[-1.76213998e-02  9.24892630e-03 -1.25272768e-02 -1.75025333e-02
 -1.98775902e-02 -9.92797315e-03  4.82328199e-02  1.58954132e-02
 -1.37401838e-02  2.00969167e-02  2.22935285e-02  8.80796346e-04
  1.79676637e-02 -1.60642136e-02 -9.88371391e-03 -1.75021049e-02
 -1.39233377e-02 -4.11283039e-03  3.57186571e-02 -1.06881978e-02
 -1.29683027e-02 -1.76708382e-02  1.31093906e-02  7.37396255e-03
 -7.06862099e-03 -1.23407794e-02 -1.42483246e-02 -1.17150703e-02
  1.40650719e-02  1.22015979e-02  1.13730049e-02  1.37398904e-03
 -1.06138615e-02 -4.29268880e-03  3.21922190e-02 -6.12837821e-03
 -1.85040869e-02 -2.22311802e-02 -6.40722050e-04  1.84115395e-02
 -3.82591691e-03 -1.38620904e-03 -8.60985462e-03 -1.82034243e-02
  7.90489558e-03  1.42435450e-03 -1.81519315e-02 -1.51796052e-02
  3.52146430e-03 -1.61003973e-02  5.41589782e-03  5.86954411e-03
  2.26264764e-02  2.84061246e-02 -5.64243644e-03 -2.27158442e-02
  1.51334349e-02  1.57287170e-03 -1.95396561e-02 -6.54348545e-03
 -1.05006574e-02  1.55539662e-02 -1.36849210e-02 -3.58746201e-03
  5.67157492e-02  2.54462939e-02  5.24207950e-03 -1.18306670e-02
  2.34592496e-03 -9.47182439e-03  3.10971532e-02  6.42672740e-03
  2.21913890e-03 -1.16040101e-02 -1.68448873e-02 -6.03823038e-03
 -3.94451758e-03  3.99468205e-04 -1.23312874e-02  6.97708549e-03
 -1.53414132e-02  7.22703335e-05 -1.99884363e-03 -1.14134243e-02
  1.14630384e-03  4.03857557e-03 -3.35150072e-03  6.16400689e-03
 -2.50739069e-03 -4.33462486e-03  1.78717496e-03  1.48997353e-02
 -8.84726085e-03 -6.09870825e-04  9.30338446e-03 -1.43102380e-02
 -1.53660672e-02 -1.36134708e-02  5.13579361e-02 -1.32815037e-02
  6.29046233e-03 -1.42835537e-02  2.38497788e-03  1.12917414e-02
 -1.01559199e-02  3.69639210e-02  1.62655173e-03 -1.55079998e-02
  8.66420660e-03 -1.91615373e-02  7.36749098e-02 -1.49901370e-02
 -1.46403331e-02 -2.09098998e-02 -1.38331549e-02 -6.92163035e-03
  2.15496644e-02 -1.11609334e-02  6.65713474e-03 -1.51442653e-02
  3.22212931e-04  5.04286028e-03 -7.59522198e-03 -4.76076547e-03
 -1.89148840e-02 -7.64653506e-03  1.55291734e-02 -1.17180217e-02
  4.59291833e-03 -3.21858451e-02  6.70184381e-05 -9.44865961e-03
 -4.90023475e-03  1.60182349e-03 -1.36052736e-03 -1.92522118e-03
 -1.14332372e-02 -8.18704162e-03 -1.56325176e-02  1.45163173e-02
  5.46660041e-03 -1.85660236e-02 -1.33085353e-02  3.42439598e-04
  2.98436992e-02 -9.07107815e-03  5.90147311e-03  1.36739351e-02
  1.22392420e-02 -2.76309401e-02 -9.88025870e-03  3.02474685e-02
 -8.19846150e-03  1.06468480e-02 -9.63433273e-03  1.77819200e-03
  1.27728982e-02 -9.04393196e-03  2.05656141e-02 -2.86366651e-03]
tensor_name:  TemporalFusionTransformer/dense_25/kernel
[[-0.02429426 -0.13160877  0.03229751 ... -0.05691092  0.10974653
  -0.11649529]
 [ 0.02063221 -0.01346227  0.06684699 ... -0.00605779  0.03220323
   0.09610943]
 [-0.13769305  0.08662058 -0.08387291 ... -0.05784613 -0.02680454
  -0.04548107]
 ...
 [-0.1498261   0.07438438  0.09700152 ...  0.02976828 -0.04967829
  -0.11437629]
 [ 0.06116701 -0.11440308  0.10035279 ... -0.07304017 -0.1333376
  -0.00889593]
 [ 0.08674341 -0.09866892  0.1334449  ...  0.00606206 -0.12795371
  -0.05395888]]
tensor_name:  TemporalFusionTransformer/dense_26/bias
[ 2.08041314e-02  8.96377768e-03 -2.81509496e-02  1.23611721e-03
 -3.93270701e-02 -5.71485469e-03 -7.07242731e-03 -4.73105721e-02
 -1.25488648e-02  7.14197755e-03 -3.43919545e-02  1.14374720e-02
 -4.96232929e-03 -9.18461737e-05 -1.91404298e-02  2.23049782e-02
 -1.36867464e-02 -2.56162719e-03 -1.91642921e-02 -2.11535748e-02
  1.60787418e-03 -1.55777112e-02  1.68367736e-02  2.16340162e-02
  5.04859537e-02 -1.44261857e-02 -2.92115454e-02 -2.86343694e-03
  2.59549394e-02 -4.17356379e-02  2.24572849e-02  5.88192721e-04
  2.05874965e-02  1.91510040e-02  1.05528925e-02  3.27719413e-02
 -1.33347269e-02 -5.34230564e-03 -8.50362983e-03 -2.66365288e-03
 -5.83812082e-03  2.62118988e-02 -2.38668676e-02  9.14352108e-03
 -1.31380819e-02 -1.17016176e-03 -1.14142466e-02  2.44596857e-03
  1.00246351e-02 -8.44178256e-03  4.84832490e-05  3.25631127e-02
  3.24792275e-03  1.18956463e-02  5.17045297e-02  3.97755504e-02
 -9.87821841e-04  9.38233640e-03 -1.37387272e-02 -4.31630090e-02
  1.18682897e-02  1.23836501e-02 -5.38101420e-03 -9.04029887e-03
 -3.50337774e-02  2.31638621e-03 -1.74077023e-02  3.34244519e-02
 -1.30008580e-03  1.89128425e-02 -1.41018834e-02  2.17951834e-02
  1.72587503e-02 -1.23344874e-03  4.93471511e-03  1.34752579e-02
 -9.57841706e-03 -1.26542682e-02  2.66344100e-02  1.11008892e-02
  3.95957120e-02 -6.33134926e-03  1.01216650e-02  2.02011857e-02
 -3.11355423e-02 -2.86951549e-02 -2.51110252e-02  3.59926037e-02
 -8.92834086e-03 -1.90041810e-02  5.07758325e-03  5.28814876e-03
 -1.56649221e-02 -1.89257357e-02  4.65119164e-03 -1.41393160e-02
 -7.94020388e-03 -1.83334798e-02  2.59692390e-02  8.43744446e-03
 -1.84201952e-02  7.44275469e-03 -2.06528651e-03  5.25484085e-02
 -1.47999683e-02 -1.47067173e-03 -2.27741841e-02 -5.20249922e-03
 -2.96867117e-02 -2.51312517e-02  1.11944107e-02 -2.75585912e-02
  4.89344215e-03 -3.76400463e-02 -4.17804997e-03 -1.09503223e-02
 -3.57977003e-02  1.28068626e-02 -2.76853554e-02 -1.48426900e-02
 -2.48638298e-02 -1.22414613e-02  1.43974032e-02  2.49998886e-02
  2.07427852e-02 -8.81967542e-04  3.11374273e-02  1.74353905e-02
 -5.75289014e-04  1.81843974e-02  3.29591078e-03  2.87944288e-03
  1.55581825e-03 -9.21870582e-03 -7.83047057e-04  2.48397025e-03
 -1.17457788e-02 -8.95830896e-03 -4.39069280e-03  2.20314991e-02
  2.51625013e-03  4.99086222e-03  6.46390952e-03  4.76469006e-03
 -2.49060281e-02 -3.78445983e-02 -9.52404831e-03 -1.96370110e-02
  1.24335429e-02 -1.32145965e-02  7.55133340e-04 -4.98104468e-02
  3.19088600e-03 -1.21141365e-02  2.85966564e-02  8.76343716e-03
 -1.12220338e-02  3.41072977e-02  1.17732421e-03  1.75027791e-02]
tensor_name:  TemporalFusionTransformer/dense_26/kernel
[[-0.10386777 -0.10526745  0.03664207 ... -0.07421166 -0.08196726
  -0.0341386 ]
 [ 0.1054593  -0.05038299 -0.06167104 ... -0.01012506 -0.05670644
  -0.04787921]
 [ 0.08501042  0.00205805 -0.07822583 ... -0.02473395  0.06026619
   0.07649139]
 ...
 [ 0.02632375  0.07369732  0.16049132 ... -0.03137877  0.07839488
  -0.05025379]
 [ 0.09810145 -0.04369388  0.06694356 ...  0.107053   -0.08651917
   0.14721802]
 [-0.10673733  0.00920749  0.11229443 ...  0.1762508   0.00129244
  -0.05377942]]
tensor_name:  TemporalFusionTransformer/dense_27/bias
[ 0.00382657 -0.01839125  0.01068437  0.0018293   0.00135166 -0.0073294
  0.00419984 -0.00515298  0.00579568 -0.00310787  0.00903994 -0.02997259
  0.00888607  0.01431982 -0.00219163 -0.00866875 -0.06270426  0.00158579
 -0.00336386 -0.00317392 -0.00388101  0.00260387 -0.01978688  0.00261737
 -0.00424086  0.06119231  0.0055707   0.00552208 -0.00614964  0.01013929
  0.00024639  0.00425941 -0.0056902   0.00935372 -0.01008536 -0.00300631
 -0.001192    0.00327826 -0.00597601  0.00371951 -0.01068791  0.00565678
 -0.00328     0.02072042 -0.03560552  0.00289301  0.01440259  0.0013125
  0.00299969  0.00344742  0.0060984  -0.00042181 -0.00355608  0.00577703
  0.0031495   0.00390228 -0.00362678  0.00123571 -0.02640813  0.00503729
  0.0254007  -0.00165884  0.00359427  0.02294213  0.00289093  0.01754999
 -0.00288818  0.00272305  0.00348645 -0.00518217  0.00645372  0.00315138
 -0.0235583   0.00654689 -0.00374311 -0.00587774  0.00541225  0.00216491
 -0.00287908  0.03388096 -0.0076065  -0.00404876 -0.0139153   0.00827942
  0.01088735  0.00516748 -0.0158394  -0.01947269 -0.0053382  -0.01838459
 -0.02847259 -0.00392109 -0.00724328 -0.03785849 -0.0021612  -0.01869036
 -0.00369511 -0.00340158 -0.00128553  0.00540003  0.02396758  0.00451813
  0.00487958 -0.00513373 -0.01251493  0.00579353 -0.00092797 -0.00934202
 -0.03618716  0.03766893 -0.00620981 -0.00411003  0.00772474 -0.02422139
  0.0075675  -0.01235956  0.00616159  0.01803757  0.00710843 -0.00514601
  0.04599031  0.0073413  -0.00625496 -0.0060185  -0.01664485  0.01182506
  0.00052378  0.00705069 -0.0118244  -0.00892275 -0.00608761 -0.03811827
  0.00591335  0.08779171 -0.00772841 -0.00306318  0.03783633 -0.01081102
  0.00010755  0.01157867 -0.0041781  -0.00151973  0.00531812 -0.02158487
 -0.0031084   0.00713372 -0.04474013  0.02251928 -0.05572988 -0.00213309
  0.00149125  0.03971423  0.00326891  0.00350049  0.00242996  0.01949754
 -0.00376565  0.01374326  0.00181843  0.00504586]
tensor_name:  TemporalFusionTransformer/dense_27/kernel
[[ 0.06031868 -0.04314247 -0.01360296 ... -0.07333488  0.02851808
   0.01448651]
 [ 0.00092971 -0.07441553  0.10717805 ... -0.05056103  0.0046318
  -0.09042772]
 [-0.06181307  0.03811327 -0.06555455 ... -0.0544149  -0.13969176
   0.01154244]
 ...
 [-0.01681333  0.0507669   0.05055926 ... -0.04769004  0.08985475
   0.14907941]
 [-0.09038216 -0.01028435  0.08393107 ...  0.09835459 -0.07327928
   0.06329439]
 [ 0.06381063 -0.1658162   0.06921664 ...  0.17065132 -0.07496991
  -0.03758224]]
tensor_name:  TemporalFusionTransformer/dense_28/bias
[-0.02120398  0.0270631   0.00759977 -0.02460536 -0.02034226  0.00052098
 -0.01992038 -0.00683061  0.00548288 -0.01417421 -0.01839016  0.01453734
 -0.01656793  0.01073725 -0.01341462 -0.0313259   0.02852865 -0.02463653
 -0.00789915 -0.0191185  -0.01853539 -0.00191277  0.0134703   0.01005097
 -0.01056052  0.03180076  0.00087387 -0.0278084  -0.02365051 -0.02700601
 -0.0226135  -0.01475536 -0.00960323  0.00074068 -0.02518975 -0.03922327
  0.02187022  0.00980539 -0.01794832 -0.00705597 -0.00600152 -0.01075185
 -0.0168653   0.03217243  0.01899051  0.00078245 -0.02260675 -0.02718992
 -0.00611907 -0.01984186  0.00320373 -0.00399687 -0.00442199 -0.01549313
  0.00934543 -0.01973313 -0.02960277 -0.0284506  -0.03102911 -0.01296175
  0.00270453 -0.0050276  -0.02526814  0.01398095 -0.01662605  0.00822293
 -0.02627728 -0.00750354 -0.03669675  0.0096866  -0.02758089 -0.023376
  0.01710298 -0.01238414  0.0137995  -0.00255113  0.00978235 -0.01951099
 -0.02422276  0.01313356 -0.01431156 -0.01607455 -0.03256303 -0.02981395
  0.00110294 -0.00202838  0.03051025  0.01131648  0.01692703  0.010578
  0.0309713  -0.01687489 -0.01042706  0.01995783  0.01115288  0.02769411
 -0.01791243 -0.03286114 -0.00032497 -0.02336238  0.00827371 -0.01081017
 -0.00677362  0.00616981 -0.0078959  -0.01435206 -0.02602325 -0.00393177
  0.02250537  0.0167401  -0.02088727 -0.01618596  0.00305662  0.02865194
 -0.01937202 -0.0015576  -0.01942904  0.01906322 -0.02415476 -0.01442222
  0.02708228 -0.01672159 -0.00863456 -0.01935927  0.01395484  0.01459773
 -0.0203916  -0.02719377 -0.02548001 -0.02666893 -0.00107947  0.01506073
 -0.02132227  0.03684323  0.0164942  -0.01373956  0.01220149  0.00544805
 -0.02941755  0.01161955 -0.0225154  -0.02798231 -0.00837111  0.0211866
 -0.01873816 -0.016042    0.0263524   0.01543393  0.0325128   0.01915959
 -0.00312913  0.03548147  0.00551364 -0.01242421 -0.00247848  0.0225863
 -0.00758501  0.01437444 -0.03962405  0.00965315]
tensor_name:  TemporalFusionTransformer/dense_28/kernel
[[ 0.04061992  0.01265285 -0.06091847 ... -0.06717956 -0.13035007
  -0.07692563]
 [ 0.00961992 -0.01834746 -0.14438643 ... -0.07826252  0.09338956
  -0.05856448]
 [-0.11904325 -0.05994329 -0.01266785 ...  0.02707017  0.02065518
  -0.0903748 ]
 ...
 [-0.07809377 -0.11740813  0.00910203 ...  0.07214975 -0.04507402
   0.15417759]
 [-0.00804194  0.01751957 -0.05799297 ...  0.01128366  0.06053409
  -0.0480626 ]
 [-0.00783568  0.01040359 -0.0142548  ...  0.16114353 -0.1992825
  -0.15127589]]
tensor_name:  TemporalFusionTransformer/dense_29/bias
[ 0.01014899 -0.00528359  0.03356391  0.00572067 -0.00088749 -0.00976002
  0.00910761  0.03819366 -0.0045788  -0.00808432  0.00527613 -0.01150822
 -0.01877432  0.00240841  0.00212621 -0.00829951 -0.00463829 -0.0120522
 -0.00688006 -0.01000302 -0.00448811 -0.00251494 -0.0129969  -0.00427182
 -0.00962875 -0.00928069 -0.01220366  0.01582212 -0.01483325  0.00669222
 -0.01210932  0.01178614 -0.00181452  0.00239395  0.00074976 -0.01036132
 -0.00998654  0.00072436 -0.00334457  0.00354767 -0.00903963 -0.00287357
 -0.00254602  0.00159528 -0.00061583 -0.02094092  0.02049248 -0.02388095
  0.00519503 -0.00757761 -0.01426596 -0.01730196 -0.00814951 -0.00161001
 -0.00296223 -0.00759891  0.0335122  -0.00774151  0.01069462  0.00249231
 -0.00954505  0.01255032 -0.01459599  0.02538337  0.01549119  0.02153586
  0.01105565  0.02390703 -0.01103591 -0.00453467  0.01124984  0.00807708
  0.00144886  0.00667185 -0.01300018  0.02803043 -0.0190201  -0.00533666
  0.02495261  0.0023789   0.00836682 -0.0045333   0.00779308  0.01961218
 -0.00841711  0.01189824 -0.0130469   0.03319828  0.00057293  0.01719603
 -0.0094953   0.01965508  0.00078884  0.00562612  0.02197674  0.02044304
  0.0097815   0.00851957 -0.01273581  0.00402451 -0.00358031 -0.00069404
 -0.00855081 -0.01227735 -0.00089561 -0.00482936 -0.00585339  0.00614005
  0.00502409  0.00742126 -0.01094514 -0.01314754  0.01172394  0.01637078
  0.00538563 -0.01089815  0.01636683 -0.00091293 -0.01258673 -0.01742162
 -0.00773447  0.01231214 -0.01128028 -0.00990048  0.02793388  0.015807
 -0.00402612  0.02896166  0.03104995 -0.00778357 -0.00511798  0.00376014
 -0.00896831  0.01007732 -0.00695089 -0.00177282 -0.01147712 -0.01291074
  0.00031881  0.00274672 -0.01275521  0.00542128 -0.00528469 -0.00186907
 -0.0070634   0.00618166 -0.00674999 -0.01264488 -0.00884047  0.00707277
  0.02316691 -0.01660709 -0.01226443 -0.01390836  0.00212475  0.00872781
  0.00064527  0.01650655 -0.02209526 -0.00915684]
tensor_name:  TemporalFusionTransformer/dense_29/kernel
[[-0.0952925   0.07725515 -0.15660487 ... -0.14408919 -0.01407955
  -0.04134195]
 [ 0.00514181 -0.07314155  0.1322321  ...  0.08447678  0.12240717
   0.06054095]
 [ 0.10772838  0.04320927  0.10877024 ...  0.0556296  -0.03663509
  -0.12074468]
 ...
 [-0.04962644 -0.12893975  0.11886559 ... -0.0049503  -0.00976472
   0.11754677]
 [ 0.11183666  0.08441229  0.08541499 ... -0.09384046  0.10523355
  -0.11947857]
 [ 0.02795867  0.07348884 -0.00560149 ...  0.1381295   0.07458979
   0.08522083]]
tensor_name:  TemporalFusionTransformer/dense_30/bias
[ 1.58486106e-02 -2.26103421e-02 -1.81652710e-03 -1.05899442e-02
  4.38911142e-03  2.99569406e-02  5.97612280e-03 -1.25216013e-02
 -1.16338925e-02  4.25560735e-02  1.33916261e-02  2.90976204e-02
  1.18096154e-02 -7.02851498e-03  3.61216255e-03  1.13471504e-02
 -6.19951915e-03 -9.36946925e-03  1.55216325e-02 -2.31734328e-02
 -8.99245683e-03  3.78954923e-03  8.49944353e-03  1.05167637e-02
 -8.60137492e-03  7.06928829e-03  9.52487625e-03  7.20176613e-03
  3.10888886e-02 -5.40368957e-03  7.24306190e-03  4.37957747e-03
 -4.99182986e-03  6.46729395e-03  1.29430811e-03  2.25432534e-02
  5.74086187e-03  1.99433183e-03 -3.60523234e-03  4.37916396e-03
  7.88782351e-03 -3.48088257e-02  7.77901476e-03 -2.47303937e-02
 -1.09464685e-02  2.93104295e-02 -6.92636706e-03 -8.07643030e-03
  4.82803304e-03  6.82168035e-03  1.33298561e-02 -5.53010788e-04
  4.92085586e-04  3.20361985e-04  2.12588068e-02  1.31978444e-03
 -1.08696790e-02  3.46657559e-02  1.57045468e-03  2.46470813e-02
  3.60686257e-02 -1.48274575e-03  1.07872775e-02  6.68203644e-03
 -1.19162211e-02  8.25230405e-03  1.21912025e-02 -4.25042445e-03
  1.47690775e-03  1.93871949e-02  1.38966171e-02 -7.46766478e-03
  3.01121804e-03 -4.12104316e-02  4.79020365e-03  3.24949399e-02
 -2.24458724e-02 -1.99392159e-02  5.68379874e-05  2.23335065e-02
  2.20343806e-02  2.38687843e-02 -6.98535377e-03  1.44342985e-02
  3.25437542e-03  9.17915441e-03  1.11163114e-04  5.82726300e-03
 -1.65713578e-02  2.67374399e-03 -1.35566425e-02 -1.79596115e-02
 -4.46249507e-02 -4.26244736e-03  8.17418471e-03  1.41478637e-02
 -2.39581903e-04 -1.82968006e-02 -1.93125531e-02 -1.37047758e-02
  3.74504976e-04 -2.01386288e-02  4.57630772e-03  1.01442877e-02
  2.37928703e-02 -1.36174615e-02  5.43705770e-04  9.83522041e-04
  4.08526883e-03  3.44775617e-02  2.61477055e-03  1.02896355e-02
 -3.70069444e-02  9.11770388e-03 -1.60896275e-02 -3.21786702e-02
  1.83239505e-02 -3.35654244e-03  1.16320336e-02 -1.38384867e-02
  5.91858104e-03 -5.02600055e-03 -2.40155645e-02  1.47352656e-02
 -9.42600984e-03  7.50577450e-03 -6.41194033e-03  9.11295228e-03
 -3.37701407e-03  4.22712695e-03 -1.09293368e-02  3.05732060e-03
 -3.38730565e-03  7.64759199e-04 -9.32316296e-04  1.40358172e-02
 -2.21425411e-03 -8.36419349e-04  3.11866216e-02  6.18512928e-03
  3.49996909e-02  1.73150934e-02  8.71808641e-03  3.20871472e-02
  2.48562284e-02  6.09893948e-02  1.92660075e-02  5.34810941e-04
 -2.49515520e-04  3.70070674e-02  1.10384235e-02 -1.09731285e-02
  5.20275440e-03  1.82821508e-02 -2.87133008e-02  4.14595846e-03
 -8.39239359e-03 -8.00740148e-04 -1.82436612e-02  1.15851162e-03]
tensor_name:  TemporalFusionTransformer/dense_30/kernel
[[-0.09314007 -0.02847746 -0.05668051 ... -0.13902591  0.07514634
   0.09811506]
 [ 0.09366103 -0.06113822 -0.11230919 ... -0.09453568  0.18192266
   0.08767191]
 [ 0.16753343 -0.05021489  0.13409583 ... -0.05924938  0.07939362
   0.1115909 ]
 ...
 [-0.02035547 -0.16586217 -0.09940226 ... -0.04618735  0.09477025
  -0.08718549]
 [-0.01733538  0.14649266 -0.11269157 ...  0.15071668  0.07361005
   0.08198241]
 [-0.13872127 -0.09947095 -0.0669915  ...  0.00612989  0.02578502
   0.02684957]]
tensor_name:  TemporalFusionTransformer/dense_31/bias
[-0.00423488 -0.00847895 -0.01245459 -0.00158383 -0.01272937 -0.03921
 -0.00515002 -0.00133871 -0.0056058   0.0016579  -0.00362897 -0.00985171
  0.01911222 -0.00614036 -0.00419921  0.01247588 -0.00347001 -0.04091263
 -0.00209372 -0.00876132  0.00665676  0.00142803  0.00198132  0.00574623
  0.00042062  0.03720962 -0.00668623 -0.02755171  0.00948422  0.01152103
  0.01388483 -0.00091151  0.00197652  0.06586621 -0.02026842 -0.03619782
 -0.00057258 -0.01264995 -0.04222905  0.02389297 -0.00118833  0.00034907
  0.00260274 -0.00848762  0.00878998  0.00212316 -0.00172866  0.00297608
 -0.00028678  0.00497494  0.01360263  0.00679489 -0.00212737  0.00636923
  0.00941527  0.0059951  -0.00563052 -0.00796061 -0.00395858  0.02555022
  0.02428507  0.02953701 -0.02487865  0.01065578 -0.00608752 -0.00636206
  0.00598346 -0.00271565  0.0044461   0.00847832  0.00329145 -0.0032127
 -0.01186817 -0.01509601  0.00553872 -0.00340546  0.00439462  0.0054158
 -0.00522571 -0.00876089 -0.00571869 -0.02242578  0.02414715  0.00995465
  0.01966575  0.00612321  0.0062069  -0.00486271 -0.00466629  0.0016476
  0.00146419  0.01463587  0.00062687 -0.00501237 -0.01240842  0.002226
  0.02235441 -0.00214799 -0.00732242  0.00670351 -0.00499953  0.00637259
  0.00374674 -0.00162947 -0.00661118  0.0056322   0.00209199 -0.0052209
  0.0064446   0.00051661  0.005591   -0.01231935  0.01066366 -0.00532421
 -0.00084764  0.0243774   0.02933239  0.00164822 -0.00973736 -0.00239511
  0.00442821  0.02065366 -0.00786069  0.00146255 -0.00411597  0.01009575
  0.00620537  0.06105904  0.00225479  0.00333627 -0.00612224  0.01146413
  0.00545941  0.00607873  0.00274374 -0.00544009  0.02947353 -0.02976873
 -0.00073954  0.00668179  0.00395867 -0.00496358  0.01103913 -0.00323854
 -0.003325    0.00860681  0.00699639 -0.00416472 -0.00676335  0.01307732
  0.00455595 -0.00711177  0.01159991 -0.00528969  0.00127346 -0.00166394
  0.00938305  0.01915122 -0.0277489   0.00245252]
tensor_name:  TemporalFusionTransformer/dense_31/kernel
[[-0.04456004 -0.09671904  0.03552762 ... -0.03744234 -0.04483771
  -0.01492815]
 [-0.03084436 -0.03665888 -0.00717493 ... -0.04334005  0.0710179
  -0.1120595 ]
 [ 0.06911325 -0.11531845 -0.1023671  ...  0.00230925 -0.14300048
   0.08826151]
 ...
 [-0.04622103 -0.05972904  0.11895709 ...  0.00242922  0.08830044
  -0.03297668]
 [ 0.01452733 -0.05603364 -0.01095621 ...  0.10905773  0.10450415
  -0.08443013]
 [ 0.04868809  0.0327345   0.06667433 ...  0.00953998  0.11024626
   0.05597604]]
tensor_name:  TemporalFusionTransformer/dense_32/bias
[-0.01045314  0.01725824  0.01382318 -0.01013118  0.00214037  0.02280155
 -0.0137091  -0.02324642  0.02012385 -0.00325091 -0.02148203 -0.01102503
  0.0039161  -0.01381536 -0.0257625   0.01945437 -0.0129183  -0.01950575
 -0.02880516 -0.00786432 -0.00913625 -0.01456487 -0.01444873  0.02588768
  0.00799493  0.01380941 -0.00720911  0.02813056  0.01324276 -0.00643531
  0.00490776 -0.02862893 -0.00221175  0.01457366 -0.00408684  0.02044157
 -0.0184439  -0.0031994   0.02816074  0.01453018 -0.01398952 -0.02698301
 -0.01112488 -0.00839326 -0.02570752  0.0016558   0.00710021 -0.02463162
 -0.00713544 -0.02691474  0.01693889 -0.01962547 -0.00074006  0.01736131
 -0.02097382 -0.01271434 -0.01442302 -0.00182757 -0.01553835  0.01687418
  0.0219705   0.01169527  0.01781461  0.00865115  0.00412733  0.00869204
 -0.01537296  0.00565678 -0.00626269 -0.01419664 -0.00942556  0.00029295
 -0.02522264  0.01508672 -0.00387027 -0.00210618 -0.01122464  0.02170849
 -0.01976182 -0.02092383  0.00125767  0.02597488  0.04824349 -0.02729893
  0.02410255 -0.00639359 -0.01879676 -0.00388743 -0.00464196 -0.01207461
 -0.02801421  0.00956417 -0.02152128 -0.0318069  -0.01722256 -0.01524647
  0.0229407  -0.01866246 -0.01770905 -0.02762908  0.00187218 -0.01674869
  0.01794025 -0.00437222 -0.01141055 -0.00778868 -0.00943292 -0.0036779
 -0.01367408  0.00969826  0.01873066  0.01147735 -0.02140022 -0.02278867
  0.0020709  -0.01992998 -0.01609772  0.01740907  0.00757066 -0.02700747
 -0.01503148  0.02541182  0.01498282 -0.02010897  0.02426169 -0.01317087
 -0.01534664  0.03755515 -0.02073586  0.0029437   0.00211941 -0.03334203
 -0.01150415 -0.01907814 -0.0174092  -0.00804128  0.00945795  0.0107099
 -0.01834377 -0.00221677 -0.03122952 -0.0091025   0.00089807 -0.00809986
  0.00912713 -0.01093888 -0.01827631 -0.00563372 -0.00469518 -0.01932546
 -0.00452117 -0.00049421  0.01952036 -0.01528958  0.00172159 -0.02144674
 -0.00088811  0.02162769  0.02023894  0.00699811]
tensor_name:  TemporalFusionTransformer/dense_32/kernel
[[-0.10832649  0.07166212  0.0313695  ...  0.08594061  0.03608075
   0.01086853]
 [ 0.0622919   0.01481992 -0.10539493 ...  0.1481497   0.09119689
   0.04385034]
 [ 0.02255362  0.07420079  0.14883055 ...  0.00413629 -0.04910933
   0.04729105]
 ...
 [ 0.10214437 -0.07062307 -0.03321952 ...  0.03553652 -0.10676258
   0.04747829]
 [-0.08806678 -0.12063321  0.00397487 ...  0.04723782 -0.18121627
   0.09264781]
 [ 0.10018168 -0.06839325 -0.04878763 ...  0.01464529  0.08484755
   0.04844685]]
tensor_name:  TemporalFusionTransformer/dense_8/bias
[0.]
tensor_name:  TemporalFusionTransformer/dense_8/kernel
[[ 0.12179121]
 [-0.15310538]
 [ 0.15403286]
 [ 0.10076314]
 [-0.15532899]
 [ 0.08677465]
 [ 0.00805146]
 [-0.12295884]
 [ 0.01362322]
 [-0.15715948]
 [-0.06014915]
 [ 0.1130468 ]
 [ 0.01182333]
 [ 0.12284553]
 [ 0.15907615]
 [-0.00554033]
 [ 0.04381564]
 [ 0.03347114]
 [-0.0171477 ]
 [-0.00205359]
 [-0.16047321]
 [ 0.17877379]
 [ 0.03714588]
 [ 0.13703331]
 [-0.02648707]
 [ 0.07198045]
 [-0.14086537]
 [-0.1363558 ]
 [-0.10106926]
 [-0.03211801]
 [ 0.12596768]
 [ 0.11532089]
 [ 0.18525851]
 [ 0.15713388]
 [-0.09365619]
 [ 0.1639601 ]
 [-0.04172391]
 [-0.06121944]
 [-0.00986111]
 [ 0.05957434]
 [ 0.01892366]
 [-0.1149848 ]
 [-0.06914847]
 [ 0.10764691]
 [ 0.06244954]
 [-0.08785959]
 [ 0.05333014]
 [ 0.13187101]
 [-0.13523051]
 [-0.13427773]
 [-0.14111401]
 [-0.11922144]
 [ 0.0085513 ]
 [-0.10691599]
 [ 0.04189968]
 [ 0.07512039]
 [-0.14710635]
 [-0.08894975]
 [ 0.11293775]
 [ 0.14091015]
 [ 0.01226145]
 [-0.17089358]
 [ 0.1492947 ]
 [ 0.17925766]
 [-0.05683003]
 [ 0.10488799]
 [-0.11797349]
 [-0.05872294]
 [-0.16669211]
 [-0.18745284]
 [ 0.10601681]
 [ 0.10271922]
 [-0.05780846]
 [ 0.10455859]
 [ 0.0603143 ]
 [-0.1669139 ]
 [-0.17114322]
 [ 0.07012573]
 [ 0.03770068]
 [-0.11039472]
 [ 0.07372206]
 [ 0.10981801]
 [-0.03300545]
 [-0.13619149]
 [ 0.11728099]
 [ 0.04208714]
 [ 0.0422615 ]
 [-0.03612743]
 [-0.03379358]
 [ 0.12154606]
 [ 0.01073091]
 [-0.19043104]
 [-0.17594162]
 [-0.06587856]
 [ 0.05557376]
 [-0.11622294]
 [ 0.00023782]
 [ 0.14860114]
 [-0.05037545]
 [-0.02820654]
 [ 0.19191027]
 [ 0.1070329 ]
 [-0.14857398]
 [ 0.15275046]
 [-0.1616667 ]
 [ 0.13328394]
 [ 0.04128274]
 [ 0.03848229]
 [ 0.0856868 ]
 [-0.1658449 ]
 [-0.1791564 ]
 [-0.14616084]
 [-0.0122146 ]
 [ 0.16620049]
 [ 0.16399148]
 [ 0.10623029]
 [ 0.07285026]
 [ 0.10839173]
 [ 0.12790346]
 [-0.05791855]
 [-0.18321426]
 [-0.07308116]
 [ 0.14702055]
 [ 0.0050206 ]
 [ 0.18665424]
 [ 0.19085231]
 [ 0.10465902]
 [ 0.06185111]
 [ 0.1570848 ]
 [-0.18514855]
 [-0.08071999]
 [-0.1168019 ]
 [-0.16291341]
 [ 0.1497271 ]
 [-0.06963727]
 [-0.13910718]
 [ 0.06458035]
 [ 0.02487445]
 [ 0.0342717 ]
 [ 0.05648419]
 [ 0.05424859]
 [-0.14100157]
 [-0.14624493]
 [-0.10624304]
 [ 0.01831892]
 [-0.0326121 ]
 [ 0.03951605]
 [-0.10746977]
 [ 0.11141375]
 [-0.01549348]
 [ 0.03037749]
 [ 0.16503397]
 [ 0.13095257]
 [ 0.10424289]
 [-0.05263735]
 [-0.06515503]
 [-0.05910653]
 [-0.19077191]
 [ 0.01729485]
 [-0.00465097]]
tensor_name:  TemporalFusionTransformer/dense_9/bias
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
tensor_name:  TemporalFusionTransformer/dense_9/kernel
[[ 6.72109723e-02 -4.35981825e-02 -1.65903568e-02 ... -5.06592318e-02
  -1.02046289e-01 -1.15280256e-01]
 [-8.39129090e-02 -8.01752433e-02 -4.65958789e-02 ... -6.41231015e-02
  -8.90194625e-02  2.95788050e-05]
 [-1.24279290e-01  6.02098554e-02  1.26640201e-01 ... -9.17107016e-02
  -1.33355618e-01  1.26821101e-01]
 ...
 [-5.70689738e-02  3.14112008e-03 -1.06865704e-01 ...  1.30374461e-01
  -3.26972455e-02  1.28709942e-01]
 [-4.37633097e-02 -9.05134380e-02  2.62813717e-02 ... -6.84765875e-02
  -7.12668076e-02 -2.10924521e-02]
 [ 1.30120218e-01  1.36020631e-02  3.39801759e-02 ...  3.16087753e-02
   6.54108822e-03  1.32503510e-01]]
tensor_name:  TemporalFusionTransformer/embedding/embeddings
[[-0.03258996  0.0140067   0.03902913 -0.0321811   0.02522124 -0.03343284
   0.04126567 -0.03743618  0.04945181 -0.02418184 -0.01844786 -0.0184461
  -0.00125277  0.05391986 -0.02750159  0.05603892  0.0036296  -0.00230884
  -0.00051679 -0.04407297 -0.00791653  0.02952636  0.03399637 -0.03870456
  -0.00803708  0.01732885 -0.04106402 -0.0456234   0.05229086 -0.00101697
  -0.03175943 -0.04301109  0.03523635 -0.00594022 -0.05332492 -0.05398371
  -0.02078816 -0.01147833 -0.06800898  0.05372725  0.05904198  0.02596408
  -0.01872772  0.03765904 -0.04037835 -0.01159958 -0.01796138  0.02942509
  -0.02998959 -0.00883565 -0.02159924  0.07012529  0.04253082  0.05039107
   0.04348968 -0.00529575  0.01418313  0.04061921 -0.03503908 -0.03636761
   0.05353046 -0.00445181 -0.05755346  0.03626093  0.00227444  0.02578986
  -0.0466492  -0.02558993 -0.03426764 -0.01314132 -0.01715465  0.02540482
  -0.03870424 -0.02913517  0.01085639  0.07951117 -0.02006062  0.02382855
   0.03181696  0.03144733  0.02240993 -0.02584602 -0.029542    0.05420972
  -0.01032713  0.04212808  0.03786424  0.02646113  0.00378035  0.06215094
   0.00215305  0.00401954  0.04620206  0.03726291 -0.05050915 -0.01763618
   0.05812969  0.0045776   0.00064115 -0.04630755  0.0079604  -0.00193726
  -0.0379438   0.04940057 -0.01286088 -0.00369215  0.00708906 -0.07912473
   0.00284618  0.06003943 -0.03209743  0.01371909 -0.05051101 -0.05106532
   0.03818015 -0.03756596  0.05112588  0.03274819  0.03570543 -0.04421897
  -0.04113537 -0.01076738  0.00940526  0.03098816 -0.02768533  0.02214507
   0.05522509  0.05035502  0.03480735 -0.0329878  -0.03658907 -0.02649345
   0.03142251 -0.03277645  0.04141969  0.01790868  0.03823905 -0.00437701
   0.05131657  0.01530105 -0.0244001   0.01775163  0.04483988 -0.04729528
  -0.07343204  0.02482607  0.0406018  -0.04550648 -0.07359135 -0.00377912
  -0.02047517  0.01439369  0.01191    -0.00267453  0.00197443  0.04416884
   0.02700323  0.05703038 -0.0359504  -0.02624951]]
tensor_name:  TemporalFusionTransformer/layer_normalization/beta
[0.]
tensor_name:  TemporalFusionTransformer/layer_normalization/gamma
[1.]
tensor_name:  TemporalFusionTransformer/layer_normalization_1/beta
[-9.36973281e-03 -4.10410156e-03 -7.47035781e-04 -1.17183495e-02
 -2.43890309e-03 -3.29996622e-03  8.99889413e-03 -6.50868751e-03
  2.19996572e-02  7.26366416e-03 -8.42554122e-03 -1.00318091e-02
  1.48895904e-02  3.02355271e-02 -9.30299889e-03  8.25256296e-03
 -2.12128200e-02 -5.92095125e-03  7.66600436e-03  6.75159693e-03
  2.42463034e-03 -4.17966070e-03 -4.87882784e-03 -3.66971106e-03
 -3.32849479e-04  1.77328475e-02 -1.61878932e-02 -5.87301096e-03
  2.27523446e-02  7.29942229e-03 -1.61112507e-03 -5.01134724e-04
 -5.83622931e-03  8.50627292e-03 -1.01141641e-02 -1.66952703e-02
 -1.42404223e-02  8.89277318e-04 -2.52245925e-02  1.70547310e-02
  1.40006300e-02  8.59154388e-03  1.88971474e-03  3.45851248e-03
 -5.45458589e-03 -7.51965446e-03 -2.02454370e-03  7.72741623e-03
  3.39638931e-03  2.18988210e-03  5.88678755e-03  1.90221183e-02
  1.20270411e-02  1.06250970e-02  7.47303572e-03 -6.22248556e-03
 -1.87093287e-03  6.03319332e-03 -4.71696863e-03 -1.41677458e-03
  5.41055482e-03 -2.91143218e-03 -9.06579848e-03  1.10851824e-02
  1.80648849e-03  1.06718978e-02 -1.30612012e-02 -7.81903602e-03
 -1.37866018e-02  6.92523608e-04  2.32497789e-03  7.79675879e-03
  1.52084546e-03 -1.69825722e-02 -2.13598507e-03  3.05136107e-02
 -8.16557370e-03 -3.73233124e-05 -6.66271383e-03  1.79286115e-03
  3.74177308e-03  7.35325925e-03 -8.01508967e-03  1.03926109e-02
 -2.87103094e-03  6.92914426e-03  3.95990722e-03  3.10432864e-03
 -3.93141853e-03  1.07990550e-02 -1.38723161e-02  2.20558300e-04
  5.46560809e-03  5.74819976e-03 -3.08109424e-03 -2.18335446e-02
  6.33669598e-03  9.39665362e-03 -9.36321169e-03 -1.10898316e-02
 -3.69733735e-03  9.21544526e-03 -8.50430632e-04  1.27269262e-02
 -1.50658097e-03  1.86413364e-03 -9.61253513e-03 -3.41150686e-02
 -4.08809073e-03  3.54875997e-02 -3.65966861e-03 -3.36310710e-03
 -7.14456104e-03 -2.08965428e-02 -2.19709077e-03 -2.35904311e-03
  1.03954449e-02 -4.33671009e-03  4.02464112e-03  3.20989289e-03
  6.07677444e-04  6.08456321e-03 -2.57991906e-03 -1.03966482e-02
 -7.78048625e-03  6.78139552e-03  2.24892106e-02  2.81915236e-02
  1.76520913e-03 -2.02543847e-03 -2.55334028e-03 -9.92418360e-03
  7.42472941e-03 -1.96878309e-03  1.27100535e-02  5.17658656e-03
  1.90820347e-03 -6.50749728e-03  8.13669525e-03  9.85938776e-03
 -8.51222221e-03  5.24153188e-03  7.88920186e-03 -1.08722365e-02
 -2.17940211e-02 -1.10375672e-03 -5.70641458e-03 -8.19652528e-03
 -2.55348030e-02 -1.57968258e-03  8.92748870e-03  9.67986323e-03
  4.22659609e-03 -1.14077488e-02 -7.83938274e-04 -1.41679507e-03
  1.68340169e-02  1.72427837e-02 -1.37229532e-03 -2.86979135e-03]
tensor_name:  TemporalFusionTransformer/layer_normalization_1/gamma
[1.0040067  0.9883252  0.99515754 1.0001549  0.9946001  0.9955814
 1.0036447  0.9997952  1.0190439  0.97242    0.995949   0.9990678
 1.0014259  1.0332409  0.98493916 1.0001079  0.9966421  0.98983043
 0.9846516  0.98781455 0.98056006 0.98670495 0.97599864 0.98251736
 0.9786699  1.0043586  1.0070218  0.9895761  1.0214512  0.98142767
 0.9953158  0.9864023  0.9848362  0.9942585  1.0030743  1.011309
 1.0055507  0.98380303 1.0209423  1.0091254  1.0049374  0.99174047
 0.9901798  0.99958867 0.9993223  0.9753405  0.9851999  0.9926011
 0.98218536 0.99404407 0.98223925 1.0164845  1.0090667  1.0057062
 0.9788965  0.97341985 0.9945099  0.98470676 0.975638   0.9928539
 0.9933563  0.99800014 1.0022664  0.98952997 0.98629767 0.9951385
 0.9925348  0.9989818  1.0081491  0.994804   0.9775327  0.9901952
 0.9914512  1.0076464  0.9951285  1.0327924  0.999844   0.9956188
 0.97756165 0.9745734  0.9925089  0.9825963  0.9988622  1.0095966
 0.99209297 0.99743605 0.9918613  0.9924565  0.9830796  1.0076749
 0.99414617 0.9846989  0.9913495  0.9970187  0.9896564  1.0192648
 1.002322   0.9985481  1.0030683  1.0045091  0.97271854 0.98277897
 0.9893294  1.0080351  0.98317564 0.9850303  0.98200864 1.0352788
 0.9828324  1.044427   0.9809976  0.9813649  0.96942973 1.0201999
 0.97535145 0.9955509  1.0034839  1.0017328  0.9708467  0.9803378
 0.9744956  0.9814277  0.97828627 0.99537057 0.97070736 0.982929
 1.0049016  1.0333748  0.97915447 0.9819322  0.9969982  0.995751
 1.0006164  0.99493575 1.0041595  0.9791307  0.98861915 0.973403
 0.99825406 1.0031433  0.9820456  0.99438703 0.99245864 0.9921928
 1.0186313  0.98360676 0.9921228  1.0014577  1.0322335  0.98947865
 0.9796308  1.0001719  0.98292136 1.0046958  0.9655661  0.988372
 0.9984679  1.0066295  0.98547477 0.98986286]
tensor_name:  TemporalFusionTransformer/layer_normalization_10/beta
[-0.00336626  0.02726004  0.02083713  0.00513544  0.00625213 -0.02705692
 -0.01853019 -0.02492593  0.00232543 -0.00034098  0.02952975  0.01554287
  0.0021062   0.0224737  -0.00636988 -0.00377542 -0.00951538  0.01305932
  0.03037598 -0.01615885 -0.00370471 -0.01302332 -0.00728776  0.00875652
 -0.00937937  0.02574027  0.00769657  0.00748892  0.02150555 -0.01219373
 -0.0040627   0.00260629 -0.00260218  0.00209266 -0.01239728  0.01147807
  0.00622397 -0.01735114 -0.00020481  0.01463881  0.00031618  0.0143641
 -0.01409793  0.00622954 -0.01576243  0.00241384 -0.00818926  0.02192775
 -0.00048009  0.00524117  0.01049042  0.03629545  0.00442344  0.00726574
  0.00905332  0.01002895  0.02028921  0.00010055 -0.01775638  0.00849036
  0.00059816 -0.00255304  0.01490705 -0.00282586 -0.00744683 -0.0040791
 -0.00613709  0.01534819  0.00587027 -0.01332965  0.0220727  -0.00288482
  0.02801413 -0.00888344 -0.01675219  0.01473908  0.01262398  0.00876932
  0.01382788 -0.01127058 -0.00677818  0.0065574   0.00890828  0.00085429
 -0.01540305  0.00351121 -0.00379722 -0.01023038 -0.01074611 -0.02163975
 -0.02592577  0.0010319  -0.00338073 -0.00474394  0.01658233  0.00855163
  0.01052587  0.00316621  0.0064424  -0.00785934 -0.00914208  0.01387999
  0.02239286  0.02132916 -0.02080826 -0.01295302  0.01535105 -0.01521561
  0.02861311  0.00556754 -0.00322032 -0.00908493 -0.02807742  0.0097439
 -0.02331224 -0.01779428  0.00972634 -0.01888113 -0.02527956 -0.00910561
  0.00772764  0.00128498 -0.01576368 -0.00601698  0.01231251  0.01567558
 -0.01461861  0.01520701  0.0073902   0.02740659 -0.00722825 -0.00193872
 -0.01798499  0.00597225 -0.02339796 -0.00316908 -0.01045688 -0.00275718
  0.00998436 -0.00835581 -0.00559771 -0.01033585  0.00195961  0.0241743
 -0.00567906  0.02369105 -0.01640266 -0.00704432 -0.00234317 -0.02195928
  0.00315408 -0.00074421 -0.00046766 -0.02058928  0.02970294 -0.0223143
  0.01411643 -0.00115623  0.00683368  0.01807252]
tensor_name:  TemporalFusionTransformer/layer_normalization_10/gamma
[1.0081437  1.004029   1.1124251  0.9944783  0.97460777 0.9748718
 0.94623005 1.014987   0.9880319  0.96999514 0.9505316  1.0286705
 1.1377074  0.9681792  1.0478827  1.0626429  0.9635604  0.9636946
 1.0380659  0.9589436  1.0915875  0.9867067  0.9797725  1.0096825
 0.97204745 0.96439844 1.0831915  0.98920536 0.9542591  0.9670675
 0.9576987  0.92564267 1.0905087  1.0039206  0.98493147 1.0871474
 1.0362247  1.0123048  0.95251167 1.0106783  0.9529326  0.95947325
 0.98306227 1.0206407  0.96638364 1.2800881  0.99047345 0.9656622
 0.9731296  1.0067698  0.9538003  0.9580798  0.9739259  0.9996805
 0.95978945 1.1332979  0.9865005  0.951355   0.99449015 1.0035181
 0.97191465 0.9559911  1.0118816  1.0024346  0.9848845  0.9282055
 0.9757002  1.0396408  0.9917897  0.99979216 0.9918803  0.9616249
 1.050131   0.948058   1.0253724  0.9085053  0.9832345  0.97724235
 0.9730498  0.92627716 1.0205438  0.9808139  0.978307   1.0198936
 0.9638033  1.0607165  0.9981576  0.9846534  1.1843511  0.98358065
 1.0109127  1.1889533  0.9933722  0.9935343  1.0359886  0.9870993
 0.9845274  1.2637928  0.9860494  1.0537283  1.1121151  1.042142
 0.9817656  0.97633266 0.98308873 0.9703519  1.0189333  0.9876891
 0.96743613 0.96440786 1.0046476  0.9881445  0.9664541  0.99647355
 1.1773247  0.96649677 1.0329114  1.1033531  0.9529972  1.0463334
 0.9561473  0.9650362  0.99535507 0.9687931  0.96131295 1.0172828
 1.0733708  1.0762475  1.3521906  0.9696885  0.9779168  1.0482289
 0.998725   1.0354896  0.92738295 0.9979547  1.0561829  0.9785582
 0.98040736 0.9786045  1.1859105  1.0256219  0.9685479  0.94909126
 1.0330193  1.1016092  1.0261208  0.98732203 0.92483467 0.988015
 0.9935909  0.9635079  0.97596323 0.9596531  1.0034     0.96653956
 0.95727634 0.9294937  1.0335212  0.98027694]
tensor_name:  TemporalFusionTransformer/layer_normalization_11/beta
[-5.8530802e-03  1.8572556e-02  1.5406033e-02 -2.3050401e-03
  3.4732423e-03 -1.6698878e-02 -2.6852489e-02 -2.2410288e-02
  1.6733436e-02  9.0628787e-04  2.0014551e-02  1.0521414e-02
 -6.7612603e-03  1.4519578e-02 -3.3056247e-03 -2.0213934e-02
 -9.6420227e-03  1.0295203e-02  3.4000620e-02 -2.0824142e-03
 -3.3440557e-04  1.6112091e-03 -1.0789919e-03 -2.5913173e-03
 -8.2237348e-03  3.0649871e-02 -2.4013231e-03  1.0069786e-02
  2.1713376e-02 -1.0596677e-02  1.1437493e-03  1.8239426e-03
 -8.3292862e-03  6.3273679e-03 -1.5863428e-02 -5.0979191e-03
  1.2742809e-02 -1.0254009e-02 -9.5279783e-04  2.3027005e-02
 -6.1644078e-03  1.0981664e-02 -8.0397306e-03  5.4323446e-04
 -1.3173455e-02 -2.1491610e-03 -1.1532838e-02  1.8883049e-02
 -5.6223683e-03  1.8486343e-04  1.1150403e-02  3.0810203e-02
 -5.1227811e-04  1.3221226e-02  9.1687161e-03 -1.3067984e-03
  2.3116892e-02 -2.1077814e-02 -1.2135805e-02 -3.1885847e-03
  9.3492918e-04 -3.1732300e-03  1.3232553e-02  2.7906871e-03
 -1.0410681e-02 -6.1690254e-04  1.2723707e-02  1.2817847e-02
  4.3301946e-03 -1.2379180e-02  2.0855667e-02 -3.0171145e-03
  2.0015126e-02 -7.2938553e-03 -4.8772134e-03  1.4718690e-02
  8.3510345e-03  1.7190028e-02  1.0841719e-02  9.2315478e-03
 -6.4258333e-03  4.9776719e-03  1.0376136e-02 -5.9410543e-03
 -2.1717642e-02  6.0918229e-03  1.2161511e-02 -7.5159096e-03
  2.0331782e-03 -1.4494114e-02 -2.0760868e-02 -9.7487886e-03
 -3.2590160e-03 -4.9113929e-03  1.6149752e-02 -1.5074085e-04
  1.4382569e-02  1.0638335e-02  1.1029535e-03 -1.5182942e-02
  1.5458255e-04  8.0986030e-04  1.4183503e-02  2.6182689e-02
 -1.7546073e-02  6.8105554e-04  2.4095902e-02 -1.7017953e-02
  2.6255487e-02 -8.0532013e-03 -2.6189361e-04 -1.0316377e-02
 -1.9409955e-02  5.2304362e-04 -1.7831841e-02 -7.9741441e-03
  1.7385088e-02 -1.6513964e-02 -1.6141072e-02 -1.3278280e-02
 -6.6107328e-05  7.4430471e-03 -1.0758296e-02 -1.2196931e-02
  1.1966823e-02  1.1539567e-02 -4.5437752e-03  2.3722623e-02
 -2.3421501e-03  2.6998892e-02 -1.2063097e-02  1.3811949e-02
 -1.9817609e-02  3.1945051e-03 -2.1826632e-02  1.5015885e-03
 -1.3716661e-02 -1.4030029e-03  1.4164285e-02 -6.4454805e-03
 -6.2077481e-04 -1.2670196e-02  9.0257376e-03  1.5516774e-02
 -4.1435133e-03  7.0283567e-03 -1.1269749e-02 -1.8511768e-02
 -8.2493424e-03 -1.7519167e-02  1.5317811e-02  5.2034603e-03
  1.3323225e-02 -1.2993244e-02  2.8554972e-02 -2.6416386e-02
  1.8352794e-02  8.4780401e-04  1.6455660e-02  1.1265599e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_11/gamma
[0.9772474  1.0385064  1.039865   1.04886    0.93507063 0.99470705
 0.97131073 0.9651125  1.0036242  0.96553355 0.99333876 1.0638726
 1.0409594  0.98324484 0.9934976  1.0117059  0.91883296 0.99592483
 1.0357418  1.0081447  1.0407984  0.98605156 0.9736327  1.0379235
 0.9810445  0.9592183  1.0511671  1.0014019  0.9793386  0.9699745
 0.96723306 1.0568663  1.0856624  1.0072784  0.9544783  0.9788321
 1.0929114  0.9700126  0.9719577  0.98587126 0.9661751  0.944698
 1.0070994  0.99962556 0.97848326 1.1707886  1.0188768  0.97372544
 0.9717365  0.9587476  1.0697407  0.9746749  1.0050353  0.973771
 1.0284581  1.1398127  0.98765093 0.9953682  0.9727335  1.0443311
 0.98088825 0.98214364 1.0225885  1.0080618  1.0015622  0.925464
 0.98470795 0.9636509  0.98594433 1.0117246  1.0027717  0.9807941
 1.1369092  1.0068456  0.99179363 0.94644827 1.0637914  1.0019753
 0.98609006 0.96853375 0.9702703  0.9977528  0.9483912  1.0916523
 0.97543424 1.0514106  0.9834316  0.9818827  1.0568392  0.95708406
 1.0358888  1.1130524  0.9870238  1.0048681  1.0363561  0.97610706
 0.97612476 1.1867816  1.0047542  1.0581568  1.1338443  1.015372
 0.954982   0.9618055  0.9976595  0.9902966  0.9318775  1.0002894
 0.95734364 1.000973   1.0188445  0.9487771  0.9926586  0.9931956
 1.0243161  1.0096525  1.001531   1.0578347  0.9503649  1.0707759
 1.0667253  0.9197631  1.0068679  0.97944736 0.9714794  1.0415578
 0.9766478  1.0191272  1.2120241  0.9705495  0.9669789  1.065193
 0.9847368  1.0157031  0.9788455  0.9622197  1.0732739  1.0086839
 0.9701292  0.96862054 1.0436382  1.0299186  0.9639398  0.90833914
 1.0661241  1.0265837  1.0180284  0.98188895 0.9754704  0.9936882
 0.9901549  0.98820716 0.96211416 0.9121371  0.99693793 1.0911644
 0.98403084 0.95976394 0.99614465 0.9730362 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_12/beta
[-0.01611358  0.0277388   0.00804069 -0.0026961   0.0097051  -0.01143184
 -0.01647414 -0.04182716  0.01859235  0.03366993  0.01704832  0.00260624
 -0.01233056  0.00732401  0.00937814 -0.04192191 -0.01767055  0.01465896
  0.02916328  0.00436948 -0.0085484   0.00379846  0.00460316 -0.0160215
  0.00170728  0.01117301 -0.02150804  0.00865253  0.01797367 -0.01198035
  0.01386968  0.01958562  0.01001985 -0.00175251  0.00938275 -0.02136592
  0.01122528 -0.00762193 -0.00768736  0.02779298 -0.01085935 -0.01201086
  0.00769195 -0.01708335 -0.01060644  0.00857545 -0.00219738  0.01555609
  0.00963766  0.0117516   0.02183689  0.03538904 -0.02014132  0.0051654
  0.00975929  0.00701873  0.01795634 -0.02878526 -0.03145427 -0.03964861
  0.0151429  -0.02186784  0.00862651 -0.02192482  0.01266033 -0.00305944
  0.06113727 -0.00997384 -0.00674684 -0.01200986  0.0193155   0.00241987
  0.00291389  0.00155269 -0.00519953  0.01011751 -0.00026143  0.02445317
  0.02037133  0.03244854 -0.01332642 -0.00223501  0.01165526 -0.01649161
 -0.00032875 -0.00735187  0.01980171 -0.0151127   0.01491302 -0.01500914
 -0.03095146  0.00590539 -0.00146766  0.01288208 -0.00102003 -0.01383386
  0.00178239  0.04679842  0.0211424   0.00074348 -0.00427792 -0.03961919
  0.00461857  0.00997108 -0.00624393 -0.00214524 -0.00429677 -0.00070974
  0.029208    0.00854552 -0.00213257 -0.01808181 -0.01589556 -0.00216381
 -0.02812272 -0.01958488  0.00618121 -0.01344017 -0.00619487 -0.01243661
  0.00292169  0.0246716  -0.00787503  0.00393901  0.00258876 -0.00021989
  0.0301904   0.0129242   0.01040128  0.0208961  -0.00930123  0.02436874
 -0.00038608 -0.01359232 -0.01895465  0.01441009  0.00240949 -0.01260455
  0.01255554 -0.01605399 -0.01379701 -0.0096786   0.00200393  0.01150441
 -0.00035034  0.00230542  0.02188173 -0.02811667 -0.0030854  -0.01082258
  0.01678275  0.00789312  0.01462472 -0.04077895  0.01646334 -0.02556353
  0.01120269 -0.00108997  0.01288598  0.00831373]
tensor_name:  TemporalFusionTransformer/layer_normalization_12/gamma
[0.92657167 0.9713317  0.9102261  1.011914   0.99227875 0.9780155
 1.0100448  1.1235002  0.93264353 1.059371   1.0389314  1.0268649
 0.9542094  0.94441897 0.9949453  0.97311795 1.110125   0.962797
 0.93580216 0.9694729  0.92002875 0.9601471  0.95096946 1.0399008
 0.9465657  1.18367    0.9468989  1.0211928  1.148767   0.9819779
 1.1598139  1.019836   0.92500496 0.95103383 1.0381527  1.0038447
 0.944035   0.9317934  0.99026096 1.0168738  1.0196515  1.0102732
 1.0181065  0.9745301  0.9220652  1.1281539  1.0890114  0.9848658
 0.9175218  1.0567456  0.9171508  1.1102343  1.0086752  1.0057163
 0.9913958  0.90702707 0.9334483  1.0294896  0.8910823  1.0225781
 0.96860856 1.006177   0.9665504  0.95146567 1.1505588  0.9260568
 1.0577378  1.035541   0.94211376 0.9879799  0.95303386 1.0352135
 0.9880284  0.948248   1.033766   0.8818374  0.98096114 1.0999733
 0.98645437 1.169072   1.0387287  0.8589496  0.9088625  0.98396915
 1.0030857  1.0186565  0.9642902  0.87994105 1.1945239  1.0343653
 0.9986935  1.0504141  0.93005913 0.9572944  1.1529331  0.9770548
 0.96106976 1.0737227  1.0262194  0.93862885 1.0021647  1.0184237
 0.97190374 0.9878887  0.9440427  0.9756349  1.1587065  1.005789
 1.0045882  0.9828815  0.9695929  0.96695775 0.9809164  1.1311976
 1.0019538  0.9675161  1.0247704  0.94718856 0.96618533 0.9176156
 0.95870584 1.0816866  0.9320651  0.9975676  1.0234612  0.85026985
 1.2219675  0.97549015 1.1103779  0.95115817 1.0029817  1.1921114
 0.9141025  0.95168483 0.9516155  0.9803022  1.0061389  1.0264392
 0.9971474  0.9792138  0.9532021  0.9525901  1.0482125  1.0141299
 0.9021469  0.93671715 1.0285721  1.0194008  0.98845166 0.99638385
 1.1303223  0.89546376 1.0919305  1.0636631  1.0497535  0.99381196
 0.9931578  0.97072184 0.9937981  1.0568033 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_13/beta
[ 0.01069246  0.02310115  0.0311802   0.01225917 -0.00313545 -0.03467438
 -0.01776939  0.03878337 -0.00510486 -0.0303501   0.02956125  0.02376472
  0.0048303   0.03472098  0.01081372  0.04885686  0.00809083  0.00539528
  0.02871317 -0.03164699  0.00639729 -0.02461983 -0.00983085  0.05927012
 -0.01805135  0.0313636   0.01128811 -0.0018378   0.02380462 -0.00659525
 -0.03294739 -0.03294086 -0.01325315  0.01489684 -0.03559466  0.00509104
 -0.00057706 -0.01682412  0.00695427 -0.01088201 -0.00754575  0.02737826
 -0.04293663  0.01765226 -0.00510775 -0.00531453  0.00860695  0.02230188
 -0.00236035  0.00452758 -0.00781911  0.02267435  0.02160307  0.01283001
  0.00045465  0.00425419  0.01155265  0.04868305 -0.00010753  0.05906994
 -0.0220158   0.01473302  0.0093727   0.02377413 -0.01247736 -0.00189096
 -0.08137856  0.01592454  0.02088158 -0.00913612  0.01365894 -0.01095034
  0.02867672 -0.01996486 -0.02768569  0.0151814   0.01893457 -0.0129294
  0.00207898 -0.08965702  0.00066353  0.01967334  0.00555239  0.00851191
 -0.03073401  0.01019955 -0.02023927 -0.02143881 -0.0224006  -0.03228991
 -0.01832554 -0.00565563  0.00979832 -0.01670256  0.02433913  0.02451853
  0.01940655 -0.01697486 -0.02132962  0.01303511 -0.01617263  0.0362363
  0.03290243  0.02330614 -0.01608253 -0.01534043  0.0181317  -0.01665602
  0.0284513   0.02672766 -0.0075504   0.00513311 -0.01938858 -0.00262539
 -0.01188699 -0.01243346  0.00459176 -0.01569372 -0.02313286 -0.00784914
  0.00438561 -0.0040287  -0.00784129 -0.01060167  0.01676626  0.02787599
 -0.05160654  0.01430979  0.00396436  0.0366472  -0.00290773  0.00393592
 -0.03519929  0.00138534 -0.02328531 -0.0101097  -0.01066318  0.02771382
  0.008456   -0.01204716  0.01205302 -0.01186299  0.00648934  0.04333978
 -0.00054947  0.04203791 -0.05849576  0.01449807 -0.01193459 -0.01272303
 -0.00897566 -0.0065641   0.01665226  0.02296581  0.02818873 -0.01201005
 -0.00179552  0.00425518 -0.0026708   0.01712718]
tensor_name:  TemporalFusionTransformer/layer_normalization_13/gamma
[0.9767893  1.022062   0.99457985 1.0202465  0.97225565 0.9832593
 1.0115     1.2412369  0.97373563 1.053441   0.9218541  0.9175257
 0.97496086 0.9934685  0.9879907  1.1637232  1.019268   0.95779157
 0.99521023 1.0738904  1.0595504  1.196832   0.9659446  1.301908
 0.9608619  0.948989   0.99707913 0.9608863  0.9503935  0.95673066
 1.0808132  1.0722607  0.9324616  0.9735616  1.0627499  0.93113893
 0.96714306 0.9943454  1.0174696  1.1017258  1.0058407  1.0977739
 1.0280981  0.9913774  0.95268387 1.0198898  1.0872198  0.9482437
 0.9748613  0.9237325  0.98862654 0.99240386 0.99289745 0.94887394
 1.024568   0.95342934 1.0128292  1.2891816  0.9496369  1.2634898
 1.0477982  0.96838737 0.9033186  1.1211381  1.0420599  0.9252864
 1.4339921  0.9614269  0.9859401  0.97416145 0.9839054  0.9510156
 0.9453907  1.0049233  0.9884292  0.9796331  0.9446875  1.0527211
 0.9403508  1.3763722  0.9887973  0.93079305 0.99574614 1.0219281
 0.9987503  0.96258533 1.2066104  0.92731315 0.9869662  0.97279716
 1.0339072  1.0090626  0.9638546  0.96730673 0.97796404 1.1148473
 1.0305486  1.0475668  1.1030158  1.0976069  1.0425026  0.95271176
 0.9598236  0.9093102  1.022246   0.9096925  1.0060017  1.0184387
 0.9315184  0.97957116 0.95721567 0.9669813  0.9657114  1.0137452
 0.9594614  0.99993414 0.99916947 1.017458   0.96753734 0.8968627
 0.9900096  1.0073632  1.0079799  0.9528011  0.95264924 0.9444755
 1.1749467  1.0009083  0.95498985 0.95372593 0.962595   1.0368469
 1.0097351  0.9933778  0.9897684  1.0473481  0.9843659  1.0923587
 0.9708476  0.97458905 0.96837777 1.0091609  0.99489665 1.1149737
 0.9876142  1.0772593  1.0212754  1.1453164  0.99967957 0.9941411
 1.0580512  0.9309345  1.0008928  1.1411377  1.0257713  1.0061039
 0.9993887  0.90613425 0.93018806 0.9886108 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_14/beta
[ 1.34579185e-02  7.82715715e-03 -1.39715746e-02 -5.95484301e-03
  1.51112992e-02 -1.46200070e-02 -2.18231957e-02 -2.49682814e-02
 -1.69995930e-02  2.44485121e-02  4.68320586e-03  3.41846086e-02
  7.85364024e-03  8.22556205e-03 -3.97413317e-03 -2.78154612e-02
 -1.92797519e-02  1.42311156e-02  1.43172452e-02 -8.06193706e-03
 -1.56322811e-02  5.55864302e-03  1.78458393e-02 -7.57673709e-03
 -1.19806398e-02  2.56944485e-02  2.13961757e-05 -9.27225687e-03
  3.66534367e-02 -7.61011476e-03 -1.69011124e-03  2.31742729e-02
 -7.97035173e-03 -1.05155380e-02  2.50761816e-03  3.79912485e-03
  1.94698456e-03  3.38654104e-03 -1.23802660e-04  3.23681757e-02
  1.35043757e-02 -6.24720939e-04  4.36524767e-03  8.23473651e-03
 -2.66741365e-02  5.29981032e-03 -2.46819146e-02  1.25827175e-02
  1.33886153e-03 -5.35053900e-03  1.83153879e-02  1.64331514e-02
 -2.27733310e-02 -1.84232264e-03 -9.01421008e-04  7.03498442e-03
  1.11485776e-02 -2.15218011e-02 -3.04789264e-02 -2.23925430e-02
  1.21979853e-02 -1.91174708e-02  3.49096418e-03 -1.25810094e-02
  1.12608261e-02 -3.26451752e-03  2.86725126e-02 -5.01681026e-03
 -1.01321675e-02 -1.70832705e-02  2.71457322e-02 -4.52946697e-04
  1.67635716e-02  6.54026493e-03 -2.08472963e-02  1.12400772e-02
  6.61512325e-03  1.52970487e-02  2.17023888e-03  1.19166868e-02
  1.09918858e-03 -2.54030563e-02  2.15198006e-02  2.78026797e-02
 -1.47621837e-02  1.69570302e-03  2.88028810e-02  9.41296667e-03
  6.61789486e-03 -7.89703242e-03  6.86978409e-03  1.09403785e-02
  2.02465034e-03 -2.08564335e-03  1.84855703e-02 -6.83987699e-03
  9.76828299e-03  1.57568287e-02  2.25810874e-02 -5.34351589e-03
  1.70821603e-02  9.46567114e-03 -5.40309073e-03  1.46385189e-02
 -1.87916867e-02 -1.41309556e-02  3.42958421e-02  4.73815249e-03
  3.69224362e-02  3.16284318e-03  3.56329518e-04 -5.79510583e-03
 -3.98846380e-02  3.14078890e-02  1.07039500e-03  9.95110627e-03
  1.90660194e-03 -2.84828674e-02 -9.24787018e-03 -7.66324904e-03
  4.05786280e-03  8.90042167e-03 -8.66683293e-03  8.81673396e-03
  1.33706843e-02 -9.30037349e-03 -1.41434688e-02  7.48499809e-03
  1.77354850e-02  1.77354943e-02  5.24891121e-03  1.24328239e-02
 -8.63065757e-03  1.89725822e-03 -1.66197252e-02  2.86666583e-03
 -9.74872557e-04 -2.63611544e-02 -3.81703023e-04 -7.25286221e-03
 -2.01918148e-02  1.24828089e-02  1.60847660e-02 -1.27798156e-03
  1.38786423e-03  2.88976636e-02  1.82225443e-02 -9.74956993e-03
 -1.47961071e-02 -2.28976700e-02  1.14087481e-02  4.77937190e-03
  1.01061538e-02 -1.61858127e-02  3.62363532e-02 -2.50993483e-02
  1.42030353e-02  9.25187115e-03  1.22849885e-02  1.87314220e-03]
tensor_name:  TemporalFusionTransformer/layer_normalization_14/gamma
[0.9932849  1.0448867  1.0531394  0.9709744  0.95839435 1.0053259
 0.9950213  0.92607975 0.9794994  1.0039543  1.0926461  1.058466
 0.95464456 0.98603314 0.9658972  0.9043563  1.0017321  0.9800489
 0.98600703 1.0126617  0.9251428  0.98426694 1.028254   0.9273082
 0.9745944  0.9992366  0.97740674 1.0302478  0.96593165 1.0033593
 0.98763347 0.9742278  1.0318165  1.0021623  0.87998027 1.0203557
 0.93445724 0.9774181  0.94012576 0.9959406  1.0341638  0.9731185
 1.0974134  0.9671125  1.0381354  0.89265233 0.91396964 1.0564171
 1.0280826  1.0189514  0.92335266 1.090921   1.0031825  1.0016354
 0.9359025  1.0230271  1.0066108  0.9575906  1.0479612  0.9625725
 0.97678334 0.9871689  0.967921   1.072772   0.9524442  1.008912
 0.9695014  1.0724827  1.0833054  0.9711808  1.0245872  0.8971153
 0.9364105  0.98574686 0.98898923 0.9938859  1.0144752  0.93481135
 0.96694654 0.93066585 0.9841697  1.1151946  0.99948174 0.9607082
 1.0139554  0.9850279  1.0872126  1.1294038  0.9988843  1.0284122
 1.0256226  0.9944295  0.94547373 1.0181342  1.0508932  1.026361
 0.9779939  0.9041837  0.9532339  0.97846085 0.98513794 0.9660465
 1.0103626  1.0530438  0.95059365 0.9951627  0.9842952  0.975738
 1.070723   0.9307701  0.9203654  0.9756668  1.0214372  0.9999506
 1.1036924  0.9949687  0.96454066 1.0233121  1.0461746  0.9972854
 0.93385553 1.0370201  0.94080085 0.98999673 0.9875514  1.0843744
 0.92009443 1.0475756  0.94092447 1.0283641  1.0886434  0.9604316
 1.0055449  0.9857177  0.9886558  0.9649846  0.96789944 1.0768417
 1.0177854  0.92578185 0.9483585  0.9896567  1.0318091  1.0941349
 1.0015683  1.0333784  1.0097228  1.0062973  0.94928676 0.988764
 0.89899385 0.9665438  0.9406065  1.0072727  1.0676938  0.9207845
 1.0252475  1.0197212  0.9771536  0.99962324]
tensor_name:  TemporalFusionTransformer/layer_normalization_15/beta
[-0.04091345 -0.02147888  0.06090223 -0.0015077   0.01618215 -0.03864418
  0.06481392]
tensor_name:  TemporalFusionTransformer/layer_normalization_15/gamma
[1.0375923  0.96442425 0.9216022  1.0027018  1.0668234  1.0663052
 1.0420202 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_16/beta
[ 1.9965276e-02  1.7960416e-02  5.6920890e-02  2.4513861e-02
 -2.4691988e-02  5.3608112e-02  4.8129965e-02 -3.4113906e-02
 -6.1284356e-02  7.5769678e-02  1.2950284e-02 -5.9850376e-02
 -1.4724763e-02 -1.5794300e-05  1.0041841e-01  2.1402184e-02
  1.1705890e-02  8.8669986e-02  6.7625386e-03  2.9429870e-02
 -2.1731362e-02 -2.6823105e-02 -3.6056414e-02  1.7671227e-03
  2.4965875e-02 -4.2226329e-02  6.1437085e-02 -4.5122579e-02
 -2.7854608e-02  7.2873339e-02 -8.4744357e-02 -3.3117207e-03
 -5.8686621e-02  4.0027115e-02 -3.4671105e-02 -1.6372213e-02
 -3.1800214e-02 -2.7252393e-02  2.1523947e-02  2.7344249e-02
  1.3611835e-02  2.0928141e-02 -3.8703322e-02  6.7711757e-03
  1.3110443e-02  5.9852488e-02 -2.2598239e-02 -1.9985812e-02
 -7.2071508e-02  7.6843403e-02 -2.2147885e-02  1.5364064e-01
  1.7039001e-02  2.3367252e-02 -4.2063028e-02  6.4622231e-02
  3.4092434e-02 -4.9991990e-03 -1.9271355e-02  2.8206915e-02
  7.5635419e-04  3.4112658e-03  6.1362498e-02 -1.6812077e-02
 -2.4721311e-02  4.2821068e-02 -5.8807757e-02  8.3018981e-02
  3.7531506e-02 -8.2961686e-02 -3.1748813e-02  6.6976763e-02
  2.9542640e-02  8.4911726e-02 -5.7670478e-02  3.1315330e-02
  1.7499181e-03  6.0121375e-03 -8.6786384e-03  5.0012764e-02
  4.1152395e-02  7.4904934e-02 -7.4666314e-02 -8.9103140e-02
 -3.2507384e-03 -8.3358511e-03 -3.6463723e-02 -3.1579688e-02
  4.4482369e-02 -2.2127394e-02 -2.3611465e-02  1.5674109e-02
 -5.5840760e-02  4.3597326e-02 -2.3485661e-02  2.7967459e-02
  1.3531731e-02  1.0414922e-02 -1.7498376e-02 -6.2614657e-02
 -2.0236835e-02 -2.8379915e-02  6.8008958e-04 -8.5645448e-03
  7.0170701e-02 -8.0496790e-03  1.4516981e-02  8.1081331e-02
 -4.5406022e-03 -3.8171284e-02  4.3320987e-02  6.0460768e-03
  6.0740888e-02  3.6320809e-02 -3.0706048e-02 -4.1103236e-02
  2.4434680e-02 -3.8425080e-02  8.1877999e-02  4.0991940e-02
 -2.6361825e-02  5.4419595e-03 -2.7887851e-02 -6.5969676e-02
  5.6853779e-03  7.8816362e-02  3.7294786e-02  5.1807929e-02
 -2.3725573e-02  3.8497783e-02 -5.6944691e-02  3.5192090e-04
 -4.8904452e-02  3.6128640e-02 -2.1037523e-02 -1.2254197e-02
  2.5005128e-02  6.4125650e-02 -4.3609299e-02 -8.6911008e-02
 -2.2416756e-02  5.0122511e-02 -4.0704712e-02  5.4496754e-02
 -4.2418070e-02 -5.2870470e-03  8.4913932e-02 -4.0243879e-02
 -4.8697948e-02 -4.5464733e-03 -3.0740131e-02 -3.9734505e-02
 -5.8295798e-02 -1.9716483e-02  6.0655046e-02  2.3797359e-02
 -4.9116075e-02  2.9455489e-02 -3.0385140e-02 -6.1592858e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_16/gamma
[1.0011756  0.98471147 1.0499943  0.9751735  0.97703457 1.0220968
 1.0349845  1.0187634  1.0815059  1.0874395  0.9934273  0.9950063
 1.0029848  0.9900217  1.094734   0.95091236 1.0091641  1.0944984
 0.97500545 0.9670477  1.0037833  1.0160015  0.9838344  0.9934679
 0.99401134 1.0347818  1.0560983  1.0369092  0.9947266  1.0685772
 1.102658   0.9976266  1.0731113  1.0250303  1.0120922  0.96187544
 0.9994493  0.96402526 1.0174663  0.97762394 0.9999608  0.9888429
 1.0084494  0.9852102  0.9798548  1.0526841  0.99746656 0.9733561
 1.0430043  1.0669148  0.9857222  1.1808901  0.97646046 0.9880095
 1.0033098  1.0560154  1.0233377  0.9908873  0.9719153  1.008855
 0.99784184 0.9916141  1.0828118  0.9831187  1.0040351  1.0061172
 1.0668443  1.0980793  1.0003836  1.0351765  1.0266358  1.0853398
 1.0012625  1.0950712  1.0375906  1.0043707  0.9593121  1.004162
 0.9914517  1.0323144  0.9824532  1.0753783  1.0721197  1.1144183
 1.0223516  0.97930205 1.0250429  1.0101317  1.0155607  0.96980613
 1.012948   0.97241455 1.0534486  0.98606527 0.9834722  0.9637109
 0.9850532  0.9894802  0.99592763 1.0544357  1.0102826  1.008917
 1.0029601  0.98328465 1.0622451  1.0076327  0.9604324  1.0943612
 0.948935   1.0145084  1.0359733  0.99183404 1.0339191  0.9937968
 1.018256   1.0228984  0.98338753 0.9816751  1.0896956  1.0397981
 1.0195756  0.99684924 1.0145763  1.0601847  0.94554526 1.0833986
 1.0055162  1.0318643  0.98863685 1.033029   1.0494794  0.99579334
 1.0298358  0.99744344 1.0100648  1.0006468  0.9969425  1.0644813
 1.0222857  1.1023418  1.0008492  1.0359759  1.0355772  0.97552824
 1.0299305  0.9681521  1.1097654  1.0224764  1.0299038  0.99576837
 0.98550653 1.013232   1.051768   1.0018364  1.0636054  1.0109622
 1.0269812  0.9542872  1.020757   1.0562966 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_17/beta
[-0.00078657 -0.00135599 -0.01172044 -0.01094156 -0.00178767 -0.00942359
 -0.02915186 -0.00620129  0.02082361 -0.00239341 -0.00701688  0.01579962
  0.00905176 -0.00114511  0.01043107  0.00048838  0.02896775  0.05417062
 -0.00809526 -0.00033861  0.00219323 -0.00998333  0.01188133  0.02929865
  0.00447836 -0.0191504   0.02521251 -0.00113274  0.00742187 -0.01372051
  0.0181627   0.0034778   0.00540021 -0.00064234 -0.01542206  0.00715405
  0.03471218 -0.00540775  0.02372809 -0.01023713 -0.02543179 -0.01473175
  0.01790653  0.00091703 -0.00340951 -0.02308337  0.00664998  0.00461917
  0.02476113  0.043686   -0.00192283  0.06986898  0.00626707  0.00842179
  0.02645796 -0.02969996 -0.01072526 -0.00840335  0.01851844 -0.00636422
  0.01525143 -0.00142631 -0.00959243  0.00183707 -0.00136218  0.01186245
  0.01809942 -0.02582933 -0.03112153  0.04509706  0.01675832 -0.00636818
 -0.00846834 -0.01171068  0.01573302 -0.03362644  0.01533741  0.02059572
 -0.01065142  0.0165585  -0.01175751 -0.01615422  0.00802684 -0.00264074
  0.06006641 -0.00991882 -0.00365633  0.02720603 -0.00453982  0.01030622
  0.02150465  0.0016487  -0.01051299 -0.02959832  0.01638846  0.01776426
 -0.01217637 -0.00305452  0.0177866   0.04923474  0.01659608 -0.0062344
  0.03556278 -0.00245568 -0.0286597  -0.02239639 -0.00896144 -0.02163331
 -0.01137346  0.01296245 -0.01609167 -0.00802981 -0.00877825  0.00420228
  0.02573647  0.01617849  0.00110251 -0.00285788  0.00155361 -0.00733592
  0.00718682 -0.02179163  0.00302617 -0.00750062 -0.02085095 -0.04850282
  0.01509473  0.00726618  0.01135875 -0.01806166  0.01472161 -0.02099592
  0.02415528 -0.03198396  0.00963828  0.0122518  -0.00469503 -0.047534
  0.01900231  0.00991262  0.00777568  0.00392638  0.01438444 -0.02699682
 -0.00630443 -0.0034204  -0.01609468 -0.00221572  0.00409864 -0.02064394
  0.00957757  0.03405743  0.01072495  0.01436632 -0.02053429 -0.01868053
  0.0101911   0.02023522  0.01130552 -0.01461588]
tensor_name:  TemporalFusionTransformer/layer_normalization_17/gamma
[0.9307038  0.9817249  0.98114085 0.9743989  0.96207035 0.99060637
 0.9114705  0.9319118  0.9548578  0.9809847  0.98146594 0.8920747
 0.9855255  0.9917244  0.9884304  0.90707195 0.97269547 1.0139052
 0.91524506 0.96220046 0.9769617  1.0027995  1.0258543  0.9765298
 0.9612537  1.0347389  0.993678   1.0169886  0.98025924 0.96081066
 0.95190245 0.9740134  0.9364873  0.96198565 0.99546754 0.84990114
 0.93759567 0.9036727  0.99233264 0.969278   0.9381114  0.8782439
 0.94963425 0.9213373  0.95627856 0.9458434  0.97168714 0.9776477
 0.9980311  1.0038546  0.88767964 1.0697428  0.98923814 0.9934407
 0.9696132  0.8964663  0.9328034  1.0316949  0.94812506 1.0207603
 0.9873684  0.9888853  0.99612874 0.95746875 0.9699018  0.9713966
 0.9279415  0.9493725  0.93172395 0.97512835 0.96794647 0.9676325
 0.9850461  0.9786442  0.9688632  0.9643468  0.985246   0.9882449
 0.98809475 0.9897201  0.9540437  0.9904536  0.99525315 1.0195314
 1.1278905  0.97365886 1.0272766  0.83591074 0.9500057  1.0048676
 0.9763697  1.0045508  1.0001466  0.99584657 0.991117   0.8321778
 0.9490255  0.9855653  0.95984155 0.9424741  0.9420192  0.9863719
 0.96324325 0.9896125  0.96866083 1.0143596  0.97947633 0.96841073
 0.98374766 0.8296919  0.92325246 0.92590296 0.94186044 0.9450777
 0.94222164 0.9845992  0.9606859  0.919819   0.9557587  0.9707968
 0.93665725 1.0193454  1.0092509  0.9885988  1.0007415  0.77043253
 0.9816079  1.0082985  0.9657191  0.8813813  0.9600377  0.9718601
 0.9604815  0.86367786 0.9851378  0.9987632  0.9588265  0.9133969
 0.95891947 0.9790794  0.951056   0.94416285 0.9571145  0.90955085
 0.98157835 0.9573816  0.95236456 0.98645765 0.9803066  0.9779903
 0.94169205 0.90223306 1.0313932  0.9769972  0.9647129  0.98685855
 0.9709963  0.9851722  1.0020124  0.9925826 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_18/beta
[ 0.03270654  0.02373009  0.07138367  0.0345717  -0.03004536  0.05255923
  0.03394505 -0.04433738 -0.0435527   0.05739856 -0.01346347 -0.05445529
 -0.01116126  0.01334729  0.08301184  0.03766495  0.02360553  0.11211322
 -0.0012859   0.02665171 -0.00448911 -0.0415816   0.02372795  0.01275071
  0.01064973 -0.06437731  0.05008045 -0.02002029 -0.01503955  0.0424259
 -0.07325435  0.0099109  -0.04152459  0.0244425  -0.06207912 -0.01362741
 -0.0241104  -0.04664201  0.04569167  0.04846972 -0.01416956  0.02144653
 -0.01976395  0.02346291 -0.00203875  0.03794601 -0.00412204 -0.01839315
 -0.0448567   0.07815358 -0.0159234   0.15966423  0.03596513  0.03901398
 -0.04609298  0.04892781  0.02305139  0.0104187  -0.02768697  0.03435921
  0.02480987  0.02162556  0.06093033 -0.02696885 -0.00235686  0.04870309
 -0.06109448  0.06674173  0.02147991 -0.06302398 -0.01802967  0.04274047
  0.02012192  0.06985229 -0.05769861  0.02980133  0.04475117  0.01356927
 -0.01707684  0.05285432  0.04770678  0.0713025  -0.0505421  -0.0649025
 -0.0109134  -0.01240408 -0.03928948 -0.01340627  0.03071503 -0.04415699
 -0.01161162  0.00399633 -0.07477028  0.01141039 -0.03009077  0.05112986
  0.01315828  0.00821694 -0.00725854 -0.03805467 -0.0135071  -0.02689409
  0.01627962 -0.01487882  0.07381103 -0.00258645 -0.00034398  0.05880729
 -0.04432647  0.00799203  0.02202268 -0.00294141  0.05372053  0.04635897
 -0.01287834 -0.0542751   0.0376057  -0.03575828  0.09249976  0.02500786
 -0.00397951  0.01386832 -0.02083616 -0.07910176  0.00204872  0.04049484
  0.04262824  0.07076932 -0.01914831  0.02448334 -0.05408702 -0.01521035
 -0.05431761  0.0137179  -0.01062412 -0.00108232  0.02564348  0.0524219
 -0.03276892 -0.06101704 -0.02357939  0.06742179 -0.02166873  0.02624624
 -0.05635861 -0.01066202  0.06109569 -0.05803895 -0.07531414 -0.01694835
 -0.02832414  0.00319366 -0.07911582 -0.00901946  0.03527623  0.02234364
 -0.06411753  0.01041419 -0.01238915 -0.06381285]
tensor_name:  TemporalFusionTransformer/layer_normalization_18/gamma
[1.1275403  1.0197479  1.1190149  0.998624   0.98679143 1.0130451
 1.0170939  0.9869292  0.97457725 1.1205144  1.0466676  1.0972172
 0.9705728  1.057029   1.0209348  1.0067991  1.0997115  1.1109098
 1.0225846  1.0935493  0.96931833 0.9808113  1.0183673  1.1742648
 1.0205412  1.0489112  1.0299771  1.0717044  1.0551016  0.9903607
 1.0003651  1.0060499  0.9665096  0.99974597 1.031975   0.97627115
 0.98331577 0.9633579  1.0523742  1.0768703  0.99865514 1.0002655
 1.0071731  1.0128566  0.96454895 1.0026593  1.0069983  0.9781933
 1.0821235  1.0115572  0.9714077  1.1085414  1.0041677  1.0157652
 1.0541011  0.97286993 1.0318484  1.1815487  0.97661716 1.0018648
 1.0225528  1.1036677  1.0622127  0.97871405 0.94434035 0.95035934
 0.99549335 1.0344199  1.04161    0.96748775 1.0143436  1.0855324
 0.9901142  1.000078   0.9845237  0.97255605 1.0497886  1.0270572
 1.0176313  1.023358   0.9989279  1.0124185  1.1737717  0.93475217
 0.9961264  0.97008455 1.0053831  0.9782561  1.0284096  0.9875603
 1.0436211  0.96888995 1.0409429  0.99614924 1.0242774  1.0887008
 1.0384974  1.0437697  0.9569313  0.9918952  1.0035623  0.9976234
 1.0118796  1.0484533  1.0128417  1.022929   0.92621565 1.0736015
 1.055318   1.3635954  1.0056598  0.99302334 0.9504346  1.0404011
 1.02828    1.0380839  0.96672374 1.064594   1.043521   1.0343895
 0.9523947  1.007468   1.0139514  1.044199   1.016328   1.0925384
 1.023089   0.99920076 1.0242507  0.9798349  1.0451432  1.0944207
 1.0550691  1.2389388  0.992839   0.9901216  0.96823925 1.0357828
 0.98590934 1.0801626  0.9616385  1.0496099  0.98945063 1.0799919
 0.98071396 0.9794196  0.971526   1.0584955  1.0462931  0.9224697
 1.0086662  1.0917621  1.0196174  1.0495962  1.0113022  0.9954265
 1.0360229  0.9678475  1.017164   1.0187395 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_19/beta
[ 0.01894324  0.0152092   0.05134987  0.02952461 -0.02911623  0.05641504
  0.03994407 -0.04110506 -0.05919782  0.08202168  0.01331093 -0.07445942
 -0.01698177  0.00554902  0.10537454  0.02776235  0.01460242  0.08388587
  0.00131852  0.04761511 -0.02296312 -0.03615277 -0.05831711  0.00980038
  0.02654748 -0.03841567  0.07146837 -0.04187793 -0.03713563  0.07834364
 -0.09795253  0.00214167 -0.06909867  0.05113023 -0.0374744  -0.02243354
 -0.03836888 -0.05005238  0.02223845  0.03526128  0.00154567  0.02074216
 -0.05612417  0.01553698  0.01303025  0.04958851 -0.02515961 -0.03113699
 -0.07256189  0.07818957 -0.03328649  0.16149814  0.0189617   0.03143287
 -0.04203553  0.0683874   0.04380606 -0.00085012 -0.01694553  0.01414904
  0.009299   -0.02117489  0.06829669 -0.0253752  -0.03558459  0.05525737
 -0.06809344  0.08321274  0.02646038 -0.08619379 -0.03233352  0.07753488
  0.02060943  0.09362172 -0.06843541  0.01907014  0.01555309  0.01216771
 -0.0117136   0.06516398  0.04272959  0.09158417 -0.0796467  -0.08758555
 -0.02192537 -0.015012   -0.03601829 -0.01960231  0.0559079  -0.01463253
 -0.02631265  0.00908204 -0.0639963   0.05045553 -0.02062003  0.04210171
  0.02288494  0.01140734 -0.01100709 -0.05256462 -0.01184237 -0.02918533
  0.01064367 -0.0120049   0.0793929   0.00533687  0.01059699  0.08357
 -0.01299221 -0.05037482  0.04195465  0.00370208  0.08428883  0.04102192
 -0.02011725 -0.04103933  0.04289246 -0.06551737  0.09332509  0.04138776
 -0.0246855  -0.00668611 -0.02426141 -0.07052306 -0.00310343  0.06242869
  0.0441701   0.06497672 -0.02077508  0.03221662 -0.06086687 -0.00071323
 -0.04088452  0.01747473 -0.01805969 -0.00717605  0.02348995  0.04987816
 -0.04610424 -0.09724408 -0.02426628  0.05751763 -0.02889452  0.06001189
 -0.05704484 -0.00470871  0.08627161 -0.04592169 -0.06045184 -0.01550708
 -0.02454796 -0.03498637 -0.05179175 -0.01363955  0.06894585  0.02031375
 -0.06053646  0.04919192 -0.0228836  -0.07188576]
tensor_name:  TemporalFusionTransformer/layer_normalization_19/gamma
[0.9895054  1.0236938  1.0426209  0.95556456 0.9931193  1.0347172
 0.9988875  1.0119576  1.0677446  1.0751758  0.9966467  1.0552241
 0.9946015  0.9639637  1.0534967  1.022186   0.98409176 1.1157842
 0.98347926 1.0130835  0.96533716 0.9980464  1.0201813  1.0590707
 0.9786626  0.99318385 1.0369601  1.0866513  0.9871162  1.0256709
 1.0344201  0.94000643 1.0339055  1.0111457  1.0003818  0.97655904
 1.0115222  1.0302411  0.99360085 1.0244849  1.0091192  0.96936303
 1.0556817  0.9944536  1.0024807  0.97887146 0.99656874 1.0072821
 1.0597535  1.0626955  0.98956215 1.1916387  1.022583   1.0121881
 1.0526978  1.0341209  1.0491828  1.020651   0.9941525  1.0089144
 1.0081075  0.9949124  1.0391304  1.000921   1.0403701  0.94387656
 1.0102698  1.0881265  1.0118607  1.067256   0.9996616  1.022145
 1.0127598  1.1015475  1.0266311  1.0150529  1.0021261  0.99150467
 0.9920834  1.016438   1.0088108  1.0751472  1.0655886  1.0818272
 1.1144693  0.9618976  1.0460132  0.9842319  1.0248936  0.98806894
 1.0027744  0.99199456 1.0220991  0.9929162  0.9884403  1.0105639
 1.0103713  1.0230445  0.99915713 1.0334297  1.0265242  1.0140426
 0.9585766  0.9835125  1.0168943  1.00451    0.9746839  1.0430562
 1.0308942  1.0087029  1.0226471  0.97652525 1.0043292  0.982
 0.9660587  1.0068028  1.0203216  1.0492465  1.0871606  0.9835683
 0.9772714  1.0395117  1.0186906  1.0473884  1.0030433  1.0299032
 1.0038321  1.0315595  0.98618096 0.99843735 0.9993803  0.98429286
 0.9817167  1.2099575  1.0200821  0.9630032  0.99055743 1.0051626
 1.0524521  1.0903451  0.9777268  0.9653883  0.9906423  0.96753764
 1.0248591  0.99282736 1.0922523  0.9929014  1.0398856  0.9926623
 0.95874894 1.0023382  1.0493659  0.9820475  0.97896314 1.0065888
 1.0646077  0.9770793  0.9763702  1.0120076 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_2/beta
[-9.54537839e-03  1.67292077e-02 -1.52593991e-02 -1.84432585e-02
 -6.24444569e-03  7.34519027e-03 -2.44841655e-03 -1.70543473e-02
 -6.07135240e-03 -1.76939946e-02  9.50023159e-03  2.13249531e-02
  1.74161396e-03 -1.68042481e-02  6.81986427e-03  2.28781975e-03
 -3.51230912e-02 -1.54359778e-02  6.29882747e-03 -2.15752777e-02
  2.77268123e-02 -3.04177459e-02  1.70587916e-02 -2.11402960e-02
  1.06669022e-02 -7.66814128e-03  1.08161522e-02 -5.87267522e-03
 -2.35521477e-02  3.82524077e-03 -7.61269359e-04  4.73574782e-03
 -3.58174113e-03  2.86148326e-03  1.45427929e-02  1.33795515e-02
  9.51147266e-03 -7.92696886e-03 -6.37367950e-04  1.24420123e-02
  1.14214234e-02 -6.50810730e-03  1.02996789e-02  2.41974313e-02
 -3.06009855e-02 -1.57316942e-02 -4.25419658e-02  1.17044598e-02
 -8.46139563e-04  1.03819929e-02 -1.28442720e-02  2.68910006e-02
 -3.50639294e-03  1.22312745e-02  3.97556135e-03 -2.31169946e-02
 -1.45548461e-02 -1.99445174e-03 -1.57754775e-02 -6.65081711e-03
 -1.77572686e-02 -1.51942438e-02 -8.69982596e-03  7.48689286e-03
 -2.46870536e-02 -1.11629721e-02 -2.22775452e-02 -6.20146655e-03
  2.42125187e-02  2.16333847e-02 -1.68967955e-02  1.36552276e-02
 -2.68494766e-02  9.19291005e-03  1.90474764e-02  4.72407276e-03
  2.90426076e-03 -2.21011825e-02 -1.51967984e-02 -1.66672897e-02
 -1.17662931e-02 -3.33000557e-03  2.68611461e-02 -6.99020224e-03
 -2.38592867e-02 -9.13679972e-03  2.47397670e-03  9.07531660e-03
  3.33209708e-03 -7.86070433e-03  7.44478079e-03 -4.50650975e-03
  3.49837216e-03 -4.19207476e-02 -6.29624119e-03  1.74390171e-02
 -1.69269349e-02 -1.28608635e-02  5.20565407e-03 -1.01580960e-03
  1.41046224e-02 -1.23870214e-02  5.39637916e-03 -1.19533297e-02
  1.57656167e-02 -1.13070160e-02 -2.39678106e-04  2.69621867e-03
 -5.19443769e-03  1.33216707e-03  2.35449150e-02  8.67471751e-03
 -2.94364076e-02  7.66067486e-03 -1.16578257e-02 -1.22585043e-05
 -1.51684610e-02  6.02479419e-03 -1.44627574e-03  1.59427226e-02
 -1.92989931e-02 -1.48675172e-02 -1.33582857e-02  5.44562656e-03
 -1.55147808e-02  2.28375103e-02  1.32578786e-03 -3.46048214e-02
 -1.27453310e-02  1.56903099e-02  7.60024777e-05 -3.71046062e-03
 -8.56342819e-03 -2.11579464e-02  1.84344631e-02 -3.61750281e-04
 -1.54888369e-02 -2.21225694e-02  1.07380701e-02 -6.82328688e-03
 -1.52983926e-02 -2.15865858e-02 -1.41336089e-02  3.71385529e-03
 -3.10859503e-03 -8.61039036e-04 -1.53474445e-02  7.84907583e-03
 -2.09658463e-02 -3.07989377e-03  2.19832882e-02 -2.63376832e-02
  1.34474644e-02  1.99462455e-02 -1.66943911e-02 -4.25131731e-02
 -4.48006717e-03  1.53677724e-02  6.01094356e-03 -2.83672363e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_2/gamma
[0.99816895 0.9685063  0.99234736 1.0219625  0.9871844  0.98108083
 0.99934644 0.94473696 0.98351324 0.9799591  0.9855001  0.97063017
 0.97330385 0.97591084 0.9377315  1.0039076  0.9238436  0.98720485
 0.97436404 0.9800259  0.97039264 0.9730085  0.942919   0.9728804
 0.98764354 0.98302704 0.9705707  0.9810123  0.9558512  0.9870593
 0.98436314 0.97768843 0.9833666  0.97298026 0.97353184 0.99925214
 0.9816691  0.98792565 0.99950796 1.0054203  1.0025237  0.97283643
 0.98961025 0.918606   0.9728721  0.95862824 0.99912006 0.9977165
 0.9764885  0.9832577  0.98400736 1.0242437  0.9585723  1.0051712
 0.9929561  0.9415265  0.9947025  0.9726324  0.9666122  0.9776134
 0.98980594 0.98883903 0.99329877 1.0004056  0.9882195  0.97839653
 0.9614115  0.936936   0.9824252  0.9960292  0.97479457 0.9696408
 0.9523631  0.99153984 0.96755487 1.0087832  0.99578834 0.9877776
 0.98345625 0.96408224 0.99992174 0.9788771  0.96406543 0.97772115
 0.99669695 0.9932578  0.98830044 0.9940864  0.97853523 0.9924544
 0.99030614 0.9836344  0.97760224 0.95009416 0.9873584  0.9946429
 0.972695   1.0072165  0.99602175 1.0093471  0.9725184  0.97914547
 0.9697834  1.0003515  0.939139   0.9890097  0.97693396 1.0019403
 0.97251755 0.99659073 0.96747184 0.97970074 0.97651875 0.9766592
 0.97629887 0.9023956  0.98848784 0.9846885  0.99417746 0.9875586
 0.9780665  0.95870656 0.9874     1.0014563  0.9838389  0.983781
 0.9985364  0.9615319  0.9840165  0.99088085 0.9931425  0.9942789
 0.9870716  1.002637   1.0231923  0.98740226 0.9853648  0.9686228
 0.9281636  0.9970852  0.9421437  0.9915258  0.9887567  0.97451234
 1.0083718  0.9794555  0.9836503  0.9877238  1.0188402  0.97596973
 0.98452926 0.9580133  0.9859373  0.99777097 0.97289467 0.98436576
 0.970813   0.9772592  0.9722277  0.96410376]
tensor_name:  TemporalFusionTransformer/layer_normalization_20/beta
[ 3.02456096e-02  1.04979202e-02  5.63701540e-02  3.03501803e-02
 -3.16082276e-02  5.45305386e-02  2.05727760e-02 -4.84768189e-02
 -4.64668684e-02  6.44577593e-02 -1.65903347e-03 -6.09700829e-02
 -1.51961958e-02 -2.25106510e-03  9.35544968e-02  1.46702370e-02
  2.35172547e-02  8.60623941e-02 -1.18965551e-03  4.82584573e-02
 -1.95894875e-02 -3.25306617e-02 -2.72087269e-02  2.07287967e-02
  1.68952141e-02 -2.85897870e-02  6.48384020e-02 -3.39589864e-02
 -1.77790411e-02  5.91793954e-02 -8.87259245e-02 -5.71000250e-03
 -5.71653582e-02  4.30240445e-02 -4.00130525e-02 -7.20568746e-03
 -5.06189950e-02 -3.32435183e-02  3.84684578e-02  4.29607406e-02
  3.11700907e-02  8.20584316e-03 -3.20920274e-02  1.65550113e-02
  5.42282360e-03  3.60057242e-02 -2.16339752e-02 -2.58037746e-02
 -5.45536987e-02  6.56368658e-02 -1.82050541e-02  1.51572689e-01
  1.41872698e-02  2.35386919e-02 -3.86097394e-02  6.56582788e-02
  2.91598625e-02  4.17691795e-03 -1.15026487e-02  1.80388000e-02
  1.46546634e-02 -5.03383903e-03  5.37343137e-02 -2.83172820e-02
 -1.80313215e-02  4.71238904e-02 -5.69060035e-02  6.57721758e-02
  1.53562538e-02 -8.67240429e-02 -2.98042726e-02  5.46012446e-02
  9.44039319e-03  8.34148526e-02 -6.37848303e-02 -9.18777223e-05
  1.50083676e-02  1.40194101e-02 -1.48237525e-02  5.18487543e-02
  3.79912704e-02  8.48249868e-02 -5.60362823e-02 -7.04551712e-02
 -9.99257341e-03 -1.35490010e-02 -3.74917872e-02  1.14224525e-02
  4.50314209e-02 -3.37368362e-02 -2.96039376e-02  3.83904716e-03
 -6.43466711e-02  4.14708592e-02 -1.77727938e-02  6.28226623e-02
  6.84674410e-03  1.48906270e-02 -4.15183231e-03 -4.78507355e-02
 -1.45991920e-02 -2.77349278e-02  1.43642621e-02 -1.03493929e-02
  6.68499544e-02  9.19786282e-03  1.13464901e-02  5.88332862e-02
 -2.70462148e-02 -2.67212894e-02  2.83020847e-02 -3.91216076e-04
  7.68329650e-02  3.78620960e-02 -1.50583107e-02 -4.15241346e-02
  3.21517251e-02 -6.47229701e-02  8.74371156e-02  3.36721241e-02
 -1.60222091e-02  6.86198752e-03 -1.44365774e-02 -6.37971163e-02
  5.04340045e-03  4.86730859e-02  4.60481271e-02  5.36910966e-02
 -1.28659252e-02  2.68890560e-02 -5.21443971e-02 -9.62372776e-03
 -4.08216752e-02  1.16911558e-02 -1.95047427e-02 -5.81965549e-03
  3.25685702e-02  3.53507958e-02 -3.76129858e-02 -6.89040571e-02
 -1.89855061e-02  5.41110225e-02 -2.49933992e-02  6.88487366e-02
 -4.81191427e-02 -1.84805915e-02  7.68684596e-02 -4.81359214e-02
 -5.87056577e-02 -2.23094895e-02 -2.07386911e-02 -1.09314313e-02
 -5.92293814e-02 -3.47060943e-03  5.70422709e-02  1.40932044e-02
 -6.84040636e-02  2.96279788e-02 -1.34416092e-02 -6.46397620e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_20/gamma
[0.97366273 1.0162854  1.0289562  0.977518   0.9960189  0.97527015
 0.972548   1.0356376  0.978157   1.0252625  0.9780205  1.0889475
 0.9897225  0.98000985 1.0360568  1.0282264  0.9662926  1.0532672
 1.0094413  1.0059102  0.96224606 0.9917897  0.9668051  0.979874
 1.0016714  1.0550474  1.052533   1.0308557  0.9653752  0.9759309
 1.0395741  0.9965311  0.9923566  0.9971629  0.99473256 1.0122825
 1.089545   1.063833   0.9951569  1.0095525  1.0827724  0.9910402
 1.0540392  1.0159534  0.97295433 0.99040383 0.99289936 0.93093807
 0.98530483 1.0317361  1.005493   1.1342833  1.0388831  1.0064367
 0.97297865 1.0212783  0.9462918  0.96298915 0.96701676 0.9943781
 0.99615264 0.9772912  0.9562763  0.97225463 0.9985176  0.9907925
 1.0120627  0.9612733  0.9826913  1.0338724  1.010546   0.9483054
 0.93374836 0.9973133  1.026574   0.97071075 1.0273216  1.0008206
 0.9854243  1.0496724  0.963204   1.0352273  1.0269222  1.0107095
 1.0097029  0.9926779  1.0277582  0.9824995  0.9666885  1.0138793
 1.0027755  0.9813822  0.9894153  0.9863725  0.9675724  0.93432105
 0.9727355  1.0118467  0.9716185  1.032169   1.0358965  1.0219016
 0.9981885  0.9461321  1.0004998  0.9663664  0.977959   0.9587934
 0.99035615 0.96495056 0.9989204  0.9869877  1.0412925  0.9534124
 0.967961   0.9754223  1.0996174  1.0186367  1.0652832  1.0058738
 1.0069832  1.0892371  0.9713739  1.0262846  0.9972429  1.0379344
 0.9933677  1.0801066  0.98661625 0.99521244 0.9905574  0.9706073
 0.9682773  1.0765892  1.0388536  1.0235858  1.0395105  0.9504693
 0.9575325  1.0071688  0.9986233  1.0510912  1.0700306  0.9746573
 1.0555235  0.98141086 1.0482947  0.98189604 1.0314844  0.98402256
 0.99049294 0.9690016  1.019097   0.9413076  0.9332999  0.983378
 1.0219585  0.931653   0.9887049  0.9640962 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_21/beta
[ 0.03051873  0.02194825  0.0585889   0.03265324 -0.02826674  0.05414334
  0.03704095 -0.03544987 -0.05542803  0.06762058  0.00260889 -0.07131734
 -0.01235213 -0.00395723  0.09454504  0.03049259  0.02364827  0.07194793
 -0.00147103  0.0380116  -0.01745649 -0.03628424 -0.04272934  0.00672713
  0.01746465 -0.02479078  0.06099668 -0.03060596 -0.02208877  0.06943405
 -0.09287018  0.00143111 -0.0606162   0.03948234 -0.0426365  -0.017845
 -0.03923774 -0.04582722  0.02663257  0.04303405 -0.00737453  0.01836183
 -0.03759522  0.01539303  0.00720371  0.04685002 -0.01776251 -0.03393806
 -0.06491914  0.06226244 -0.02656928  0.14047863  0.02488746  0.03005689
 -0.04743191  0.06796481  0.03333523  0.00815049 -0.02186652  0.01589931
  0.01504858  0.00171748  0.06132795 -0.02614124 -0.0230633   0.0558233
 -0.06455987  0.08420889  0.02474367 -0.08553136 -0.02569662  0.06522509
  0.01911898  0.08853951 -0.06878724  0.01776232  0.01938306  0.01477016
 -0.01749692  0.06196039  0.04602299  0.07991676 -0.06179179 -0.07854435
 -0.03283638 -0.0174249  -0.03215325 -0.01293368  0.041907   -0.0216742
 -0.02456045  0.01284642 -0.06785214  0.0454086  -0.0198857   0.05218796
  0.01439183  0.0059133  -0.00805135 -0.04620386 -0.01227651 -0.02808547
  0.00963849 -0.02030769  0.07407529  0.00122582  0.00623181  0.07803453
 -0.02274623 -0.00651168  0.03356273  0.00214804  0.07543511  0.052346
 -0.02282879 -0.04927378  0.03666191 -0.05226194  0.090516    0.03544822
 -0.0164474   0.00557968 -0.01592126 -0.06393486 -0.00577168  0.05076553
  0.04152771  0.06373229 -0.01634681  0.02871628 -0.06157172 -0.01396099
 -0.04771196  0.01120345 -0.01072794 -0.0043777   0.02694069  0.04714086
 -0.04331117 -0.08238076 -0.02305507  0.06332203 -0.02781205  0.05794173
 -0.05599562 -0.0103894   0.07948758 -0.05206286 -0.06204475 -0.01853312
 -0.03087053 -0.01887094 -0.0487465  -0.00424903  0.06159662  0.02185892
 -0.0580172   0.04039782 -0.01906995 -0.07170361]
tensor_name:  TemporalFusionTransformer/layer_normalization_21/gamma
[0.9437412  1.0369436  1.0278867  0.98901945 1.0054829  1.0711492
 0.99524117 1.0147986  1.028394   1.056202   0.98181736 1.0601997
 0.9777864  0.9902555  1.0931821  0.9766791  1.0422319  1.1522024
 0.9599435  1.0045522  0.9951715  1.0120075  0.998683   0.97256494
 0.97110534 0.9506876  1.0239718  0.948124   0.96243656 1.0043828
 1.0786322  0.9642719  1.0041904  1.027592   1.01159    0.96947485
 1.1308725  1.0288328  1.0108902  0.91469824 1.0458016  1.0114199
 1.0441757  0.9617925  0.93981385 1.000657   0.9779121  0.9590947
 1.0667549  1.0051532  0.9837695  1.1310074  0.97661    1.0010271
 1.0218695  1.0709616  0.9803877  1.0058159  1.0268368  0.98530173
 0.95873696 1.0249254  1.0569571  0.99038893 0.9800153  0.9842836
 1.0766131  1.1303271  0.9772472  1.1207     0.969135   1.044679
 0.9864464  1.0428449  1.0401101  0.97901595 0.9640558  1.0035298
 1.02692    1.034722   0.9876146  1.0894759  1.0129864  1.110171
 1.0572333  0.97713363 0.99476504 0.9723619  1.003918   0.9577643
 0.9843152  0.9579601  1.0318666  0.99205333 1.0111231  1.0704083
 1.0438455  0.94618016 0.9784846  1.0794656  0.9745997  0.98901296
 1.0068189  0.9691419  1.0330337  0.99965936 1.0149374  1.0618883
 0.9605693  1.0013348  1.0095901  0.96905166 1.0124626  1.052873
 0.9467342  1.0003594  0.98424643 1.0105813  1.1285747  1.024613
 0.98004615 1.0648448  0.9972722  1.0544559  1.0418898  0.9771566
 1.0215608  1.030855   1.0105083  1.0076377  1.1016877  1.0081618
 1.0123664  1.0224228  0.98213273 0.97256833 0.9827539  0.99214655
 1.0023836  1.0679411  0.99447316 1.0139719  0.9785523  1.1155434
 1.0106597  0.98785883 1.0302017  0.9592229  1.0174745  0.9587656
 1.0106746  0.9741857  1.0051144  1.0052912  1.0055816  0.98494303
 1.015834   0.98669904 0.99804974 1.0608368 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_22/beta
[ 0.01509479  0.01180499  0.06205025  0.00826624 -0.02083225  0.04936183
  0.07506928 -0.04759057 -0.06901718  0.08763865  0.02272659 -0.05042076
 -0.01868128  0.00605457  0.1041369   0.02206284  0.00928196  0.13014525
  0.00956448  0.00243354 -0.02409987 -0.0183292  -0.00779032 -0.00635217
  0.03269319 -0.06914771  0.07062619 -0.06065021 -0.03145079  0.06812879
 -0.06973447 -0.00483604 -0.05497023  0.03161517 -0.03660736 -0.0141156
  0.00888193 -0.00662541  0.01521644  0.00855239  0.00813898  0.03816629
 -0.0225478  -0.00575949  0.01518687  0.07786564 -0.01925054  0.00157491
 -0.07062175  0.09913892 -0.01796015  0.17204507  0.01499195  0.02014336
 -0.04239358  0.065865    0.03270102 -0.01838809 -0.02802054  0.04934548
 -0.0125121   0.03966162  0.06867529 -0.00302286 -0.01582154  0.03518175
 -0.05705903  0.09271634  0.05207915 -0.06718004 -0.03537275  0.06361039
  0.0486897   0.07167794 -0.04753461  0.05850098 -0.00463229 -0.00566149
 -0.00433926  0.04332803  0.04050627  0.0553479  -0.0879792  -0.10889129
  0.06560083  0.00383575 -0.04955643 -0.05966082  0.03442574 -0.01479486
 -0.02726282  0.02772423 -0.05156679  0.03674065 -0.02465706 -0.01011523
  0.0132518   0.01525493 -0.03324431 -0.06271694 -0.03299724 -0.03585666
  0.0004312   0.00296262  0.06504969 -0.03097577  0.01132481  0.08750004
  0.00824804 -0.02054833  0.05233122  0.00490429  0.02841819  0.03362564
 -0.04591404 -0.0401701   0.00643406  0.00518437  0.06907973  0.05255291
 -0.0279118  -0.00092388 -0.04750447 -0.06908613  0.01044719  0.09687221
  0.03021257  0.04163096 -0.02919482  0.0548006  -0.0533548   0.00177194
 -0.07070824  0.05215864 -0.02506867 -0.02158711  0.02163045  0.09167593
 -0.03972239 -0.09240077 -0.02387636  0.04382873 -0.0578728   0.03399315
 -0.03278019  0.00257062  0.07940662 -0.03331731 -0.037569    0.01047749
 -0.03214386 -0.05164766 -0.07803074 -0.0405389   0.05156957  0.03854648
 -0.02822546  0.0128998  -0.04946438 -0.05480616]
tensor_name:  TemporalFusionTransformer/layer_normalization_22/gamma
[0.9766925  0.9875765  1.0155517  0.9747752  1.001594   0.9887694
 1.163355   1.035287   1.0423068  1.0257729  0.9979894  1.0485979
 0.99690557 0.9647845  1.0562078  0.9429771  0.9974678  1.2025319
 0.98843    1.1429079  0.96212053 1.0152125  1.1529659  0.98989385
 0.9342353  1.0558869  1.0334184  1.2083682  0.9817309  1.0391576
 1.0410419  1.0099552  1.0649205  1.045682   0.98134106 0.9871152
 1.1214212  1.0614703  1.010519   1.0336004  0.9773067  1.0069537
 1.0281802  1.0343324  0.98381174 1.1543463  1.0044264  1.0318493
 1.0717272  1.0565845  1.0308864  1.1295507  0.99790686 1.008745
 0.9866609  0.94176334 1.0563424  0.990418   1.034362   1.031024
 0.9849241  1.1178957  1.0316118  1.0138252  1.0312313  1.0085822
 1.0001636  1.050494   1.0684469  1.0698643  1.00842    1.0897462
 1.0277553  1.0720972  1.046246   1.14112    0.9674023  1.0149533
 0.9740481  1.0245789  0.9892838  1.0920997  1.027791   1.1359708
 1.28979    0.95047843 1.0211269  1.1433458  1.0169529  1.0162954
 0.9969638  0.99337983 1.0345097  0.9866386  0.9973732  1.17944
 0.9912577  0.9839694  1.0330298  1.0205594  1.0417219  0.9879467
 1.0130134  0.96773773 0.98195714 1.0824482  0.98428226 1.0363499
 1.0124028  0.97528    1.0513647  0.9971715  1.1275669  0.9999036
 1.0536715  0.9958979  1.0493337  1.1576059  1.0395913  0.9959951
 1.0331157  0.98453665 1.0095898  1.0167683  0.9797296  1.260578
 0.9764762  1.0425442  0.9719198  1.0471003  1.0243455  1.0026406
 1.0241466  1.185728   0.9673896  1.0259576  1.0092337  1.1729815
 0.9799842  1.0847023  0.9905984  1.0253845  1.1042575  1.1138647
 1.0593313  0.9875761  1.0270389  1.0088205  1.0275832  1.0198368
 0.9524758  1.0739682  1.0980355  1.041548   1.0531089  1.0063435
 1.0051725  0.9968158  1.116836   1.0396782 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_23/beta
[ 1.25680501e-02 -1.27610825e-02  1.49855483e-02 -2.00578794e-02
  3.14214290e-03  1.55028712e-04  1.62994340e-02 -2.04037875e-02
  7.09731877e-03  2.14476977e-03 -8.06220807e-03 -1.18527208e-02
 -3.29848123e-03 -7.36061065e-03  2.50963476e-02 -1.16396951e-03
  2.61246972e-02  8.17560479e-02 -4.42713825e-03 -6.77172188e-03
 -6.62818039e-03 -5.78226848e-03  6.65064454e-02  2.14893352e-02
 -1.18657472e-02 -3.73429172e-02  4.83858474e-02 -3.82867046e-02
 -2.09911051e-03  7.10962620e-03 -1.00832516e-02 -8.80216900e-03
 -5.01347054e-03  5.13427705e-03 -3.12265754e-02 -4.74515697e-03
  2.48668492e-02 -1.70808006e-02  4.74134162e-02  6.14131335e-03
  2.05068178e-02  2.61280756e-03 -1.19450837e-02  8.94149020e-03
 -1.34622976e-02  3.51124257e-03 -1.67728052e-03 -8.41686688e-03
  2.45939419e-02  6.38956800e-02 -3.79588408e-03  8.89802128e-02
  1.17211659e-02  3.30171408e-03  3.71137424e-03  9.38719418e-03
 -1.27585430e-03 -3.30421217e-02 -1.61414072e-02  8.58020131e-03
  2.22844002e-03  2.07421985e-02  5.73497964e-03 -1.15713943e-02
 -6.03540568e-03  8.20793957e-03 -1.11457622e-02 -5.38839813e-05
 -1.50584960e-02 -7.26576429e-03  6.06663665e-03 -1.52645400e-03
  2.94091366e-03  1.15612624e-02 -7.03230547e-03 -1.23012494e-02
  1.47207370e-02  2.83557884e-02 -1.21898167e-02  3.15826088e-02
 -1.34731503e-02  7.98086915e-03 -1.64736342e-02 -1.87762678e-02
  9.24967080e-02 -1.77057576e-03 -1.07822260e-02  8.47319886e-03
  1.02230487e-03 -1.45841539e-02 -9.63098835e-03 -8.35027825e-03
 -2.23119278e-02 -6.63957372e-02  1.12452358e-02 -3.55467363e-03
 -3.09973746e-03 -1.25811482e-02  1.03013339e-02 -2.24755867e-03
  9.17545520e-03 -2.59978417e-03  2.78989486e-02 -1.02126524e-02
  8.43650941e-03 -3.22500728e-02 -1.69369839e-02 -1.11456392e-02
 -1.72547214e-02 -1.52171892e-03  2.10737623e-03 -3.26174758e-02
  8.95556342e-03  1.58892758e-02  1.55246089e-04 -2.21408744e-04
  1.43255126e-02  9.86007217e-05  2.03210153e-02 -3.84564954e-03
  7.43766874e-03 -3.42205204e-02  5.28651476e-03 -2.66268384e-02
 -7.87356962e-03  1.72241740e-02  1.59058142e-02  1.35012586e-02
  9.56530217e-03  2.06042756e-03  2.05348805e-02 -2.16121618e-02
 -1.06085120e-02 -2.63197697e-03  5.74424121e-05  1.76289689e-03
  1.21952966e-02  3.61667993e-03 -3.30466498e-03 -5.84207522e-03
 -7.14494474e-03  1.32823512e-02  4.62641800e-03 -4.32851957e-03
 -1.36294011e-02  2.75278161e-03 -2.03726464e-03 -1.11502903e-02
 -1.76355392e-02 -2.02868339e-02  8.22495669e-03 -9.16566642e-04
 -3.52616720e-02  5.55257127e-03 -2.86127254e-03 -9.25530586e-03
 -7.01575214e-03  8.44579469e-03 -6.29765913e-03 -1.46184294e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_23/gamma
[0.95384276 0.9961771  0.9466     1.0408322  0.9219615  0.9610679
 0.9650522  0.97366196 0.94726574 0.98149616 0.9800071  0.86341405
 0.96554005 0.9652037  1.008407   0.8491092  0.98399776 1.1473678
 0.8645135  0.943457   0.98225176 1.007043   1.1155508  0.99952936
 0.96621346 1.1464235  1.0193148  1.0637307  0.9575209  0.9340985
 0.9398865  0.9696705  0.91810983 0.9538913  0.96068627 0.87286705
 0.9818678  0.9571907  0.9907008  0.9456091  1.0233514  0.9289436
 0.9595244  0.90497375 0.9686433  0.8997413  0.9502528  1.0227357
 1.0047429  1.0226163  0.89440626 1.0588855  1.006059   0.9442916
 0.91446805 0.8972514  0.9263337  1.068217   0.91515243 1.0537376
 0.9772581  0.9952849  0.95421785 0.9460498  0.9640362  0.9683685
 0.89242226 0.9228676  0.93662494 0.9516449  0.96240777 0.9384342
 1.011794   0.9191661  0.95213073 0.9428361  0.9555641  1.0215697
 0.9698504  0.98055935 0.9507061  0.915907   1.0011225  1.0095123
 1.1768428  0.995182   1.0204396  0.8532046  0.91129965 1.0232017
 0.99880034 0.96849346 0.92038333 1.0469822  0.94487476 0.9134204
 0.9197416  0.99406505 0.99505067 0.9467868  0.9526994  0.95595753
 1.011831   0.96514165 0.8957457  0.99842167 0.9524624  0.943806
 0.9440774  0.97084224 0.91664785 0.9554348  0.8821968  1.0109936
 0.94149923 0.98443365 0.8811051  0.9569261  0.81282854 0.95908064
 0.96115637 0.98070204 0.9955564  0.9609957  1.0217102  0.83554035
 1.004512   0.90785515 0.9223552  0.8983112  0.9554923  0.9728118
 0.90844536 0.9417632  0.9635658  0.9677167  0.9597879  0.83654565
 0.892369   0.9522242  0.90777785 0.8815991  0.98878735 0.9295396
 0.88544714 0.9708698  0.88997793 0.95429766 0.89413744 0.9756485
 0.9304294  0.95409226 1.0360626  1.016094   0.94225454 0.9507798
 0.90723884 1.0850178  1.0268223  0.9812759 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_24/beta
[ 1.31389825e-02 -2.43770946e-02 -5.58214728e-03  1.68663654e-02
  1.01876371e-02 -2.25463267e-02  4.95242374e-03 -6.00900874e-03
  2.70102322e-02  2.13097911e-02 -1.00584822e-02  1.49086602e-02
 -1.16182049e-03  5.80072962e-03 -2.87059192e-02 -2.73554120e-02
 -4.40368196e-03  2.01043114e-02  3.59183922e-03 -1.00212963e-02
  9.06306843e-04  1.68744493e-02  3.83385015e-03 -3.13928584e-03
  1.42120803e-02  8.96691624e-03 -1.29216285e-02 -2.10397318e-02
  1.68362923e-03 -1.46441413e-02  2.59849839e-02  1.07926782e-02
 -2.35171453e-03  1.89715791e-02  2.64327601e-02  1.75674330e-03
  1.34713715e-02 -2.37797759e-02  1.16802333e-02 -2.62118410e-02
  1.72094870e-02  1.37835024e-02  1.04763407e-04 -2.68576667e-03
 -4.17329502e-05 -1.51518336e-03 -1.07161617e-02  7.62995984e-03
 -8.33427161e-03 -1.19825210e-02 -1.52849350e-02 -1.42724474e-03
 -4.46683727e-03  8.28098040e-03  1.86724886e-02  2.17003375e-02
  1.78286042e-02 -2.25076755e-03 -9.07488726e-03  2.13336758e-02
 -7.06735114e-03 -2.78042089e-02 -9.05756559e-03  1.38027752e-02
  9.32131428e-03 -2.60630194e-02 -2.27111317e-02  2.65993015e-03
 -3.08160065e-03  1.64470635e-02  8.77399836e-03 -1.29524674e-02
 -1.54384389e-03  1.87934039e-03 -4.74683329e-04  1.00979926e-02
  1.32564288e-02 -1.54122170e-02 -3.26943072e-03 -1.28604984e-02
 -9.34768096e-03 -1.96043178e-02  1.94280595e-02  2.20028237e-02
  1.05939033e-02  9.27473069e-04  2.08539013e-02 -3.88007914e-03
 -1.75594930e-02  1.56216202e-02  3.40765662e-04 -8.56056903e-03
 -1.22832824e-02 -6.24527689e-03  1.46421101e-02  8.05773947e-04
 -8.65209661e-03 -2.02055890e-02  2.28427700e-03  7.43416604e-03
  5.00822673e-03  9.40556824e-03  3.75394262e-02 -1.39993522e-02
  7.88199343e-03 -1.43631827e-02  8.74492992e-03 -1.66600775e-02
 -6.77378057e-03 -5.20338258e-03  2.23579649e-02  4.68653440e-03
 -1.99368279e-02 -1.03541408e-02  1.76695921e-02  3.49617861e-02
 -1.97741110e-02 -3.91263136e-04  1.76985282e-02  4.20868304e-03
 -1.99616794e-02  1.01911537e-02 -1.64816715e-02  1.27262883e-02
  1.20498491e-02 -3.34457261e-03 -3.20569426e-03 -3.16978781e-03
 -3.29552032e-03  9.32612456e-03  5.24714449e-03 -2.02829242e-02
  4.36563557e-03 -1.37239206e-03  5.10049611e-03  2.05820717e-04
 -1.43426924e-03 -1.58664596e-03 -1.35348202e-03 -8.44337745e-04
  2.38583912e-03 -1.74701288e-02  2.15560049e-02 -1.38026346e-02
  1.44191906e-02  7.30253756e-03 -1.54585894e-02 -7.48182461e-03
 -8.93737935e-03  1.07789478e-04 -1.79011654e-02 -1.46991713e-02
  3.10222991e-03  1.14238588e-02 -2.09309924e-02  3.00175212e-02
 -3.04373563e-03 -1.16169797e-02 -1.70755628e-02  3.00603267e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_24/gamma
[0.9914931  1.0171511  1.0036404  0.96183896 0.96335113 1.0134414
 0.9885159  0.98220164 1.006398   1.0505617  1.0064363  0.95499885
 0.9521632  0.99794513 0.98677534 1.0011928  0.9708083  1.0075477
 1.0070137  0.9898698  1.0001966  1.0114723  0.9684697  1.0156512
 0.99473166 0.9930105  0.97437465 1.0039947  0.98152614 1.0047569
 0.9908421  0.9943507  0.9942047  1.0081033  0.9800984  0.9596588
 0.98064286 0.9580423  1.0001733  0.9898226  0.96794415 1.0234072
 0.99484724 0.9553593  0.98032737 0.987847   0.9757744  0.97608554
 0.9676236  0.97116053 0.9922069  0.9832532  1.0037172  0.96997756
 1.0029731  0.98422027 0.9995556  0.9922722  0.92868406 1.0047417
 1.011063   0.97939056 0.9903305  0.9978835  1.0004433  1.0200862
 1.0548986  1.012387   1.0062033  1.0099311  0.9810485  1.0141081
 0.97265    0.9997402  0.98707527 0.97261804 0.9976205  0.9894115
 0.99119925 0.9695392  0.9913445  1.0057408  0.98308843 0.97829235
 1.0078902  0.96408236 0.9623672  0.99518275 0.9915906  1.0166001
 1.005123   0.99515927 1.021728   1.0034575  1.0079308  0.9742723
 0.97171575 0.99356925 0.9813499  0.9960068  0.9948662  0.99038756
 0.99034584 1.0115911  0.9656625  1.0093617  0.9643951  0.98819965
 0.9899513  0.988837   0.9685453  0.9872971  0.995137   1.0017823
 1.0119619  1.0020851  0.989113   0.99282396 0.9842666  0.9979248
 0.9669784  0.9546765  0.9960188  0.9880433  1.0102488  0.97512263
 1.0001976  0.9941906  1.0367091  0.9742299  0.97421044 1.0185205
 0.97158235 0.98851156 0.9946164  0.97314197 0.9895077  0.9601526
 0.9873888  0.9885202  0.9742551  0.98417985 0.9856931  0.9859254
 1.0206473  0.97871083 0.96653193 1.0070299  0.99499583 0.9724454
 0.9746464  0.9639076  0.99056643 0.9529236  1.02551    0.9733107
 0.9915621  0.9925758  0.99377376 1.0081784 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_25/beta
[ 0.03238874 -0.05753686 -0.00972949  0.03324654  0.00622307 -0.03611035
  0.00011789 -0.02919603  0.05736537  0.03427051 -0.03369313 -0.00326925
 -0.02786044 -0.00812218 -0.02544156 -0.04050264 -0.01615147  0.04789378
  0.00173073 -0.02876912  0.00496766  0.02351982 -0.0049019   0.02617759
  0.03349381 -0.04054791  0.01036311 -0.06043868  0.04204011 -0.01357088
  0.02964855 -0.000886    0.00707277  0.06166376  0.05248604  0.00210234
  0.02001721 -0.07742316  0.02646898 -0.03959234  0.00979746  0.00942702
 -0.01153096 -0.0168683   0.0174452  -0.01288024 -0.01299084  0.01791446
  0.01692318 -0.00063506 -0.04235676  0.01128914 -0.0031643   0.01546607
  0.05715873  0.0315932   0.02524187 -0.03444085 -0.0323101   0.04098785
 -0.0396547  -0.00752016 -0.02841081  0.01193753 -0.01472894 -0.04793656
 -0.07199666  0.00990503 -0.00275016  0.02854014  0.01247762 -0.00564791
  0.00255566  0.00963312 -0.01506177  0.02080774  0.02149368 -0.02412552
 -0.03690268 -0.00855507 -0.01915581 -0.06036891  0.0282268   0.02314424
  0.0360151   0.01164019  0.06370028 -0.01597363 -0.04655904  0.02327337
 -0.02217916  0.00774429 -0.02217487  0.0149987   0.03181     0.0228748
 -0.03612021 -0.04162636  0.00084422 -0.00129042  0.03043634 -0.00173943
  0.08968576 -0.07625431  0.03092531 -0.0295005  -0.00588332 -0.03968259
 -0.01775813  0.02124917  0.01251178  0.0283793  -0.02095025 -0.00407319
  0.02393457  0.05594267 -0.04154918 -0.01049398  0.02677379  0.01801931
 -0.06540141  0.00300959 -0.06918712  0.03758157  0.00437024 -0.01543756
  0.00297458 -0.01280195  0.00916057  0.01488057  0.02943667 -0.04741282
  0.01987435 -0.02943144  0.03276912  0.02310073  0.04038864 -0.01910373
 -0.01768674 -0.03362249  0.0126948  -0.04723928  0.03705522 -0.02447564
  0.02942019  0.01932516 -0.05137037 -0.01399327 -0.01157452 -0.02539409
 -0.01909532 -0.02451585  0.04444487 -0.00062767 -0.08009026  0.05683394
 -0.01105944 -0.01382605 -0.05164383  0.05296536]
tensor_name:  TemporalFusionTransformer/layer_normalization_25/gamma
[0.9664066  1.0208881  0.96052057 0.99648994 0.96132433 1.0139271
 0.98734754 1.0157351  1.0252503  0.9997185  1.0174412  0.9636295
 0.9857255  0.9710195  0.98714703 1.0074984  0.9552796  1.0189081
 0.96091545 0.98734456 0.9931703  1.0162803  0.9702761  0.9826066
 0.9966192  1.0152956  1.0030496  1.0385374  1.0279025  1.0007623
 0.9945633  0.9378776  0.9545753  1.0338596  0.98824483 0.9721849
 0.9791572  1.0391314  0.99218893 0.97012806 0.99640024 0.96890575
 0.9922159  0.9631742  0.9845237  0.9844205  0.9994496  0.99109215
 0.97797513 0.98297745 0.99116546 0.9911437  0.9962898  1.0096074
 1.0350044  0.9778973  1.0152471  1.0167097  0.98246545 1.0101043
 1.0491738  0.97016513 0.9912195  0.97624826 0.9735794  0.98998564
 1.0093275  0.9697785  0.9964066  0.98443043 0.9993551  1.000321
 0.9881911  1.0010371  0.98770213 0.98597205 1.0131562  0.978456
 0.9811917  0.97893775 0.98062104 1.0468936  0.93807024 0.9791371
 1.0269597  0.97594744 1.0055823  0.9676421  1.0096207  1.0014501
 0.9986554  1.0043437  1.0172205  1.0276341  1.0234283  0.97658837
 1.0034671  0.996186   0.97436136 0.9738931  1.0072819  0.9968587
 1.0433823  1.0799692  0.98789555 1.0023477  0.95604664 0.99465674
 0.99956506 1.0042486  0.9780464  0.97804075 0.9952101  0.99083745
 1.017948   1.0313145  0.9919324  0.9714646  0.9915068  0.97062427
 1.021511   0.97533906 1.026053   0.99659956 1.0061918  0.9734833
 0.97192454 0.99295276 0.98515904 0.9903206  1.0003543  1.0311528
 0.9600439  0.9906356  0.9614741  0.9971363  0.9777385  0.9854437
 1.0028219  1.0140995  0.96603054 1.0002434  1.005912   1.0016268
 1.0081465  0.97670084 1.0060426  1.0103775  1.0062534  0.9817008
 0.98524004 0.98756635 1.0044293  0.97685057 1.0141422  0.98689044
 1.0139205  1.00525    1.015393   1.0277418 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_26/beta
[-0.00911833 -0.03632144 -0.02292933  0.07527453  0.02362585 -0.07373007
 -0.02316309 -0.03582668  0.06859799  0.04541731 -0.00374626  0.06185307
 -0.08459767 -0.01007194  0.00360779 -0.06467335  0.02819492  0.07207618
 -0.02541757 -0.12409855 -0.07607455  0.02359006 -0.00899868 -0.02257863
  0.06591439 -0.04367958  0.06307106 -0.07586704  0.11288404 -0.07071808
 -0.00032168 -0.03248576  0.03386829  0.11216488  0.01184289  0.04504676
  0.00325904 -0.0101837   0.09961694 -0.00303238  0.03161059 -0.01524918
  0.00950389  0.05067033  0.04962739 -0.01862504 -0.0079192   0.0791233
  0.03659653  0.06486902 -0.058768    0.02370283  0.00238849  0.11486948
  0.13611108  0.00014618  0.03310248 -0.05316855  0.00230648  0.08539451
 -0.0439469  -0.04298097 -0.00652746  0.03002147 -0.01369266 -0.01278795
 -0.10276231  0.03725104 -0.0445607   0.01505686 -0.00140783 -0.02041297
 -0.02489566 -0.01289555  0.01134581 -0.00522313  0.0052051  -0.02106966
  0.00134522 -0.02354025 -0.01300088 -0.03924985  0.04134248  0.00054362
  0.05382657 -0.00388497 -0.00811335 -0.02861646 -0.05215621  0.04670842
  0.02809731  0.00569895 -0.08520468  0.05033812  0.06627195  0.03410398
 -0.03129134 -0.04649129 -0.01163508  0.05530478  0.06776229 -0.06261224
  0.08488026 -0.04702153  0.05708035 -0.03499743 -0.04581142 -0.00643789
 -0.01200407  0.01236218  0.07970259  0.03250062  0.0139898  -0.01887032
  0.05553541  0.02385288 -0.02530129 -0.03051591  0.08620393  0.07825594
 -0.08323763  0.00020518 -0.09952325  0.01843617  0.06150927 -0.00639624
 -0.02508345  0.03255373  0.03425271  0.07104217  0.01395757 -0.05395618
  0.02035409 -0.05145174  0.00697162  0.0299581   0.00377995 -0.00526053
 -0.03203518  0.01889636  0.03729598 -0.04425957  0.05674541 -0.08287907
 -0.01564692  0.02205568 -0.13150081 -0.05691548  0.00405167  0.06497178
  0.0099259   0.01283112  0.03448205  0.00157063 -0.05211575  0.00564057
  0.05313265 -0.06237387 -0.08482309  0.05058578]
tensor_name:  TemporalFusionTransformer/layer_normalization_26/gamma
[0.97374296 1.0026264  0.9965373  1.0173817  0.9768973  1.0374736
 0.9691619  1.0141777  1.0183645  1.039429   0.9974138  1.01655
 1.0672449  0.96855515 0.9752376  1.0068258  0.9458156  1.0379496
 0.97151375 1.107398   1.0472561  0.9928682  0.96624833 0.9847657
 1.0065005  0.9886916  1.0175384  1.0331053  1.1054724  1.020894
 0.9777821  0.968367   0.9572967  1.0926777  0.9744229  0.9499364
 0.99930125 0.95771706 1.057279   0.9748545  0.9816457  0.9750889
 0.97594386 0.96997935 0.9983318  0.9695783  0.9742575  1.0545466
 1.0204915  1.0055041  0.9782181  1.006115   0.9935397  1.082397
 1.1317793  0.9559608  1.030836   1.0245774  0.9586196  1.0268863
 1.0178337  0.98446035 0.9865543  0.9837183  0.99690205 0.9822338
 1.0742921  0.9927742  1.0254345  0.9825564  0.9897118  0.99669456
 0.98438996 0.99263024 1.0051385  0.9678382  1.0058422  0.98014164
 0.9788751  0.9608774  0.97980005 1.0027571  0.9711542  0.9700756
 1.0197868  0.9611237  0.9865402  0.9611646  0.98134625 1.0027386
 1.0209609  1.0059888  1.0849726  1.0141959  1.0332304  0.9724173
 0.9751418  0.9931454  0.96623987 0.9998829  1.0102402  1.0300026
 1.0386877  1.0309635  1.0075607  0.9871983  1.0347089  0.95213056
 0.9941198  1.0022795  1.0575365  0.97667974 0.9707573  0.98130924
 1.0375986  0.99891925 0.9709958  1.0051028  1.0067056  1.0428112
 0.9758841  0.9628445  1.0698317  0.9731717  1.0096765  0.9697519
 0.97587925 0.988498   0.9696874  0.98852557 0.9819065  1.0339011
 0.979384   1.0447272  0.97003764 0.9793537  0.9822418  0.98721445
 0.9868363  0.989371   0.95354563 1.0221459  1.0349705  1.0461441
 1.0288653  0.97166485 1.1217957  1.0284678  1.0247734  0.9863446
 0.9686564  0.96690214 1.0093063  0.9848545  0.9982479  0.97829556
 1.028736   1.0248712  1.0640528  0.9937618 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_27/beta
[ 9.55272373e-03  7.25618424e-03  1.03301685e-02  1.08801872e-02
  2.84458813e-03  8.71917792e-03  1.19077386e-02 -1.37713028e-03
 -5.85599011e-03 -1.91793346e-03 -2.65216990e-03 -5.88582456e-03
 -1.55082776e-03 -1.06634935e-02  8.83118808e-03  6.01361040e-04
  9.56666376e-03 -6.06226549e-03 -2.56203604e-03  2.71421252e-03
 -2.69740098e-03 -8.35937820e-03 -2.14088205e-02  6.47251680e-03
 -4.26651631e-03  9.20197368e-03  2.58901902e-03  2.43949611e-03
 -7.07900559e-04  1.18576447e-02 -1.10057788e-02 -1.45513203e-03
 -5.28684305e-03  5.13061834e-03 -3.72517825e-04 -1.49566529e-03
 -1.22051639e-02 -1.04705151e-02  6.49086060e-03  1.10216821e-02
 -5.50562143e-03  4.91508236e-03 -2.25982792e-03  4.91910381e-03
 -3.04880925e-03  8.61088373e-03 -1.86781795e-03 -1.06805367e-02
 -7.22363824e-03 -8.95856787e-03 -1.86559081e-03  1.63098844e-03
  1.52886864e-02  1.92916463e-03 -3.41950846e-03  1.06838206e-02
  1.32331229e-03  1.51904197e-02 -1.15930866e-02 -6.41387980e-03
  1.28534874e-02 -6.32700929e-03  6.28798641e-03 -6.38099853e-03
 -1.15322322e-03  1.01188393e-02 -7.10961036e-03  5.60528738e-03
 -7.25469727e-06 -1.06817549e-02  2.00599688e-03  3.86548461e-03
 -7.60928355e-03  1.15476400e-02 -9.47660673e-03 -7.91308656e-03
  1.20034246e-02  5.32910274e-03 -4.48855897e-03  6.74319919e-03
  5.20029012e-03  7.70204049e-03  5.20032225e-03  3.04739689e-03
 -1.05711343e-02 -7.31556164e-03  2.99383979e-03  9.00039170e-03
  8.36550910e-03 -1.07593797e-02  8.22833925e-03 -1.07901786e-02
 -5.42133860e-03  7.41589488e-03  3.16856476e-03  1.70453880e-02
  5.48602920e-03 -2.06682622e-03  4.95502725e-03 -4.24745172e-04
  4.57759015e-03  4.46298160e-03  6.06959267e-03 -5.39417658e-03
  1.31506426e-02  1.07241981e-02 -8.86762980e-03  8.18278641e-03
 -8.39049648e-03 -1.09513884e-03  3.80264758e-03 -8.66510731e-04
  1.10082710e-02  1.45020587e-02 -1.80117099e-03 -6.82786293e-03
  1.21566532e-02 -3.92929476e-04  9.51302238e-03 -1.38033333e-03
  2.60703615e-03 -2.53384933e-04  5.18122222e-03  1.13851053e-03
 -6.75802538e-03  5.34986518e-03  1.33825643e-02  8.51934962e-03
  3.92914843e-03  2.49119173e-03 -1.29073029e-02 -6.52871048e-03
 -6.70928182e-03  4.31069871e-03  3.32359341e-03  2.02953862e-03
  9.68730636e-03  5.47475042e-03 -2.22641393e-03 -1.70730380e-03
  1.27891707e-03  8.04099534e-03  4.50560264e-03  5.75739471e-03
 -8.62566847e-03  2.65303883e-04  6.57374971e-03 -7.49559235e-03
 -5.17891999e-03 -8.29142518e-03 -4.30939835e-05  5.88198658e-04
  1.87916670e-03  5.35837095e-03  9.65326373e-03  6.10382762e-03
 -1.00763068e-02  1.30228158e-02  4.32793429e-04 -7.26859365e-03]
tensor_name:  TemporalFusionTransformer/layer_normalization_27/gamma
[0.9453242  0.96362686 0.9117082  0.98270917 0.9387441  0.9631867
 0.9312814  0.9707667  0.9616037  0.9360357  0.9738021  0.91510826
 0.96738267 0.9502558  0.995335   0.9174737  0.97540027 0.9616162
 0.93959624 0.9363934  0.966574   0.96426076 0.9912027  1.0021491
 0.9592844  0.97218907 0.9611861  0.95860416 0.9555651  0.90978324
 0.9432476  0.96666557 0.92211246 0.9489836  0.95377684 0.9409364
 0.99645567 0.956419   0.97975487 0.96117884 0.9737391  0.95439845
 0.9498122  0.93328553 0.96122724 0.92919844 0.9363767  0.9769963
 1.0086715  0.93454665 0.91388834 0.9337672  0.95157075 0.9568939
 0.9367597  0.92087233 0.9197492  0.9618195  0.93392485 0.995466
 0.94448376 0.98342997 0.96205187 0.9589221  0.93953264 0.9754315
 0.93492264 0.9431801  0.96680295 0.9591543  0.94034404 0.938883
 0.97404635 0.94636047 0.94993365 0.92147374 0.94441605 0.9928117
 0.9836078  0.97043556 0.9811722  0.9115273  0.94058245 0.93714523
 1.010326   0.97666454 0.9675321  0.845872   0.936654   0.9813315
 0.95241874 0.95485526 0.93638235 1.0262997  0.95169544 0.969788
 0.94485044 0.9876281  0.9583518  0.94256157 0.93905586 0.9571041
 1.0109037  0.9804     0.9424834  0.9647968  0.9593189  0.98320293
 0.95744747 0.94531095 0.94687515 0.97552    0.92500603 0.97434473
 0.9332921  0.9650956  0.90341455 0.937516   0.9180882  0.95116407
 0.9812062  0.9855583  0.96841115 0.93350476 0.98844695 0.9248856
 0.95314443 0.9257127  0.94471914 0.9309349  0.9952944  0.99640214
 0.9291022  0.9261282  0.9619967  0.95093    0.9366024  0.8922508
 0.9245266  0.93250227 0.9514658  0.9483366  0.96695536 0.932043
 0.90983915 0.9436042  0.9445836  0.9611249  0.92341757 0.9967942
 0.9335416  0.92902017 0.9560777  0.98204905 0.9696023  0.9520528
 0.9535714  0.9869355  0.9706174  0.97642463]
tensor_name:  TemporalFusionTransformer/layer_normalization_3/beta
[ 4.66338731e-03  8.86086375e-03 -8.27182457e-03  5.90439327e-03
  7.39745237e-03  8.78183637e-03 -9.64350626e-03 -2.58413190e-03
 -4.51884372e-03 -5.47240721e-04 -5.62586728e-03  4.34725033e-03
 -8.91747512e-03 -2.32797787e-02  7.86907785e-03 -1.06595494e-02
  8.65650643e-03  1.38630485e-03  2.35194922e-03  8.38254672e-03
  8.47734860e-04 -4.11855942e-03 -1.66596880e-03 -7.82251079e-03
  9.85377189e-03 -9.88734514e-03  1.28680700e-02  7.82446843e-03
 -2.02197842e-02 -1.93813804e-03 -6.90462693e-05  2.20608315e-03
 -5.81701566e-03 -1.25760883e-02  1.07774558e-02 -2.08832044e-03
 -1.35388374e-02 -5.66215022e-03 -1.23499869e-03 -4.44471976e-03
  1.04973005e-04 -1.77418790e-03 -7.44209811e-03  2.75060907e-03
  1.22645693e-02 -2.44533573e-03  3.01841088e-03 -7.56695494e-03
  1.22515466e-02 -4.76786867e-03 -3.21624940e-03 -5.51656308e-03
 -2.56345700e-02 -9.61184688e-03 -6.40327227e-04  1.97455927e-04
  2.71735759e-03 -9.56696272e-03  5.47622982e-03  6.52878603e-04
 -1.12037845e-02  6.54680189e-03  6.16160035e-03  1.54010335e-03
  4.28801839e-04 -6.16330747e-03  3.17223580e-03  1.23159168e-03
  3.94859770e-03  6.22530188e-03  1.34352897e-03 -1.08440621e-02
 -3.54012079e-03  2.30281428e-03 -1.32364491e-02 -3.70082888e-03
  7.13642221e-04 -1.36387022e-02  1.50136545e-03 -2.17607692e-02
 -1.90500021e-02  5.65898512e-03  1.73446033e-02 -7.79122766e-03
 -4.75919433e-03 -9.02496930e-03 -9.20732319e-03 -5.33641956e-04
  5.73638128e-03 -5.67619037e-03  8.13900586e-03  5.96200395e-03
 -5.54412976e-03 -7.18665193e-04  9.87973250e-03  3.41810938e-03
  3.87126161e-03 -2.17212713e-03 -4.14653565e-04  1.14448033e-02
  2.57755648e-02  2.64554331e-03  8.65003560e-03  1.07955066e-02
  9.34704673e-03 -1.45440539e-02  1.38294939e-02  3.09138503e-02
  3.83577007e-03 -2.82244245e-03  1.75148380e-04  5.74356550e-03
 -3.60744749e-03  1.09311389e-02 -2.96636787e-03 -3.73893487e-03
 -4.68721054e-03 -1.03225913e-02 -6.52012043e-03  2.25441251e-03
 -9.58375912e-03 -5.26163960e-03 -4.66742134e-03 -7.70414044e-06
  6.67972909e-03 -5.00961393e-03 -9.74446815e-03  4.62960033e-03
  1.22706490e-02  2.84825615e-03  4.50503733e-03 -1.26439682e-03
 -2.17730831e-02  7.75520876e-03  6.22566789e-03 -6.25315588e-03
 -1.13128107e-02  1.32800955e-02 -1.30520174e-02 -9.96315572e-03
 -8.99635628e-03 -7.33274734e-03 -2.55953491e-04 -9.93135385e-04
  1.26143415e-02  1.75354281e-03 -8.69776937e-04  4.23869304e-03
  1.56316403e-02 -8.62759445e-03 -1.40311290e-02 -5.75497607e-03
  7.02205626e-03 -8.39599408e-03 -1.78026967e-02 -8.92720744e-03
 -1.04896426e-02 -9.02751926e-03 -1.48312356e-02  3.44323879e-03]
tensor_name:  TemporalFusionTransformer/layer_normalization_3/gamma
[0.98296374 0.958808   0.979114   0.9931317  0.9775683  0.99018043
 0.9939186  0.9979663  0.98812664 0.98579264 0.9985378  0.96905893
 0.98541766 0.96916765 0.9856766  0.9857489  0.99212587 0.9887331
 0.9921105  0.98110455 0.97970194 0.9874534  0.9799059  0.9817673
 0.9685552  0.98888105 0.9935074  0.97538894 0.9662528  0.9935234
 0.9977991  0.98633695 0.9865006  0.9864295  0.9725949  0.9987932
 0.9743899  0.9912858  0.98241585 0.98905045 0.9940176  0.99476194
 1.0014585  0.9954832  0.988596   0.98961085 0.98511755 0.98149264
 0.98658735 0.98161525 0.9888985  0.99561363 0.95411056 0.99384147
 0.98008007 0.9783997  1.0013617  0.98374313 0.986983   0.96609426
 0.9913694  0.9732034  0.9903703  0.98204416 0.9738635  0.98968434
 0.98646396 0.99165624 0.97939384 0.99241424 0.9823613  0.9848522
 0.9950197  0.9998024  0.9981141  0.98970807 0.9882813  0.98423755
 0.9825445  0.9800972  0.9868108  0.9874367  0.9820297  0.9933062
 0.9878043  0.9968392  0.98837143 0.99395937 0.98580474 0.9972405
 0.96965444 0.9959163  0.99897695 0.9971441  0.98950666 0.9930394
 0.99695086 0.98337597 0.9891104  0.9851334  0.94658524 0.9786732
 0.99232274 0.99946326 0.9897957  0.9641307  0.97214043 0.981212
 0.97441435 0.9878482  0.9855816  0.9830765  0.9951516  0.99369574
 0.97998184 0.9993063  0.97373617 0.99768025 0.98393095 0.9858259
 0.9828412  0.9851245  0.9955769  0.9849002  0.98803985 0.9908754
 0.97617084 0.9891919  0.97658193 0.9730315  0.9940111  1.0000523
 0.98766524 0.9895274  1.0013512  0.9840998  0.9908295  0.9913902
 0.9864853  0.98984694 0.9753785  0.99315923 0.97697175 0.9953053
 0.99091434 0.97620845 0.9925668  0.985513   0.9780315  0.9962519
 0.97584534 0.99375707 0.9945659  0.96784157 0.938495   0.9878864
 0.97948813 0.9879083  0.96700954 0.98370117]
tensor_name:  TemporalFusionTransformer/layer_normalization_4/beta
[ 6.15788903e-03 -6.80039404e-03  3.85990776e-02  1.17827114e-02
 -2.37909388e-02  4.04154795e-04 -9.96524841e-03 -2.92343553e-02
  2.71147247e-02  1.96549725e-02 -4.22928855e-03 -4.12423834e-02
  9.82015766e-03  2.91272886e-02 -4.77236323e-02 -4.68375199e-02
 -8.02482814e-02  7.24157458e-03 -3.42040614e-04  2.12967359e-02
 -5.39441891e-02  1.48691172e-02 -2.13115793e-02 -3.37495655e-02
 -8.07346776e-03  7.78358430e-02 -4.21143286e-02 -3.18097621e-02
  2.26668417e-02  8.43136292e-03 -5.60620725e-02  4.01607491e-02
  1.91077963e-02  4.45806533e-02 -1.12700788e-02 -9.46607068e-03
  1.50153395e-02  3.57819796e-02 -2.96285911e-03  4.85806987e-02
 -2.06889454e-02 -1.83327477e-02  2.89285649e-02 -6.33543450e-03
 -5.12640588e-02  1.15128756e-02  3.65909538e-03  3.40567306e-02
  5.81268147e-02  2.78900973e-02  3.48553583e-02  3.67515236e-02
  3.85901518e-02 -1.64216235e-02  5.71026886e-03 -1.73740890e-02
 -1.39861358e-02  1.20729655e-02 -4.11215574e-02  1.66423675e-02
  4.64294553e-02  1.36910575e-02 -5.60220368e-02  3.04866284e-02
  2.17936672e-02  3.60561982e-02 -8.19737371e-03 -1.07343318e-02
 -3.93742695e-02  3.73597909e-03  4.73298915e-02 -1.76839717e-02
 -2.68159099e-02 -1.65633745e-02 -1.05114821e-02 -4.44261916e-03
  7.52777793e-03  2.48219706e-02 -1.70351996e-06  6.64019883e-02
  4.38578352e-02  5.92747144e-03 -2.57223677e-02  5.67334443e-02
 -5.89019945e-03  3.32700424e-02 -1.34444563e-02 -3.27598080e-02
  4.92559047e-04 -2.45002098e-02 -5.10914922e-02 -2.17412561e-02
 -4.47726808e-02 -4.15254198e-02 -1.36664659e-02 -1.11748558e-02
 -1.48477191e-02 -1.26751345e-02  9.60283354e-03  4.64103967e-02
  4.46724147e-02 -1.49320383e-02  2.44499464e-02 -2.84144878e-02
  1.59646384e-02 -2.30964506e-03 -5.21328114e-03 -8.70303158e-03
 -4.64807786e-02  4.79756221e-02  3.44808307e-03  1.94174461e-02
 -1.65753122e-02 -3.23906876e-02  2.23084469e-03  5.54040400e-03
  4.13539557e-04  3.66754904e-02  2.07829215e-02 -1.24756331e-02
  8.42871070e-02 -1.32153798e-02  4.50549833e-02 -5.96389733e-02
 -1.56985819e-02  2.25921161e-02  3.73409726e-02  4.82976250e-02
 -1.44730303e-02  1.59626380e-02 -2.15012990e-02 -5.13347909e-02
  5.03572635e-02  9.85552296e-02 -1.59215946e-02 -3.27368975e-02
  4.95262668e-02 -2.60011666e-02 -4.38874820e-03 -1.49437308e-03
 -1.15243634e-02  7.47130960e-02  3.61003466e-02 -4.34216969e-02
  7.25011760e-03  4.36657444e-02 -4.59469147e-02  3.40728872e-02
 -5.45097888e-02 -8.21341760e-03 -4.55249548e-02  2.89204400e-02
  1.92990638e-02 -6.30851686e-02  3.18528339e-02  4.03286964e-02
  2.41107047e-02  2.97194999e-02 -3.83227691e-02  1.15335733e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_4/gamma
[0.9495261  0.9245579  0.9960161  0.9949478  0.97230923 0.91263056
 0.9628698  0.98417133 0.98096865 0.9547828  0.9975717  1.005361
 0.99286634 0.95050323 0.9704672  0.9586266  1.0839498  0.94815266
 0.9713719  0.97283643 0.98525375 0.9381272  0.9418417  0.9006827
 0.9922004  1.0959358  1.0182341  1.0106871  1.0017458  0.97609484
 0.9946322  0.9912266  0.9695806  1.0040007  1.0012876  0.98423475
 0.9750098  0.94250035 0.99461097 1.0113527  0.96052366 0.9635069
 0.9856047  0.9435984  1.017587   1.0039796  0.9201721  0.98947436
 0.9961532  0.9898185  0.9209743  0.9962394  1.0125831  0.9932752
 0.9352577  0.98640615 0.91012883 0.9624914  1.0222032  0.9580779
 1.0452611  0.9441852  0.99989825 0.99406207 0.9810339  0.9773512
 1.0072324  0.987055   1.0053937  0.9322019  1.0083537  0.9658367
 0.9760041  1.0059056  0.926986   0.96774316 0.9362854  1.0011337
 0.9580937  1.0622332  0.9944099  0.9654206  0.9804389  1.0212264
 0.96495503 0.9989796  0.961454   1.0094538  0.9007242  0.9483284
 0.9871338  0.9690482  0.9879454  1.0164165  1.0064204  0.98218304
 0.97386473 0.9943569  0.9746819  0.9574595  0.94490427 0.9795989
 1.0011207  0.9527492  0.99386346 0.971236   0.9040109  0.99209124
 1.0047512  1.039284   0.9994995  0.9709738  0.89361036 1.0156467
 0.9846095  0.8982833  0.98308885 0.9870335  0.9861691  0.9196543
 1.0289024  0.99039465 0.9808012  0.96674484 0.91546464 0.98638475
 0.9920952  1.025822   0.9939324  0.9865992  1.002492   1.0274525
 1.011669   1.1054394  0.9553033  0.9897339  0.99995637 0.9827644
 0.9804065  0.89404106 0.97169894 0.9559758  0.99547106 0.98270136
 0.96371067 1.0050782  1.0111235  0.98607886 1.0470496  0.9170884
 0.98220474 1.0133631  0.90751815 0.9906028  0.96267045 0.97682273
 0.9906895  1.0130986  0.9763389  0.9841525 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_5/beta
[ 9.3049100e-03  4.8935334e-03 -1.5680460e-02 -6.7701172e-03
 -3.3091292e-02 -4.4987939e-02  1.3641887e-03  9.6292511e-05
 -6.6725989e-03  3.7104081e-02  1.1711927e-02 -4.1153323e-02
  8.1726126e-02 -5.1296223e-02 -7.1656771e-02  4.7350734e-02
  1.2334824e-02 -8.5799679e-02  3.6552134e-03 -8.8007646e-03
  1.1477507e-04  2.1367155e-02 -1.4120942e-03  9.9933082e-03
  1.5996398e-02  1.1162044e-01 -2.8661575e-02 -6.3980162e-02
  7.8510121e-02  1.5108114e-02  3.4024008e-02 -1.2667551e-02
  5.5687232e-03  1.2566194e-01 -2.0815564e-02 -5.5429347e-02
 -9.9134892e-03 -1.5624112e-02 -5.0227728e-02  5.5417508e-02
 -1.8373413e-02  1.7831314e-02 -3.6572155e-02 -8.4755860e-02
  2.1585120e-02 -1.6501345e-02  8.1490474e-03 -2.4223065e-02
 -5.2997470e-02  1.4938132e-02  2.9964257e-02  7.0201084e-02
 -3.2458275e-03  2.8169552e-02  1.8659282e-02 -1.3918060e-02
 -4.5580953e-02 -1.1837700e-02 -3.6315400e-02  4.6815481e-02
  3.8837589e-02  7.6343864e-02 -5.2215040e-02  2.1248739e-02
  2.7726075e-02 -7.2360658e-03 -3.7692323e-02 -2.0767368e-02
 -6.9585694e-03  2.4012750e-02  6.1377138e-02  5.0681299e-03
 -8.8338070e-03 -3.7946664e-02 -6.6773696e-03  2.9189300e-02
  8.2344234e-02  1.0426249e-02 -2.6681712e-02 -8.2985340e-03
  4.8485156e-03 -3.5654332e-02  2.3368055e-02 -1.7372474e-02
  6.1144471e-02 -4.8909453e-03  5.9392668e-02 -1.1292247e-02
  5.3188000e-03 -1.1220233e-02  4.3180998e-02  2.5131816e-02
  5.3268835e-02 -3.7687968e-03 -2.6957225e-02  2.7331352e-02
  4.2766292e-02 -2.2222498e-02  2.1720566e-02 -1.8998370e-02
 -2.0407762e-02  9.7064525e-03 -2.0332284e-02 -3.4751005e-02
  6.9387336e-03  4.1367039e-03 -5.9233462e-03 -2.1529935e-02
  3.7830599e-02 -4.5145182e-03  5.2962997e-03 -4.6669062e-02
  2.4500009e-02  2.7343683e-02  1.5327796e-02  3.8451806e-03
  9.5508114e-02 -4.6868883e-03 -1.9542100e-02 -1.5804334e-02
 -1.7986089e-02  5.8225598e-02 -2.3631733e-02 -8.0121130e-02
 -1.6381707e-02  2.5162252e-02  1.8608449e-02  8.7674350e-02
 -2.5255125e-02  1.4265929e-02 -1.7008370e-02  3.5096377e-02
  2.6110861e-02 -1.1613165e-02  1.2522833e-02 -2.1086492e-02
  5.8937453e-02 -5.5495281e-02 -3.0202908e-02  5.8278836e-02
  3.5368642e-03  2.8921820e-02  6.0578436e-02  7.9684369e-03
  1.8142750e-02  8.6790927e-02 -5.9876102e-03 -1.9968783e-02
 -7.8884818e-02  1.8039944e-02 -8.1238961e-03 -1.5899175e-04
  4.9956705e-02 -6.9502056e-02  2.3181294e-03 -1.7354555e-02
  1.5537536e-02  5.4617442e-02 -5.8507234e-02  3.5535760e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_5/gamma
[0.97759724 0.93405306 0.9573213  0.9902429  1.0351971  1.051379
 0.9931097  0.9959917  0.96897453 0.9638319  0.97252834 0.9923599
 1.1523377  0.97476393 1.0399536  1.0177625  0.9873155  1.0567918
 0.968707   0.990142   0.9892016  0.9626762  0.9831057  0.9417076
 0.96841556 1.133411   1.0221251  1.0451555  1.017082   0.9679065
 0.9795423  1.006892   0.9608967  1.1583788  1.0158819  1.0562999
 0.99382746 1.0178081  1.0235182  1.0485939  0.9946343  0.93646234
 0.99189657 0.98593956 0.9785907  0.90552545 0.9487206  0.97842133
 0.9867559  0.9681057  1.0062877  1.0036001  0.9144837  0.99307954
 0.98898894 0.9839789  1.0099115  0.99377483 0.966663   1.0430778
 1.0200458  1.0010034  1.0595964  0.93078244 0.86347353 0.93233126
 1.0191404  0.9871891  0.9623815  0.9761627  0.9709087  0.9530377
 0.9705822  1.0218796  0.9531539  0.99117136 0.91905665 0.90064806
 0.98649883 0.96745133 0.9785326  1.0122176  0.8525206  0.99581957
 1.0754528  0.9946243  0.98981404 1.0055456  0.980176   0.995351
 0.95487535 0.9299968  0.9500588  0.9260949  0.9902809  0.98441285
 1.0076532  1.0099509  0.9786044  0.9995937  0.99019796 0.9727337
 0.9707625  0.98554844 0.97982556 0.96253794 0.99258786 0.97636056
 0.96484965 0.967      0.90430474 1.0104579  0.98201716 0.98007464
 0.9491179  0.97585005 1.0576413  0.99017644 0.9744966  0.97410125
 0.97865033 1.0702668  0.97626686 1.0537926  0.9577395  0.9736175
 0.97138786 1.0826112  1.0168451  0.97075677 1.0007408  0.96591157
 0.99149257 1.0064819  0.9481526  0.997304   1.0209986  1.0180948
 0.9843243  0.99554116 0.9692171  0.98420733 0.99981564 0.9924055
 0.9537065  0.95485425 0.99951434 1.0042496  1.0419316  0.98722076
 0.98801935 0.96379983 1.0781492  1.0405416  0.9259021  0.9861424
 0.95050436 1.0059569  1.0538195  0.9545332 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_6/beta
[-0.07551267  0.00466933  0.01978751  0.01721929 -0.02573395  0.00874215
  0.02944682  0.03152801]
tensor_name:  TemporalFusionTransformer/layer_normalization_6/gamma
[1.0578684  0.9667333  0.88367885 0.9897178  1.0261034  0.9031681
 1.0265534  0.9700363 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_7/beta
[-5.82130393e-03  2.27946620e-02  8.27334542e-03 -1.17850979e-03
  8.29468016e-03 -1.38970362e-02 -1.74322780e-02 -1.56723820e-02
  2.13431660e-03  2.59388937e-03  2.02323887e-02  5.56960795e-03
 -1.62263575e-03  1.78073309e-02  8.10952857e-03 -5.39092394e-03
 -6.90718275e-03  4.50860010e-03  1.90296415e-02 -3.36108101e-03
 -7.21265329e-03 -1.40342023e-03 -8.26990977e-03  9.56394826e-04
 -4.89234924e-03  1.38516547e-02 -4.00107820e-03  3.20668938e-03
  1.04581797e-02 -1.02279307e-02 -4.45502764e-03  2.24004150e-03
  8.21964629e-03  7.15918234e-03  2.89973617e-03 -7.13011669e-03
  2.58352561e-03 -5.65923750e-04  7.36431684e-03  8.83978233e-03
 -9.75835661e-04  5.22817764e-03 -5.04582748e-03  1.95390731e-03
 -2.60431436e-03 -1.53101562e-03 -5.10508008e-03  1.32501293e-02
  9.43345251e-04  6.03915751e-03  1.12420588e-03  1.89871304e-02
  6.83654274e-04  4.17075213e-03  1.32834828e-02  4.03946918e-03
  1.48669602e-02 -4.91191447e-03 -3.05437972e-03  4.69303178e-03
  3.61974817e-03 -5.22441929e-03  6.77395007e-03 -5.48161188e-05
 -4.48370725e-03 -8.76795268e-04  8.74318357e-04 -1.63861155e-03
  8.02670047e-03 -1.60707142e-02  1.20807821e-02 -3.48950294e-03
  5.92859089e-03 -7.77575513e-03 -8.72355234e-03  1.02841910e-02
  5.33929514e-03  1.17776524e-02 -1.45247020e-03 -1.81819720e-03
 -1.37519110e-02  3.71136772e-03  4.28332668e-03  7.24012870e-03
 -8.51456728e-03  4.39776108e-03 -3.76023585e-03 -1.86130758e-02
 -3.59265273e-03 -2.14535240e-02 -1.61172152e-02 -2.21411069e-03
  2.95378780e-03  4.00364306e-03  1.77973986e-03  2.86154472e-03
  3.79623566e-03  2.09733434e-02  8.94936360e-03  3.76006844e-03
 -1.25062978e-02 -7.40386173e-03  4.50348575e-03  1.64977591e-02
 -1.19692488e-02 -8.89070239e-03  1.05612248e-03 -1.21538872e-02
  1.17119420e-02  1.08725196e-02 -1.33827887e-03 -5.66787319e-03
 -1.28417509e-02  5.35869505e-03 -1.28779178e-02 -2.58410582e-03
  6.10130513e-03 -6.15585828e-03 -1.22769754e-02 -5.34600997e-03
  1.94875826e-03  1.03280935e-02 -7.08421040e-03 -3.62207554e-03
  6.30471669e-03  6.51734276e-03  6.55160239e-03  1.03188455e-02
  1.09663540e-02  2.22560354e-02 -8.18977971e-03  5.57246432e-03
 -9.34935734e-03 -1.69731758e-03 -1.54342409e-02  2.52532330e-03
 -5.83386840e-03 -1.40258775e-03  9.44235362e-03 -5.25250239e-03
 -3.32116894e-03 -1.99922547e-03  1.21540565e-03  1.05874687e-02
 -4.21498576e-03  3.86109296e-03 -1.85913797e-02 -1.08628506e-02
 -6.79214019e-04 -1.00768674e-02  5.95093370e-05  3.69852642e-03
  1.04941223e-02 -1.11085968e-02  1.33709414e-02 -1.50151961e-02
  8.84000398e-03 -1.47236744e-03 -1.72200220e-04  1.31494431e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_7/gamma
[0.98411137 1.0239538  0.98069996 0.98734343 0.9964688  0.9845601
 1.0004278  1.0081136  0.9785141  0.97045004 1.0081449  0.9908848
 0.977704   1.0058448  0.9908752  0.9855039  0.9463343  0.9968741
 1.0054244  0.951245   0.997374   0.9732694  0.97640103 0.9735346
 0.96164745 0.99248636 0.9743309  0.9828399  0.9943085  0.972641
 0.97508734 0.9861619  0.98390037 0.9899505  0.99218285 0.96743226
 0.98151153 0.97124046 0.9960804  0.9923527  0.97860557 0.9794022
 0.9565204  0.9939605  0.96111923 0.9610522  0.9877279  1.001125
 0.9791001  1.0037756  0.9821205  1.0127821  0.98254514 0.97644407
 1.0057772  0.9764599  1.0013736  0.98489684 0.97716135 0.98518
 0.9829067  0.9804171  0.9801404  0.94832754 0.97797513 0.979383
 0.955941   0.9680969  0.98474616 1.0199316  0.99567264 0.9853941
 0.9412082  0.96270025 1.0119781  0.9750642  0.97000384 0.99346375
 0.9922391  0.9506871  1.0056435  0.9444193  0.97442067 0.9797087
 0.9693907  0.9828428  0.99316365 1.01237    0.9703203  1.0152102
 0.99241614 0.986892   0.96931744 0.977814   0.98695606 0.9625542
 0.9649053  0.9815357  0.9970494  0.9716459  0.9798892  0.9785722
 0.9889039  1.0004613  0.9996661  1.0116316  0.9967338  0.9962589
 0.9743668  0.99733967 0.98412323 0.9823719  0.9771347  0.98413587
 1.0051007  0.9751997  0.97558707 0.962368   0.9954985  0.9755425
 0.9800276  0.9706658  1.0085162  0.96884096 0.97320014 0.98451847
 0.9584954  0.9808195  0.9580918  1.0087266  0.9645587  0.9072895
 0.9910409  0.9646097  1.0048242  0.9864563  0.98820597 0.98457617
 0.9773129  0.99280393 0.9797463  0.9838177  0.97944564 0.9619856
 0.98940104 0.96197087 0.9307241  1.0063437  0.97717196 0.9996285
 0.9741226  0.9820146  0.9616109  0.97586346 0.99806666 1.0074669
 0.9793377  0.9834568  0.9694345  0.98049515]
tensor_name:  TemporalFusionTransformer/layer_normalization_8/beta
[ 9.13947728e-03  1.51565243e-02  2.04946641e-02  2.97706909e-02
  4.87261685e-03 -1.37442341e-02 -1.08332857e-02 -3.05953268e-02
  2.66935444e-03 -8.50117486e-03  1.57716218e-02  1.91597696e-02
  8.51521082e-03  6.78637531e-03 -9.95104783e-04 -4.44626249e-03
  2.50364235e-03 -2.46703788e-03  2.15054378e-02 -2.39112717e-03
 -1.64133199e-02 -2.84945313e-03 -5.43324742e-03  3.95031972e-03
  7.61041371e-03  3.41037614e-03  4.91180131e-03 -1.65652088e-03
  1.69061851e-02 -3.09560006e-03 -8.06219038e-03  1.20372484e-02
 -2.60472787e-03  1.73489638e-02  5.01528382e-03  2.26482414e-02
  6.85532345e-03 -1.88130531e-02 -4.14741924e-04  2.28142329e-02
  5.44013781e-03 -3.10443644e-03  2.82503897e-03  1.53469481e-02
 -4.28830739e-03 -2.31045589e-04  1.00822814e-04  1.37049453e-02
  1.90119073e-02 -6.04712870e-03 -1.56281306e-03  3.19324397e-02
  1.63052864e-02 -4.64124372e-03  1.70740969e-02  1.82103757e-02
  2.68452964e-03 -6.56288723e-03  2.61732307e-03  1.60227064e-02
 -1.09057513e-03  4.65915259e-03  4.59914282e-03 -1.18647497e-02
 -2.42527742e-02  1.55006554e-02 -4.11071163e-03  1.24934884e-02
 -7.91189168e-03 -1.08659500e-02  1.08806984e-02  1.21127404e-02
  2.96583660e-02  5.89181390e-03 -2.50381902e-02 -7.62691896e-04
 -2.25773710e-03  8.93983431e-03 -3.08976229e-03 -1.40252942e-02
 -5.26470598e-03  1.36135304e-02 -2.03304715e-03  2.93424958e-03
  5.47792297e-03 -8.97006132e-03  4.15834412e-03 -1.89448503e-04
 -1.84221473e-02 -1.62966847e-02 -1.98125765e-02  1.43000670e-02
  3.66611127e-03  1.33498237e-02  5.33234887e-03 -5.81959216e-03
 -6.52672679e-05  1.42161269e-02  1.82051323e-02 -1.35598825e-02
 -7.78866746e-03  1.35422731e-02  2.58866996e-02  7.84416869e-03
 -3.93145019e-05 -1.97673738e-02  1.74699612e-02 -1.30637446e-02
  2.39646714e-02  7.55830528e-03  4.75783180e-03  2.57477490e-03
 -1.88408885e-02  1.33868083e-02 -2.12917365e-02 -3.25491615e-02
  8.33992567e-03 -1.76361259e-02 -2.90396269e-02 -5.93993114e-03
  9.26152989e-03 -5.72035275e-03 -1.12178838e-02  3.83900176e-03
 -1.02539835e-02  1.61528494e-02 -1.80215072e-02  3.68804648e-03
  2.02610679e-02  1.33223264e-02  8.66577774e-03 -1.58770271e-02
 -1.34980837e-02  3.32678622e-03 -8.15926772e-03  7.69033842e-03
  5.87585988e-03 -1.89012121e-02 -2.16329689e-04 -2.50499900e-02
 -2.40451004e-03 -1.42922183e-03 -2.90118041e-03  1.65723562e-02
  1.43665436e-03  6.06654771e-03 -1.56250708e-02 -7.20952637e-03
  3.62052023e-03 -1.66218039e-02  1.34289647e-02 -5.43592684e-03
 -7.34409411e-03 -1.55242970e-02  1.37490118e-02 -1.25710787e-02
  1.82113294e-02  1.20525667e-02  6.62390655e-03  4.18220693e-03]
tensor_name:  TemporalFusionTransformer/layer_normalization_8/gamma
[0.93486625 0.9442285  0.8894813  0.97631085 1.0756135  1.0097123
 0.949444   1.0095515  1.035794   0.9614676  0.9147389  0.91908413
 1.0897701  1.0357374  1.0010086  1.0155787  0.9978747  1.0277523
 1.0492067  0.96256125 1.0522083  1.058058   0.9797663  0.97169584
 1.0000474  0.96618146 1.0439044  1.0060663  0.9607733  1.1054511
 1.036645   1.0593152  1.008526   1.0222797  0.96618503 1.0309943
 0.9280783  1.0665733  0.933223   0.9521939  0.98855036 1.0165293
 0.96156    1.0577803  1.0110091  0.9791227  1.0254978  0.9831025
 1.0287837  0.9361382  1.0383232  1.002779   0.99741554 1.0783727
 1.0369112  0.8968213  0.95581543 0.99350226 0.8960283  0.9156062
 1.0672234  1.0437527  1.0401361  1.0088661  1.0432909  1.0196446
 0.8785809  0.9216505  0.87875634 1.0365207  0.9819698  1.0762496
 0.9970874  1.024198   0.97444296 1.0736631  1.01154    1.0350114
 1.0240921  0.9446729  1.0400437  1.0070021  1.0292454  1.0034745
 1.0106506  1.0005901  1.0234956  0.89885616 0.8388872  1.0389333
 0.96372527 1.0085168  1.0430735  0.9817965  0.92777425 0.9427955
 1.067483   0.9187505  0.9794138  0.962826   1.0242462  1.0036466
 1.0496495  0.9353065  0.92349714 1.0206006  1.02409    1.0341184
 0.9585756  0.9952199  1.0595284  1.088775   0.91899246 0.8979335
 0.8686804  0.95543945 1.0221888  1.0346236  0.9883865  1.1224246
 0.99082726 0.99817973 1.0280113  0.98593134 1.0139672  0.8924273
 0.9380644  0.9808019  0.8554393  0.9647333  0.9994253  0.8611804
 1.0006744  0.9990725  0.9776579  1.0380017  1.0275933  0.9176288
 1.0262357  1.0270079  0.9485963  1.0306094  1.0073487  0.95056176
 1.0017715  0.9637469  1.0102165  0.96843785 0.99191344 0.9763076
 0.9600212  1.0671351  0.9895592  0.9022602  0.9900746  0.9164687
 0.9614066  1.0622338  1.0550202  1.0403866 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_9/beta
[-0.00519363  0.03591245  0.00995243  0.02465997  0.00744018 -0.03725822
 -0.02176268 -0.02018972 -0.00773525  0.00176062  0.02751697  0.01205782
  0.00045619  0.0225259  -0.00157671 -0.00312656  0.00314146  0.0022859
  0.0378195  -0.00696066 -0.00587672 -0.00995268 -0.00468562  0.00288136
  0.00320723  0.01794942  0.00168951  0.00597965  0.01581177 -0.00841476
 -0.01669587  0.00321274  0.00663491  0.01062202 -0.00572655  0.01552931
 -0.00519475 -0.01462634  0.00025886  0.02781988  0.02379045  0.01416304
 -0.000803    0.00882532 -0.00882776 -0.01772327 -0.00125114  0.01777364
  0.00218919 -0.00874555  0.01120444  0.03292371  0.00248504  0.00200943
  0.01513718 -0.00592059  0.02659008  0.00252636 -0.02848428  0.01606379
 -0.00532091  0.00084094  0.01334665  0.00409166 -0.02218637  0.00502323
 -0.02695174  0.01589696  0.01148715 -0.02324067  0.02498863  0.01162414
  0.00826304 -0.00759075 -0.01736455  0.01043939  0.00965321  0.01187693
 -0.00306629 -0.0103115  -0.01256165  0.00862427  0.00871082  0.00401855
 -0.00559433  0.01129865 -0.00521112 -0.00244982 -0.00392042 -0.02037061
 -0.02956996 -0.01733814 -0.01162771 -0.00763209  0.02592529  0.00742959
  0.01270463  0.01146099  0.01455902 -0.00526978 -0.0213778   0.01559335
  0.022619    0.02322058 -0.01200398 -0.01468352  0.01588875 -0.00825531
  0.04246284  0.00406112  0.00974731 -0.00754301 -0.03559824  0.01574809
 -0.00389787 -0.02353405  0.01432315 -0.01498474 -0.02509896 -0.01106628
  0.01534151 -0.01544658 -0.01384406  0.00089918  0.00515095  0.01120638
 -0.00916804  0.01858103 -0.01235037  0.03558978 -0.00239312 -0.03960204
 -0.01950709  0.00520002 -0.02049666  0.00794898 -0.01024945 -0.00463832
  0.00679353 -0.01621475  0.01206665 -0.00387293 -0.00889437  0.0188011
 -0.00705586  0.02314357 -0.01854206 -0.01746103  0.00402333 -0.02218269
  0.01594301 -0.01799568 -0.02543805 -0.00138773  0.03414625 -0.00963858
  0.0229181   0.00828947  0.00058494  0.00957844]
tensor_name:  TemporalFusionTransformer/layer_normalization_9/gamma
[0.9535019  1.0835446  1.0388062  1.0266181  0.9429133  1.1270117
 1.0971715  0.9526265  1.0484784  1.2649965  0.9224615  0.99192923
 1.0745146  1.0411792  0.9927155  0.9727606  1.0468028  1.1665256
 1.0715321  0.9638956  0.95592594 0.9729153  0.9710718  1.0633717
 1.1244228  0.9551158  1.0255108  0.9752244  0.95241773 1.0419339
 1.0373431  0.98630524 1.0067258  0.94947445 1.0297463  0.95268226
 1.0591474  1.0809275  0.9670897  1.0694413  0.89206874 1.0769966
 1.0006015  0.9896098  0.9560692  0.9191361  1.0181538  0.95850646
 0.9947234  1.0119466  1.0297984  0.9547491  0.9638328  0.9219408
 0.9633072  0.88027555 1.0439848  0.9436891  0.9701164  1.04091
 0.94833916 1.0301845  1.1167629  0.9926126  1.0669369  1.1561093
 1.0495329  1.0041684  1.0015125  0.98393464 0.9985929  1.0430079
 1.0526263  1.0159222  1.1333195  1.0082419  0.91994643 1.0149889
 1.0606307  0.9197502  0.9639251  0.97875404 1.0644703  1.0318533
 1.1140056  0.94361234 0.9463655  0.9809154  0.91464996 0.98583126
 0.9521219  0.9395779  1.023038   0.9667144  1.0499372  0.9413562
 1.0374622  1.0043614  1.1079348  1.0601909  0.9824544  1.0711741
 0.93874997 1.0227559  1.1333462  1.1563747  0.99872875 1.0620549
 1.0099599  0.9717777  0.94585806 0.93782467 0.98222274 1.0507432
 0.9204055  0.9538991  1.1441953  0.9287404  0.9592721  0.9620748
 1.2262247  0.97629607 1.0345767  0.95595855 1.031855   1.0105329
 0.9439588  0.91922766 1.0083247  1.0186113  0.9677914  0.89812577
 1.0799774  1.1246315  1.1171504  1.0202247  0.96275884 0.9527721
 0.941046   1.0021744  0.9036721  0.97662216 0.94077945 1.0058277
 1.0329949  0.91127217 1.0163293  0.9940594  1.1644161  1.0529473
 0.98448676 0.95399195 1.0558003  0.9755256  1.0263789  1.0991771
 0.9688876  0.9677844  1.0877687  1.019753  ]
tensor_name:  TemporalFusionTransformer/time_distributed/bias
[ 0.05172906 -0.07072026 -0.01486049  0.02345293 -0.01532155  0.00081422
  0.01787089 -0.04036764 -0.00424919  0.00256031 -0.02738022  0.01767973
 -0.01555551 -0.00909853 -0.00033494 -0.04155089  0.00767555  0.03389239
 -0.02825085 -0.05109479 -0.02453918 -0.02056346  0.03441648 -0.0089856
  0.00046093 -0.02737155 -0.0052559  -0.01586512 -0.01215737 -0.01061571
 -0.00411168  0.0221105  -0.02726011 -0.0063847   0.00471783  0.04573749
  0.0193896  -0.00253264  0.03856651  0.01701929  0.04633978 -0.01837502
  0.03617075  0.01364387 -0.03637142 -0.00310578  0.01088057 -0.03219159
  0.02195496 -0.04351944  0.02359802 -0.02316209 -0.04336183  0.00070476
 -0.00547387  0.03991455  0.00506919 -0.01234028  0.00839739  0.00868235
  0.03276463 -0.02574261 -0.01263574 -0.03901354  0.03163878  0.0122221
  0.04379246 -0.03992356 -0.04718648  0.02063985  0.02527451 -0.02189326
 -0.01208857  0.02112957  0.02531935 -0.00654906 -0.00986032 -0.00144544
  0.01042559 -0.02519077 -0.01641525 -0.03026143  0.04690642 -0.00457972
  0.03763593 -0.01111148  0.03979595  0.04566137  0.01525565 -0.00759624
  0.04666834  0.00988783 -0.0115198   0.0495493  -0.01302836 -0.01583084
  0.01968852 -0.00758588  0.04064543 -0.02509607  0.02415885  0.02693152
  0.00836484 -0.00299144 -0.02558933  0.01202476  0.00436797  0.01552493
  0.02950994  0.01239141  0.03036799 -0.0066932  -0.03320374 -0.00628563
  0.0284457   0.00361832 -0.02193464  0.01197104 -0.00661054 -0.04728517
 -0.02366651 -0.03261064  0.02398554  0.03035808  0.00119407 -0.02578967
 -0.01529341 -0.01480133 -0.01460897 -0.01580971  0.05425246 -0.03198227
 -0.00425867 -0.0192723  -0.00076079 -0.00244441 -0.00138581 -0.0434963
 -0.00442871 -0.0106663  -0.03381002  0.0284664   0.01422041 -0.02207183
  0.0208576   0.00061643  0.0113863   0.01235028 -0.0111349   0.00645984
 -0.00880769  0.02300094  0.03273857  0.0370899  -0.00510318 -0.02851219
 -0.03096391  0.01801606  0.02903823 -0.01615725]
tensor_name:  TemporalFusionTransformer/time_distributed/kernel
[[-0.01647696  0.17162116 -0.14264558  0.02343817  0.03942281 -0.01045948
   0.0410211   0.07056116 -0.14810452  0.02273321  0.0630115  -0.01454699
  -0.06676108  0.02780376 -0.153938    0.11719785 -0.11644351 -0.10538205
   0.00820835  0.1454718   0.14308225  0.00404032  0.07204917  0.01372324
   0.00717275 -0.12483481  0.05595019  0.07279094  0.01612327 -0.178201
  -0.06146481 -0.06998058 -0.166432   -0.12918988  0.11411468 -0.14858294
   0.07814533  0.10361189 -0.06828146  0.13266958 -0.11701911  0.00578843
  -0.17211215 -0.08291274  0.05622442  0.01845074  0.11191434  0.08198626
  -0.01096512  0.1260122  -0.15425272 -0.02285133  0.06498041 -0.02311527
  -0.02627651 -0.03588631  0.17194782  0.0402048  -0.10299499 -0.13515607
  -0.15041202 -0.03217313  0.13454369 -0.13794346 -0.14899626 -0.17694053
  -0.07846382 -0.14977705  0.0105994  -0.17269768 -0.04710919  0.03719657
  -0.05812405 -0.03912802 -0.10998952  0.18675138  0.05125247 -0.01449851
  -0.15940571 -0.05673182  0.18806599 -0.02985577 -0.11913053  0.05870145
  -0.11632783  0.16946214 -0.04073298  0.1501896   0.10264776  0.07414751
  -0.00354924 -0.10634816 -0.13463649 -0.13871826  0.19717544  0.14177683
   0.07693204  0.08365387 -0.08071526  0.04251207  0.05908812 -0.01561577
  -0.09797534 -0.01250856  0.14600052 -0.16045538 -0.16903755  0.06418114
   0.01514621 -0.02913301 -0.07828547 -0.139894   -0.05381452  0.15106408
   0.17693564  0.1123606  -0.05765817 -0.08979698 -0.00169146  0.13530497
   0.0333498   0.19573753 -0.03349347  0.09754161  0.14706348 -0.18432796
   0.03237655 -0.02171476 -0.06554712  0.17720596 -0.00716687 -0.04487305
   0.00167748 -0.0248363  -0.06060882  0.02360434  0.00334439  0.03695772
   0.01901378  0.01222723  0.08991456  0.08814114 -0.0205887  -0.13890593
  -0.04953251  0.18949766 -0.0258429  -0.10222349 -0.10113828 -0.15172024
   0.04903111 -0.1331397  -0.09176376 -0.03273836  0.17340396  0.10216802
   0.03299218  0.04851088  0.01699231  0.02714268]]
tensor_name:  TemporalFusionTransformer/time_distributed_1/bias
[-2.0117124e-03  3.6671773e-02  4.1892946e-02 -3.2881264e-02
  1.4933991e-02 -3.2102082e-02 -1.6014905e-03 -5.6237038e-02
 -7.1544476e-02  7.8632236e-02  6.5662704e-02  1.6434373e-02
 -2.9153233e-02  3.9190281e-02  3.2723580e-02  1.6717901e-03
  3.4563515e-02  6.0385104e-02  1.7200250e-02 -1.6358612e-02
 -2.9553264e-02  1.8637747e-02 -3.2828315e-03 -3.0531878e-02
  4.7277134e-02 -3.9918467e-02  4.2356387e-02 -4.4784404e-02
 -3.4376055e-02  6.4062268e-02 -3.0562263e-02 -2.4922928e-02
 -2.1051399e-02  3.2819789e-02 -2.2974763e-02  4.7995681e-03
 -2.6844516e-02 -5.9956627e-04  2.5394741e-02  2.0306287e-02
  4.3024424e-02  2.2675183e-03 -1.2516741e-02  2.5017781e-02
  7.4776742e-03  3.4103973e-03 -2.3913369e-02  7.4674703e-02
  1.7460941e-03  6.4804003e-02 -3.8537111e-02  8.5752390e-02
 -4.9301684e-02  5.4225302e-03  1.5332841e-03  6.9314845e-02
  6.1348397e-02 -2.9847702e-02 -4.0381093e-02  5.2072141e-02
 -4.6761911e-02 -4.3428957e-02  4.3895792e-02  3.3497240e-02
 -4.2350575e-02  3.6182098e-02 -2.7186612e-02  5.3435534e-02
  5.4506250e-02 -6.6329725e-02 -2.1930350e-02 -2.2592249e-03
  7.4041992e-02  5.8634866e-02 -2.3518974e-02  3.1048587e-02
 -4.1101366e-02  1.0940997e-02 -1.9864568e-02  3.0707734e-02
 -1.8230539e-02  5.9333574e-03 -5.6468684e-02 -7.5315736e-02
  6.5985791e-02  4.3820363e-02 -6.2816672e-02 -6.0463756e-02
 -1.1821013e-02 -4.3811131e-02 -3.6894817e-02  3.9095540e-02
 -2.8364711e-02 -1.7513234e-02 -1.8137418e-02  4.3638330e-04
 -2.7854931e-02  5.4014508e-02  1.8519736e-03 -4.2904913e-02
 -2.0082533e-02 -3.2036915e-02  2.8873298e-02  5.5449314e-02
 -8.6369058e-03 -6.6502646e-02  3.4656074e-02  1.6485419e-02
  2.0330239e-02 -8.3405469e-03  6.0763273e-02 -1.2797218e-02
 -7.4305915e-04  2.0655908e-02 -6.2973075e-02  1.2998934e-02
 -2.8988325e-06  3.8773540e-02  3.1381655e-02 -3.3448411e-03
 -3.3492491e-02 -5.9095118e-02 -5.9835505e-02 -4.1932091e-02
  2.9635539e-02  5.9976451e-02 -6.2992140e-03  3.4175154e-02
  1.2295592e-03  5.7691175e-02  2.1761197e-03 -5.6518028e-03
 -4.5616034e-02  3.0837376e-02 -5.9075624e-02 -1.2752116e-02
  4.8634657e-03  3.7168756e-02  3.4417845e-02 -7.9267889e-02
 -2.9053694e-02  1.3180331e-02 -5.3980570e-02  4.3557081e-02
 -2.0540943e-02  2.2643315e-02  4.4979863e-02 -4.0220302e-02
 -2.1029016e-02 -1.8272415e-02  1.4895339e-03 -4.6969403e-02
 -1.9526437e-02 -2.3708697e-02  3.2395683e-02  4.7819722e-02
 -1.8271811e-02  1.6724896e-02 -6.6060677e-02 -2.5992092e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_1/kernel
[[-1.92547187e-01 -1.79788053e-01  5.05689979e-02  1.65934056e-01
  -6.49338216e-02  6.02246821e-02 -8.95619392e-03  6.08880520e-02
   1.26663685e-01 -1.19531192e-01 -1.68192133e-01  5.39320111e-02
  -1.67817801e-01  2.33317912e-02  2.89448947e-02  1.56682700e-01
   1.54082179e-01 -1.03649296e-01 -1.89717233e-01 -1.23584978e-01
  -1.42468184e-01 -1.74410701e-01 -1.55522987e-01  1.87576324e-01
   1.05893850e-01  1.73413008e-01 -8.43398422e-02 -6.41454756e-03
  -5.37172109e-02 -9.24023464e-02 -9.20037627e-02  7.26963878e-02
   1.91349536e-01 -1.90407038e-04 -6.78820610e-02 -5.19203097e-02
   8.73809159e-02 -6.64064735e-02 -1.63307533e-01  1.68567330e-01
  -1.18215404e-01 -1.17973357e-01 -1.61583036e-01 -2.41435617e-02
  -1.62078321e-01  3.16289365e-02  1.55697554e-01 -1.88165784e-01
   1.08484596e-01 -1.55274540e-01 -1.31906509e-01  1.28933966e-01
   1.02877498e-01 -3.35516781e-02 -9.10858661e-02 -8.23442489e-02
  -3.45386118e-02 -1.31259024e-01  4.34707701e-02 -3.21726054e-02
  -1.72530770e-01 -5.94637841e-02 -1.22201666e-01  7.27696121e-02
   1.15525335e-01 -2.80418694e-02 -7.91755021e-02 -1.90572396e-01
   1.20940953e-02  7.92983770e-02  1.87838733e-01 -1.01340078e-01
  -4.51250821e-02  5.28344810e-02  1.58901006e-01  9.71913934e-02
   1.85793489e-02  5.26933223e-02  1.42189324e-01  1.36103213e-01
   1.38914376e-01 -1.56412572e-01 -1.28438368e-01  2.26559490e-02
  -1.51179329e-01 -1.63820177e-01 -8.21518600e-02 -1.88743085e-01
  -5.08715212e-03  4.35828567e-02  1.77023172e-01 -1.40060604e-01
   1.67765021e-01 -1.72992200e-02  4.71621752e-04 -2.28202194e-02
  -8.03026780e-02  1.63690925e-01 -1.07325613e-02 -1.08141012e-01
   1.05241597e-01  1.36702240e-01 -1.35145962e-01  1.77369058e-01
   1.02225542e-01  3.72316390e-02  6.48122728e-02 -1.45189881e-01
  -9.99814868e-02  4.04478312e-02 -1.87794566e-02 -1.13142006e-01
   6.97336793e-02 -4.24235016e-02  8.74958038e-02  8.36238265e-04
  -1.24742575e-01  2.46097594e-02  6.99369609e-03  4.33102399e-02
   7.74229169e-02  7.19073117e-02  1.30255282e-01 -2.32910663e-02
   8.84677172e-02 -3.48436683e-02  1.39113635e-01 -7.71747530e-02
   1.85239136e-01  1.15600020e-01 -9.41063166e-02  1.65866017e-02
   1.03190869e-01  7.08247423e-02 -1.69246122e-01  6.81356192e-02
  -5.62610179e-02 -7.95680583e-02 -1.23121634e-01 -9.62686688e-02
   1.65160865e-01 -4.59575653e-02 -1.60656989e-01 -3.54143083e-02
  -9.67054516e-02 -1.02737695e-02  7.96174407e-02 -6.19536042e-02
   1.30303144e-01 -8.11206922e-02  1.46184027e-01 -4.90580499e-02
   1.35255605e-01 -8.44954550e-02  2.52151340e-02  1.92320347e-02
   1.84002191e-01 -8.64831805e-02  1.39823258e-01 -1.17194735e-01]]
tensor_name:  TemporalFusionTransformer/time_distributed_10/kernel
[[-0.082217   -0.0047657   0.04960731 ...  0.12994422 -0.08752041
   0.09239015]
 [ 0.11152766 -0.122166   -0.03109711 ... -0.04369991  0.09048406
  -0.06818523]
 [ 0.04708523  0.12254782 -0.01185452 ... -0.03300362 -0.12987171
   0.04006074]
 ...
 [-0.0414101   0.08641356 -0.12055659 ...  0.02241812 -0.03203716
  -0.10195864]
 [-0.0151275   0.06506993 -0.06865607 ...  0.06992049 -0.04943988
   0.14803477]
 [ 0.02966266 -0.13370265 -0.08418017 ...  0.07634148  0.00882635
  -0.0293626 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_11/bias
[-1.27829192e-03  1.64705813e-02  1.67002231e-02  3.18706110e-02
  4.49944381e-03  1.77471377e-02 -3.37522477e-02 -2.83782799e-02
  3.98015082e-02 -8.55322182e-03 -3.17787863e-02  5.85863460e-03
  5.04788943e-03  8.44176114e-03  3.54960710e-02  2.79282704e-02
 -6.88733114e-03  1.55784674e-02 -3.55609022e-02  9.96149424e-03
 -3.54241729e-02 -1.98751478e-03  1.14825424e-02 -3.67926098e-02
 -2.19673533e-02 -1.24806287e-02  2.38536745e-02 -4.32239100e-03
 -1.78471475e-03 -3.62599380e-02 -5.87711053e-04  1.94352623e-02
 -1.58721544e-02 -1.56457517e-02 -8.80486146e-03 -1.45387286e-02
  8.07767268e-03 -3.54188196e-02 -1.60845555e-02  5.30157052e-03
  1.79331079e-02  1.96669511e-02 -2.10205819e-02 -1.06222993e-02
  1.95352286e-02 -1.10433325e-02 -1.15625430e-02  8.60007200e-03
  2.37238351e-02 -3.23219667e-03 -1.72644500e-02  2.96721831e-02
  2.82857064e-02  2.08442975e-02  1.50354370e-03 -1.03819445e-02
  2.53493357e-02 -1.41976262e-02 -1.32372463e-02 -4.28805202e-02
 -2.19666660e-02 -2.31488055e-04 -1.84481554e-02 -4.88717528e-03
  8.83173663e-03  2.68254522e-02 -3.29851918e-02  2.80068014e-02
 -2.20330041e-02 -6.31106086e-04 -5.87095926e-03 -1.11972447e-02
 -2.34641805e-02 -5.35920821e-02 -8.48823134e-03  1.31678749e-02
 -2.02446170e-02 -2.87195258e-02  2.23175175e-02 -1.44055299e-03
  2.98354845e-03  9.31496732e-03  5.75608620e-03  2.70866975e-03
  3.46057005e-02  2.61853845e-03  4.39520516e-02  6.10849966e-05
 -4.13854793e-02  6.13523740e-03 -4.14010510e-02  2.30955128e-02
  6.60639629e-03  2.46633608e-02  2.54375208e-03  1.39093790e-02
  3.29524130e-02 -2.59879343e-02 -4.82889684e-03  6.38906797e-03
 -1.92986764e-02 -5.15684970e-02 -2.07715649e-02  3.04600894e-02
 -1.72130521e-02 -1.84953678e-02 -1.55951278e-02 -6.11035153e-02
 -4.01129648e-02  5.53046428e-02 -1.01797690e-03  2.66144536e-02
  3.33474651e-02 -4.59943013e-03  2.03981642e-02 -2.21065581e-02
  2.10822858e-02 -2.28381529e-02  4.04389389e-02  1.19173061e-02
 -1.46713732e-02  4.34712246e-02  1.25859035e-02 -4.87302281e-02
  5.81496535e-03 -2.74826176e-02  1.85573008e-02 -4.08097878e-02
  4.14188132e-02  2.78964965e-03  6.75221672e-03 -1.08983452e-02
 -8.43627006e-03  2.11286396e-02  3.66523601e-02 -2.43048128e-02
 -2.24276762e-02  1.11932149e-02 -2.50352360e-03 -4.09295131e-03
  6.63194852e-03 -3.04223485e-02  2.12716050e-02  1.30293546e-02
 -1.34534705e-02  6.38218150e-02 -1.01205269e-02  2.52314433e-02
 -9.57823882e-04  4.36955169e-02  3.78394313e-02  2.36476064e-02
 -9.60530806e-03  2.24390198e-02  1.53287780e-02 -1.30651623e-03
  3.43435397e-03 -5.42965718e-03  2.74830796e-02 -3.92700769e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_11/kernel
[[-0.0785774  -0.07678664 -0.08204547 ...  0.05174883 -0.06145128
  -0.04112088]
 [-0.04993621 -0.04737451 -0.15266295 ...  0.10113875  0.00077486
   0.04779539]
 [ 0.02394175 -0.08989847  0.12964723 ...  0.14930123 -0.04011473
  -0.04909798]
 ...
 [ 0.019839   -0.08946295 -0.10640156 ...  0.12432775  0.09803666
   0.0581646 ]
 [ 0.0174339   0.08282854  0.13877717 ...  0.07561683 -0.0805005
  -0.10867155]
 [-0.02358177 -0.07500313  0.08606029 ... -0.05345352  0.1287097
  -0.03939542]]
tensor_name:  TemporalFusionTransformer/time_distributed_12/bias
[-0.06041083  0.01951905  0.03115241  0.00134384 -0.04790976 -0.00379275
 -0.0140307  -0.01124581]
tensor_name:  TemporalFusionTransformer/time_distributed_12/kernel
[[-0.0944741   0.18714298 -0.04943701 ...  0.15889764 -0.1419629
   0.1266682 ]
 [-0.27931088  0.05646273 -0.00894918 ...  0.09187187 -0.1370951
   0.10864238]
 [-0.12534869 -0.01107222 -0.01652241 ... -0.0199269   0.00737787
  -0.12647064]
 ...
 [ 0.02754125 -0.16462234  0.10950193 ... -0.12948737 -0.02158827
  -0.19050473]
 [ 0.15608147  0.14404646  0.10136462 ...  0.05793324 -0.03492694
  -0.09902318]
 [ 0.05809632  0.01416192  0.03524521 ...  0.0330548   0.08925357
  -0.00566279]]
tensor_name:  TemporalFusionTransformer/time_distributed_13/bias
[ 0.01635584  0.01121775  0.02698434 -0.00214899  0.01469363  0.0340374
  0.00845102  0.03732761]
tensor_name:  TemporalFusionTransformer/time_distributed_13/kernel
[[ 0.14862494 -0.02126867  0.22902411 ...  0.1623977   0.04779286
  -0.03847435]
 [ 0.06299306  0.03571825 -0.06937543 ...  0.01411613  0.05335576
   0.0777691 ]
 [-0.09843532  0.17851518  0.00811257 ...  0.11265096  0.12574333
   0.12662077]
 ...
 [ 0.06204381  0.04874536 -0.07879029 ... -0.2353334  -0.19032674
  -0.1873653 ]
 [-0.11655334  0.12389929 -0.13034607 ... -0.03898139  0.02834687
  -0.09476197]
 [ 0.03085338 -0.09313615 -0.03364419 ... -0.02907305 -0.06480126
  -0.07663915]]
tensor_name:  TemporalFusionTransformer/time_distributed_14/bias
[ 0.01699186 -0.0087219  -0.00939621  0.00972212  0.0129893   0.00765949
  0.00342646 -0.00587036 -0.01819979 -0.02533085  0.01472283  0.0074539
  0.01390919  0.00516424  0.00753316 -0.018735    0.01281652 -0.00825353
 -0.00057716  0.00066921  0.00087851 -0.00319388  0.01458751  0.00679378
  0.00615752 -0.00431903 -0.0078698  -0.010172    0.00121784 -0.00923654
  0.00571091 -0.00341223 -0.01155738  0.01010778 -0.00553634 -0.01476827
  0.01510551 -0.00868346 -0.01475519  0.00038832  0.00562755  0.00234613
 -0.00798178 -0.00675458 -0.00065323 -0.00478435  0.0054626  -0.00160799
 -0.01382562  0.00357185 -0.00110689 -0.00724612 -0.0018509  -0.00832313
  0.01759914  0.00225788  0.00338089  0.00489497  0.00026194 -0.00709461
 -0.00045054  0.00236809 -0.01833194 -0.01482978 -0.00087168 -0.00397458
  0.01308126  0.00825277  0.0085139  -0.00501299  0.00891959  0.00560643
 -0.00496036 -0.01524543  0.00385799  0.00190806  0.00919276 -0.00303368
 -0.0112525  -0.01259379 -0.00240998  0.00392412 -0.01640889 -0.00981833
  0.01816262 -0.00509012 -0.00503948  0.00127876 -0.00583414 -0.01094417
  0.00550524  0.01117441  0.00188553  0.00144825  0.00077369 -0.02163549
  0.00388923 -0.00149756 -0.01496699 -0.01104401 -0.00751143  0.01018561
  0.0034239  -0.00240342  0.0032738   0.00064921  0.00565266 -0.01994617
 -0.00447891 -0.00262799 -0.01304781  0.01515338  0.00825563 -0.00815575
 -0.0040554   0.00383346 -0.00317738 -0.0128337   0.00258162 -0.0084024
  0.01248857  0.00308135  0.00288475  0.00325178  0.02249077 -0.0044891
  0.00766482 -0.00818839 -0.00449215 -0.00368666  0.00252488 -0.00183413
  0.0152636  -0.01046609  0.01581185 -0.0087384   0.00149718  0.0013126
  0.00792441  0.00734101 -0.00122211  0.00062924  0.00396052  0.00909667
  0.01896945 -0.0009167   0.00127329  0.00049962 -0.00500255 -0.00561659
 -0.00442771 -0.01281703  0.00835092 -0.00811884  0.00568639  0.00834509
 -0.00081248 -0.00494508 -0.00431752 -0.01373771]
tensor_name:  TemporalFusionTransformer/time_distributed_14/kernel
[[ 0.0783786   0.01188803  0.04709345 ...  0.13127801  0.10899181
  -0.06986749]
 [-0.09463186 -0.10424588  0.11126634 ... -0.05805226 -0.11841004
  -0.12930374]
 [-0.08958948 -0.10498018 -0.11599748 ... -0.05927001 -0.02167531
  -0.08714224]
 ...
 [ 0.13911776  0.12877326 -0.06394403 ...  0.05349414  0.08651043
  -0.04730789]
 [ 0.09032844  0.06752411  0.10315645 ...  0.10458948 -0.06541239
  -0.09056323]
 [-0.03044415  0.10557666  0.10749545 ...  0.10324268 -0.12694919
  -0.0997574 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_15/bias
[-0.00126622  0.00914776  0.01452392  0.00446119  0.00451295 -0.02301319
 -0.0007213  -0.00206676 -0.00856631  0.01567077 -0.00845644 -0.01563069
 -0.00482997  0.00110304  0.01010033 -0.00346083  0.01792073  0.0154109
 -0.00140993 -0.00072367  0.00329323 -0.01084443 -0.01735107  0.00495366
 -0.00175663 -0.00200138  0.0079033  -0.02450174 -0.00475525 -0.00772487
 -0.01301278 -0.01702238  0.00138196 -0.00702041  0.0104238  -0.00748155
  0.00615055  0.01097461  0.00716284 -0.01832994 -0.00620679  0.0156306
  0.00397583 -0.0102339  -0.02133515 -0.01026881  0.00763055 -0.00522072
  0.02662317  0.01395492 -0.00537072  0.0077919  -0.01312979 -0.00305942
  0.00341319 -0.01379024 -0.00299825 -0.01506886  0.00102851  0.00013692
  0.01779757  0.02250736  0.00070375  0.00182992  0.0163796  -0.01761914
  0.01483776 -0.01103379 -0.01779887  0.01737902 -0.00251288  0.01384218
 -0.00047908  0.00257619 -0.01920473 -0.0071736   0.01291219  0.0155147
 -0.01555738 -0.00658533 -0.00393368 -0.02170429  0.00209421  0.00787963
  0.00650444  0.00717682  0.00783438 -0.00424161 -0.00227289  0.0056621
 -0.01752054 -0.00491012 -0.02043956  0.01379791  0.0024686  -0.01315064
  0.00985816 -0.02435449  0.00544526  0.01130336 -0.01331943  0.00267873
 -0.01226862 -0.00363456  0.00782143  0.00068574  0.00651986 -0.00406326
  0.00432887  0.02346442  0.00715423  0.0096298   0.01119872  0.00903637
  0.00847463 -0.01119947 -0.00783956  0.00268406  0.00556289  0.01040248
 -0.00327375 -0.00769345 -0.01104091  0.0125883   0.02240972  0.00248584
  0.01357609  0.02499921 -0.01316138  0.01495263 -0.01557895 -0.01758217
 -0.00115049 -0.01778961 -0.02041178 -0.01788543 -0.01030962  0.00976602
 -0.0048309  -0.00869744 -0.01888452  0.00897579 -0.01690155  0.00735491
 -0.0198272   0.01744131 -0.00266251 -0.01421668  0.00027446  0.00363425
  0.00043816 -0.01489417 -0.01887441 -0.00945127  0.00684126  0.00688957
  0.00203635 -0.00597889  0.00303039 -0.00145525]
tensor_name:  TemporalFusionTransformer/time_distributed_15/kernel
[[ 0.11666681  0.07873603 -0.1182929  ... -0.08451873  0.02912634
  -0.00874475]
 [-0.09132916  0.10623075 -0.08872987 ... -0.10372507 -0.02309846
   0.1060098 ]
 [-0.03663051 -0.04017424 -0.07426241 ... -0.10062521  0.04383553
   0.13240616]
 ...
 [ 0.01671127 -0.03632637 -0.15272239 ... -0.02785885 -0.08011984
  -0.06078485]
 [-0.06272195  0.07238842 -0.06134329 ...  0.06308838 -0.04736331
  -0.09480289]
 [-0.10578899 -0.09927691 -0.12728217 ...  0.07199977 -0.08147401
  -0.07304423]]
tensor_name:  TemporalFusionTransformer/time_distributed_16/bias
[ 0.00860774  0.03341628 -0.00615412 -0.00182574  0.01021022 -0.00576841
 -0.01476942 -0.01766335 -0.01294786 -0.00058585  0.02792747  0.00145229
  0.0010914   0.01042576  0.01202382 -0.00386856 -0.00243886  0.00078953
  0.01920243  0.00159779 -0.01310423  0.00631911 -0.00763507 -0.00334766
  0.00058475  0.0122928  -0.00512749 -0.00283339  0.02138342 -0.00657493
 -0.00730934 -0.0008595   0.014563    0.01519487  0.01203533  0.00131418
 -0.00088237 -0.00266235  0.01131613  0.02505562  0.00288426 -0.0011786
  0.00033153  0.00934332 -0.00268335 -0.00741281 -0.00591493  0.0255199
  0.00779426  0.00556207 -0.00199869  0.02299589  0.00333511 -0.00510316
  0.02122386  0.00588407  0.01374609 -0.01395217 -0.01155384 -0.00128172
 -0.00804094  0.00020197  0.00672258  0.00025321 -0.00752819  0.00893449
  0.00454587  0.00462266  0.00766143 -0.0301801   0.00951075  0.003558
  0.003081   -0.00075161 -0.02863295  0.00631971  0.00036712  0.00853946
 -0.01092097  0.00347483 -0.01307151  0.00151792 -0.00154158  0.01392536
 -0.00374599  0.0055429  -0.00708994 -0.02991317 -0.00746932 -0.03314706
 -0.00956644  0.00552836  0.0093876   0.00449053 -0.00549055 -0.00319555
  0.00228335  0.01765223  0.01458507  0.00800164 -0.02826351 -0.00837786
  0.0075097   0.01223136 -0.01134916 -0.02166716  0.01144077 -0.01420912
  0.01158612  0.01031847 -0.00343191 -0.00011026 -0.0118475   0.01231035
 -0.01281373  0.00895634  0.01255092 -0.01012315 -0.02372675 -0.00634079
  0.01557134  0.00119401 -0.01435487 -0.00592341 -0.00229812  0.00776718
 -0.00547027  0.00823322  0.00960466  0.02106616 -0.00349358 -0.00117117
 -0.02158384 -0.00484821 -0.01185132  0.00717757 -0.00690718 -0.01154849
  0.00639261 -0.02205832 -0.00128511  0.00293077 -0.0065063   0.01319977
 -0.00578294  0.00493428 -0.01000421 -0.02911253  0.00400273 -0.01715788
 -0.00301701 -0.00783222  0.00319725 -0.01196231  0.01551208 -0.01758521
  0.00728474 -0.00031833  0.00606957  0.01237637]
tensor_name:  TemporalFusionTransformer/time_distributed_16/kernel
[[ 0.05459544  0.09283878  0.12690355 ... -0.0231332   0.14340451
   0.03557736]
 [ 0.12951836  0.08804225  0.0942331  ... -0.12256777  0.11190695
  -0.03987771]
 [ 0.08977732  0.02773379 -0.00595953 ...  0.11923866  0.03030702
  -0.113474  ]
 ...
 [ 0.06467474 -0.09427708  0.04550541 ...  0.10860437 -0.0574535
   0.03746009]
 [ 0.02275688 -0.06036755  0.05252008 ...  0.09141348 -0.09835745
  -0.04452832]
 [ 0.09505406 -0.06023697  0.09171697 ... -0.04409778  0.13451087
   0.0299284 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_17/bias
[-0.01322268  0.05959004 -0.01695069 -0.01546801 -0.00314114 -0.009792
  0.0162937   0.0059597  -0.01680042 -0.04629363  0.03791013  0.00390821
 -0.0273468   0.00324717 -0.01011357 -0.01201086 -0.02234019 -0.02683718
  0.01232849 -0.02271868  0.00140602 -0.03397062 -0.0143493  -0.02668007
 -0.0244709   0.00973139 -0.02427945 -0.02821294  0.03429964 -0.01239768
 -0.02885002 -0.00896859 -0.00758556 -0.01125062  0.00373052 -0.02635341
 -0.01633375 -0.01945481 -0.00732142 -0.00332529 -0.02331181 -0.01934792
 -0.03541921 -0.00226811 -0.02090865 -0.042151   -0.01321347  0.02716529
 -0.02314358  0.03054552 -0.02433837  0.03819199 -0.01439131 -0.02083308
  0.02262367 -0.04241198 -0.00191118 -0.00791346  0.00116101 -0.00363831
 -0.01394685 -0.02885919 -0.03585756 -0.04551607 -0.03248432 -0.0246139
 -0.0284745  -0.02572166 -0.00214644  0.03638419  0.00517348 -0.00992295
 -0.02511149 -0.03926684  0.05668209 -0.02520924 -0.02026384 -0.01438407
 -0.00616976 -0.03324206  0.01585734 -0.04311639 -0.02874926 -0.00661823
 -0.04330195 -0.01131078  0.00900485  0.0503005  -0.01580122  0.0243218
 -0.00232041 -0.01182164 -0.01806033 -0.01760892 -0.00691095 -0.02217166
 -0.02266742 -0.03199226  0.0032867  -0.01042761 -0.00785088 -0.0108744
 -0.00800384  0.00518676  0.01301848  0.02469079  0.02247752  0.00051958
 -0.00567295  0.00289623 -0.01130196 -0.01899825 -0.01584725 -0.00896954
  0.01958976 -0.00132507 -0.02727345 -0.00991071  0.01882662 -0.02751338
  0.00378286 -0.03094073  0.02372408 -0.02779284 -0.03017486 -0.01631756
 -0.03465233 -0.02804266 -0.03715989  0.03179204 -0.0361518  -0.04499442
 -0.00803151 -0.02833487  0.01422447 -0.00547703 -0.00652731 -0.01034125
 -0.01937983 -0.00490588 -0.02589101 -0.01938448 -0.00629217 -0.0423679
  0.00318003 -0.03468109 -0.03657797  0.05190396 -0.01235027  0.00647228
 -0.01099379 -0.01005841 -0.02198287 -0.02832741  0.01588796  0.02036374
 -0.00712486 -0.01603742 -0.02719756 -0.00705226]
tensor_name:  TemporalFusionTransformer/time_distributed_17/kernel
[[ 0.10210564 -0.00333845 -0.01204973 ... -0.12316604  0.02512291
   0.0337576 ]
 [-0.03484981 -0.11304214  0.11784251 ... -0.00514721  0.03584245
  -0.03232809]
 [-0.04327559 -0.04209078 -0.07025536 ... -0.15219635  0.02247484
  -0.00644626]
 ...
 [ 0.12861109 -0.13364168  0.14798646 ... -0.09749249 -0.00441494
   0.00430657]
 [ 0.08399284 -0.02138014 -0.02415912 ...  0.00403797 -0.00562227
  -0.03328011]
 [ 0.0471862  -0.10692583 -0.03694922 ...  0.13088149 -0.04321784
  -0.08244856]]
tensor_name:  TemporalFusionTransformer/time_distributed_18/bias
[-3.34870862e-03 -2.10580853e-04  7.80512113e-03 -1.71794500e-02
  1.17878215e-02  3.11945542e-03  6.87519927e-03 -1.29811615e-02
  1.36535186e-02 -1.75001211e-02 -1.75029002e-02  1.38431443e-02
 -1.02860229e-02  2.54891324e-03 -1.17396284e-02 -2.88259257e-02
  1.12612126e-03  3.82106053e-03  1.04600880e-02  8.28934088e-03
 -6.28530327e-03 -7.84041267e-03 -2.26697815e-03  1.77170392e-02
  1.50369769e-02 -1.25947613e-02 -2.15558950e-02 -1.03577494e-03
  1.83484685e-02  1.01788705e-02 -2.95130201e-02  1.74035076e-02
  6.09553093e-03 -2.83715228e-04 -1.58224795e-02  2.33397000e-02
  2.26778118e-03 -2.69200206e-02 -6.55910186e-03  4.87774797e-03
 -2.20384430e-02 -1.09261991e-02 -1.93376802e-02  1.00135235e-02
 -8.18013772e-03 -4.44441428e-03 -2.77255755e-02 -1.55009236e-02
  1.02023818e-02  1.53275318e-02 -8.24078266e-03  1.21178515e-02
 -3.25024873e-02 -1.43221496e-02 -2.23861579e-02 -1.23291984e-02
  8.15644301e-03 -3.51631345e-04 -2.40876675e-02  7.68229086e-03
 -7.07018608e-03  6.24533137e-03 -1.05900858e-02 -1.26214325e-02
  1.72268432e-02 -3.54084489e-03 -7.42716994e-03  5.49894013e-03
  1.92203734e-04  2.30771909e-03 -1.74138322e-02 -6.27745176e-03
 -8.60151742e-03 -8.99998564e-03 -1.02384789e-02 -2.01980546e-02
 -1.05484920e-02 -2.19783559e-03  8.06257501e-03  3.06008570e-03
  4.68944712e-03 -5.58538502e-03 -1.68743194e-03 -7.02266768e-03
  1.13195181e-02  9.86547675e-03 -2.97594722e-02 -9.73808486e-03
 -2.65925657e-03 -7.71340774e-03 -1.49048716e-02  2.29308084e-02
  1.08625889e-02 -3.17854434e-02 -1.26384571e-02  9.91518144e-03
 -8.74457974e-03 -1.23510463e-03 -8.00056104e-03  5.80464723e-03
 -1.54612893e-02  9.06747766e-04 -8.57408158e-03 -1.50632402e-02
 -1.02017494e-02  1.18557559e-02  4.11393726e-03 -5.07145002e-03
 -1.24611305e-02  7.48357706e-05 -8.61529075e-03  4.40377928e-03
  2.24043224e-02 -1.33177694e-02 -6.61556236e-03  2.10139975e-02
  3.22276703e-03 -1.11577660e-02  6.36474788e-03  2.02268939e-02
  2.04078257e-02 -1.99204721e-02 -1.29278321e-02 -1.60094968e-03
 -2.06367206e-02 -3.06437202e-02 -2.16733497e-02  9.17769619e-04
 -3.27981776e-03 -1.21600637e-02 -3.65778455e-03  3.62583227e-03
  1.02215698e-02 -1.42031731e-02 -1.52231683e-03  7.66070746e-03
 -1.47713698e-03 -8.52506142e-03 -1.17876939e-03  1.25874272e-02
  5.07701887e-03  1.34995309e-04  1.22551285e-02  1.97518319e-02
 -7.55238114e-03  1.51204709e-02  1.85538549e-02 -1.87182911e-02
  7.67867081e-03 -5.13374107e-03  8.93612020e-03  1.11919257e-03
 -1.22474488e-02 -1.13409869e-02  3.65488697e-03 -1.72962938e-02
  2.29333225e-03 -3.94692365e-03  5.09677641e-03  7.90826418e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_18/kernel
[[ 0.09659263  0.08383542  0.02700068 ...  0.08614867 -0.08177849
  -0.08526643]
 [-0.06503283 -0.1392615  -0.12860407 ... -0.06365894 -0.11532064
   0.04598664]
 [ 0.14026782 -0.09454368 -0.03153554 ...  0.02896787  0.05886421
   0.11234087]
 ...
 [-0.00634685  0.00419935  0.05811103 ... -0.06331734 -0.10135182
  -0.02391838]
 [-0.06506021 -0.11257622 -0.05598498 ... -0.05898999 -0.12967286
  -0.05575683]
 [-0.05474734 -0.11685491  0.13676947 ...  0.13733226 -0.04068204
   0.1203135 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_19/bias
[ 3.25725935e-02 -1.12026185e-02 -7.48906750e-03  6.35556597e-03
  2.30974201e-02  2.58304961e-02  1.61119699e-02 -4.98236157e-03
  3.38951661e-03 -5.43584442e-03 -5.26866817e-04  1.35602830e-02
 -5.87286148e-03 -2.66561867e-03  8.34000576e-03  3.28547833e-03
 -9.14227590e-03 -3.00040026e-03 -6.12114323e-03  1.42270066e-02
  4.57302993e-03  1.31863134e-03  2.68227630e-03  1.10108759e-02
  2.91488832e-03 -7.75940344e-03  2.41388334e-03 -8.69351719e-03
  3.76174948e-03  8.00904445e-03 -4.74031921e-03  1.67355351e-02
  1.26785887e-02 -4.07679155e-02 -1.97644643e-02  1.13042109e-02
  1.41824203e-05  8.10098543e-04 -1.93818775e-03  4.50888276e-03
 -6.25966873e-04  7.75287906e-03 -1.39872925e-02 -1.77499058e-03
 -1.23884920e-02  1.02169532e-03  1.19246934e-02 -1.01306411e-02
  9.06166155e-03 -4.61572874e-03 -7.24240299e-03  2.54440540e-03
  1.20710433e-02  2.04882282e-03  3.62333667e-05  1.13250893e-02
 -1.33830616e-02  9.10663605e-03 -3.63024771e-02  7.78689375e-03
  7.15922052e-03  1.43253515e-02  2.65566576e-02 -1.01783229e-02
  1.82733424e-02  1.38465222e-02  5.56816952e-03  1.20958891e-02
  8.68458953e-03  3.94296879e-03 -1.49305072e-02  2.60825288e-02
  9.86963883e-03 -1.74148101e-02  6.69381022e-03 -1.94592625e-02
 -8.21972825e-03  2.44656745e-02 -7.93792773e-03  7.12120300e-03
  1.39987376e-02  7.62543408e-03  7.42476550e-05  2.44931672e-02
 -1.67218819e-02  1.27536273e-02  1.53953293e-02 -8.09542369e-03
 -8.50974862e-03 -9.97193530e-03  1.36812208e-02  1.89234459e-04
 -1.19426148e-02 -9.37239360e-03 -1.26430308e-02  1.73114007e-03
 -5.25133451e-03  6.18586503e-03  2.87955869e-02 -1.55415293e-02
 -1.94607656e-02 -1.02521302e-02  1.00892724e-03  7.84436893e-03
 -1.25086559e-02  4.56356863e-03 -4.80048871e-03 -9.90911014e-03
 -1.26894563e-02  4.20528091e-03 -4.54373332e-03  2.14447193e-02
  2.14027218e-03 -1.59972012e-02 -1.25462245e-02  3.84358829e-03
  3.81519599e-03 -2.56738923e-02  2.29349616e-03  4.43982135e-04
  1.10944221e-02 -1.52072487e-02  8.40403046e-03 -8.99131782e-03
 -1.14269303e-02  7.82904029e-03  2.03074496e-02  2.44483687e-02
  4.16041128e-02 -1.59803107e-02 -1.51133379e-02  3.03577799e-02
  9.95847583e-03  3.33206914e-03  3.19633377e-03 -1.06688431e-02
  1.68420263e-02 -4.34679445e-03  1.56512507e-03 -3.97162139e-03
  2.68429797e-03 -1.55344605e-03 -3.38383066e-03  1.45240296e-02
  2.71490333e-03  5.91216236e-03 -1.26349891e-03  5.75620867e-03
 -2.84172967e-02 -9.96048003e-03  8.64651427e-03  1.95423625e-02
  1.15165384e-02 -3.75260524e-02  2.79814261e-03 -2.07876302e-02
 -5.62372943e-03 -1.99346221e-03 -1.20865125e-02  8.05808377e-05]
tensor_name:  TemporalFusionTransformer/time_distributed_19/kernel
[[-0.08349534  0.02980676 -0.09162892 ...  0.06693622  0.11559339
   0.0758826 ]
 [ 0.07001708  0.12731022 -0.04969512 ...  0.06354     0.03637851
  -0.01237539]
 [ 0.03600077 -0.01914112  0.08655438 ...  0.09173714  0.121617
  -0.03043474]
 ...
 [-0.02757384 -0.14230451  0.02064983 ...  0.08630089  0.04198325
   0.04456159]
 [-0.12910832 -0.11432891  0.13075785 ... -0.14794093  0.14236994
  -0.09648099]
 [ 0.08540446  0.09347395 -0.00987477 ...  0.09693131  0.13011311
  -0.0092934 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_2/bias
[ 5.12082595e-03 -2.21841894e-02 -3.91844697e-02 -2.32127625e-02
 -1.95024870e-02 -5.55372350e-02 -8.74727406e-03 -2.15482316e-03
  4.23094109e-02  1.89325009e-02  2.44751889e-02 -2.40944413e-04
  2.69510970e-02  4.37737480e-02  1.92500465e-02  8.85278918e-03
  2.73865033e-02  1.44433482e-02  1.78265572e-02 -1.69904623e-02
  1.86339878e-02  8.18931684e-03 -8.59064894e-05  2.86079925e-02
  1.31404689e-02 -5.56294136e-02  4.70498987e-02 -9.86239687e-03
  4.61056037e-03 -3.23478691e-03  2.22350024e-02  7.91716576e-03
  2.40659863e-02  2.99489987e-03 -2.69958656e-02 -1.88513901e-02
  1.35411313e-02 -6.04861358e-04 -4.92696185e-03 -2.24950295e-02
  1.26098869e-02 -4.44619134e-02 -6.93691615e-03  2.17225812e-02
  5.51270181e-03 -4.98695336e-02  2.32491381e-02  1.50311254e-02
  5.61740138e-02  5.11943549e-02  5.95751079e-03  8.12870413e-02
 -1.17629198e-02  2.26121321e-02 -2.05024990e-04 -1.22048687e-02
 -5.29634394e-03 -4.81462404e-02  1.61972996e-02  9.26121080e-04
 -1.24023901e-02  8.62266868e-03 -2.82255728e-02  3.74196353e-03
 -2.17639152e-02  5.33496682e-03 -4.16231458e-04  7.77393207e-03
 -1.72770787e-02  3.25201005e-02  1.22541906e-02 -3.30624171e-02
  1.98351871e-02 -3.10050510e-02  3.42426486e-02 -1.70183796e-02
  1.52564608e-02  1.53066358e-02 -1.94315948e-02  2.68419199e-02
 -8.35081562e-03 -2.92554982e-02 -2.53894050e-02 -4.35873829e-02
  1.30420670e-01  6.55708136e-04 -1.42588764e-02 -1.63004734e-02
 -2.62026712e-02  2.50665732e-02 -2.63782497e-02  1.94900110e-02
  9.49247973e-04 -4.94307419e-03 -1.17318956e-02 -4.26462926e-02
 -5.42080365e-02 -1.36426091e-02  1.88935585e-02 -1.99774816e-03
  1.38936546e-02 -4.33157273e-02  4.70521711e-02 -3.00319586e-03
 -4.03631739e-02 -4.58685532e-02  2.76619326e-02 -3.31389792e-02
  2.43524928e-03 -9.86050069e-03 -1.66328754e-02  1.07768050e-03
 -1.95134729e-02 -1.49186766e-02  1.24784922e-02  2.15248223e-02
  3.67231347e-04 -7.65993260e-03 -1.12414034e-02 -8.05291440e-03
  3.83724016e-03 -2.85369363e-02 -1.89900573e-03 -1.85237862e-02
 -1.69483665e-02 -6.01659296e-03 -1.95671478e-03  7.08337314e-03
 -1.78050101e-02 -2.76043378e-02 -4.98509919e-03 -3.05220461e-03
  2.07878631e-02 -1.43964104e-02  1.35175539e-02  1.17050195e-02
 -1.37906373e-02 -7.47587672e-03 -2.41421768e-03 -1.30257756e-02
 -2.32412945e-02 -1.71609223e-02 -6.18459098e-03  1.14380019e-02
  1.03430552e-02 -6.08460139e-03 -1.83257852e-02  1.59282070e-02
  1.37387495e-02 -1.79200824e-02  1.07812993e-02  1.71523057e-02
 -5.32113342e-03  7.41493830e-04 -2.15657614e-02 -1.15956143e-02
  3.19591761e-02  2.74147261e-02  7.86737073e-03 -5.12875011e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_2/kernel
[[ 0.05623581  0.00491189 -0.05362975 -0.02946872 -0.03602357 -0.07986382
   0.02425281  0.06238286 -0.0368645   0.09442617  0.07828265 -0.06694952
   0.11239113 -0.14347203  0.09932102  0.01541184  0.10226748 -0.0365326
  -0.0063063  -0.10914961 -0.14216252  0.12447748 -0.18952136 -0.03717723
   0.10123455  0.16686466  0.17168996 -0.13684064  0.09810168  0.16751467
  -0.13009706 -0.11933462 -0.18291841  0.15355007  0.088716   -0.06143292
   0.03106656  0.00450832 -0.14441803 -0.03548974  0.02042446 -0.14838588
  -0.01893016  0.01975992  0.09979313  0.11708508 -0.16172966 -0.15160772
   0.01753318  0.05906628 -0.04241655 -0.04695752 -0.09966078 -0.17649628
  -0.00953105  0.10040668 -0.01439924 -0.17350131 -0.00128583 -0.19720884
  -0.03395199  0.01071755 -0.14381732  0.03119019 -0.11390635  0.21555442
  -0.06933651  0.07102479 -0.04184154  0.01170364  0.07100055  0.1787905
   0.01176604  0.22458544 -0.140187   -0.12877645 -0.10494782  0.16825631
  -0.1639656   0.17033847 -0.02139287 -0.09456388 -0.05217094 -0.1933922
   0.14542273 -0.16454338  0.17108382 -0.02136286 -0.00833327  0.12443832
  -0.07476548  0.1316872   0.14738461  0.08135069  0.20133343 -0.08417723
  -0.17547113 -0.128765    0.08306246 -0.00510557  0.1688295  -0.08217382
   0.01700104 -0.15136881 -0.09611421 -0.1293655   0.13970526  0.14721262
   0.13927482 -0.01456403 -0.01914021  0.01441652  0.15312809  0.04983409
  -0.08733496  0.05858378  0.00370544 -0.02629424 -0.00131899  0.05312072
  -0.05772794 -0.15885183  0.19078082  0.00964569 -0.16814002  0.07405655
   0.01010644 -0.14566149  0.0670151  -0.06092244 -0.04303933 -0.12757619
   0.09761984 -0.04469981  0.07773073  0.05724712  0.08898218 -0.02386033
  -0.17165352 -0.15580668 -0.07479423 -0.05873372 -0.07400891  0.07170259
   0.07787897 -0.00421802  0.12094335  0.08830369  0.0971318  -0.19617991
  -0.0778758  -0.11620537  0.11586838  0.13958384  0.1930616  -0.03150309
   0.09465951  0.17053579 -0.14737466 -0.2291919 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_20/bias
[ 2.9117487e-02 -3.8468642e-03  3.1745765e-02  5.1157057e-02
  2.6059916e-02  1.8640831e-02  1.3022120e-02 -2.9717136e-02
  3.2616202e-03 -2.8110037e-02 -2.0873033e-02  2.5911089e-03
 -2.6395541e-02  1.0558279e-02 -1.8476114e-02 -2.9868418e-02
  1.9614162e-02 -2.9362028e-02  2.2129474e-02  4.1943621e-02
 -1.1220592e-04 -1.2235338e-02  5.9706471e-03 -1.8207803e-02
  2.8262516e-02 -1.6918700e-02 -7.8809978e-03 -2.0236675e-02
 -3.3696458e-02  1.2828560e-02  4.4959602e-03  3.3550154e-02
  7.9257423e-03  3.2499347e-02  3.9341651e-02  5.4255176e-02
 -1.4458108e-03 -5.6125131e-02 -4.7548208e-03  3.0453229e-02
  1.2251496e-03 -2.3588445e-02  1.7519480e-02 -5.7983887e-03
  1.4191084e-02 -1.9476967e-02  6.0971864e-03 -4.4000102e-03
  2.4265550e-02 -5.2475560e-02  1.5636655e-02 -1.7489668e-02
  1.1476733e-02  1.6562955e-02  2.5590701e-02  1.7969014e-02
  1.2967093e-02 -1.5019307e-02  3.5271116e-02 -1.6318204e-02
  3.1131957e-02  1.6104216e-02  1.9549010e-02 -4.0622711e-02
 -4.6613514e-02  3.1269960e-02  2.8810261e-02  5.7522734e-03
 -8.6903665e-03  1.5964802e-02 -4.2518039e-04  3.0784829e-02
  2.1500763e-02  1.9103238e-02 -7.1433787e-03 -4.5413859e-03
 -4.5124888e-02  8.5127354e-03  1.0440910e-02  2.6703145e-02
 -9.6243713e-03  2.3603475e-02 -2.7244976e-02 -1.3648722e-02
  1.2385848e-02 -8.0326572e-08  1.3285409e-02  3.4969438e-02
  2.0940287e-02 -1.8468594e-02 -1.7852428e-03  6.8668830e-03
 -2.5815474e-02  2.5432006e-02 -1.2433983e-03 -2.0005390e-02
  2.7224394e-02  1.7996596e-02  3.0206153e-02 -2.9952612e-02
 -2.7210422e-02  6.9545597e-02  4.0157344e-02 -8.9114392e-03
  1.2880989e-02  8.0022076e-03 -7.1819583e-03  6.8444568e-03
 -1.6924446e-02  4.1814032e-04  4.3260742e-02 -2.5222458e-02
 -6.7817224e-03 -9.6175801e-03 -6.9124331e-03 -4.2523358e-02
  9.8385150e-03 -1.6835970e-03 -1.9021325e-02 -4.3672372e-02
  6.5751853e-03 -2.7880490e-02 -9.9584227e-03  2.4742858e-02
 -1.8435845e-02  3.4513460e-03  1.4334393e-03 -1.5609347e-02
 -1.4057482e-02  8.7434091e-03  2.2327011e-02 -2.5498902e-02
 -2.5706165e-02  2.4457572e-02 -1.5960144e-02  8.8476865e-03
 -4.7793803e-03 -2.7633952e-02 -1.1282725e-02 -5.4175634e-02
  2.0669641e-02 -4.4434305e-02 -2.7286587e-02 -1.9542240e-02
  9.6651781e-03 -7.0572817e-03 -4.4602800e-02  2.1179030e-03
  2.4894360e-02 -2.5043809e-03  3.6645055e-02  3.0653039e-02
 -2.1829717e-02  2.2130558e-02 -2.8091604e-03 -1.9517319e-02
 -1.0665109e-02  1.6936827e-02  2.4621913e-02 -2.2477416e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_20/kernel
[[-0.07837474  0.03832673  0.05835847 ... -0.20084181  0.07917923
   0.14381954]
 [ 0.00737365 -0.01512452 -0.12048186 ...  0.11772996 -0.1033925
   0.03816971]
 [ 0.06631689  0.09483972 -0.02399958 ... -0.04595828 -0.11773856
  -0.06991487]
 ...
 [ 0.09906043 -0.0461353   0.01159278 ... -0.14828105  0.03772038
   0.11357695]
 [ 0.04250855  0.04211178  0.06210685 ...  0.08249211 -0.13812272
  -0.05805621]
 [ 0.08868647 -0.0261104   0.02359386 ... -0.12989947 -0.03306647
   0.02170796]]
tensor_name:  TemporalFusionTransformer/time_distributed_21/bias
[-0.07985342 -0.06271847 -0.10518312 -0.02437057  0.08251236  0.00790149
 -0.04991471 -0.04018964  0.03678788 -0.07665023 -0.10310531 -0.06595345
  0.12760101  0.02255944 -0.01796481  0.01123329 -0.02500921  0.04775104
  0.04891305 -0.02444432  0.08259385 -0.00420226 -0.09091425 -0.04640964
 -0.0247557  -0.04218215  0.07231173 -0.01575252 -0.12881516  0.10677909
  0.04062962  0.0466186  -0.00805411 -0.01516555 -0.04837957 -0.00781742
 -0.04457305  0.05572341 -0.02770265 -0.03584996 -0.00970448 -0.01280434
 -0.03809665  0.05623867 -0.04314161 -0.07558972  0.01177478 -0.05405164
  0.05248711 -0.05531057  0.07167614 -0.06746708  0.0215894   0.11054415
  0.0363299  -0.102707   -0.07456465 -0.05779852 -0.10928702 -0.01122628
  0.04702222  0.03847111  0.05167787 -0.0131353   0.04968902  0.0054549
 -0.10922665 -0.10308753 -0.07054944  0.02021161  0.01170247  0.11394286
  0.00625886 -0.02654961 -0.08667213  0.10578649  0.02730734  0.03879219
  0.03170537 -0.09676538  0.06580688 -0.05003362  0.02132026  0.04573581
 -0.03924428 -0.05709266 -0.03024044 -0.08647394 -0.15859695 -0.00158604
 -0.0920499  -0.03624729  0.00166693 -0.00466568 -0.16221975 -0.02051665
  0.09730969 -0.15286931 -0.04533539 -0.01896213 -0.00207781 -0.03470835
  0.00750744 -0.11773477 -0.03522977  0.00090738  0.00119719 -0.01933585
 -0.11814115  0.00579337  0.04994998  0.07996941 -0.1512758  -0.12488586
 -0.06933042 -0.07299957  0.03798684  0.0545702  -0.02537889  0.13858531
  0.03575329 -0.03879325  0.00312455 -0.03169199 -0.01302617 -0.05417768
 -0.06399231 -0.07328256 -0.22202866 -0.06740218  0.02033583 -0.09457109
  0.00618214 -0.00745101 -0.05390772  0.0395842   0.03439157 -0.07505261
  0.02368057  0.02211091 -0.01533701  0.05071977 -0.00303364 -0.0666762
 -0.02581501 -0.03766618  0.02035582  0.00386209 -0.0153379  -0.00577889
 -0.07241467  0.07450788 -0.06422362 -0.08414821 -0.01938193 -0.08550805
 -0.09545925  0.08143907  0.05708245  0.02039346]
tensor_name:  TemporalFusionTransformer/time_distributed_21/kernel
[[ 0.07447588 -0.02908528  0.03811133 ... -0.09738332  0.09362918
   0.04013298]
 [-0.05985516 -0.11911815  0.02161047 ... -0.0308686   0.05181677
   0.05510516]
 [-0.08717167  0.04397878  0.02736332 ... -0.04781054 -0.01299624
   0.09067946]
 ...
 [ 0.12287944  0.10242017  0.03973405 ... -0.03014741  0.01687206
  -0.07832641]
 [-0.02657739 -0.07277507 -0.04795933 ... -0.0327049  -0.1058509
  -0.01847148]
 [-0.05401034  0.14573501  0.06767399 ...  0.02040878  0.00666456
   0.18001574]]
tensor_name:  TemporalFusionTransformer/time_distributed_22/bias
[-1.97396260e-02 -5.37326150e-02  1.02466960e-02 -1.03583168e-02
  3.31836790e-02  1.78423058e-02 -8.89857998e-04  4.54520360e-02
 -4.01204228e-02  2.78815813e-02 -4.03125696e-02  2.27483790e-04
  1.92437042e-02  3.65164056e-02  1.18802004e-02 -3.00614387e-02
  4.18358073e-02 -1.11754537e-02  2.31513493e-02  1.27924951e-02
  5.02259023e-02 -5.69243804e-02  4.46512923e-02 -3.41655873e-02
  4.88600275e-03 -1.93236803e-03  4.01447304e-02 -4.85005043e-02
  1.36062801e-02 -3.20187919e-02  1.19584929e-02  2.83069853e-02
  6.40614470e-03  4.84626293e-02 -3.18896845e-02 -1.06047578e-02
  3.40210535e-02 -1.18791498e-02  6.78766817e-02  3.02347373e-02
  6.24747910e-02 -3.41876014e-03  1.44517673e-02 -1.86103377e-02
  6.69082403e-02 -4.31225225e-02 -2.76992228e-02  2.65792236e-02
 -2.57499442e-02  5.59720322e-02  4.16344265e-03  4.39559575e-03
  5.70625812e-02 -5.75414859e-03 -3.82814743e-02 -8.02843180e-03
  1.13234879e-03  4.13625613e-02 -4.14575376e-02  8.68021697e-03
  2.08777320e-02  1.72509607e-02 -4.10567299e-02  1.15927763e-03
 -7.72281410e-03 -9.92045272e-03 -3.99622917e-02 -2.09685531e-03
  3.32232490e-02 -4.35760394e-02 -3.74675468e-02 -3.54481190e-02
 -1.83961950e-02  4.24642004e-02 -5.19386381e-02 -4.68508486e-04
 -1.96235459e-02  3.20092328e-02  9.05160327e-03 -3.20982747e-02
  1.25261927e-02 -2.13817786e-02 -3.64644825e-02  5.35539351e-02
 -7.70063326e-03  1.33592961e-02 -8.63505062e-03  1.43775879e-03
 -5.29094823e-02  3.51669863e-02  6.87128231e-02  1.02520622e-02
  2.71123480e-02 -5.60452463e-05 -2.38040816e-02  5.68470918e-02
 -3.48077081e-02  2.41567027e-02  3.47562134e-02 -4.97096181e-02
  4.69142012e-02  5.53281642e-02  2.69850325e-02 -5.40651530e-02
  2.80751544e-03 -5.49703240e-02 -8.10769014e-03 -2.50864159e-02
  2.73742676e-02  6.42207963e-03 -2.64546871e-02  4.54389974e-02
 -6.77747978e-03  6.89034211e-03  3.16762999e-02 -4.15679254e-02
 -5.10155559e-02  2.86239218e-02 -4.70977053e-02 -5.02287783e-03
  1.87744703e-02  8.78794584e-03 -1.36476727e-02  4.40459438e-02
 -1.27994809e-02 -9.69292689e-03 -1.80712827e-02 -2.97722239e-02
  8.75892304e-03 -5.33257015e-02 -6.94587082e-03  2.30562259e-02
 -3.92970890e-02 -3.72611135e-02 -1.65791879e-03  2.04101577e-03
  3.25328559e-02 -4.71937247e-02  8.39576405e-03  1.29716741e-02
  5.69041111e-02 -4.39296924e-02  6.04909360e-02  2.53134314e-03
 -1.86028592e-02 -6.52143955e-02  1.50661860e-02  5.76492772e-02
  6.43921178e-03 -4.26516794e-02  1.76872127e-02 -4.57184687e-02
 -3.02343089e-02  1.72845088e-03  1.20487455e-02  2.97031458e-02
  2.66816709e-02 -6.69119600e-03 -1.85838975e-02  5.41243935e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_22/kernel
[[-0.02858344 -0.01574125 -0.07786961 ...  0.10637592  0.1149215
   0.09990628]
 [ 0.00023863  0.0217063  -0.13368014 ... -0.10451625  0.12483086
   0.08542113]
 [ 0.06387054 -0.06296527  0.14109157 ...  0.0022489   0.05638957
  -0.05511428]
 ...
 [-0.1224753   0.09000272  0.07231214 ...  0.13237567 -0.0784706
  -0.00962311]
 [-0.0067264   0.01316002  0.05724052 ... -0.005017    0.04646935
  -0.12108978]
 [-0.09590758 -0.1525015   0.00938891 ...  0.03275701 -0.06343874
   0.10256448]]
tensor_name:  TemporalFusionTransformer/time_distributed_23/bias
[ 1.9078512e-02  5.3122740e-02 -4.1839562e-02 -2.0301824e-02
  4.1459636e-03 -4.6513748e-04  4.2796873e-02  2.6109323e-02
  2.3503078e-02 -4.3912489e-02  1.8477134e-02  2.9536443e-02
  8.2119484e-05 -9.0449117e-03 -1.8630801e-02 -7.6763965e-03
 -1.0964405e-02  1.0720461e-02  4.7354188e-02  7.8488057e-03
 -1.6474422e-02  4.1020978e-03 -1.0194527e-02 -1.8670876e-02
 -1.5697762e-02 -1.9148627e-02  3.1230191e-02 -2.2472398e-02
 -1.4565208e-02 -3.8787384e-02  1.1060196e-03 -4.9480707e-03
 -1.7042832e-02 -9.3398783e-03 -7.5531233e-04  1.4597158e-02
 -1.8275503e-02  1.5569177e-02  2.8673541e-02 -4.3749280e-02
  3.1546272e-02 -1.5507430e-02  2.7264688e-02 -2.1032959e-03
 -3.6790270e-02 -3.4595352e-02  3.2673574e-03  1.5550530e-02
 -4.3489769e-02  5.8665823e-02 -4.6123778e-03 -1.1411890e-02
  1.4395416e-02  1.2920163e-02  3.0502204e-02  5.4769110e-02
 -3.6520213e-02  5.3945202e-03  3.4139499e-02  2.1530179e-02
  4.6840254e-02  1.1938342e-02  1.7664047e-02  7.2076698e-03
 -2.8564457e-02  1.2481217e-02  7.3826462e-03  2.4946075e-02
 -5.4332837e-02  8.2376283e-03 -3.2818023e-02  1.6263912e-02
  4.0943276e-02  1.5140315e-02  4.5975661e-03  3.7849862e-02
  2.8225243e-02 -6.2333355e-03  5.7716966e-02  3.5209920e-02
 -1.1417263e-02 -2.2051483e-02  7.4524269e-03  6.3583568e-02
  3.3542395e-02  4.0463503e-02  2.8046640e-02 -2.0309608e-02
 -2.6564747e-03 -7.6179802e-03 -4.4882432e-02  2.6140872e-02
  2.2612037e-03 -1.3664804e-02  2.1767046e-02 -4.4168886e-02
  8.4436228e-03 -4.4171553e-02 -1.9774733e-02 -4.5389887e-02
  4.6259791e-02  4.0617988e-02  4.4850197e-02 -3.7056793e-02
  4.1961512e-03  2.0039416e-04  3.1391270e-02 -4.3664902e-02
  2.3218349e-02  1.8075753e-02 -4.0383060e-02  2.3334209e-02
 -2.1505827e-02  3.4410428e-02 -2.3367545e-02  3.1385429e-02
 -2.6807373e-02 -4.6640623e-02 -5.6414958e-02  2.2558203e-02
 -1.5879365e-02 -2.7821671e-02  3.0054785e-02  2.5383852e-02
  3.0999023e-02 -1.8723490e-02  7.4710432e-03  5.9150308e-02
  5.3007580e-02 -3.8979821e-02 -4.4212289e-02 -2.1693401e-02
  1.9500114e-02 -2.4843790e-02  5.4080136e-02 -2.8204935e-02
 -2.6996503e-02  2.2222972e-02  2.8454658e-02  4.3678101e-02
  2.5710858e-02  3.4771517e-02 -3.1449731e-02 -5.2861493e-02
  5.7955179e-02 -6.7591746e-03 -1.8731050e-02  1.3223132e-02
  3.6210451e-02 -5.9090152e-02  2.1086857e-02 -2.6033465e-02
  3.5844233e-02 -3.9359266e-03  8.6774686e-03  1.1619702e-03
 -6.6712121e-03 -7.4452654e-02  4.7210656e-02  4.7831424e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_23/kernel
[[-0.04343172 -0.01354701 -0.03180519 ...  0.00874027 -0.01720136
  -0.1367711 ]
 [-0.08166549 -0.18443377  0.0526416  ...  0.18649112  0.07511018
  -0.15032516]
 [ 0.03755948 -0.09963682  0.03158939 ... -0.05315766 -0.09724285
   0.10888628]
 ...
 [ 0.10375889 -0.11373401  0.0147569  ... -0.04688139  0.12242784
  -0.08109871]
 [ 0.08384509  0.00473057 -0.02302898 ...  0.15863948 -0.08493172
  -0.10767078]
 [-0.08906237 -0.00028076 -0.09631369 ... -0.05455719  0.09271772
   0.02495262]]
tensor_name:  TemporalFusionTransformer/time_distributed_24/bias
[-1.72228105e-02  5.66294491e-02  3.77571993e-02  6.99973479e-03
  1.71309896e-02 -6.31164666e-03 -4.97318134e-02 -3.38875093e-02
 -3.47245820e-02 -7.90636986e-02  2.59341151e-02  3.61791672e-03
 -8.05746065e-04  5.42600453e-02  8.46871827e-03  6.24453183e-03
 -3.42528783e-02  3.46505754e-02  5.56505919e-02 -7.61974975e-03
  1.18239429e-02  1.15194870e-02 -1.16305016e-02  1.43728014e-02
 -4.66370918e-02  3.14244740e-02 -8.32395256e-03  1.34668425e-02
  2.18932685e-02 -2.75020320e-02  1.84230879e-02 -1.53627852e-02
  1.36940265e-02  7.80575117e-03 -1.72000937e-02  8.27991776e-03
 -1.19353579e-02 -3.92584763e-02  5.68170939e-03  8.96144565e-03
  1.05240301e-03  3.82813662e-02 -3.16829979e-02  5.89955784e-03
 -1.60164982e-02 -1.66621711e-02 -2.58674175e-02  2.33312733e-02
 -1.61764026e-02 -5.83168771e-03  3.64579000e-02  2.96099707e-02
  1.67475827e-02  1.30044259e-02  1.62466094e-02 -9.86232795e-03
  4.50298376e-02  6.04964281e-03  9.29036736e-03  1.97787378e-02
  5.23519795e-03  1.66683197e-02  3.76012400e-02 -3.44622484e-03
 -2.68651061e-02 -3.84791940e-02 -5.84149100e-02  2.43344121e-02
  4.24868986e-02 -3.10855526e-02  3.29528823e-02 -2.60718279e-02
  1.47873778e-02 -2.86112539e-02 -3.72976356e-04  4.28820811e-02
  4.32554493e-03  3.30344401e-03  3.26931826e-03 -5.71423385e-04
 -1.63282845e-02  2.22301129e-02  2.52208933e-02  1.16283465e-02
 -6.51189685e-02 -3.35159275e-05 -1.50253549e-02 -3.59111503e-02
 -2.32700608e-03 -4.20936868e-02 -4.29910310e-02 -7.94006046e-03
  6.34587230e-03 -3.38356197e-02 -8.98337178e-03  1.85001306e-02
  1.20023759e-02 -2.74727563e-03 -1.01383880e-03 -1.22268163e-02
 -1.47958100e-02  1.40034053e-02  4.16487921e-03  4.65225540e-02
 -1.71010289e-02  2.36371700e-02  2.41193231e-02 -3.55632678e-02
 -3.35178850e-03 -1.32043776e-03 -2.06849724e-03 -1.14620300e-02
 -3.33581492e-02 -1.58867165e-02 -1.46464789e-02 -1.91272199e-02
  5.35311140e-02 -2.33083148e-03 -3.53755169e-02 -1.15901278e-02
 -4.83451597e-02 -8.68504960e-03 -4.80020195e-02 -3.43173034e-02
  3.24216671e-02  3.23149599e-02 -2.60056253e-03  3.16077769e-02
 -2.38465872e-02  4.73025292e-02 -4.80952077e-02 -7.65723584e-04
 -1.33613879e-02 -3.23721301e-03 -3.39040272e-02 -2.85717193e-03
 -1.51096089e-02  1.87522557e-03  2.30793227e-02  2.19300240e-02
 -6.82955096e-03 -2.65147965e-02 -1.44114671e-03  2.87641454e-02
 -3.00382469e-02  4.34007589e-03 -4.46301438e-02 -1.43137630e-02
 -4.39260043e-02 -4.45877910e-02 -9.35800653e-03 -6.30205357e-03
  3.06466408e-02 -7.39596831e-03  3.55849490e-02 -2.41441396e-03
  6.88767573e-03  1.28686999e-03  2.69174855e-02  5.65755852e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_24/kernel
[[ 0.1150526   0.07984078 -0.06329153 ...  0.07625527  0.11355542
   0.1621476 ]
 [ 0.02231991 -0.04418447  0.1138304  ...  0.0469104   0.16085455
  -0.03459322]
 [ 0.06193194 -0.05483145 -0.13673781 ... -0.04135642 -0.11973946
  -0.08368987]
 ...
 [-0.09965644  0.08683487 -0.08297211 ... -0.00156107 -0.11523731
  -0.17312956]
 [-0.05536225 -0.05264015  0.16103332 ...  0.14049792  0.06013967
  -0.00533029]
 [-0.10501427  0.18488273  0.05663727 ... -0.01755061 -0.01010353
   0.02798696]]
tensor_name:  TemporalFusionTransformer/time_distributed_25/bias
[-0.08583537  0.02761108 -0.00826873 -0.04168445 -0.08084022 -0.01175292
  0.06127746 -0.06939162 -0.01612736  0.12509365 -0.04964387 -0.05530926
  0.01228121  0.00349268 -0.07033799 -0.06170088  0.03187444 -0.05565159
  0.0472906  -0.03838788 -0.05747854 -0.02548275 -0.05094    -0.04158723
  0.02238012 -0.03902442 -0.01986709 -0.11917198 -0.07737409 -0.05796443
 -0.03257526 -0.03406386  0.01446832 -0.08541885 -0.00755559 -0.08637889
  0.04440064  0.04222016 -0.05782862  0.04285428 -0.07918947  0.05704754
 -0.00213516 -0.04173249 -0.07918812 -0.17074162 -0.01099152 -0.09259923
 -0.02986328 -0.02396965  0.04017007 -0.10040058 -0.09516229 -0.0706066
 -0.07491717 -0.11480367 -0.00380433 -0.04216195 -0.1288339  -0.01930635
 -0.08867188  0.01284556  0.06856719 -0.05841062 -0.02931103 -0.00408068
  0.02264767 -0.05514479 -0.00485018 -0.02752551 -0.03949964 -0.04281971
  0.01429509  0.01419263 -0.00124128 -0.02803535 -0.0391163  -0.01260408
 -0.04123775 -0.06871117 -0.01036504 -0.04064899 -0.03577469 -0.01824032
  0.01746716 -0.07218397 -0.09856059 -0.0228227  -0.11420023 -0.03871234
 -0.02071753 -0.05614413  0.00949938 -0.03817327 -0.03245618 -0.04691062
  0.01888826 -0.01093003  0.0141996   0.01463948 -0.07405182 -0.01518349
 -0.11876067 -0.01937649  0.03941409  0.03830885 -0.07057495 -0.03622077
 -0.08366576 -0.00530656 -0.06566449 -0.12726945 -0.04074265  0.001111
 -0.13179438 -0.03758083  0.05232376 -0.09230053 -0.02848255 -0.12628308
  0.10775636 -0.02512331 -0.0080301  -0.08638924 -0.06645568  0.00480769
 -0.13394046 -0.0364456  -0.06342112 -0.05391876 -0.1056134  -0.10492016
  0.01698099  0.03056158  0.03843035 -0.01863549 -0.0647574  -0.1063811
 -0.06048868 -0.06582011 -0.08807197 -0.04587261 -0.06693427  0.04295886
  0.00158309 -0.06645627 -0.04698076 -0.07730656  0.0175718   0.01605629
 -0.01954712 -0.04574115  0.04874336 -0.10836916 -0.03215405  0.0945328
 -0.09119947 -0.11083008  0.0131325  -0.04591211]
tensor_name:  TemporalFusionTransformer/time_distributed_25/kernel
[[ 0.14063066 -0.04020169 -0.1225175  ...  0.09363458 -0.12817599
   0.07911784]
 [-0.07874078  0.10402472 -0.03429247 ...  0.07343936 -0.03805351
  -0.15670273]
 [ 0.16005619 -0.11913835  0.08476977 ...  0.0334984   0.09334195
   0.04607574]
 ...
 [ 0.07947107 -0.14053388  0.12884058 ...  0.11880252  0.03624765
   0.13747068]
 [-0.12042322 -0.01372442  0.02491111 ... -0.13326603 -0.14372692
   0.10520821]
 [-0.0316665  -0.00278761 -0.13552526 ... -0.10592362  0.16907181
   0.04568442]]
tensor_name:  TemporalFusionTransformer/time_distributed_26/bias
[-1.43816024e-02  4.50065546e-02  4.85733105e-03 -5.86998388e-02
 -4.52461727e-02 -3.55002750e-03  2.14514919e-02 -5.89260831e-02
  3.95602128e-03  1.00694820e-02  1.72528625e-02  1.55409528e-02
 -1.66066848e-02  6.64449576e-03  3.20586972e-02  2.92751065e-05
 -4.66465279e-02 -2.25269087e-02 -4.70076799e-02  3.54927480e-02
 -1.77516676e-02  1.15190558e-02  1.67870652e-02  5.38027287e-02
 -5.55117130e-02 -2.63098604e-03 -6.09529577e-02 -5.19851632e-02
  1.76108629e-02 -3.51485051e-02 -1.33173922e-02 -4.64139320e-02
 -6.54484257e-02  2.35753208e-02  2.51895897e-02  4.30214442e-02
 -3.71425711e-02 -6.84618205e-02  1.24235619e-02 -8.57177600e-02
  3.10039744e-02 -1.59796625e-02 -2.32531762e-04  9.11836233e-03
 -8.34796354e-02  5.53654730e-02 -8.65933374e-02  1.38766821e-02
 -4.40988783e-03 -1.99262202e-02  1.87626928e-02  2.07652412e-02
 -8.07964578e-02 -4.51862998e-02 -1.20565044e-02 -8.72450694e-02
 -1.36682577e-03  1.22434627e-02 -4.19916911e-03 -4.91597131e-02
 -7.04814643e-02  1.58957485e-02  2.95279063e-02  1.70371607e-02
  6.53958097e-02  3.22297146e-03  3.91763449e-02 -6.19002208e-02
 -3.98825109e-03  3.06417253e-02 -2.03423770e-05  1.41483301e-03
 -9.16852150e-03 -3.05502247e-02  1.83687117e-02 -3.12116975e-03
  3.54067907e-02 -8.27290192e-02  3.52781974e-02  5.16634919e-02
 -6.21546470e-02  1.12570347e-02 -1.38383955e-02  4.70858626e-03
 -6.41868711e-02 -4.16248813e-02  2.22448297e-02 -1.69039648e-02
  1.46591780e-03 -9.76752117e-03  1.25691835e-02 -2.50169002e-02
 -5.76881543e-02 -8.53622518e-03 -1.32618251e-03 -4.45494466e-02
 -5.38391136e-02  2.66480073e-02 -3.91501784e-02  3.08182854e-02
  3.75465974e-02 -5.14791952e-03  3.98228003e-04  2.83074975e-02
  1.74610186e-02  4.35750990e-04 -2.52767131e-02  6.00409275e-03
 -2.40535270e-02  2.22376697e-02  1.30812936e-02 -7.54434764e-02
 -1.72667820e-02 -6.76315418e-03 -6.68836664e-03  1.81427822e-02
  2.11988017e-02  1.15406504e-02  2.60891709e-02 -1.51223792e-02
  5.93637303e-03  1.61449499e-02  1.98912919e-02  4.61930118e-04
 -9.23328940e-03 -5.23546562e-02 -4.86878939e-02 -2.55781002e-02
 -1.16035799e-02 -1.82555243e-02  8.83237645e-03  7.95965176e-03
 -5.57660237e-02  1.41916918e-02 -4.60493099e-03 -2.52621751e-02
  2.33614687e-02  1.73336398e-02  1.35238506e-02 -4.00731666e-03
 -6.47158083e-03 -5.81296422e-02 -2.02532252e-03 -1.33190891e-02
 -3.15964147e-02 -1.38143413e-02 -1.48715861e-02 -1.05169155e-02
 -1.71249546e-02  9.13486723e-03  5.46901161e-03  3.22577311e-03
  5.30684926e-03 -6.93168899e-04  4.55836812e-03 -2.02533100e-02
  5.51529787e-03  5.65028051e-03 -5.31039685e-02 -2.35981308e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_26/kernel
[[ 0.10628407 -0.02482762  0.11476713 ...  0.01366048  0.07013019
  -0.03529688]
 [-0.00902232 -0.03943103 -0.04382499 ...  0.14844155 -0.09849688
  -0.05436784]
 [-0.0604209  -0.12471444 -0.05369239 ...  0.01952964  0.06142361
  -0.04715242]
 ...
 [ 0.01375246  0.12000673  0.02280744 ...  0.00040416 -0.05068236
   0.08896416]
 [-0.10687495  0.02089455  0.07473246 ... -0.12821923 -0.0877379
  -0.00906125]
 [ 0.10634635  0.06095101 -0.08712635 ...  0.0711433  -0.07622877
   0.11657533]]
tensor_name:  TemporalFusionTransformer/time_distributed_27/bias
[-3.19190626e-03 -4.88897637e-02  1.97221059e-03  6.46461174e-03
  3.90289538e-02  1.82432756e-02 -2.93838456e-02  1.46715706e-02
  2.74749212e-02 -3.36033218e-02  2.49552284e-03 -1.36988116e-02
  1.06528830e-02 -1.33808411e-03  2.07402613e-02 -1.35784866e-02
 -2.10838113e-02  8.54469743e-03 -4.18938585e-02  2.73442660e-02
 -4.12565023e-02  5.43744005e-02  3.21524404e-02  6.49217144e-02
 -4.56508212e-02  1.31347906e-02  3.46682034e-02 -6.14269152e-02
  3.24216858e-03  7.07264170e-02 -1.75465439e-02 -6.55016750e-02
  3.66297588e-02 -3.39774303e-02 -1.57203060e-02 -2.21450664e-02
 -4.12453413e-02 -4.62464802e-02  6.42174706e-02  1.52704224e-03
 -4.80067432e-02  3.97582091e-02  9.65878833e-03  1.71938576e-02
 -5.83124999e-03 -3.79048660e-02 -1.52810952e-02 -1.79750081e-02
  6.17843978e-02  2.72360537e-02  4.85576503e-02 -4.04841378e-02
  4.57562059e-02 -1.45092430e-02  3.17377336e-02 -1.28830671e-02
 -4.53046896e-02  2.97535043e-02  4.92879786e-02  2.27898993e-02
 -3.76512446e-02  2.45939684e-03 -2.83152573e-02  4.51782979e-02
 -2.78700273e-02  2.36125663e-02 -2.10681781e-02  9.99662746e-03
  1.74078101e-03 -3.94030549e-02  4.74720001e-02  3.42399813e-02
  9.48365312e-03 -4.23754305e-02  2.75322273e-02  5.76401455e-03
  7.85365608e-03 -3.59352957e-03  3.22018750e-02  1.20222662e-02
 -1.93248340e-03 -8.11189786e-03 -1.46026714e-02 -3.97366732e-02
 -5.32824099e-02  1.95613094e-02 -3.46278287e-02 -4.60699499e-02
  1.61620211e-02  4.87585776e-02  1.82314757e-02  4.13485616e-02
 -3.63734066e-02  2.52210740e-02  1.25810215e-02  2.78781001e-02
  2.92031411e-02 -1.28311710e-02 -6.54934533e-03 -3.63574028e-02
  1.20817786e-02  2.89856270e-02  3.55355777e-02 -3.07296775e-02
  1.52210109e-02 -4.44778055e-03  3.85581329e-02 -2.51714569e-02
  8.08553956e-03 -3.06021068e-02 -5.48316306e-03  2.63320170e-02
  8.86496715e-03  2.61386279e-02  1.91343147e-02 -2.34265724e-04
  2.24993657e-03  3.89785655e-02  4.93715797e-03  3.27097178e-02
 -5.09235226e-02  3.89871635e-02  3.29670757e-02 -3.92396050e-03
  3.21626216e-02  1.86591744e-02 -2.18560211e-02 -8.23978055e-03
  1.89099446e-05 -1.91176981e-02 -2.07786169e-02 -1.59991272e-02
  1.76039878e-02 -1.98337063e-02 -5.15115308e-03 -4.60894853e-02
  1.13989701e-02 -3.36614773e-02  3.52134407e-02  3.63048986e-02
 -2.62050182e-02  8.54677893e-03  4.53474745e-02 -1.53171131e-03
 -2.09187567e-02 -4.75467481e-02  4.38071303e-02  3.05450391e-02
  4.24554721e-02  6.02127099e-03 -6.43803403e-02  3.88297811e-03
 -2.51167472e-02 -2.14316081e-02 -5.01911864e-02  1.57290790e-02
  1.53484177e-02  1.45519394e-02 -5.10269888e-02  3.30830999e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_27/kernel
[[ 0.09090005  0.09977282  0.03000396 ...  0.01530307  0.11982358
  -0.04914333]
 [ 0.04899614 -0.04823646  0.06660996 ...  0.09568    -0.12558001
   0.14408469]
 [ 0.11613605 -0.00424542 -0.14389206 ...  0.03222448 -0.00172082
  -0.02328936]
 ...
 [-0.09070677  0.03913841 -0.03104562 ...  0.07893298 -0.05327374
   0.12345292]
 [-0.10605975 -0.09704371  0.08807279 ... -0.03994658  0.03424571
  -0.03224358]
 [-0.08201624 -0.06514244 -0.02549405 ...  0.00576374  0.10130206
  -0.07534748]]
tensor_name:  TemporalFusionTransformer/time_distributed_28/bias
[-3.43701914e-02  5.32603413e-02 -2.17525680e-02 -1.24683548e-02
  1.41709046e-02 -6.70327665e-03 -2.92808153e-02  4.25207807e-04
  1.97197739e-02 -1.27195846e-02  3.70427668e-02 -4.42386270e-02
 -5.83301298e-02  3.69915031e-02  9.07390844e-03 -9.81053617e-03
 -1.35220457e-02  6.93852035e-03  6.18184246e-02  2.89499182e-02
  3.35710235e-02  1.59283876e-02 -3.43570709e-02  2.33464278e-02
 -2.54482049e-02  2.09742058e-02 -4.09695096e-02  4.23061699e-02
  1.91724263e-02 -2.76005324e-02  2.67052976e-03 -1.06632197e-02
  6.40224963e-02  3.06762177e-02 -1.38230808e-02 -3.20369303e-02
 -1.12297777e-02 -3.11302450e-02 -5.45141567e-03  1.95229836e-02
 -2.13706377e-03  1.76462717e-02 -1.66904069e-02 -3.86561938e-02
  8.19941110e-04 -1.02177471e-01  2.65090470e-03  4.01253812e-02
 -3.54703143e-02  9.02159698e-03  2.86614839e-02  2.02270448e-02
  1.93951298e-02  2.45775357e-02  3.12927216e-02 -3.61831114e-02
  4.22358662e-02 -1.13835288e-02  5.01296541e-04 -1.60706684e-03
  5.78158477e-04  1.43637620e-02  5.05993888e-02  3.80843207e-02
  2.67495611e-03 -8.73483531e-03 -3.04967929e-02  6.35728333e-03
  4.07916568e-02 -3.00287046e-02  2.30492111e-02 -1.05401026e-02
 -2.60934681e-02 -2.93754563e-02  2.68454012e-02  2.52339672e-02
 -6.01450307e-03  1.88370347e-02  8.26681126e-03  9.25720576e-03
 -4.44998965e-02  4.25675251e-02  6.92191068e-03 -2.01680139e-02
 -3.64539288e-02  2.30129771e-02 -3.19416299e-02 -3.25845219e-02
  1.85987763e-02 -3.46463323e-02 -4.23928127e-02 -5.86876161e-02
 -1.06235975e-02 -3.17509025e-02  1.05247695e-04  8.11936427e-03
  2.25167815e-02  6.09326474e-02 -2.11094040e-02  3.06196958e-02
 -8.19910839e-02  2.30359321e-04  8.36691447e-03  3.54103483e-02
 -3.71911866e-03  3.12865968e-03 -7.80080957e-03 -3.85081396e-02
 -9.61446576e-03  7.58775277e-04  8.92208889e-03 -2.52154078e-02
 -1.31475488e-02 -2.23664697e-02  2.21611448e-02 -3.89033649e-03
  6.53815418e-02  5.40335625e-02 -3.19230072e-02 -2.11946703e-02
 -1.33841233e-02  1.75065994e-02 -4.22447287e-02 -4.03291807e-02
  1.04922848e-02  6.47676289e-02  2.11065616e-02  5.38636558e-02
 -1.29595220e-01  3.84804830e-02 -3.16396430e-02 -3.02776434e-02
 -4.27791774e-02  9.52422433e-03 -2.03503072e-02  3.58421748e-05
 -4.55120653e-02  5.07445373e-02  2.99268141e-02 -6.72244886e-03
  5.08508533e-02 -4.94605824e-02  5.63144509e-04  3.36693488e-02
 -1.85535494e-02 -3.39125395e-02 -6.03198595e-02 -2.42649354e-02
 -8.44053831e-03 -1.12037724e-02  5.69415791e-03  1.02569787e-02
  3.10086571e-02 -2.29983982e-02  2.69333608e-02  6.34142291e-03
  2.36657243e-02 -2.71525495e-02  2.35315505e-02  3.29609513e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_28/kernel
[[-0.01071713 -0.10575006  0.04136468 ... -0.03632325  0.04540681
   0.05101663]
 [ 0.02969692 -0.07172779  0.15858662 ...  0.07664123 -0.09954389
   0.14622046]
 [ 0.03184656  0.03855296 -0.02919166 ...  0.0449553  -0.11556689
  -0.04132704]
 ...
 [ 0.04680421  0.01919525 -0.16709262 ... -0.10226808 -0.05918622
  -0.03657111]
 [-0.00360817  0.06386529  0.04684087 ...  0.10274652 -0.06978658
   0.02676842]
 [-0.02424678  0.08642693 -0.16038948 ...  0.08199209  0.10124549
  -0.08784069]]
tensor_name:  TemporalFusionTransformer/time_distributed_29/bias
[-1.6367506e-02  6.7195212e-03  9.6503214e-04 -2.4302928e-02
 -3.6699072e-02 -7.2261788e-02 -6.6166818e-02 -4.9841609e-02
 -8.3240215e-03 -5.6611434e-02 -4.4039857e-02 -3.2603338e-03
  7.9045799e-03 -3.5449252e-02  1.3949483e-02 -2.0361925e-02
 -8.8197403e-02 -5.1257897e-02  4.7243413e-02 -3.5612233e-02
  6.6721089e-02 -1.1179645e-02  8.9540100e-03  1.7214373e-02
 -4.4598483e-02 -1.6595157e-02 -1.0053387e-02 -2.1216407e-02
 -4.2549752e-02 -2.8808935e-02 -3.7322879e-02 -3.8296428e-02
  9.1490336e-03 -2.5411829e-02 -3.0564807e-02  3.1244677e-02
 -2.2391401e-02 -3.9371774e-02 -2.7381435e-02 -5.1716703e-04
 -4.6716221e-02 -1.0420055e-02  8.6020632e-03 -4.0056413e-05
 -2.0310884e-02  1.1733724e-01 -3.9938215e-02 -3.8474899e-02
 -3.4163199e-02  2.0913078e-02 -1.1761212e-02 -4.0061884e-02
 -4.1972224e-02 -3.1826958e-02 -5.1550392e-02  9.8578669e-02
 -1.0213370e-02 -6.1486628e-02 -2.7269034e-02  1.6796501e-02
 -2.0404233e-02 -2.8800383e-02 -1.3863734e-02  8.2398476e-03
 -4.5685649e-02 -7.6340646e-02 -1.2869114e-02  1.1673867e-02
 -3.1654250e-02 -8.1723621e-03 -2.1017946e-02 -3.3083722e-02
  1.1854102e-02 -3.0925319e-02 -7.6319084e-02 -3.2641653e-02
 -5.6691997e-02 -1.8764114e-02 -3.5992682e-02 -6.9833346e-02
  2.3365824e-02 -1.9448450e-02 -3.5922546e-02  3.3558216e-02
 -1.7384877e-02  4.6117675e-02 -2.3047322e-02 -4.1946147e-02
  1.3851220e-02 -3.5395969e-02 -1.6340243e-02  6.1914373e-02
 -1.5934819e-02 -2.6812518e-02  5.6025088e-02 -2.3784558e-03
 -3.5741579e-02  2.4652682e-02 -1.1362780e-03  7.0618875e-03
  9.2571609e-02 -4.9760491e-03 -3.1529296e-02 -3.2122657e-02
 -2.0030625e-02 -3.9897889e-02 -7.1254812e-02 -1.6698495e-02
 -4.0811807e-02 -5.1417984e-02 -2.0662718e-02 -4.3696735e-02
 -2.0217083e-02 -3.9009262e-02 -3.7247669e-02 -1.9904520e-02
 -2.9269846e-02 -1.5449682e-02 -4.2622890e-02  3.5834402e-02
 -6.3208230e-02 -5.7014905e-02 -1.3406075e-02 -3.5896953e-02
 -6.9172464e-02  1.6628586e-02 -2.2508619e-02  3.3665717e-02
  5.2834097e-02 -2.8587349e-02 -2.1278612e-02  3.0582270e-03
 -1.4481809e-02 -3.9129421e-02 -2.1536656e-02 -1.8992784e-02
  2.5403909e-02 -1.3379394e-03 -5.1725231e-02 -4.7291904e-03
  7.1893871e-02  2.8465718e-02 -5.3977635e-02 -4.8195746e-02
  3.1475832e-03  8.4128760e-02  1.6546639e-02  6.0543562e-03
 -8.9829892e-02 -1.7984580e-02 -4.6175018e-02 -4.2320766e-02
 -3.1518761e-02 -5.7111192e-02 -1.7375519e-02 -1.3345209e-02
 -3.5446655e-02 -2.9741436e-02 -2.6531765e-02 -3.5648923e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_29/kernel
[[-0.0623487   0.05303861  0.1539514  ...  0.02751539  0.06443675
   0.17476514]
 [-0.01568013  0.00358492  0.07702416 ...  0.038102    0.09698375
   0.07667573]
 [ 0.01243547 -0.09978582  0.01664977 ... -0.02835715 -0.0948761
   0.15298547]
 ...
 [ 0.04737056  0.02205804  0.08031184 ... -0.16122945  0.00189137
  -0.01915627]
 [-0.05332652 -0.05883318  0.07126313 ...  0.03641679  0.10747355
  -0.01396876]
 [-0.11223104 -0.12832235  0.06097117 ... -0.04508192 -0.09983078
  -0.12279942]]
tensor_name:  TemporalFusionTransformer/time_distributed_3/bias
[-0.01821646 -0.01610249  0.01120408 -0.03598551 -0.00409311 -0.03515612
 -0.08698289 -0.0282375  -0.00135955 -0.00336594  0.01050658  0.05174975
  0.01438097  0.03483738  0.0246209   0.04164374 -0.02647833  0.03701122
 -0.00964686 -0.01075812 -0.00533335  0.06663699 -0.01665881 -0.06073726
 -0.02532992 -0.0151585   0.06823792  0.00757158  0.01006888 -0.02869172
  0.06758792 -0.01327818  0.00540334  0.04625016 -0.0110521   0.04944944
  0.05029036  0.0083308   0.05860649  0.04256796  0.04619953  0.0358498
 -0.01693929  0.0193211  -0.02892145  0.02157829 -0.0379636   0.07113557
 -0.00374591  0.02881425 -0.01324972  0.09292088  0.01622013  0.00980759
  0.04484922 -0.02338483  0.04228708 -0.07218149  0.00282678  0.05934022
 -0.02682379 -0.00471663  0.02560647  0.02343465 -0.01802723 -0.0457524
  0.01435197 -0.05415532  0.00607805  0.04409374  0.00283555  0.00172851
  0.05178979 -0.00742228  0.02972389 -0.06645734  0.01564105  0.04200986
  0.01900234 -0.02046626 -0.02302298  0.00028865  0.01425848  0.00827387
  0.02955534  0.05338933 -0.039124    0.03027956  0.01982766 -0.04491038
  0.02111262 -0.030671    0.04907994 -0.04028694 -0.00341355 -0.06139414
  0.00392903  0.02746614  0.02856409 -0.03157585 -0.04578618  0.0034464
  0.00382537  0.08425319 -0.07125495 -0.02935213  0.00068119 -0.0426076
 -0.08207756  0.01134372 -0.02326111 -0.02635648 -0.03640771  0.00776576
 -0.0053607   0.04591705  0.02414166 -0.02451796 -0.01519304 -0.02205178
 -0.03009633  0.00814012 -0.05438639 -0.02398934  0.05686568 -0.00304511
  0.01500515 -0.02281144  0.02535424  0.01150771 -0.01514048 -0.0127937
  0.00576276 -0.05227677 -0.04273221  0.0269042  -0.00136462 -0.02765722
  0.00969546  0.02124836 -0.01485973 -0.00505569 -0.0626374  -0.03451745
  0.0212331   0.02224224 -0.04480203 -0.03778969 -0.00331823  0.00517662
  0.00330778  0.00286636 -0.03063917 -0.05346707  0.02425169  0.00889721
  0.03536723 -0.03026601 -0.0033843   0.05494108]
tensor_name:  TemporalFusionTransformer/time_distributed_3/kernel
[[ 0.02637859  0.02812994  0.16703029  0.125517   -0.02238038  0.08311107
  -0.04868799 -0.09276445 -0.03946117 -0.12375386 -0.18604024 -0.06629371
  -0.08796818 -0.07822456 -0.02697269  0.19317245  0.14291772 -0.09999517
  -0.07591119  0.03031411 -0.06986433  0.0546433  -0.13099816  0.1639795
  -0.21869884 -0.09795613  0.16515371  0.16135123  0.00312355  0.0069966
   0.08220231 -0.06713545 -0.01127746 -0.01736141 -0.06397343 -0.02621713
   0.05038061  0.02809594  0.07028579  0.06967214 -0.0113217  -0.03777354
   0.17571104  0.04387158  0.02330569 -0.14039047  0.09337186 -0.03544527
   0.01043882  0.04779512 -0.108888    0.16777954 -0.11566126  0.06959696
  -0.03850326 -0.0488207  -0.16479345 -0.04350154 -0.10829685  0.16374615
   0.10606933  0.04011442  0.06786937  0.13598578  0.00280662  0.05057545
   0.0230031   0.13342334  0.07905877  0.16487467  0.14933512 -0.12819627
   0.0648861  -0.16306403 -0.01124533  0.05542511  0.13794303  0.23501304
  -0.18842092  0.01894195  0.11970655 -0.19239931  0.1474693   0.02998076
  -0.05438735  0.03936371 -0.07993516  0.1014098   0.01121871  0.05284121
  -0.09031772  0.0461029  -0.07721126  0.03749267 -0.10032499  0.00292356
   0.05296099 -0.11408446  0.00054054  0.10318269 -0.1837539  -0.10672549
   0.18460512 -0.06876876 -0.18784873  0.10305692  0.00591854 -0.1638839
  -0.01348734  0.17859899  0.06861567  0.02138647  0.01638657 -0.07470217
  -0.0712576  -0.14717337 -0.15198804 -0.01586951  0.1461449  -0.0197374
   0.03240676  0.11192916  0.06121692 -0.17580625 -0.13939935 -0.06802095
   0.12827797 -0.18928865 -0.00322701  0.0607594  -0.14450918  0.00542834
  -0.20967658  0.10560136 -0.08676934  0.12538037 -0.00080744  0.10491867
   0.11767865  0.01712119  0.05496372  0.02407843 -0.03324399  0.11481202
   0.08981126  0.05023682 -0.10975284 -0.0912313  -0.08841038  0.08225995
  -0.17596504  0.07604198 -0.17369331 -0.03992603 -0.07247926  0.05421101
   0.15307547 -0.00414574  0.11008572 -0.11733112]]
tensor_name:  TemporalFusionTransformer/time_distributed_30/bias
[-0.01307212 -0.05591575 -0.05696697 -0.00373673  0.01262478 -0.06433205
 -0.01854845 -0.05286134  0.05276792 -0.00837241 -0.02438937 -0.03165387
 -0.02931662  0.00186129  0.02965637 -0.01233864  0.00069451 -0.06008286
  0.03763978 -0.00206019 -0.00148221  0.0152337   0.00208891 -0.00347463
 -0.01594168 -0.00470613  0.01132956 -0.03087223 -0.01522966  0.03334262
 -0.05779829 -0.04566495  0.00649451  0.00632091 -0.00659887  0.04729129
 -0.05351724  0.0028003   0.00905165 -0.00208898  0.03471772 -0.05210523
 -0.02587922  0.01937994 -0.05360609 -0.04245166  0.01035016  0.00931375
 -0.00644514 -0.03018567  0.03573393 -0.00719617 -0.00227302 -0.00370888
  0.04344584 -0.0152981  -0.04715679  0.03786131  0.01304376 -0.08533499
  0.00101452 -0.00020967 -0.05711603  0.00046445 -0.02256623 -0.04415911
  0.01173476  0.03060907 -0.02250359  0.03007898 -0.01299848 -0.05786616
  0.03126572  0.02997789  0.00192078 -0.01812537 -0.06573238 -0.03825061
 -0.02514519  0.0127449  -0.01899439 -0.03058245 -0.02183136  0.0288294
  0.02004146 -0.00995025 -0.00050235  0.0027505   0.01389065 -0.01012239
 -0.04998046 -0.04517004 -0.03162348 -0.02714829 -0.00572328  0.00519432
 -0.04604898 -0.05063838  0.00390134 -0.01629694 -0.05314267 -0.01609615
 -0.03702791  0.00067536  0.04052719 -0.01389126 -0.03717504  0.01937927
 -0.02864539  0.00049885 -0.01990182  0.00617027 -0.05087867 -0.04623048
  0.0199009  -0.04309379 -0.04634826 -0.01565939  0.0070219  -0.06683712
 -0.05730527 -0.01070472 -0.01246187 -0.02808876 -0.06202902 -0.0054752
  0.02909742 -0.03333694  0.01877718 -0.0053261  -0.02307367  0.01476658
 -0.0058592   0.02725168  0.0434      0.03993106 -0.04005364  0.02259586
  0.00358959 -0.01100864 -0.02958127  0.00299049 -0.0361721  -0.02526989
  0.00207062 -0.01866558 -0.01000026 -0.0562399  -0.02207074  0.00340747
  0.00284407 -0.01142247 -0.0243972  -0.05732577  0.02690138  0.01313524
  0.00873854  0.0524686  -0.03919698  0.01273643]
tensor_name:  TemporalFusionTransformer/time_distributed_30/kernel
[[-0.09168014  0.03742472  0.02461408 ...  0.16516511 -0.11132371
   0.06483553]
 [-0.01451748 -0.00598532  0.15039524 ... -0.0338522   0.10428535
  -0.04015159]
 [-0.04350688  0.15202227  0.01404187 ... -0.14570741 -0.0604764
  -0.06367657]
 ...
 [-0.08557509  0.00176757 -0.07616989 ... -0.02055587  0.05668892
   0.11021582]
 [-0.07413773 -0.03180482 -0.11269556 ... -0.11544718  0.0613476
   0.02943471]
 [ 0.1316864  -0.03943763  0.14243199 ... -0.06789732 -0.12505491
  -0.03516603]]
tensor_name:  TemporalFusionTransformer/time_distributed_31/bias
[-4.6098106e-02 -3.4535296e-02  1.5575541e-02 -1.8619588e-02
  7.2136400e-03  6.0190246e-03 -3.7855901e-02 -2.0564256e-02
  2.0607198e-02 -1.5099864e-02  1.4492860e-02  1.4612191e-02
 -2.9822487e-02 -5.7490636e-03  3.7623378e-03 -8.0942381e-03
 -4.4563785e-03  3.5217118e-02 -1.9637093e-02  1.1613895e-02
 -4.3456506e-02  1.3898248e-02  5.3709369e-02 -3.1831652e-02
  2.4395926e-02 -8.3026923e-03 -4.3088779e-02  2.7233744e-02
  2.9705290e-02  2.8547656e-02 -2.7128698e-02 -2.1992030e-02
  2.0838384e-02 -9.6208453e-03 -5.3365774e-02  2.1437874e-02
 -2.8569739e-02 -2.0656334e-02 -1.7076388e-02 -2.7994972e-02
  3.1877600e-02 -1.9385554e-02 -5.9286170e-03  2.3719145e-02
 -3.3345655e-02 -1.1770066e-02 -2.4144740e-03  1.6337115e-02
  4.1487936e-02 -9.8230951e-03  1.3522074e-02 -2.2434996e-02
  4.0170878e-02  9.7109377e-03  5.0440270e-02 -9.1171786e-03
  6.9327511e-02  2.1300206e-02 -2.9738715e-02  5.1273003e-02
  2.3497408e-02  2.5817091e-02  8.7996330e-03  2.7099960e-02
 -7.5900694e-03 -3.5048414e-02  8.5233664e-03  6.8769954e-02
  4.6657980e-03  2.8761560e-02  5.1449709e-02 -9.0037078e-02
  2.2273138e-03  2.5791565e-02  2.8216686e-02  1.0458990e-02
 -7.1974300e-02 -5.0264578e-03  3.6810972e-02 -3.1811430e-03
 -2.1227125e-02  2.9928068e-02  1.8906176e-02 -2.3943625e-02
  3.3194676e-02 -3.6655512e-02 -4.4118784e-02 -2.0217661e-02
  5.0805048e-03 -2.9525582e-02 -2.4022989e-03  3.0321323e-03
  1.1510657e-02 -3.6749593e-03  3.6211580e-02 -1.4680818e-02
  3.6312602e-02  1.5969927e-06  4.1629151e-02  2.4365872e-02
  3.1867363e-02  3.0375944e-02  4.8651256e-02  4.8787955e-02
  5.5827327e-02 -5.8888786e-02 -1.3150182e-02  1.5652800e-02
 -4.7493421e-02 -1.2219439e-02 -1.4599492e-02  3.3416912e-02
 -1.1057471e-02  6.6032596e-02 -8.5211908e-03 -2.3161512e-02
  3.1509973e-02  4.6680771e-02  4.6950832e-02  4.2332383e-03
 -1.7820884e-02  2.3034675e-02 -4.0239636e-02 -3.3281367e-02
  1.9817198e-02  4.5269754e-02 -3.3947643e-02  1.9881973e-02
  3.9020032e-02 -2.1821263e-03  4.4705432e-02  5.2609672e-03
 -2.5797471e-02 -5.3588487e-03  2.4500629e-03  6.6511962e-03
 -1.8675363e-02  5.3674905e-03  5.5869883e-03  3.2084484e-02
 -1.5258944e-02  3.2262560e-02  2.4885323e-02  2.0989070e-02
 -5.4675452e-02 -1.0302838e-02  5.6501333e-02 -1.1536674e-02
  7.4808300e-02 -4.2015336e-02 -1.4563910e-02 -1.2191299e-02
  1.7605420e-03 -4.5601685e-02  1.8347802e-02 -5.3018383e-03
 -4.5266662e-02  3.7785493e-02  2.8794635e-02 -7.4901223e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_31/kernel
[[-0.016752   -0.01061265  0.01615014 ... -0.06607267  0.10333789
  -0.0023068 ]
 [-0.08262438 -0.08329178 -0.02769233 ... -0.06939548  0.00680107
   0.08528966]
 [-0.09029442  0.09258556  0.05477986 ...  0.02503674 -0.1293233
  -0.01367293]
 ...
 [-0.04532977 -0.1154388   0.03822459 ...  0.08987018 -0.07435076
  -0.04771071]
 [-0.06964873 -0.01581419  0.10515989 ... -0.05632493 -0.09032434
   0.0137496 ]
 [-0.12331104 -0.12171873 -0.08857505 ... -0.11623184  0.1381656
  -0.08824877]]
tensor_name:  TemporalFusionTransformer/time_distributed_32/bias
[-0.04130142  0.04863546 -0.01638079 -0.01221186  0.01693052 -0.01491901
 -0.03200046 -0.00668521  0.0129627  -0.00655222  0.0311242  -0.04213121
 -0.04174327  0.03523865  0.01053104 -0.02647297 -0.02084799  0.01272097
  0.05024439  0.02155075  0.03459714  0.01583039 -0.01238761 -0.0089326
 -0.00448102  0.01726034 -0.02980408  0.04239801  0.02140741 -0.02191945
 -0.00401029  0.00857261  0.05954541  0.04092289 -0.01231982 -0.02174565
 -0.00919604 -0.02766727 -0.01997392  0.01940339 -0.00048058  0.01822083
 -0.01221342 -0.02888443  0.01363798 -0.08521096  0.00968904  0.03934735
 -0.0303753   0.00586826  0.00836275  0.01422748  0.0094171   0.0334402
  0.03330328 -0.04274667  0.02846041 -0.00703041 -0.00669662 -0.00502178
 -0.01444832  0.00322018  0.04073236  0.03227104 -0.00728623 -0.00251345
 -0.02267182  0.01980735  0.04108214 -0.04876724  0.01688882 -0.01367401
 -0.01992453 -0.03814366 -0.00167432  0.0228884   0.00891075  0.02078668
  0.00407122  0.01213361 -0.02258119  0.04118205  0.00459148  0.00888423
 -0.02454093  0.0415553  -0.03202635 -0.03710862  0.03490939 -0.03338886
 -0.05489106 -0.05887277 -0.02121457 -0.02542861  0.00568743 -0.00439117
  0.01887169  0.08834816 -0.00800416  0.04200837 -0.07895719 -0.02548335
  0.01050855  0.0291191   0.00090066 -0.00256919 -0.00871013 -0.03447349
 -0.01324854  0.00852048  0.02400023 -0.02995404  0.00572977 -0.02353768
  0.00488992  0.00317672  0.04670249  0.05172766 -0.02766538 -0.02610491
  0.00394665  0.01808879 -0.03708967 -0.02649873  0.01524891  0.05206737
  0.0171551   0.05119567 -0.10666054  0.04150446 -0.04302572 -0.02857607
 -0.04083773 -0.01969752 -0.01284025  0.00243706 -0.05495254  0.03790205
  0.03069972  0.00350715  0.04722096 -0.03184421 -0.0115149   0.02355257
 -0.02335571 -0.01517587 -0.03213209 -0.02019629  0.00338438 -0.02130347
  0.01086994  0.00783482  0.00818564 -0.02911575  0.02839213  0.02330902
  0.02213614 -0.01460675  0.02462269  0.01316227]
tensor_name:  TemporalFusionTransformer/time_distributed_32/kernel
[[-0.07904201 -0.10609823 -0.13726006 ... -0.09520712  0.06736207
  -0.03158029]
 [ 0.04983283 -0.13996157  0.02741983 ...  0.01881653 -0.06688283
  -0.02544915]
 [-0.11568753  0.1015913  -0.02410302 ... -0.0108477   0.00508211
   0.00166395]
 ...
 [ 0.088685   -0.01701569 -0.05523506 ...  0.00896753  0.01009496
  -0.11221979]
 [-0.1395119   0.01701163 -0.08452939 ... -0.05093194 -0.06895306
  -0.09699239]
 [ 0.03656505 -0.11250998  0.14724284 ... -0.00491523  0.14362036
   0.16225109]]
tensor_name:  TemporalFusionTransformer/time_distributed_33/bias
[-3.8645267e-02  2.7197334e-03 -7.8921746e-03  5.4938059e-02
 -8.1740193e-02  1.6736697e-03 -3.6747415e-02 -1.1174995e-01
  3.4111023e-02 -2.4276193e-02  5.8720359e-03 -2.0385185e-02
 -9.4985133e-03 -1.3497643e-02 -1.3034691e-02 -2.1953050e-02
 -4.6101496e-02  2.2237314e-04  1.2245801e-02 -1.8152317e-02
  4.5627374e-03 -2.2999533e-02 -2.1968855e-02  4.5909923e-02
 -4.3991935e-02 -1.0414704e-02 -2.5589840e-02 -3.0852871e-02
 -7.7297717e-02 -3.1142430e-02 -2.1361038e-02  3.3441845e-02
  6.1313685e-02 -3.6479101e-02 -1.6401211e-02 -9.5656421e-03
  7.2931021e-02 -3.4576461e-02 -1.0689538e-02 -1.2971627e-02
 -2.4204541e-02 -2.4456035e-03 -6.3565999e-02  3.4920049e-03
 -8.9338303e-02  5.1301137e-02 -9.4348304e-03  7.3534045e-03
 -5.6364264e-02 -4.2367220e-02  9.6536599e-02 -8.1985801e-02
  7.5674383e-03 -1.0439546e-05  3.9865160e-03  1.4023739e-01
 -2.1174205e-02  3.8815495e-03 -1.1524846e-02  6.4659216e-02
 -1.7730547e-02 -3.3880726e-03  3.5328902e-02  8.2024764e-03
 -1.3926772e-03 -3.7174106e-02 -3.1609949e-02 -1.7857244e-02
 -2.2832027e-02  2.0762403e-03 -3.5040895e-03 -2.7004730e-02
  4.3343052e-02 -2.0686604e-02 -2.6623817e-02 -3.3222590e-02
  8.1200249e-02  4.5934985e-03 -3.4206264e-02 -3.3719260e-02
 -1.1861404e-02 -1.5101368e-02 -2.5690009e-04  9.5990889e-02
 -1.3453526e-02  2.1077614e-02 -4.9602259e-02 -2.4152175e-02
 -2.9733075e-02  1.4934781e-02 -3.8712861e-03  1.6678574e-02
 -9.9994121e-03  1.4696325e-02 -2.0674333e-02 -2.1640116e-02
 -3.2595679e-02  4.8238710e-02 -8.3879959e-03  5.6145463e-02
  8.1747271e-02 -1.2609588e-02 -9.2358617e-03 -1.2578327e-02
 -8.1058638e-03 -4.6759967e-02 -8.9851730e-02  7.2091860e-03
 -6.6553488e-02  1.6479960e-02 -2.3099114e-03 -2.6959063e-02
 -3.3411648e-02  5.6306436e-03 -4.8262361e-02 -2.3397287e-02
 -1.3456545e-02 -2.1396475e-02 -1.6751412e-02  2.6430978e-02
  3.0963117e-02 -2.5826044e-02  1.1576553e-02 -1.1825620e-02
 -5.3112268e-02  2.5644476e-02 -6.8187237e-02 -2.6712983e-03
 -1.3291474e-02 -1.8311024e-02 -3.1923681e-02  5.5764387e-03
 -1.7995412e-02 -2.8738473e-02 -2.5089920e-02  4.4842614e-03
  3.4550775e-03  1.2017997e-02 -1.8764084e-02 -2.4528302e-02
  2.5087332e-02 -2.4412053e-03 -1.2166623e-03 -4.2973779e-02
  5.3883284e-02  1.7653169e-02  4.9281981e-02 -4.3291029e-02
 -2.1501832e-02 -3.4099442e-03 -6.3093111e-02 -4.9821371e-03
 -6.2821455e-02 -7.3173635e-02  4.0164459e-03  3.5144143e-02
 -1.5648175e-02 -3.3789001e-02  4.1118683e-03 -6.6625744e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_33/kernel
[[ 0.0767486   0.09595176  0.09295542 ...  0.06959911 -0.02636393
   0.05990861]
 [-0.11113784 -0.08366055 -0.02103567 ...  0.00360978  0.0564991
  -0.02433057]
 [-0.05167826 -0.10457318  0.02955612 ... -0.02906245 -0.04465777
   0.0795727 ]
 ...
 [-0.0492036  -0.10923326 -0.1163218  ... -0.12952368 -0.06356481
  -0.11606099]
 [-0.03647793 -0.02976065  0.12644847 ... -0.05739488  0.06609945
  -0.15757579]
 [ 0.1231951  -0.03889976 -0.07341927 ... -0.05200403 -0.04763947
   0.13637951]]
tensor_name:  TemporalFusionTransformer/time_distributed_34/bias
[ 0.05134015 -0.06179138 -0.05901241 -0.00391736  0.03767819  0.08238719
  0.07396866  0.03402446  0.00602362 -0.0203884   0.0596915  -0.07057188
  0.05723735 -0.055673   -0.00442322  0.07384785 -0.00963388  0.01921146
 -0.00678181  0.04876946 -0.0751606   0.00199869  0.01395574 -0.06597296
  0.01099672  0.04240342 -0.04539854 -0.0167514   0.02577379 -0.07387376
  0.01383454  0.00165901 -0.10002645  0.00440905  0.00441894  0.06242169
 -0.05495458  0.01087126  0.03297851 -0.03517109 -0.06364272 -0.04034616
 -0.07069003 -0.00145161  0.04727982  0.01209167  0.00041717 -0.00926964
 -0.07116913  0.02925668 -0.02018076  0.03811499  0.01867361  0.01242521
  0.04640431 -0.03080021  0.0401465  -0.02587878 -0.00774252  0.0123492
 -0.106146   -0.00268915  0.06154658  0.02784218  0.0339494   0.00595241
  0.01802065  0.06080939  0.01874565 -0.00693841 -0.0010422   0.00599992
 -0.09035388  0.0153269  -0.00507143  0.04396011 -0.08385227  0.04559609
 -0.04326328  0.01131436 -0.00203976 -0.00875166  0.01272938  0.00038456
 -0.04396515  0.01754754  0.01016884 -0.09242482 -0.01018209 -0.0236027
 -0.00237294 -0.00428928 -0.01387404  0.042691   -0.07537444 -0.03733599
  0.00596216  0.02213861 -0.00663932 -0.02614283  0.01570002 -0.03774965
  0.03307619  0.01462681  0.00796998 -0.00388952  0.01257539 -0.02829723
 -0.01329195 -0.00367865  0.00814541 -0.09214804  0.03145406  0.03197845
 -0.02552327 -0.08122288 -0.1035025  -0.03818188  0.07999022 -0.04189228
 -0.01163557 -0.01261458  0.05371713 -0.01161436  0.07108095  0.02065377
 -0.07241696 -0.07150643  0.03408895 -0.07887898 -0.09011348  0.0281347
  0.01935181 -0.00032326 -0.05551489  0.03226388 -0.04593771  0.00792657
  0.02831081  0.01057316 -0.03334532 -0.03769517 -0.07936729  0.08020896
  0.08048672  0.05896997 -0.00016541  0.01040467 -0.0123929  -0.0512125
 -0.03770686 -0.08593603 -0.03981754  0.00818558  0.02497337  0.03594692
  0.01466132  0.00192568 -0.03081784 -0.10478707]
tensor_name:  TemporalFusionTransformer/time_distributed_34/kernel
[[-0.06498326  0.0264383  -0.06798428 ... -0.11419245 -0.03137791
  -0.0847495 ]
 [-0.13561754  0.0814108   0.13920812 ... -0.06144157 -0.06558137
   0.16506313]
 [ 0.11211111  0.05105094  0.10085298 ... -0.09312481 -0.13724713
   0.17873321]
 ...
 [-0.10536803  0.13220353 -0.01972814 ... -0.01137135 -0.08465561
   0.14872706]
 [ 0.01524057  0.022515    0.10138595 ... -0.11760852 -0.16162585
   0.13658786]
 [ 0.0130898  -0.06806752  0.07646367 ...  0.11530071 -0.18532497
   0.04797873]]
tensor_name:  TemporalFusionTransformer/time_distributed_35/bias
[ 0.11678971  0.00278917  0.09406251  0.03579118  0.05624916 -0.07424629
 -0.0719262   0.05127846 -0.02520408  0.00732431  0.03850418 -0.00188
  0.07487664  0.02520859 -0.02651581 -0.066889    0.03047508 -0.04911288
  0.03751449  0.03343239  0.03737948 -0.04099089 -0.00460168  0.008852
 -0.04029957 -0.02646859 -0.01623622 -0.06237434 -0.03664321  0.08744436
  0.01740705  0.08634266  0.01549199 -0.05012366 -0.06657042  0.05475767
  0.05672815 -0.02257361  0.06036272  0.04976225 -0.00635862  0.00809374
  0.03856499 -0.01973064 -0.04814603 -0.09815356  0.04616184 -0.01827427
  0.06157541 -0.04870438 -0.06683842  0.04299887  0.05187689 -0.00194262
 -0.09524071  0.0426154  -0.04985777 -0.0409076  -0.04066574 -0.04102278
  0.02664418  0.07472099 -0.06383786  0.05961515  0.05887383 -0.07178716
 -0.00496631  0.03615756 -0.11249141 -0.04351424 -0.06748725 -0.00742638
 -0.00472605 -0.03191777 -0.09956843 -0.03995692  0.02248852 -0.0214746
 -0.00274155  0.00785825  0.0320259   0.02066    -0.06898791  0.05431253
 -0.02066032 -0.0261293  -0.08773147 -0.02520549  0.02314851  0.02609435
 -0.00997533 -0.01031362 -0.01848715  0.05933684  0.03185558 -0.00456237
 -0.01648901  0.06464194  0.07250036 -0.03716843  0.05213908  0.08158032
 -0.027171    0.03396098  0.08423863 -0.01486756  0.08059081  0.00868293
 -0.02591752  0.05862481  0.06870938  0.01096182  0.02267345 -0.05570039
  0.06791459 -0.09525821  0.05895042  0.07797401 -0.00461499  0.0662275
  0.01204139  0.05464581  0.03857299 -0.00902665 -0.05137698 -0.01051359
  0.06598122  0.07612266  0.06740886 -0.04974832  0.05528749 -0.05939046
 -0.01857028  0.00799016 -0.00020821 -0.0030083   0.0657547  -0.04514388
  0.10482569 -0.09893212  0.05786097 -0.04875128 -0.06589615  0.11319661
 -0.01572941  0.03060583  0.00508961  0.07434773  0.06813828 -0.02170837
  0.0234471   0.02517344 -0.02768571  0.09820437  0.05391921  0.00614258
 -0.01839793  0.05963572  0.04717876 -0.02338955]
tensor_name:  TemporalFusionTransformer/time_distributed_35/kernel
[[-0.05078552 -0.12754007 -0.07626289 ...  0.03088847 -0.05781887
   0.01884555]
 [-0.03908206  0.07977513  0.07228729 ... -0.11409066 -0.0015544
  -0.05589584]
 [-0.11750569  0.01376726 -0.00776443 ...  0.04731172 -0.11560033
   0.01157297]
 ...
 [-0.08000424 -0.11127636 -0.05962698 ... -0.01107442  0.0653643
   0.08271511]
 [-0.1457248   0.01997634  0.08115862 ... -0.17552054 -0.00288155
  -0.12763071]
 [-0.11994395 -0.05837433 -0.17550789 ... -0.13690823 -0.11679997
   0.13588482]]
tensor_name:  TemporalFusionTransformer/time_distributed_36/bias
[-1.90779213e-02  3.00042611e-02  2.91364873e-03  1.03772134e-02
 -7.52359396e-03 -4.03317101e-02 -4.14756387e-02 -8.92517790e-02
 -1.00976838e-04  6.54218569e-02  2.47402079e-02 -1.71156563e-02
  1.99919268e-02  2.19644140e-02 -6.51381444e-03 -2.45826431e-02
 -5.86368218e-02  1.98124144e-02  1.61382388e-02 -5.21005923e-03
 -8.89126025e-03  1.07658710e-02 -1.32167786e-02 -3.76764163e-02
 -2.25728541e-03  8.02844241e-02 -2.13138815e-02  3.77333984e-02
  5.21459766e-02 -3.88891622e-02  7.03956634e-02  1.35186268e-02
  4.04692814e-02 -1.84792131e-02  2.17104964e-02 -2.94607803e-02
  1.17835971e-02  1.42678805e-02 -2.05268450e-02 -2.68044807e-02
  1.23422011e-03  3.83579433e-02 -6.69499114e-02 -1.37572421e-03
 -3.51829745e-04  3.58088352e-02 -2.06949897e-02  2.89564934e-02
 -3.19922119e-02  5.09177074e-02  3.93493101e-03  6.47490323e-02
  4.63562133e-03  1.11936685e-02  2.30144672e-02 -9.73012939e-04
  1.40165687e-02 -3.05984728e-02  9.94245708e-03 -2.84020007e-02
  1.58661045e-02 -1.11394760e-03  5.66889008e-04 -1.61497444e-02
  2.55195871e-02 -2.63799261e-03  1.00289565e-02 -1.63547171e-03
  7.38554727e-03 -4.47559394e-02  1.00472756e-02 -1.51500944e-02
  1.36350719e-02 -2.98159216e-02 -5.75569086e-02  3.46421190e-02
  4.49328944e-02  4.51042391e-02  2.14753002e-02  7.66776577e-02
 -5.59688658e-02  1.16823090e-03  8.75150226e-03  5.59813604e-02
 -6.80734450e-03 -6.05671247e-03 -2.34975014e-02 -3.85433137e-02
 -1.52163371e-01 -5.16030118e-02 -3.66861038e-02  2.60824542e-02
 -2.25780942e-02 -3.32791195e-03 -4.41363156e-02  3.76180336e-02
  2.23173131e-03  1.76289193e-02  4.01267409e-02  3.05830035e-05
  2.66992189e-02 -2.01861411e-02  2.43649054e-02  5.17289676e-02
 -2.40891110e-02 -4.85778339e-02  4.54932675e-02 -2.31990032e-02
 -3.43297347e-02  4.53827754e-02  7.54466420e-03 -2.07716525e-02
 -2.44479142e-02  1.31949201e-01 -4.33033034e-02 -2.31552739e-02
 -2.83356775e-02 -2.37581623e-03 -4.49506752e-02 -2.13440899e-02
  2.78953202e-02 -2.39982940e-02 -2.08008699e-02  2.88302638e-03
  4.18129489e-02  1.09388621e-03 -2.31646430e-02  4.71787527e-02
  6.56690970e-02  2.57299673e-02 -3.70185971e-02 -4.38370630e-02
 -2.82880068e-02 -2.50543877e-02 -1.35508105e-02  1.15622976e-03
 -2.21471395e-02 -4.07520980e-02  3.22467312e-02  2.41219625e-02
  2.16587875e-02  2.01206130e-04 -5.77386916e-02  2.93352157e-02
 -1.19763678e-02 -3.85298654e-02 -1.68169905e-02 -3.33717726e-02
  4.88610975e-02 -2.13267207e-02 -5.01744635e-02  5.84487291e-03
 -5.57349026e-02 -4.29774038e-02  2.30189562e-02 -5.55886654e-03
  3.14319134e-02 -2.15476081e-02  4.65637818e-03  5.32006286e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_36/kernel
[[-0.07576501  0.00300502 -0.02127215 ... -0.03160927  0.04584211
  -0.0144195 ]
 [-0.13977481  0.06322835  0.12691504 ... -0.00216558  0.06535155
  -0.06113631]
 [-0.03124094  0.10256242 -0.11621692 ... -0.08497258 -0.11646248
   0.03374511]
 ...
 [ 0.09318016 -0.07630984  0.04522585 ... -0.10860289  0.11087354
   0.04548492]
 [-0.10032198  0.12143306  0.00645511 ...  0.08582655 -0.07493939
  -0.12312905]
 [ 0.06226968 -0.16329528 -0.08660582 ... -0.04965921  0.0913564
   0.10498506]]
tensor_name:  TemporalFusionTransformer/time_distributed_37/bias
[-0.06460309 -0.04138963 -0.1332709   0.00094614 -0.0245568  -0.11835583
 -0.01232719  0.09815903 -0.04762729  0.07131086  0.13280696 -0.02097601
 -0.09934928 -0.06662492 -0.07275321 -0.02061587  0.07053959 -0.04113112
 -0.08363655 -0.01486036 -0.07163744 -0.02344866  0.00470632  0.00934537
 -0.09811437  0.15989661 -0.09639797 -0.00285098  0.14747448 -0.00672854
  0.06846588  0.03216124 -0.0572686  -0.04953848 -0.08245537  0.03525113
 -0.03739794 -0.06373516 -0.05685937 -0.00610408  0.07831341 -0.03771736
 -0.04793394 -0.03327821 -0.06413325  0.17089768 -0.18769312  0.06154728
 -0.04546157  0.05331123 -0.10486524  0.10002986 -0.0382673   0.0446954
  0.00612898 -0.06063897 -0.07786417 -0.00058297 -0.12559924 -0.07383844
 -0.10628112 -0.10584395 -0.04621201 -0.06855854 -0.04318768 -0.06679598
  0.04435141 -0.22618295 -0.01401191  0.0231083  -0.03167868  0.01680413
  0.02048431 -0.04781689  0.01669348 -0.07775301 -0.05274914 -0.01752821
 -0.06842754  0.07973465  0.01126033 -0.08572929 -0.09147324  0.03955165
  0.11190291  0.0415376  -0.01174962 -0.05429082  0.0486083   0.02086358
 -0.00880759  0.06451938 -0.06397777 -0.08672833  0.07821266 -0.07603963
 -0.08936762  0.04579281  0.02356469 -0.08009096 -0.04442171 -0.03309144
 -0.06197192 -0.02999699 -0.0735384  -0.05966995  0.26759258 -0.0413623
 -0.04928712 -0.03957148 -0.024748   -0.03305744 -0.03026142 -0.00691342
 -0.04897556 -0.04610797 -0.07320298 -0.02509693 -0.05757748 -0.07188811
 -0.08731335  0.08501691 -0.06289412  0.03626558 -0.00704843 -0.11491317
  0.21877427 -0.00615488  0.12721504 -0.06108258 -0.01178267  0.23319045
 -0.1012276   0.00471285 -0.00512326 -0.00936432 -0.01206809  0.02681862
 -0.00069694 -0.03107946 -0.0236656  -0.08057916  0.05323556  0.00697918
 -0.10100749 -0.01304455 -0.01901241 -0.01550317  0.01266095 -0.04288786
  0.0542328  -0.09137389 -0.0230099  -0.01381983 -0.03505472  0.0344769
  0.00028673 -0.00626662  0.01897876  0.03948274]
tensor_name:  TemporalFusionTransformer/time_distributed_37/kernel
[[-0.15802398  0.05588594  0.07549278 ...  0.04210562  0.10952
   0.21761228]
 [ 0.1297464   0.05398893 -0.10590307 ... -0.05350182  0.050746
  -0.02572742]
 [ 0.03579162 -0.09285843 -0.16078961 ...  0.05811312  0.01891772
   0.07091329]
 ...
 [-0.02702243  0.09186416 -0.03524036 ... -0.06963429  0.10389385
   0.07265949]
 [-0.02872928 -0.00828467 -0.16443285 ... -0.05374988 -0.04058212
   0.0870852 ]
 [ 0.12954405  0.09063248 -0.06090304 ...  0.08365607 -0.06372737
  -0.04396226]]
tensor_name:  TemporalFusionTransformer/time_distributed_38/bias
[-0.00164095  0.01043521 -0.00926191  0.00847187  0.01946273 -0.00016807
 -0.00392992  0.00291116  0.00889069 -0.01834822  0.02416156  0.00282605
 -0.00367198  0.0138536  -0.0062926   0.00664661  0.00688811  0.00399181
  0.01449401  0.00789903  0.01431848 -0.02630556  0.02589241  0.0085285
  0.015994    0.00050882 -0.00170168 -0.00386548 -0.00279067  0.00687106
  0.01201001 -0.00907482 -0.00651439  0.00292978  0.01867861  0.02163667
 -0.01680696  0.01140758  0.01363798 -0.00445146 -0.01263944  0.01998684
  0.0050112   0.00836551  0.01739085  0.00838736  0.00773462 -0.01134737
 -0.0077683   0.01447902  0.01241995 -0.00234445 -0.00839838  0.02872557
 -0.01380043 -0.01431221 -0.00637675  0.02311725  0.0416357  -0.01062346
 -0.00823185  0.00556014 -0.01041051  0.00874599  0.02057008  0.00080691
 -0.00064976 -0.01485974 -0.00645606 -0.00667126  0.00897438  0.00812423
  0.03019954 -0.01059555  0.01423773 -0.00138587 -0.00693172 -0.00711495
 -0.00531451  0.00083336 -0.01014692  0.00570254  0.01152746 -0.01979241
 -0.00890204 -0.01013567  0.00226589 -0.00790408  0.00994691 -0.00727849
 -0.00188813 -0.02244296  0.00916046  0.00138854 -0.0117271  -0.00523017
  0.01016522  0.02545712 -0.00687123  0.02906739  0.00995212  0.02014638
 -0.00817836  0.01866611  0.00284559  0.01646843 -0.0019022  -0.00458471
 -0.0100157  -0.00713438 -0.00547996  0.00054353 -0.01665879  0.00406981
 -0.01141007 -0.01957364  0.01413338 -0.01568935 -0.00460695 -0.01396015
 -0.00669719 -0.00108782 -0.0195038   0.00325824  0.0186018  -0.00223549
 -0.00460551  0.01236077 -0.01476209  0.00078401 -0.00850678  0.01036151
  0.0018904  -0.00927405  0.0037891   0.02650221 -0.0121616   0.00927496
  0.00402143  0.00588423  0.01613586 -0.01121479  0.03450013 -0.01566337
 -0.00213456  0.00741267  0.00992286 -0.00625211  0.03025237  0.00526918
  0.02588922  0.00202061 -0.0018277   0.01060329  0.01532675 -0.00394391
  0.01461706  0.01806903 -0.00437748  0.00896647]
tensor_name:  TemporalFusionTransformer/time_distributed_38/kernel
[[ 0.04976539  0.11190994  0.01295127 ... -0.01284319 -0.08133277
  -0.00434715]
 [-0.07855803  0.12425689 -0.07876038 ... -0.08890943 -0.00773685
  -0.0557504 ]
 [-0.07916577  0.03178474 -0.00684093 ...  0.14336316 -0.11479676
   0.07178287]
 ...
 [-0.02907201  0.00736018  0.07741569 ... -0.01826434 -0.13716926
   0.02363755]
 [-0.09764609 -0.01253964  0.10835396 ...  0.13063124 -0.01995377
  -0.1252068 ]
 [-0.02870464 -0.0958213  -0.06846809 ... -0.07419165 -0.08045429
   0.10181101]]
tensor_name:  TemporalFusionTransformer/time_distributed_39/bias
[ 6.09449763e-03 -1.79107219e-03 -6.83280267e-03  2.62061600e-03
  5.37941698e-03 -1.27407128e-03 -2.95494712e-04  2.92038750e-02
  9.74954851e-03  9.81577579e-03  1.13975443e-02 -8.47252924e-03
 -2.80767065e-02  2.48696171e-02 -3.04985624e-02  2.48469096e-02
 -3.73284239e-03 -1.21716568e-02  6.02407567e-03 -1.18104310e-03
  1.40098901e-02  1.33053819e-02  1.26504479e-02 -1.43499617e-02
 -1.80879561e-03 -9.96326376e-03 -9.88369621e-03  1.73454713e-02
  6.43303152e-03  1.05454456e-02  3.35603245e-02  3.53548415e-02
 -5.47771249e-03  2.41207909e-02  2.33643819e-02  2.05595866e-02
  2.78379594e-06  4.29937709e-03  1.37248514e-02 -2.59827934e-02
  3.19780991e-03 -7.23447651e-03 -2.83626150e-02  9.79997870e-03
  1.23632262e-02  1.20202638e-02  8.38017277e-03  4.14332142e-03
  4.59636375e-03 -1.69926435e-02 -1.48430336e-02 -5.36416518e-03
 -1.73499640e-02 -2.03266460e-02 -3.87066044e-03  5.14137419e-03
 -3.43926698e-02  2.69969534e-02 -1.11202365e-02 -1.24096461e-02
 -2.49780975e-02 -3.02303093e-03 -8.96873418e-03 -2.68216617e-03
  5.10933734e-02 -3.27629559e-02  1.35133006e-02  5.60907507e-03
  2.05132272e-03  1.38323987e-02 -2.42628604e-02 -3.78246163e-03
 -1.75483264e-02  1.05080977e-02  8.02717730e-03  1.85509250e-02
  7.80821778e-04 -2.80041657e-02  2.32909224e-03 -9.43832193e-03
 -6.71389920e-04  6.89780479e-03  3.18749226e-03 -6.43997360e-03
 -2.37225043e-03 -1.16677815e-02 -1.87750137e-03  3.27731320e-03
  5.51033672e-03 -1.92569401e-02  1.57343522e-02  3.50078605e-02
  4.75462247e-03 -1.12696607e-02 -7.15067284e-03 -1.34803879e-03
  9.44609102e-03 -2.14516651e-02  1.97706912e-02  1.39008695e-02
 -2.65868902e-02  9.34549514e-03  1.06628397e-02 -2.20363261e-03
  6.27416372e-03  3.32819223e-02  3.00735258e-03 -1.83088873e-02
  3.08901817e-03 -1.38264438e-02  8.73746537e-03 -2.55368836e-02
 -6.18469017e-03  1.24989776e-02  1.04099764e-02 -1.03139067e-02
  8.19921121e-03 -1.89778488e-02 -5.34785539e-03 -2.06029462e-03
  1.08604059e-02  1.91705544e-02 -4.16244101e-03 -4.16684290e-03
  1.53493532e-03 -3.47071439e-02  4.90251649e-03  5.35535533e-03
  1.49684702e-03 -2.08883192e-02  6.78111240e-03  2.59599579e-03
  3.77212726e-02  5.36939409e-03 -2.03232989e-02  7.45868660e-04
 -6.40957709e-03 -5.96379302e-03 -2.13635452e-02  2.79471278e-03
 -7.70855509e-03 -2.90971063e-02  8.25315993e-03 -2.16183923e-02
  1.56900398e-02  2.18691453e-02  2.17184890e-02  3.73820239e-03
  9.99882538e-03  1.47709316e-02  2.02772748e-02  1.08721778e-02
 -1.58270188e-02 -4.05976623e-02  4.20759106e-03 -1.64367184e-02
  2.56045479e-02 -5.26301656e-03  1.05772344e-02 -5.69679774e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_39/kernel
[[ 0.08333208 -0.02185713 -0.00491695 ...  0.07680636 -0.13429116
   0.01530805]
 [ 0.01041017  0.03459778 -0.03276039 ... -0.05398738 -0.07838269
   0.07463141]
 [ 0.01792411  0.0954861   0.04649143 ... -0.07807611  0.0528176
  -0.03303893]
 ...
 [-0.08524796  0.07491536 -0.1177635  ...  0.03798767 -0.03645109
   0.05552367]
 [ 0.05103038  0.02738099 -0.12303504 ...  0.03471526  0.02073019
   0.04199222]
 [ 0.11799254 -0.06909683  0.0378256  ...  0.07915032 -0.03232951
  -0.11447705]]
tensor_name:  TemporalFusionTransformer/time_distributed_4/bias
[-0.03286634  0.02257124  0.00310908 -0.07862911  0.00293695 -0.03915999
 -0.049142    0.0081792   0.06247763 -0.03361977 -0.03878478 -0.03145981
 -0.08294253  0.05384901 -0.05121926  0.02758099 -0.02686074  0.09018815
  0.00195859  0.0280075   0.05419199  0.01179482 -0.02113522  0.04273199
 -0.00391453 -0.0129728   0.02212068  0.06463918  0.01957842  0.01551857
  0.03095933  0.00237741  0.03804079  0.01781986  0.01486217 -0.01469173
 -0.04967863 -0.05373909  0.04673114 -0.02359852 -0.0135415  -0.03874828
 -0.07219572 -0.00766548 -0.00014443 -0.09079113  0.04649913  0.01427534
  0.0140988   0.05287217 -0.00713296  0.02168926  0.06030492  0.06543597
  0.02008072 -0.06715295  0.08937962 -0.0565417  -0.01327962  0.04784937
  0.03462374 -0.02624395  0.00765923 -0.00508489  0.01940271 -0.03045028
  0.01768011 -0.00089647  0.04194299  0.03653308  0.01978256 -0.04260793
 -0.03471261 -0.0532316   0.01579234 -0.0124617   0.03044915  0.04241406
 -0.02302312 -0.00076676 -0.02512502 -0.01277664  0.04020116  0.02384281
  0.00569252  0.00057217 -0.0484334  -0.00390166  0.00270203 -0.03392979
 -0.05935572 -0.05541275 -0.00911488 -0.09818673  0.02878685 -0.01810086
 -0.0038674  -0.00946045  0.07211207  0.03437829 -0.01026359  0.01039071
 -0.07816324  0.06603682 -0.02117815 -0.07309407  0.00408102 -0.07520323
 -0.0663811   0.04343505 -0.01125334 -0.04703089 -0.0432197  -0.07701325
  0.03692145 -0.00292616  0.05980585  0.05303579 -0.0268144  -0.04711605
 -0.00598791 -0.05589502 -0.0208857  -0.04313682 -0.0466539   0.0294586
  0.0238519   0.07185799 -0.00138734 -0.04607694  0.02161684 -0.0458474
 -0.04362096 -0.06765708  0.02126216  0.06267853 -0.06377339 -0.06176981
  0.0300216   0.01410828 -0.02510706 -0.02478261  0.00720909 -0.03240959
 -0.02952517 -0.0073712   0.00423743  0.0040289  -0.03758272 -0.02184991
  0.03415373  0.04635091 -0.02872956 -0.00400202  0.04956951 -0.02148529
  0.02029824  0.0009438   0.05332937  0.0426525 ]
tensor_name:  TemporalFusionTransformer/time_distributed_4/kernel
[[-1.63700044e-01  1.50388956e-01  5.72304614e-02 -7.28269815e-02
   2.34345794e-02  1.42394513e-01  4.19965619e-03  1.64157197e-01
  -2.26213839e-02 -5.77817820e-02  1.61866900e-02  8.81668702e-02
  -9.53316689e-02 -2.03197412e-02 -1.05252400e-01  1.88690722e-02
   7.68393278e-02  2.34058257e-02  1.34987712e-01  1.30589858e-01
   3.62374112e-02  6.44457191e-02  1.88721828e-02 -1.60917521e-01
  -8.01750124e-02 -6.74157515e-02  8.72139931e-02  1.91022474e-02
  -6.58509657e-02  3.64032350e-02 -7.14379549e-02 -1.10786059e-05
  -3.35932635e-02  1.28717065e-01 -1.22367054e-01  4.90521863e-02
  -3.02778240e-02 -1.02920569e-01  9.67163295e-02  9.39581096e-02
  -7.18288198e-02  2.17961110e-02 -1.15818538e-01  1.61884740e-01
   1.43499792e-01 -1.26091182e-01  1.00726530e-01 -1.09585084e-01
   6.72186241e-02  1.55773982e-02  6.69259205e-03 -3.50992195e-02
   1.67161584e-01  2.55851354e-02 -5.48186190e-02 -6.80045560e-02
   3.26146334e-02 -2.76287831e-02 -1.42520770e-01 -1.77778769e-02
   1.22803979e-01  1.55464681e-02  4.18415805e-03  8.12684447e-02
  -1.66643336e-01 -1.36412308e-02  2.88543012e-02  3.85222472e-02
   2.30251858e-03  3.50030921e-02  7.89776668e-02 -8.54507089e-02
   8.20372030e-02  1.18044928e-01 -1.34389997e-01  3.68139446e-02
   1.50428653e-01 -7.08349496e-02 -1.22435182e-01  1.15833525e-03
   1.09049506e-01  4.59991917e-02 -1.13573365e-01 -9.06157121e-02
  -7.43237063e-02  1.43264323e-01  5.02775908e-02 -4.50359285e-02
   1.50377452e-02  5.95750706e-03  1.39238685e-01 -7.41126761e-02
  -1.34817541e-01 -1.15357086e-01  1.32381260e-01 -7.23908544e-02
   1.32044524e-01  7.51716271e-02  5.33762984e-02  4.32075188e-02
   1.36777908e-01 -6.57827929e-02  1.11017503e-01 -6.85011372e-02
   4.04837430e-02  1.61353320e-01  5.52788265e-02  1.33095279e-01
  -6.18423754e-03  1.95418913e-02  8.75083432e-02 -1.39688283e-01
  -4.10895534e-02 -5.93992462e-03  1.31509779e-02 -7.05797449e-02
  -2.75718849e-02  7.12337419e-02  8.65158290e-02 -1.48190200e-01
  -4.38833944e-02  7.89078623e-02 -2.52499823e-02  4.06875201e-02
  -1.07163496e-01 -1.33318052e-01 -1.19560800e-01  5.64960623e-03
   6.10345714e-02 -8.11912194e-02 -6.02677017e-02  5.66187538e-02
  -1.02608666e-01 -1.38361067e-01  9.95173603e-02 -3.31058465e-02
  -1.17014632e-01 -6.51928261e-02 -1.40883282e-01 -7.67849609e-02
   1.15812318e-02 -7.87479579e-02 -5.23745790e-02 -1.99433621e-02
  -4.17958498e-02  1.43040076e-01  5.53980991e-02  1.60902470e-01
   4.83143106e-02 -1.11145616e-01  3.15782428e-02  3.21331900e-03
   4.22729924e-02 -1.06967516e-01  1.60800256e-02  9.29347277e-02
   1.54143155e-01  1.09324396e-01 -6.80224821e-02 -1.36113361e-01]]
tensor_name:  TemporalFusionTransformer/time_distributed_40/bias
[ 0.02728418  0.01594174  0.00834735 -0.00137164  0.0033761   0.00418022
 -0.01951454 -0.07547729  0.00120091  0.00481566  0.01355008  0.00440339
 -0.01580378  0.00946219 -0.02067543 -0.01606278 -0.01919728 -0.00201471
  0.02763919  0.01726709 -0.0171675   0.02173251 -0.0092172  -0.02613551
 -0.00759096  0.00999206  0.00309812  0.00438049  0.01105278 -0.00829957
  0.02126444  0.00627444  0.01163007  0.02061462  0.00275554  0.01150315
  0.00108631 -0.02688296  0.01969526  0.0194246  -0.02661563 -0.0047245
  0.01493176  0.00922543  0.00593844 -0.02249229 -0.04152425  0.0194241
  0.00960519 -0.01318901 -0.00529885  0.01529965  0.01546161  0.00369946
  0.03160173 -0.00394776  0.01868683 -0.04120901  0.00593774 -0.00333273
  0.00439174  0.0144532   0.0076491  -0.00954636 -0.02281982  0.00945204
  0.03503265  0.01621471 -0.00012191 -0.02478175  0.01854809 -0.00298873
  0.01835144  0.00289168 -0.02464633  0.00160267  0.00199045  0.03193041
  0.00711307  0.02825093 -0.0047076   0.0060299  -0.00647644  0.02440486
 -0.01871222  0.01076952  0.02955748 -0.00626463 -0.01145204 -0.02371836
 -0.00926954  0.00676685  0.00730883  0.0057868  -0.01283497 -0.01020823
  0.00457038  0.02058984  0.04284867 -0.02134036 -0.01548905  0.00442809
  0.02873955  0.01604874 -0.01477765 -0.00309137  0.03380547 -0.03982766
 -0.00094458 -0.00015989 -0.00377671  0.0007154  -0.01256036  0.00557579
 -0.00712302 -0.00726646  0.01830618 -0.00913818 -0.01417151 -0.00817729
 -0.00777445 -0.01269628 -0.02474232 -0.01665898 -0.00070092  0.01235403
  0.00909284  0.02197793 -0.01213796  0.01038059 -0.00751916  0.03826043
 -0.02164805 -0.01139838 -0.02420752 -0.00509164 -0.00932851 -0.01077993
 -0.00117376 -0.01820527 -0.00780688 -0.00775877 -0.01666995  0.00779425
 -0.00091018  0.00149798 -0.01923704 -0.02943996 -0.00783597 -0.02684007
  0.00495775 -0.00416767  0.02745899 -0.01799626  0.02168232 -0.02538495
  0.0114817   0.00046609  0.01561218  0.01916096]
tensor_name:  TemporalFusionTransformer/time_distributed_40/kernel
[[-0.02070754 -0.05038462  0.02273075 ... -0.09523838 -0.1137594
  -0.01714924]
 [-0.00666774  0.09259719 -0.03920958 ... -0.06297328 -0.0411036
  -0.1094211 ]
 [ 0.0155906  -0.05577845 -0.16734186 ...  0.02999578 -0.07837342
   0.03210372]
 ...
 [ 0.00988255 -0.0780604   0.00810386 ...  0.11497057  0.10254028
   0.05041011]
 [-0.07097738 -0.04140761 -0.05992045 ...  0.12571605 -0.01576071
   0.09558838]
 [ 0.07302479  0.11280111 -0.02787371 ...  0.05484587 -0.08002404
  -0.01947549]]
tensor_name:  TemporalFusionTransformer/time_distributed_41/bias
[-5.20058684e-02  4.88172323e-02 -2.62798909e-02  1.25526567e-03
 -3.63842584e-02 -1.71992574e-02  8.54392536e-03  1.36680931e-01
 -6.63747117e-02  3.58671211e-02 -4.39776033e-02 -5.03074974e-02
 -3.76835801e-02 -1.99865699e-02  5.25225839e-03  3.43496054e-02
  4.51966701e-03 -1.87755991e-02 -6.77617174e-03  2.89201103e-02
  6.61496893e-02  8.65553990e-02 -1.51536260e-02  1.31789923e-01
 -5.69540560e-02 -3.43499780e-02 -1.26448907e-02 -3.01848333e-02
 -3.67581509e-02 -2.16367319e-02  2.59842090e-02 -2.92270742e-02
 -5.22579849e-02 -4.14443351e-02  1.09442661e-03 -6.63215593e-02
 -2.18418892e-02 -1.41371982e-02 -9.40068043e-04  6.56172931e-02
  2.62143295e-02  1.50910299e-02 -3.46688032e-02 -3.59672382e-02
 -2.09798627e-02  2.37169024e-02  9.28319171e-02 -2.17761602e-02
 -3.25179212e-02 -2.76369173e-02 -1.44040603e-02 -3.85378860e-02
  4.85589867e-03 -2.53892653e-02 -9.92678758e-03 -2.77873408e-02
  8.17930512e-03  1.47055224e-01 -4.46795747e-02  9.76024643e-02
  8.27510003e-03 -5.43702170e-02 -7.18478188e-02  4.98469956e-02
  3.10218818e-02 -5.05383797e-02  2.01196089e-01 -8.81718006e-03
 -7.56551102e-02 -1.55745540e-02 -2.31979676e-02 -3.08097228e-02
 -2.87147071e-02 -1.02906665e-02 -3.89987454e-02 -4.01227735e-02
 -2.21564043e-02 -4.98580262e-02 -2.74536218e-02  2.48278484e-01
 -1.23008694e-02 -2.70517264e-02 -3.58220935e-02 -1.42277626e-03
 -2.13852767e-02 -6.50152424e-03  4.32084575e-02 -5.72503172e-02
 -7.35496543e-03 -2.68333424e-02  3.60363759e-02  2.92810109e-02
 -1.90916527e-02 -2.58255117e-02 -3.79490070e-02  1.81946233e-02
  6.12358283e-03  1.73766576e-02  4.34866361e-02  3.38124968e-02
  1.66935138e-02 -2.28744764e-02 -3.41950357e-02 -4.74523269e-02
  1.64494012e-02 -4.74041030e-02  4.57032584e-04 -5.42884413e-03
 -1.69460308e-02 -3.46226841e-02 -8.65650922e-02 -4.31814492e-02
  7.40533505e-05  1.20686051e-02  7.62855681e-03 -3.89612019e-02
 -1.85822248e-02 -2.92033306e-03 -6.45344891e-03 -7.59524480e-02
 -2.87022050e-02 -4.83176578e-03 -9.50456038e-03 -3.87030169e-02
 -2.75572054e-02 -4.32191938e-02  5.61251938e-02 -2.23451275e-02
 -2.97260880e-02 -4.26758155e-02 -2.61199195e-04  5.70705272e-02
 -3.18965018e-02 -2.70567872e-02 -3.49495490e-03  2.27754638e-02
 -2.84345541e-02  3.20476829e-03 -6.51177019e-03 -3.97542911e-03
 -9.41216387e-03 -5.50016249e-03  1.33680636e-02  3.57347657e-03
 -3.05218697e-02 -1.79028567e-02 -2.41630245e-02  1.17909193e-01
 -1.77859198e-02 -1.61145721e-02  5.87774217e-02 -5.81125952e-02
 -7.52706546e-03  1.29375413e-01  3.64187546e-02 -3.80738229e-02
  3.00737005e-02 -2.94434782e-02 -5.59691675e-02 -1.91167668e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_41/kernel
[[-0.08749716 -0.01378027  0.04856033 ...  0.00760183 -0.13300577
   0.00524689]
 [ 0.06188959  0.01456251 -0.08259627 ... -0.1282293  -0.09946544
  -0.10872359]
 [ 0.08668353 -0.05529221  0.11146645 ...  0.01573508  0.09086207
  -0.04415828]
 ...
 [ 0.06469031 -0.05263974 -0.00306837 ...  0.10574961  0.03165796
  -0.11072634]
 [-0.09741729 -0.12107685 -0.13575234 ...  0.0406187   0.04474942
  -0.00121984]
 [-0.14150889 -0.00328856 -0.06699493 ...  0.02551642  0.0763656
  -0.04018525]]
tensor_name:  TemporalFusionTransformer/time_distributed_42/bias
[ 0.00315724 -0.03565025  0.00905434 -0.01800155 -0.03427453 -0.00453825
 -0.00702463 -0.03078912  0.00641123  0.00014549  0.00676493 -0.01132688
  0.03376936  0.01369817 -0.04406039 -0.00044703  0.01622554  0.03106907
 -0.03062259  0.0151041  -0.00814765 -0.04769672  0.0038563   0.03893015
 -0.04109767  0.00809088 -0.05294886  0.02016983  0.00238693  0.00146027
 -0.00049648 -0.01172856 -0.01826857  0.02240359 -0.04279375  0.01265793
 -0.05364778  0.01290569 -0.00679935 -0.00252649 -0.02005057  0.00370366
 -0.04458993 -0.01745693 -0.06481487 -0.03833365 -0.05660074 -0.00485868
 -0.0769543  -0.05494363 -0.0076792  -0.00680301  0.03534894  0.01042583
  0.00438421  0.01609503 -0.01552298  0.04096657 -0.0071204   0.02994362
 -0.05601586 -0.0118467   0.01562332 -0.05165919 -0.01840783 -0.02138497
 -0.00503162  0.00076129 -0.05723178  0.03038861  0.04919636  0.00361805
  0.01134376  0.04286188 -0.04343406  0.03780135  0.01159342 -0.00542488
 -0.04136201 -0.00855315  0.00754026 -0.00528404 -0.02375508 -0.01754973
  0.01985004  0.02650184  0.03317605  0.04210849 -0.00600253 -0.03734187
 -0.05302019  0.05562627  0.03655876 -0.06415044  0.00012812 -0.00078946
 -0.05520786  0.00026546 -0.01133144  0.00593446  0.00418767  0.00217033
  0.00180802  0.00658887  0.03567199 -0.00052937 -0.00245445 -0.01311226
 -0.00945488  0.00499763  0.03799653 -0.02632259  0.00478296  0.04812557
  0.00463791 -0.00919239  0.00753139 -0.03361324 -0.02544707 -0.01116059
  0.00788696  0.0027348  -0.02721863  0.01516084  0.02539401 -0.01143307
 -0.02174897  0.00263578  0.03574592 -0.03535038 -0.00296249 -0.00506041
  0.02985077  0.02707185  0.01330066 -0.02394907  0.01749442  0.02422187
 -0.00657945 -0.02062859 -0.00312623  0.00851454  0.00226379 -0.01065275
 -0.00054334  0.02501208  0.00081726  0.0007403  -0.03001718 -0.02082093
  0.00388396 -0.02952815 -0.04809208 -0.0246339   0.01073595  0.00735487
 -0.04159709 -0.01320901  0.00652403  0.00775045]
tensor_name:  TemporalFusionTransformer/time_distributed_42/kernel
[[-0.10456084 -0.15330048 -0.01010302 ... -0.08258428 -0.07025041
   0.0818968 ]
 [-0.0787321   0.03607926 -0.03822719 ...  0.02724235 -0.04031961
   0.02712697]
 [ 0.12804279  0.01442235  0.12907629 ...  0.07521685 -0.06662428
  -0.07359102]
 ...
 [ 0.0647861   0.10858785  0.07896971 ... -0.01599855 -0.02249332
   0.12134963]
 [-0.06129112  0.05363479 -0.01784412 ... -0.06298443 -0.02163759
   0.01536545]
 [-0.09702835  0.00835505  0.09724853 ... -0.01330844  0.12799996
   0.0321326 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_43/bias
[ 0.01362195 -0.01306875  0.00357349 -0.00449842  0.00359067 -0.02541238
 -0.01959318  0.02350416  0.01402558  0.04805331  0.03319981 -0.04473333
  0.00296879 -0.04155092 -0.06103756  0.01405691  0.02663434  0.00235388
 -0.05810913 -0.01294174  0.02419314  0.0317084  -0.00830781 -0.02404127
 -0.02375566 -0.0445287   0.00597235 -0.0473115  -0.00536022  0.01924997
 -0.04395534  0.05081048 -0.00952662 -0.04322485 -0.02803077  0.01811869
  0.04468787 -0.00162389 -0.06342052 -0.00804498  0.03326354  0.03934778
 -0.04616995 -0.05851093  0.01990725  0.03527761 -0.00577172 -0.01055128
 -0.02427799  0.00346213  0.02875577 -0.05298091 -0.02954287  0.0381357
 -0.04479156  0.03812664 -0.00894801  0.01475007 -0.03380338  0.03360089
 -0.03606069  0.02871286  0.02710043 -0.02218287 -0.026038   -0.03548566
  0.00852052  0.03268978 -0.00225     0.01530117  0.01930423  0.01223538
 -0.0218755  -0.05292866  0.0259122   0.0316134   0.00761369  0.05133639
  0.02730068 -0.03602553  0.06863868 -0.00254282  0.03870331  0.0055769
  0.03887798 -0.04194505 -0.03803639 -0.05928483 -0.00045726  0.00839169
 -0.01042254  0.02419829  0.0419682  -0.01511682  0.03855431 -0.02623469
  0.03370912  0.01978063 -0.03145276  0.01782848  0.01581947 -0.01980141
  0.03970586  0.04741735 -0.05634656  0.00018096 -0.04036207  0.01568271
  0.03733769  0.01276453  0.0485487  -0.01016392  0.00803648 -0.04266236
 -0.02088247  0.01436771  0.02555974  0.01017934  0.01797802  0.02139062
  0.04754701  0.00931581 -0.03018992 -0.04598685  0.01034173 -0.01001321
 -0.04740723  0.01100927 -0.03582566 -0.01434216 -0.04554754 -0.04011899
 -0.02897158 -0.01116497  0.01094222  0.01917137 -0.01431057 -0.02119682
 -0.02613145  0.00737288  0.00755239 -0.01761227  0.02225249 -0.02436607
  0.05801893 -0.04204698 -0.03181085  0.02644335 -0.02018286 -0.02442422
 -0.06622349 -0.03301838  0.00613017 -0.00166176  0.03518137 -0.05822868
  0.01457812  0.00551427 -0.03785744  0.0198069 ]
tensor_name:  TemporalFusionTransformer/time_distributed_43/kernel
[[ 0.10906769  0.06940455 -0.09573065 ... -0.09786419 -0.02188241
   0.06434304]
 [ 0.07251416 -0.02569165  0.01892424 ... -0.00967298  0.11949919
   0.00987294]
 [ 0.04630934 -0.01602838 -0.04068721 ... -0.05065037 -0.08459237
  -0.04312605]
 ...
 [ 0.04772665 -0.0513855  -0.04982827 ...  0.0243165   0.17329967
   0.1347885 ]
 [-0.01631346 -0.07026559 -0.0659659  ...  0.10899552 -0.05936166
  -0.02117745]
 [ 0.01317502 -0.06867395 -0.10577999 ...  0.08375246  0.0740535
   0.06048734]]
tensor_name:  TemporalFusionTransformer/time_distributed_44/bias
[ 0.04325755 -0.06753393 -0.06004646 -0.01540458  0.00646905 -0.03448625
 -0.02840261 -0.0347566  -0.04931171  0.03569636 -0.08493876  0.07745031
  0.0228341   0.00267491 -0.00301856 -0.03307899  0.03743104  0.05543545
 -0.01378161 -0.0616152  -0.0148552  -0.02845498  0.07726765  0.01049331
 -0.02361087 -0.00753815  0.01410831 -0.0557486  -0.02270406 -0.00518339
 -0.018279    0.02244098 -0.05698527 -0.05957029  0.01232836  0.06762959
  0.02623698  0.00635559  0.03936785  0.02470364  0.06753698 -0.01579667
  0.08991531  0.03430165 -0.07155117 -0.00580103 -0.00685553 -0.07319961
  0.02798693 -0.06294058  0.02829926 -0.09697692 -0.09148518 -0.03059751
 -0.00562717  0.04066433  0.02363039 -0.00072159 -0.07793052 -0.05970392
  0.05031858 -0.04832875 -0.00318379 -0.0699846   0.0220078  -0.0290543
  0.04715148 -0.08832193 -0.06872987 -0.01447197  0.05981891  0.00245752
 -0.01341546  0.01698849  0.00789389  0.00664127 -0.05201877  0.00421412
 -0.00180448 -0.01331234  0.0247922  -0.08893431  0.0470222   0.01516302
  0.01834977  0.01953826  0.0940401   0.11537621  0.07551452  0.04349507
  0.07908051  0.0133219   0.01806818  0.04466321  0.04488772 -0.02688333
  0.02074394 -0.00929992  0.04394839 -0.01161459  0.04437885  0.03034629
 -0.01435667 -0.03005365 -0.02526813 -0.02434854 -0.01690115  0.0090796
  0.10032319 -0.0021408   0.01061202 -0.01074847 -0.07317365  0.04300447
  0.13023137  0.01474223 -0.02419841 -0.03873044  0.04101861 -0.0003049
  0.00481857 -0.05253077  0.00516995  0.04343873  0.02054458 -0.10052741
  0.00189191 -0.04980647 -0.03018662  0.00959524  0.08138021 -0.02639654
  0.04836878  0.03211857 -0.01243483 -0.01328905  0.00742077 -0.09524693
 -0.04720988  0.007956   -0.05024364  0.03041782  0.06408539 -0.10313755
  0.01211294  0.08238847  0.0597676   0.0370441  -0.01638989 -0.02397648
 -0.00539305  0.02419484 -0.00093945  0.06458772  0.04689039 -0.02806138
 -0.04644653  0.02678002  0.00877963 -0.03942778]
tensor_name:  TemporalFusionTransformer/time_distributed_44/kernel
[[-0.0144225   0.00364799  0.02340804 ...  0.01260041 -0.04784583
  -0.04183355]
 [-0.03235142  0.0822875  -0.11761947 ... -0.11606577 -0.10723312
  -0.07374808]
 [ 0.1086674  -0.02240312 -0.06993984 ... -0.00452009  0.07776994
   0.04024174]
 ...
 [ 0.0975017   0.0902053  -0.04107548 ... -0.04613755 -0.07851256
  -0.01044761]
 [-0.12394816  0.10355926  0.03321924 ... -0.08726007  0.01856142
   0.08343283]
 [ 0.04003038  0.12374431  0.01444564 ...  0.01274278  0.05585385
  -0.08965222]]
tensor_name:  TemporalFusionTransformer/time_distributed_45/bias
[-3.71655710e-02 -1.08365770e-02  3.42951231e-02  7.86017533e-03
 -5.13052084e-02  1.77705213e-02  2.94923708e-02 -1.22670509e-01
 -3.93387824e-02  1.19608892e-02  2.14734748e-02  3.33954990e-02
 -3.05281989e-02 -1.18302032e-02 -4.61080372e-02 -6.12494200e-02
 -3.41249332e-02  2.25399937e-02 -3.53949219e-02  2.80106273e-02
 -3.96641083e-02  2.64702048e-02  7.68716307e-03 -4.31140289e-02
 -2.34484095e-02  1.85547993e-02 -3.65214124e-02 -3.85812600e-04
 -7.86652490e-02 -5.14510460e-02 -1.44302510e-02 -5.76390810e-02
  1.25503205e-02 -8.00879730e-04 -6.04923069e-02 -1.73141789e-02
 -6.15412667e-02 -6.89728782e-02 -3.73606011e-02 -6.93474710e-02
  3.98601256e-02 -2.22102422e-02  4.43974696e-02 -2.09787358e-02
  1.00745089e-01 -1.08456232e-01 -4.84896563e-02  1.85728539e-02
  1.11249927e-02 -4.74693161e-03 -4.40080091e-02  2.41315942e-02
 -7.96696986e-06 -8.22450873e-03 -8.16135108e-02 -2.29528616e-03
 -6.20838664e-02 -4.87799346e-02  2.35471223e-02 -3.68648171e-02
 -2.63984371e-02 -2.79206363e-03 -5.60626797e-02  2.58600190e-02
  5.91554772e-03 -1.63617097e-02 -8.18036199e-02  3.53743210e-02
  4.28980999e-02 -4.78243046e-02  7.70230144e-02 -5.03585711e-02
 -1.21852711e-01 -2.18143221e-02 -4.91435714e-02 -2.26353984e-02
 -2.08901260e-02 -9.60234255e-02 -5.91175482e-02 -9.77887139e-02
 -1.16362525e-02  6.94394559e-02  3.47150862e-02 -3.63926403e-02
 -2.82195304e-02 -6.38573393e-02  3.26375365e-02  4.50955331e-02
 -5.16315810e-02 -1.47280078e-02  1.18486928e-02 -7.28930682e-02
 -1.47927562e-02 -5.75853400e-02  2.34961901e-02 -2.47559301e-03
 -2.79157516e-02 -3.84616926e-02 -8.13234225e-02 -2.88317148e-02
 -1.53800715e-02 -6.31228834e-02 -2.39278637e-02  3.03527564e-02
  8.09095614e-03 -2.40046866e-02  2.79878499e-04 -1.06113097e-02
  5.86096160e-02 -7.79967830e-02 -5.91083951e-02 -3.82420048e-02
  5.92736900e-02 -1.26971751e-01  1.45171415e-02 -7.75834471e-02
 -7.20067397e-02  2.60730181e-02  1.32033322e-02 -8.81937239e-03
 -4.19757999e-02 -1.27973612e-02 -8.50720853e-02 -1.11815995e-02
 -4.05190326e-02  4.66768183e-02 -1.36207983e-01 -2.80832592e-03
 -7.87111074e-02  2.73033995e-02  3.58172357e-02 -6.09192252e-02
 -1.20926332e-02 -3.20752990e-03 -1.95903331e-02 -6.15254603e-03
 -8.94010626e-03  2.78536249e-02 -7.87985791e-03 -4.97123934e-02
 -2.59927288e-03 -2.71077752e-02  5.24601117e-02  2.24997923e-02
 -6.43602200e-03  1.67496018e-02 -6.17755391e-03 -1.72133185e-02
 -8.14556703e-02 -6.70247599e-02 -6.78893924e-02 -4.43169028e-02
 -9.56683531e-02 -2.04039421e-02  6.45407736e-02 -5.97688556e-02
 -1.20856315e-02  2.91253496e-02 -2.61913370e-02 -1.97635200e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_45/kernel
[[-0.13027765 -0.07687452 -0.03479332 ...  0.08608048 -0.15460378
   0.08358065]
 [ 0.02675283  0.07517309 -0.03684796 ... -0.0322668  -0.06288222
   0.06287178]
 [ 0.03471858  0.00683769 -0.07226598 ... -0.02513184  0.08878352
  -0.04355914]
 ...
 [-0.05275942 -0.11295284 -0.05745729 ... -0.10716752 -0.13231637
   0.07711999]
 [-0.05848221  0.03614428 -0.01527276 ... -0.15679766  0.15292266
  -0.07895873]
 [ 0.09161426 -0.10539738 -0.01025936 ...  0.06817967  0.03666819
  -0.11006852]]
tensor_name:  TemporalFusionTransformer/time_distributed_46/bias
[-0.03215503  0.1180618   0.00437688 -0.03216933  0.01215528 -0.10857302
 -0.0006704 ]
tensor_name:  TemporalFusionTransformer/time_distributed_46/kernel
[[ 0.07948589 -0.04786829 -0.00394813 ... -0.04530957  0.08533464
  -0.02522412]
 [ 0.02323788  0.02849249 -0.15454164 ... -0.07678048  0.05964794
   0.04260635]
 [ 0.04620796 -0.06258069  0.01251154 ... -0.01788488  0.1309198
   0.03689978]
 ...
 [ 0.04534462  0.06714536 -0.0013148  ...  0.01385411 -0.01061998
  -0.07655847]
 [ 0.03450382  0.00248637 -0.00096133 ...  0.07771972  0.04901755
  -0.06272326]
 [-0.02487346 -0.1038122   0.0605685  ...  0.12870437  0.04740535
  -0.1081261 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_47/bias
[-0.02930741  0.03805509 -0.00736567 -0.00292862 -0.03790212 -0.02411184
  0.00675487  0.00682831  0.01279281  0.00058658 -0.02942048 -0.01012747
  0.01394061 -0.03744214  0.05029151  0.04007489  0.04719973 -0.00158996
 -0.03378604  0.03999824  0.02820695  0.02457038 -0.04831501 -0.00922092
 -0.03807054  0.00665744 -0.02435434  0.03009262 -0.01927045  0.00945027
  0.0100692  -0.03992103  0.02955364 -0.05031637 -0.00079459  0.02935547
 -0.03956587 -0.02333072  0.01629231 -0.0141545   0.02027742 -0.02824142
 -0.03675893  0.04883466  0.005056    0.05505268  0.04490996 -0.00563376
 -0.00996222 -0.04237282 -0.0344067  -0.02747631  0.02220842 -0.02082687
 -0.03997577 -0.03559449 -0.02093888  0.00890102 -0.01915447 -0.03327615
 -0.02604615  0.01623777  0.04545821  0.03054904  0.0213279  -0.03206491
  0.03088431 -0.02819326  0.00587112  0.03586589 -0.02814176  0.01459711
  0.00614624  0.0328128  -0.02283801 -0.01376546  0.00044704 -0.01067551
 -0.00768725 -0.02595612 -0.00849914  0.04569081 -0.0292406  -0.03918196
  0.00270661  0.01406993  0.00596571  0.02444839  0.01044585  0.05698242
 -0.02990629 -0.04064751 -0.03418731  0.04532456  0.02497905  0.02497226
  0.00053377 -0.03276175 -0.0265775  -0.03605456  0.02112977  0.03372572
 -0.04006883 -0.03782283  0.04175377 -0.00173561  0.03219873  0.03558943
 -0.03413851 -0.02796272  0.00194701 -0.01664729  0.00817207 -0.04659792
  0.01057966  0.01176807  0.00096596 -0.00933308  0.04962916  0.0194405
  0.03643337 -0.01447338  0.02516401 -0.03129449 -0.00505265  0.00289236
  0.00432326  0.01885596  0.00957893 -0.03734356  0.04033774 -0.01169131
 -0.00157     0.05216125  0.02891982 -0.0420338  -0.03071449  0.01787123
  0.05944622 -0.02141841  0.01206869  0.03211438 -0.02633804 -0.03695588
  0.04885713 -0.00801171  0.02547321  0.02021912 -0.02897159  0.00234445
 -0.04701086 -0.01443741 -0.00723043 -0.0022494   0.03777853 -0.05807876
  0.00552331 -0.03758741 -0.02450752 -0.0137706 ]
tensor_name:  TemporalFusionTransformer/time_distributed_47/kernel
[[-0.04770928  0.00101714  0.01530256 ... -0.04357454  0.06582338
   0.01086986]
 [-0.04614213 -0.00550284 -0.03564144 ...  0.01231208  0.05602366
   0.0711154 ]
 [-0.02889105 -0.07492721  0.01640257 ...  0.04534151 -0.02950427
  -0.02727092]
 ...
 [ 0.01006814  0.03586673  0.05134661 ...  0.03190635 -0.01359871
  -0.02180377]
 [ 0.02399358  0.07140383  0.00955559 ...  0.01643859 -0.04296003
  -0.01179401]
 [-0.00912071 -0.02580464 -0.04368682 ... -0.01111017  0.01936121
  -0.06844024]]
tensor_name:  TemporalFusionTransformer/time_distributed_48/kernel
[[ 0.14629267 -0.04328385  0.11971091 ... -0.0965229   0.1293265
  -0.06551304]
 [-0.07223825  0.03273956  0.05185932 ...  0.01768592 -0.07834934
  -0.11544306]
 [-0.07772636 -0.01536546  0.01967421 ... -0.09298364  0.04425459
   0.0007122 ]
 ...
 [ 0.07120518 -0.13975899  0.08865201 ... -0.12430741 -0.06738322
  -0.04332232]
 [-0.07619592  0.06051793  0.06232936 ...  0.12544082 -0.04018132
   0.12463161]
 [-0.09351516 -0.03836521 -0.03975981 ... -0.08092035  0.03119843
   0.04594046]]
tensor_name:  TemporalFusionTransformer/time_distributed_49/bias
[-0.01155743 -0.04298374  0.04988023 -0.06876472  0.06746066  0.07674062
 -0.06982283  0.06243524  0.03791829  0.06707118 -0.06738414 -0.08279889
 -0.05859949  0.05205078  0.03154813  0.06888301 -0.05419343 -0.03036238
 -0.0461049  -0.07203844  0.05605028  0.04218933  0.07077413 -0.01734829
  0.03691792  0.00612397  0.03140955  0.03930732 -0.07266232  0.06702093
 -0.03310671  0.06188483  0.06454875 -0.03448962  0.01995145 -0.06557376
  0.06856476 -0.06956425  0.06153616 -0.03031567  0.06590224 -0.07235002
 -0.00985424  0.06993245  0.04381321 -0.00239856 -0.0667358   0.04594113
 -0.07306279  0.00823732 -0.07519972 -0.04333686 -0.01894559 -0.08879302
  0.05622454  0.07197508  0.02639962 -0.06466344 -0.05939185  0.03963939
  0.06489176  0.0506749   0.07202872  0.00661503 -0.0218326  -0.04558016
  0.04254469  0.05357016  0.00761757 -0.06622334  0.06380403 -0.05384287
 -0.06782229  0.00095255 -0.06598225 -0.05179343  0.06183736 -0.06375053
 -0.01459872 -0.05913359  0.07858287 -0.05702862 -0.075983    0.06697834
 -0.04321416 -0.04237399  0.06431561 -0.0144726   0.07371749  0.02449505
  0.061665   -0.04460871  0.0554844   0.02684971  0.02520464 -0.0340341
  0.05636473 -0.07381579  0.06927171  0.08238889 -0.05907812  0.06965458
  0.06087045  0.06176889  0.01997074  0.0466979   0.06616132  0.03002791
  0.03444371  0.06499016 -0.02884649 -0.01487294  0.01698656  0.05584294
  0.06702515 -0.02375479  0.05035029  0.01875573 -0.06253152  0.06429415
 -0.06778843  0.01693269 -0.00141639 -0.06630071 -0.04191563  0.06011601
 -0.0354474   0.06628785  0.06217689 -0.07050729 -0.07404914 -0.03697972
 -0.07159716 -0.03948406 -0.0453425  -0.04096108  0.058418    0.0578163
 -0.0173058   0.07047398 -0.0189515   0.02269106  0.07233772 -0.00067676
  0.06396538  0.0589326   0.04924724  0.00489797 -0.00282061 -0.01506724
  0.0551361   0.06719318  0.06466209  0.05927038 -0.05719678  0.00420802
  0.06684881 -0.00683354  0.01413942  0.06783339]
tensor_name:  TemporalFusionTransformer/time_distributed_49/kernel
[[-0.11727686  0.07447964  0.00836719 ...  0.06917706 -0.09634545
   0.03469715]
 [ 0.04595317  0.03222606  0.04001012 ... -0.10163613 -0.08438397
  -0.10815778]
 [ 0.101184   -0.03882509  0.10833822 ... -0.04741732 -0.06564212
  -0.10562405]
 ...
 [-0.08915869 -0.02212493  0.03502797 ...  0.01328371 -0.0377192
  -0.05211861]
 [-0.07252168  0.06848171 -0.03190314 ... -0.08659172 -0.05512673
   0.00926551]
 [-0.08178151  0.02333798 -0.00309481 ...  0.12808242 -0.04000802
   0.00586978]]
tensor_name:  TemporalFusionTransformer/time_distributed_5/bias
[ 0.01013093  0.01388114  0.00050763 -0.02897487 -0.01623068 -0.03250474
 -0.01368377  0.02000634  0.02021268  0.02085824 -0.016202   -0.03777579
  0.0220684   0.05929192  0.01794093  0.00754194  0.00590153  0.04266568
 -0.00501756  0.01108414  0.01003112 -0.00286362 -0.02572873  0.04484167
 -0.00308803 -0.02305615  0.04733604 -0.02287997  0.01540036 -0.00253769
  0.01565233  0.02769957  0.02761196 -0.00985209 -0.02231391 -0.01667208
 -0.03356954 -0.02059259  0.02936091  0.02926356  0.08912423 -0.01808907
 -0.00053427  0.01846449  0.00428658 -0.05611708 -0.00249443 -0.01828359
  0.02637468  0.0402664   0.00854951  0.11062409  0.00176057  0.03036353
  0.00383844 -0.0538852  -0.00624206 -0.06740467  0.04651401  0.04976356
  0.00017965 -0.0301018   0.01524474  0.00155074 -0.02640671  0.01261771
  0.01082552 -0.02741129 -0.01114584  0.02881418  0.03398162 -0.01962407
  0.01102699 -0.03852151 -0.01044198 -0.05343444  0.01110411  0.0553901
 -0.01091163  0.04124819 -0.00934919 -0.00117807  0.02203044 -0.03477699
  0.04593646 -0.01322436 -0.05609886 -0.00381377  0.01625315  0.00263272
 -0.05645401 -0.03691766 -0.01726284 -0.029959    0.02347789 -0.01694926
 -0.01761608  0.00692111  0.01260952 -0.00688823  0.03229558 -0.03898057
 -0.01130473 -0.00422145 -0.00590219 -0.04296333  0.01158824 -0.01772435
 -0.0066312   0.02198198 -0.01065935 -0.02066324 -0.01062747 -0.02444576
  0.03036692  0.03955549  0.03727262 -0.01891829  0.03021717 -0.03146674
  0.02687781 -0.06324306 -0.00833522 -0.03202325  0.05808308 -0.0287302
  0.0111502   0.02750559  0.00657186 -0.02690644 -0.00635139 -0.05417854
  0.00955706 -0.02313674  0.02395576  0.03468648 -0.00553751  0.00824214
  0.0122311   0.01069523 -0.03848315  0.0112263   0.02665987 -0.00210008
 -0.02446009  0.00386425 -0.01950502 -0.01593859 -0.00976395 -0.02636088
  0.00445389 -0.0208303   0.00691812  0.01513955 -0.02467416 -0.04256907
 -0.01080279  0.01412171  0.02101177 -0.00139891]
tensor_name:  TemporalFusionTransformer/time_distributed_5/kernel
[[-0.04533852  0.13240519  0.13793445 -0.09367504  0.094156    0.12809107
   0.20383741  0.16903101  0.02019416 -0.08982334  0.16999196  0.04446525
   0.14914969  0.06331606  0.06221971  0.17401692  0.02232873  0.00944303
  -0.03229183 -0.18111637  0.05358776  0.08926048 -0.00875619  0.0847306
  -0.11564247 -0.09915733 -0.00579659  0.1286556  -0.18292642  0.08975324
   0.16362856  0.024652    0.113768   -0.11937104 -0.05291898 -0.14851713
  -0.06668712 -0.1223241  -0.13898374 -0.12686592 -0.20238495  0.1860706
   0.09907211  0.10186857  0.05919399 -0.11749511 -0.01493698  0.02881341
  -0.14112149  0.06263512 -0.18995555  0.00317782  0.15064734 -0.0846505
   0.15704632 -0.17982303  0.06894546 -0.15904346 -0.01424937 -0.04270057
   0.10428021  0.00702476  0.07501527  0.14863493 -0.09001493  0.1329675
   0.07745269 -0.02898904  0.08668704  0.16054717  0.06023964  0.19189152
   0.03901447 -0.14552091  0.18128943  0.07682875  0.11917693 -0.16352256
  -0.13420723  0.10928207  0.10562319 -0.08712516  0.06781223 -0.06161576
  -0.10676555 -0.1573377   0.02267684 -0.08067819  0.12785023  0.1379517
   0.00094362 -0.0531859   0.12019347 -0.05730449  0.09157993  0.07577231
   0.07137764 -0.10666692  0.07125791 -0.12535104  0.07291336  0.14780836
  -0.08008156  0.04059936 -0.10127298 -0.15560925  0.00141102 -0.04700832
  -0.08472028  0.06896524 -0.08526134 -0.08701298 -0.01311902  0.05709026
   0.04528736 -0.03045037  0.10840055 -0.02227076  0.14112575 -0.1412365
   0.16002187 -0.1016907  -0.12996112 -0.03711254 -0.1633503  -0.10703948
   0.13501085  0.07887881  0.05030391 -0.13386126 -0.1590476  -0.01493744
   0.09270759  0.00877446  0.16219541  0.12449435 -0.14873183  0.03875373
  -0.0720608   0.02118027 -0.03241295  0.10594487 -0.02118663 -0.00043095
  -0.12509362  0.14387299 -0.09739687 -0.14748296  0.14568919  0.0527801
  -0.10443113  0.00385734  0.17680366  0.02017306  0.10365424 -0.00560183
   0.1507104   0.00719894  0.04163227  0.07888503]]
tensor_name:  TemporalFusionTransformer/time_distributed_50/bias
[-0.00359432  0.11395361 -0.0298107  -0.00179284 -0.01418987  0.01727098
  0.00031057]
tensor_name:  TemporalFusionTransformer/time_distributed_50/kernel
[[ 0.02381147 -0.00713869  0.15470126 ...  0.01657358  0.0951394
   0.13135064]
 [-0.08233543 -0.0414042   0.06549414 ...  0.19998428 -0.04731154
  -0.15823461]
 [-0.13462733  0.0438888   0.1570333  ...  0.08772416  0.15379919
   0.02752837]
 ...
 [-0.08286478 -0.00812073 -0.06401985 ...  0.08483876 -0.09849916
   0.07395744]
 [ 0.14948863  0.0332379  -0.03169711 ... -0.00200587 -0.14163002
  -0.1904981 ]
 [-0.00621119  0.05708228 -0.0736281  ...  0.01450314  0.09262615
   0.03683402]]
tensor_name:  TemporalFusionTransformer/time_distributed_51/bias
[-0.01614159  0.03964034 -0.04795818 -0.00846739 -0.0226048  -0.02399378
 -0.00366895]
tensor_name:  TemporalFusionTransformer/time_distributed_51/kernel
[[ 0.00503381  0.10667688  0.01324477 ...  0.11912689 -0.07240614
  -0.05140115]
 [-0.04322053  0.08129805  0.1825312  ...  0.03901918  0.00068915
   0.18799466]
 [-0.10978351  0.13954175 -0.05581424 ...  0.13027692 -0.02277553
   0.06511406]
 ...
 [-0.15847486 -0.01034696  0.12529828 ... -0.16765723  0.03997825
   0.0593904 ]
 [-0.05648267  0.25756705  0.02943465 ... -0.11305518  0.00281918
   0.0087317 ]
 [-0.08792815  0.1208391  -0.07584941 ... -0.20512867 -0.17143257
  -0.04718405]]
tensor_name:  TemporalFusionTransformer/time_distributed_52/bias
[-1.89523343e-02  1.95002295e-02  3.76642100e-03  3.06603685e-02
 -9.47253406e-03 -1.77175831e-02  4.25322680e-03 -1.20395264e-02
  7.73067446e-03 -4.02277242e-03  8.65402911e-03 -3.88666335e-03
  7.74782803e-03 -8.13446008e-03  4.50920127e-03 -1.59462856e-03
  5.51412767e-03  1.19850757e-02  1.14833461e-02  2.80688889e-02
 -2.68140715e-03 -8.27642530e-03  5.74296340e-04 -1.03542639e-03
 -5.54295816e-03  8.95355921e-03 -1.31495502e-02 -1.17253857e-02
  2.02497337e-02 -3.12636071e-03  5.80608658e-03  6.27565570e-03
  4.32708021e-03  2.43724766e-03 -1.99216176e-02  1.20527409e-02
 -8.54459126e-03  1.72631443e-02  1.37879606e-02 -1.14594204e-02
 -4.77339886e-03  5.73341362e-03 -1.74672878e-03  2.95681227e-03
  4.96918289e-03 -1.23178605e-02 -9.13914351e-04 -8.29400960e-03
  2.67851749e-04 -1.22551434e-02  5.99271245e-03  1.65059825e-03
 -1.06171258e-02  3.48648950e-02 -9.94131807e-03  2.04893481e-03
 -4.53819241e-03 -5.03544649e-03  5.37210284e-03  1.24119725e-02
 -1.47898644e-02 -7.17701204e-03  3.47904935e-02 -4.93008085e-03
 -9.54062026e-03 -2.99552153e-03  8.57274700e-03  8.03401694e-03
  6.47538295e-03 -4.38063964e-03 -2.01949431e-03  1.64578669e-02
 -6.82274345e-04 -4.38200589e-03 -1.30020520e-02  1.41637679e-03
  4.24814969e-02 -8.34638998e-03 -3.73564800e-03 -7.70214526e-03
 -2.07576882e-02 -1.06424382e-02  1.66555308e-02  2.09644567e-02
 -1.70578305e-02  3.68915964e-03  4.51266009e-04 -9.04447108e-04
 -5.16016269e-03  3.86805111e-03  6.37602643e-05 -1.16429478e-02
  1.35606974e-02 -6.07640482e-03 -9.67703015e-03  8.30962881e-03
 -1.42079648e-02 -2.76274476e-02  2.28616931e-02 -4.24654735e-03
  2.83605489e-03  1.23608578e-02  1.61063112e-02 -5.82071880e-05
  4.33802977e-03 -6.21253718e-03  2.20800773e-03  1.86042534e-03
  2.01939922e-02  7.14157417e-04  1.56851076e-02  3.35817337e-02
 -1.04689447e-03 -2.25208118e-03 -9.73147340e-03  1.12464670e-02
  1.13928122e-02  1.84049029e-02 -7.24324537e-03  5.27768210e-03
  9.38968733e-03  8.96848273e-03 -8.47778050e-04 -1.32481586e-02
  1.38705689e-02 -2.70350892e-02  5.64745686e-04  7.40474882e-03
  1.50154373e-02 -4.54469621e-02 -2.66865529e-02  1.60603821e-02
 -1.01042017e-02  4.67163557e-03 -2.50905454e-02  1.73965618e-02
  1.16066483e-03  1.88256521e-02 -2.81246062e-02 -2.17973231e-03
 -1.34634692e-02 -1.35323976e-03 -8.56916606e-03 -4.04306361e-03
  2.12924965e-02  4.01984947e-03 -1.88060496e-02 -9.72498208e-03
  2.45358255e-02 -1.10456236e-02 -4.36325092e-03 -2.52582934e-02
  7.13156490e-03  1.41829820e-02  4.94747469e-03  1.97371431e-02
  2.49124151e-02 -8.83835368e-03  1.30732069e-02 -5.78539725e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_52/kernel
[[-0.10900109  0.10586438 -0.08397927 ... -0.11106155 -0.12666135
   0.07647645]
 [-0.0451837   0.08441412  0.12591107 ...  0.03795521 -0.08332313
   0.04938103]
 [-0.06202454  0.04234891 -0.02531427 ...  0.00288097 -0.06643487
  -0.0008567 ]
 ...
 [-0.00357922 -0.0586209  -0.06140184 ...  0.07098513  0.00078074
   0.06491137]
 [-0.11864454 -0.13791984 -0.08475296 ... -0.08473572 -0.04478475
  -0.13443157]
 [-0.01974266  0.02876867 -0.03338242 ... -0.07930794  0.04551141
  -0.1360219 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_53/bias
[ 4.29536961e-03  1.39851496e-02  1.18253231e-02  1.91184226e-02
  5.41173900e-03 -4.08344679e-02 -2.30773967e-02  1.59281157e-02
 -5.81806060e-03  8.10972974e-03  2.39036344e-02  2.85367784e-03
  1.12194568e-02  1.23747473e-03  8.70856270e-03 -7.23789912e-03
 -7.11462367e-03 -8.60849468e-05  1.77511536e-02  7.40718981e-03
 -1.18832197e-02 -3.08517609e-02 -1.73805542e-02 -2.09963769e-02
  8.90061632e-03  1.02466214e-02  7.74007337e-03  5.34328585e-03
  3.74545320e-03  3.36513505e-03  8.56409501e-03 -2.06105993e-03
 -1.15387356e-02  1.79040693e-02  1.51903890e-02 -9.00157262e-03
 -1.08435433e-02 -1.47877645e-03 -8.89777765e-03  2.10356899e-03
 -1.00776358e-02  1.59692243e-02 -6.48901938e-03  2.29254253e-02
 -1.56883541e-02 -1.62134611e-03  2.87353173e-02 -9.38882679e-03
 -2.06106398e-02  1.71699692e-02  2.35449034e-03  2.75768526e-03
  2.48517282e-02  1.76399592e-02  2.00391817e-03 -8.61148071e-03
 -7.72831123e-03 -1.89684220e-02 -1.72906797e-02 -2.32784208e-02
  6.15027593e-03 -1.04752295e-02  9.01960954e-03  6.42855093e-03
 -1.83069799e-02 -8.11828021e-03 -1.33015048e-02  2.01410130e-02
 -5.49459038e-03 -1.39229596e-02  1.50978944e-04  4.96087447e-02
 -1.14931157e-02 -9.36158933e-03  1.16099250e-02  7.41771888e-03
  6.54891226e-03 -1.01014758e-02 -3.43770795e-02 -2.37778481e-02
 -1.85743142e-02 -8.68385937e-03 -8.31628044e-04  1.26396473e-02
  8.20141938e-03  1.43224690e-02  1.43065664e-03  1.98990144e-02
  3.31801362e-03 -4.56546154e-03  9.60409362e-03  3.78316920e-03
 -5.05611487e-03 -2.15748837e-03 -1.70848556e-02  1.64928511e-02
 -8.24383460e-03  1.13255018e-02  1.53420381e-02  1.59281418e-02
 -2.07581222e-02 -2.06354670e-02  9.43847280e-03  1.25984233e-02
 -2.84830183e-02 -2.15504635e-02 -2.44657435e-02 -4.75085079e-04
  1.96898673e-02  9.19111073e-03 -1.56924606e-03  5.23109920e-04
  2.48853527e-02  6.72053592e-03  5.47895022e-03  1.35806296e-02
 -3.00208386e-03 -2.10642768e-03  1.79813094e-02 -3.13695036e-02
 -1.30833099e-02  1.53792780e-02  2.37535071e-02 -2.39500068e-02
  1.78160630e-02 -4.65583242e-02  9.44580976e-03  2.53221393e-03
  1.60950713e-03  1.06661934e-02 -8.84046592e-03 -5.38771460e-03
  3.97985429e-02 -1.18037947e-02  6.49987487e-03 -2.11810209e-02
  1.19165510e-04  2.02620327e-02 -1.36328591e-02 -1.01696216e-02
 -1.58488918e-02  6.20194385e-03 -1.32625131e-02  1.59325507e-02
 -5.62808709e-03  4.53569181e-03  2.99108401e-02  1.22276519e-03
 -5.36335912e-03 -7.64710037e-03  2.80109933e-03  1.38123042e-03
  6.24557631e-03 -5.22510847e-03 -1.43293040e-02  1.58479158e-02
  1.57064982e-02  1.77807838e-03 -3.19229392e-03  7.62771379e-05]
tensor_name:  TemporalFusionTransformer/time_distributed_53/kernel
[[ 0.06620134 -0.07801205  0.10907897 ...  0.08123425  0.10554598
   0.07402038]
 [-0.07137389  0.1204255   0.03858545 ...  0.07062265 -0.02213854
   0.09979931]
 [ 0.104889   -0.08317333 -0.09149941 ... -0.07123709 -0.02717956
   0.07627193]
 ...
 [-0.02773054  0.0776332   0.0425161  ...  0.00842916  0.080755
  -0.06678571]
 [ 0.0947954   0.13849251 -0.02242275 ...  0.03553407 -0.00164358
  -0.03010343]
 [-0.09590093 -0.01150288 -0.0278593  ... -0.00946206  0.13310744
   0.0514434 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_54/bias
[ 2.91897915e-03 -1.85539119e-03  1.14871785e-02 -5.88624971e-04
 -1.05821835e-02  1.64016280e-02  1.67075116e-02 -1.39944535e-02
 -2.41955575e-02  3.05486433e-02  3.74408113e-03 -1.91770941e-02
 -4.24371427e-03 -1.30506523e-03  3.23326737e-02  6.67797448e-03
  9.47104581e-03  4.16048095e-02  2.89402227e-03  1.11492937e-02
 -7.93112163e-03 -4.40954976e-03 -1.81725353e-03  6.77163887e-04
  1.19831041e-02 -2.00204793e-02  2.30646059e-02 -2.14129835e-02
 -1.10253207e-02  1.99939758e-02 -2.74111647e-02 -3.25480639e-03
 -2.46719811e-02  1.35085983e-02 -1.84968598e-02 -5.92068117e-03
 -2.84393854e-03 -8.77371710e-03  1.05057321e-02  4.85689566e-03
  7.62612233e-03  8.87033250e-03 -1.23903230e-02  2.84356577e-03
  4.01217164e-03  2.88846698e-02 -1.03807673e-02  1.16776046e-03
 -1.76224038e-02  3.52391228e-02 -9.31839645e-03  5.75102940e-02
 -1.04049942e-03  7.89422262e-03 -1.37782739e-02  1.99762657e-02
  1.47361225e-02 -6.78349147e-03 -2.02434906e-03  1.93018671e-02
 -2.40098429e-03  9.27358773e-03  2.39160117e-02 -2.02315254e-03
 -1.01227714e-02  1.60713345e-02 -2.78045498e-02  2.74069682e-02
  1.73192117e-02 -1.42873805e-02 -1.20593850e-02  1.93193033e-02
  2.32372936e-02  2.29516923e-02 -2.00506747e-02  8.94046016e-03
 -3.62327136e-03  3.12265288e-03 -1.31645589e-03  2.25222334e-02
  1.15324967e-02  2.31842417e-02 -2.49936674e-02 -3.46382372e-02
  1.72369927e-02  3.03608685e-05 -1.90060511e-02 -1.34455394e-02
  1.78684983e-02 -5.70315309e-03 -9.22896340e-03  8.86844285e-03
 -2.43751463e-02  3.23578157e-03 -2.06166459e-03  2.12975335e-03
 -1.15704657e-04  5.31912409e-03 -5.43910544e-03 -2.23414879e-02
 -8.45303293e-03 -1.48431696e-02  4.19957610e-03 -1.60741853e-03
  1.58096682e-02 -2.00426616e-02  1.87347527e-03  2.98027471e-02
 -1.09614839e-03 -8.99442937e-03  2.27362774e-02 -4.89123166e-03
  1.90783124e-02  1.17452405e-02 -1.03433318e-02 -1.09774098e-02
  3.91271693e-04 -1.14907101e-02  3.26718129e-02  1.91923939e-02
 -1.28151719e-02 -5.51909022e-03 -1.37816891e-02 -3.02400906e-02
  2.56788335e-04  3.21330242e-02  1.24608576e-02  2.06700526e-02
 -7.27019086e-03  1.87694151e-02 -1.15656797e-02 -3.75299458e-03
 -1.68848261e-02  9.26948432e-03 -1.14014242e-02 -6.60653366e-03
  9.84813366e-03  2.63475403e-02 -1.41741084e-02 -2.84675620e-02
 -1.12421364e-02  2.17398033e-02 -2.11219918e-02  1.75235569e-02
 -1.20822443e-02  1.03381858e-03  3.37332599e-02 -1.52054597e-02
 -1.65919140e-02 -7.55603716e-04 -8.44185986e-03 -1.72702186e-02
 -2.01147608e-02 -9.75789037e-03  1.38225006e-02  1.21846627e-02
 -1.46538233e-02  2.41094502e-03 -1.60476379e-02 -2.61026882e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_54/kernel
[[-0.11064723 -0.00716345 -0.13202325 ...  0.04398629 -0.09331711
   0.02716899]
 [-0.06990426  0.03738021  0.08163383 ...  0.11131367  0.01720898
  -0.01831056]
 [-0.0583805  -0.0483105  -0.0793888  ... -0.06576885 -0.08930475
  -0.01929061]
 ...
 [ 0.02703757  0.13495219  0.13941988 ... -0.05990231 -0.02294876
  -0.01482775]
 [-0.0936298   0.08908381 -0.00400772 ... -0.09131178  0.04284077
   0.0981231 ]
 [-0.00390121 -0.08496666  0.06965569 ...  0.06140609 -0.10947483
  -0.02559927]]
tensor_name:  TemporalFusionTransformer/time_distributed_55/bias
[-0.00178404 -0.01209958  0.00470146 -0.02896807 -0.02517592  0.0016785
  0.01252059 -0.00572552  0.03719267  0.02728716 -0.01889698  0.00222449
 -0.00890416 -0.01841591  0.03538204 -0.02860677 -0.00743882  0.02649729
 -0.01742089 -0.03360998 -0.00376592  0.00792933 -0.03030832 -0.01403989
 -0.00281662 -0.01122855  0.00900835 -0.00169963 -0.01274131  0.02683047
  0.04384818 -0.00746715  0.02959167  0.00817945  0.00297149 -0.02309943
 -0.0065332  -0.03377179  0.00307222 -0.01341209 -0.02135368 -0.00792791
 -0.00300925 -0.03455583 -0.00617184  0.02503731 -0.00681287 -0.02317191
  0.00559726  0.02004629 -0.01490238  0.06855069 -0.02869456 -0.00860099
 -0.00945575  0.0175434   0.00529629 -0.02315731 -0.03425638 -0.0108955
 -0.01176606 -0.0105909   0.03342936 -0.00572203 -0.00813504 -0.00524225
  0.03193597  0.02938251 -0.00436087 -0.00575705  0.00545917  0.02216832
 -0.01837425  0.03431466  0.01313206 -0.00322836 -0.06403923 -0.00856538
 -0.01041584  0.00847063 -0.01713932  0.03123496  0.01578457  0.0301635
 -0.01588921 -0.02688569  0.00188133 -0.01215479  0.0001768  -0.0270559
 -0.01329878 -0.02982993  0.03487557 -0.0140234  -0.01919995 -0.03698302
 -0.01792902 -0.0091633  -0.01745989  0.00648278  0.00177361  0.00328714
 -0.01469871 -0.02022727  0.01814234 -0.00711223 -0.02490023  0.0499271
 -0.06505888 -0.0010026   0.01831079 -0.0097359   0.01203117 -0.02562804
 -0.00196656  0.01784514 -0.01496344 -0.00532339  0.04535304  0.03089972
  0.00469669 -0.01810749  0.00077233  0.02179521 -0.03718689  0.04524264
  0.00217137  0.01945238 -0.01033359  0.00513896  0.01229822 -0.00992787
 -0.0008891  -0.01858901 -0.00107516 -0.0057481  -0.00499849  0.02385156
  0.01138476  0.03380758 -0.01037211  0.03286319  0.01259157 -0.02622349
  0.01492923 -0.02447962  0.02617109  0.01152483  0.0180589  -0.01064298
 -0.02300118 -0.00179894  0.0033151  -0.00723293  0.01617514  0.00249187
  0.01076416 -0.05717375 -0.00583177  0.02825041]
tensor_name:  TemporalFusionTransformer/time_distributed_55/kernel
[[-1.16525836e-01  2.14269944e-02 -1.16344079e-01 ... -1.19718891e-02
  -6.99343532e-02  2.44562551e-02]
 [ 4.79817688e-02 -8.77812784e-03 -1.57148167e-02 ... -7.16884285e-02
   1.22844689e-01 -2.82428432e-02]
 [ 4.50942181e-02 -1.21246874e-01  1.37876824e-01 ... -8.99971128e-02
   1.19226621e-02  3.51306461e-02]
 ...
 [ 5.77038750e-02 -7.92357549e-02 -8.21973532e-02 ... -2.29893606e-02
  -9.13220122e-02  1.52999327e-01]
 [-7.84408227e-02 -5.55459261e-02  2.13665720e-02 ... -8.16445947e-02
   1.28009394e-01 -1.29254729e-01]
 [ 1.35287270e-01 -1.28934056e-01  7.41429321e-05 ... -2.40535159e-02
  -2.63819024e-02 -2.63555720e-02]]
tensor_name:  TemporalFusionTransformer/time_distributed_56/bias
[-0.03820635 -0.00079517  0.03513652  0.01714031 -0.00371537  0.00860011
  0.0009208   0.00745185  0.02257155 -0.01568003  0.03027647 -0.00933878
 -0.00998114 -0.01748686  0.00861339 -0.00968822  0.01571031 -0.03797097
 -0.01523622  0.00410301 -0.01347358  0.00972031  0.01489388 -0.01347542
 -0.00759843 -0.01516604 -0.00126176  0.00415141 -0.0241363  -0.00188922
  0.01955751 -0.01589375  0.02485436  0.02597575  0.00082175 -0.01338057
  0.00026432  0.01393326  0.00650193 -0.00401546  0.00088933 -0.00368024
  0.01400868 -0.00759123 -0.0231564   0.0099537  -0.02013519 -0.03186758
 -0.02504749 -0.00228531  0.0125811   0.00049035  0.0035285   0.01263252
  0.01425286 -0.05278383 -0.00710825 -0.0088657  -0.00884184 -0.0122391
  0.01667618  0.00351425 -0.01855731  0.00838238  0.00865038  0.00299121
 -0.00581921  0.01516755 -0.0017646  -0.00693438  0.00213425 -0.01068061
 -0.00705369 -0.00841458 -0.01577966 -0.01210532 -0.0041569  -0.00829888
  0.02030775  0.0190831   0.03110522  0.00606603 -0.01685965 -0.00157762
 -0.0193718  -0.02153903 -0.048212   -0.01016788 -0.04401425 -0.00341237
  0.02711692 -0.00234542 -0.00684307 -0.03100105 -0.0300378   0.02898745
 -0.00065621 -0.03216872  0.01907786 -0.00197142 -0.00082145 -0.01371305
  0.00628087  0.0067001   0.03966056 -0.00872575 -0.00621254 -0.01182748
  0.00128541 -0.0317617  -0.01079983  0.0038764  -0.01663929  0.01015482
 -0.01713185  0.00233409  0.00516589 -0.02187533 -0.00921763 -0.00150633
 -0.00664972 -0.01619916  0.00607914  0.00235088  0.01460561  0.01528183
 -0.02575852 -0.00287103  0.01492809 -0.02833347  0.02679261  0.01095818
  0.00529439 -0.06326297 -0.02345392  0.00123135  0.00642702 -0.01762536
 -0.004939   -0.01336376  0.01860876 -0.01385318 -0.01176691 -0.02282491
 -0.03599107 -0.01891445  0.01774104  0.00799721 -0.01880633 -0.00024559
 -0.0112079   0.01005749 -0.0145798  -0.00786178  0.02252563  0.00995848
 -0.00402626 -0.00684021  0.00759707  0.02618395]
tensor_name:  TemporalFusionTransformer/time_distributed_56/kernel
[[-0.00049485  0.10108081  0.09640648 ... -0.09257893  0.11769114
   0.17961752]
 [ 0.08233569  0.10160449  0.01809761 ...  0.09368186 -0.09508036
   0.09404684]
 [ 0.01406323  0.04553821 -0.02043079 ...  0.11848245 -0.01818842
   0.0107749 ]
 ...
 [-0.03437759 -0.06102967  0.02299089 ... -0.03577929  0.03841305
  -0.05584786]
 [ 0.13734779 -0.01182047  0.07542969 ...  0.13104409 -0.01222599
   0.10665946]
 [ 0.08774658  0.01882663  0.02677755 ... -0.00156224 -0.09094172
   0.09816235]]
tensor_name:  TemporalFusionTransformer/time_distributed_57/bias
[-0.0625196   0.03805465  0.07339966  0.05435845 -0.06116345  0.01220861
  0.06628101 -0.08863957 -0.0502768   0.04912015 -0.00021977  0.00998892
 -0.01460038 -0.01189264 -0.0184469  -0.06043468  0.03623541  0.00942495
 -0.02797343  0.05264485 -0.05035861  0.00798394  0.05223421  0.01226908
  0.06404117 -0.00428576 -0.03134147 -0.06452648  0.07261845 -0.0493263
 -0.01514179  0.02230944  0.06114514 -0.0463075  -0.04400437 -0.02180175
 -0.01990996 -0.01544253 -0.00405081  0.05798297 -0.02471687 -0.07399404
 -0.00171628 -0.02738453 -0.04547122 -0.03284416  0.04198521  0.03469932
 -0.01603278 -0.01373305  0.00815956 -0.0002102   0.04414097  0.00935144
 -0.00167061 -0.05445784 -0.01128671  0.03383596 -0.01689326  0.0038993
  0.0532355   0.04030082  0.00010901  0.00685141  0.02612081  0.0277766
 -0.06861074  0.02536881  0.02352079 -0.01048014 -0.05157145  0.06757115
  0.06043556 -0.03278971 -0.06213784  0.08114072 -0.0447963   0.06704018
  0.03777054  0.04669738  0.01719299  0.06071107  0.04541787  0.0773214
 -0.01132351  0.00123177 -0.03047557  0.00757975  0.03053838 -0.04319616
  0.00444458 -0.08554028 -0.00478167  0.02887606  0.01480498  0.01213691
 -0.05658361 -0.00651518  0.10503211 -0.03423303 -0.06652772  0.09835983
 -0.05119784 -0.01400266 -0.05643506 -0.03689805 -0.00550598 -0.02309684
 -0.04537851 -0.0559356   0.07292759 -0.00934145 -0.04284001  0.04286677
  0.00727359  0.02285144 -0.04539709 -0.02221804 -0.07122294 -0.06875257
  0.06224098 -0.0081347  -0.01596686 -0.01590891  0.04799268  0.02280886
  0.01468142 -0.02635222  0.07733722 -0.04028853 -0.01064774  0.02648997
  0.02181308 -0.05855848  0.00057487  0.05405926  0.00099624 -0.04546449
  0.00243054 -0.06234452 -0.05887019 -0.04771205  0.04777429 -0.04805809
  0.10310998  0.06744153 -0.00903998  0.03282023 -0.03665449  0.03137231
  0.00698785  0.06752188  0.00502281  0.02257046 -0.01503909 -0.06793968
 -0.03233977  0.03882682 -0.03946413  0.01779236]
tensor_name:  TemporalFusionTransformer/time_distributed_57/kernel
[[ 0.09556767 -0.02699491  0.03935251 ... -0.0662444   0.05172514
   0.03797141]
 [ 0.01686572  0.01470887  0.00080671 ... -0.00256345 -0.12682113
  -0.00772859]
 [ 0.01174386  0.08438434  0.18629213 ...  0.11552002 -0.14708187
  -0.05462398]
 ...
 [-0.08420121 -0.0888366  -0.10788221 ... -0.00600144  0.13271666
   0.04394553]
 [-0.09440195 -0.00620143 -0.06183435 ... -0.01631075  0.11242484
  -0.06359383]
 [-0.08224346  0.02886154  0.09538137 ... -0.06265024 -0.12912889
   0.07552362]]
tensor_name:  TemporalFusionTransformer/time_distributed_58/bias
[-2.22924794e-03 -2.49706414e-02 -3.19680460e-02 -3.36587578e-02
 -2.34466232e-02 -1.66648030e-02 -3.16151492e-02 -5.35592251e-02
  4.09900062e-02  3.68894078e-02  3.96455545e-03 -2.14383733e-02
  1.96444918e-04  4.89156209e-02  6.41495660e-02  1.72912125e-02
  3.31166610e-02  1.22831404e-01  2.26622843e-03  1.59169491e-02
 -8.80034873e-04 -2.90315878e-02  3.37469913e-02  5.88271990e-02
 -1.02873817e-02 -1.54193401e-01  7.88204893e-02 -3.13302539e-02
 -1.04800975e-02 -2.63123792e-02  4.85041272e-03  1.62412245e-02
 -5.55432541e-03  1.41297719e-02 -6.06041104e-02 -1.53521914e-02
 -2.02293578e-03 -2.22929269e-02  3.86297591e-02 -1.71666511e-03
  1.17083462e-02 -1.21797053e-02 -2.66593341e-02  2.82634255e-02
 -2.39553694e-02 -4.06943746e-02  1.12531995e-02  6.38086582e-03
  5.11596389e-02  1.02974735e-01 -1.44689614e-02  1.55710280e-01
  1.00449910e-02  4.36336920e-02  1.46244075e-02 -1.19062169e-02
  2.15116944e-02 -4.46904078e-02  4.29784879e-02  2.17967182e-02
  1.65779926e-02 -1.07555483e-02  1.18954536e-02 -1.73889268e-02
 -2.48890743e-02  1.39202066e-02 -6.48207916e-03 -2.26683524e-02
 -3.24181393e-02  6.31393790e-02  2.90733925e-03 -9.63265169e-03
  3.63692939e-02  6.55792514e-03  1.38090933e-02 -1.18804397e-02
  4.13258672e-02  3.39626782e-02 -1.25357164e-02  3.88596579e-02
 -1.60953235e-02  2.03197282e-02 -5.89819923e-02 -6.05911463e-02
  2.52506644e-01 -4.94707143e-03 -4.10302170e-02  2.36539543e-03
 -5.99779561e-03  4.70265374e-02 -1.23851271e-02 -9.19673033e-03
 -3.33793797e-02 -2.92964000e-02  3.14331753e-03 -1.12523139e-02
 -2.29583252e-02  2.13830644e-04  1.78566948e-02  4.19089906e-02
  2.72498596e-02 -3.55412439e-02  4.70956117e-02  7.83330481e-03
 -1.47903254e-02 -4.08174023e-02 -1.14257960e-02 -3.25072408e-02
 -1.69440266e-02 -2.96429489e-02 -4.65102866e-03 -1.18575962e-02
  2.46045925e-03 -2.72319801e-02  2.94459593e-02  4.50378051e-03
  1.34317530e-02 -2.71617472e-02  3.25742289e-02  8.12410191e-03
  1.31464684e-02 -4.51590084e-02 -2.91815661e-02 -5.48058115e-02
 -1.39132934e-02 -2.77452599e-02  1.44904908e-02  4.72093821e-02
 -9.53403115e-03 -1.12886978e-02 -2.37330887e-02 -1.13821216e-02
  1.52851352e-02 -3.97310480e-02  4.11543110e-03  6.35988917e-03
 -5.64323692e-03 -2.75309682e-02 -3.70926317e-03 -2.65146960e-02
 -1.98450107e-02  1.31686628e-02  2.20788978e-02  1.17161991e-02
 -3.23693976e-02  1.26408623e-03 -4.07465035e-03 -1.73298195e-02
 -4.29690965e-02 -2.34396197e-02  2.79170573e-02  3.10123730e-02
 -5.91087528e-02 -6.22590957e-03 -1.49184940e-02 -1.72034430e-03
  1.21676242e-02  1.26515410e-03  1.24301929e-02 -3.50336209e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_58/kernel
[[ 0.08407196  0.09736354 -0.05876006 ... -0.11027184  0.05921048
  -0.01343154]
 [ 0.08646484  0.01272544 -0.02085439 ...  0.09147374 -0.10730299
  -0.06066276]
 [ 0.11595961 -0.06752534 -0.03243237 ...  0.08479765  0.01889334
  -0.10403193]
 ...
 [-0.00035319 -0.10807225 -0.01506562 ...  0.1238046   0.06941121
  -0.0211765 ]
 [ 0.00840668  0.13893175  0.12844893 ... -0.13494165  0.11478485
   0.08356337]
 [-0.10971866  0.11836076 -0.13771282 ...  0.10479258 -0.1500201
  -0.12332007]]
tensor_name:  TemporalFusionTransformer/time_distributed_59/bias
[-0.06421901 -0.0055066  -0.07458225 -0.03204054 -0.02803187 -0.04632379
 -0.12041471  0.03386868 -0.03557513  0.01078099 -0.02556531 -0.04202252
 -0.06292612 -0.02536408  0.11134309 -0.02784749 -0.01305755  0.08873818
 -0.0488271  -0.03153054  0.00739436 -0.0053733   0.11391307 -0.00253268
 -0.06577591  0.12797368  0.06993366  0.05353367 -0.09456325 -0.07846949
 -0.10715879 -0.03095441 -0.0968015  -0.03608977  0.02150348 -0.03044969
 -0.13009235 -0.01702466 -0.04323444 -0.07033329 -0.14048989 -0.02929611
 -0.00987231 -0.07480345 -0.06869045 -0.04547231 -0.03448344 -0.07177699
 -0.05345478  0.05285971 -0.05054355  0.20974961 -0.05322066 -0.01592171
 -0.05779224 -0.03994016 -0.01852563  0.04765098 -0.05712447  0.02592212
 -0.02672169  0.00565196 -0.0431379  -0.06797162 -0.01357668  0.00260412
 -0.04161874 -0.03811376 -0.07167213 -0.08809807 -0.07721771 -0.08443405
  0.0119137  -0.12931757 -0.1054289  -0.02653233 -0.0049506   0.00616271
  0.00369333  0.04589421 -0.04977985 -0.10576271  0.07323486  0.05783062
  0.17726576 -0.07717097  0.00909949 -0.03668465 -0.06594482 -0.04926381
 -0.01001455 -0.01305562  0.00083367 -0.0047805  -0.07359672 -0.05152754
 -0.03045942 -0.00872184 -0.04092028 -0.03491939 -0.03651717  0.00930651
  0.02615954 -0.05299036 -0.07919306 -0.00731405 -0.03656794 -0.06655919
 -0.04599255 -0.0787122  -0.06864504 -0.02864831 -0.12463091 -0.04218634
 -0.07562502 -0.04052649 -0.060204   -0.05880492 -0.1151209   0.00022189
 -0.02186523 -0.06192368 -0.00735525  0.06075984  0.00637945 -0.08469984
 -0.03895268 -0.01915595 -0.0166285  -0.05619071 -0.04180785 -0.00650401
 -0.07611889 -0.06679501 -0.01484544 -0.00194686 -0.0377709  -0.11737646
 -0.05078046  0.02642783 -0.02006165 -0.02091191 -0.05069479 -0.10020156
 -0.08979897 -0.04130453 -0.1299365  -0.04547374 -0.06187597 -0.00136811
 -0.0340749  -0.02849152  0.07408411 -0.05053432 -0.08547365  0.00468289
 -0.04874353  0.04469192  0.01564861  0.04317322]
tensor_name:  TemporalFusionTransformer/time_distributed_59/kernel
[[ 0.11086601 -0.05964652  0.06492874 ... -0.17872338 -0.0911645
  -0.04173791]
 [-0.17185919 -0.01235747 -0.14229432 ... -0.12819697  0.08077148
   0.0655541 ]
 [-0.07795814 -0.12893867 -0.00461234 ...  0.0733024  -0.09298681
  -0.00403898]
 ...
 [-0.14278534 -0.00445116 -0.14753506 ... -0.11657877  0.04770058
  -0.05429359]
 [-0.10382585  0.12482494  0.14916082 ...  0.02688218 -0.16349298
  -0.07182989]
 [-0.12593184 -0.03888992  0.00547461 ... -0.00204538 -0.02704267
  -0.07780828]]
tensor_name:  TemporalFusionTransformer/time_distributed_6/bias
[-0.01354314 -0.02110168 -0.04954943 -0.03714442 -0.02611672 -0.01830548
  0.01008825 -0.06718022  0.00391087  0.02616895 -0.0197279   0.03435615
  0.00362846  0.03744065  0.01800839 -0.01527744  0.00197439  0.09185419
 -0.00290319  0.00782766  0.01622284  0.02128854  0.00414043  0.04038461
  0.02386077  0.02607051  0.00138608  0.01903539  0.0329314  -0.02213109
  0.01426225  0.01964395  0.04102324 -0.0233976  -0.02566899  0.00216683
  0.01965739  0.00432923  0.03166708 -0.04255217  0.03943512  0.00170872
  0.00791021  0.01920343 -0.01641493 -0.02853709  0.00917398  0.03727474
  0.04324698  0.0337326   0.02159177  0.09003323 -0.00084863 -0.02654517
  0.03164481 -0.00958843 -0.00789281 -0.07692663 -0.02324351 -0.04095048
  0.00394655 -0.02158531  0.02737026 -0.02843546  0.03059296 -0.03289457
 -0.01743178 -0.00688896  0.01016231  0.00531131 -0.00674327  0.02469022
  0.01186535 -0.04060861  0.00420307 -0.00175336 -0.03187652  0.05737163
  0.00462112  0.03800195 -0.03642061  0.01366861 -0.03135626 -0.02470684
  0.07721269  0.02780505 -0.04436919 -0.04543808 -0.03370165 -0.0499328
 -0.01193535 -0.00700801  0.01741629 -0.00967539 -0.04149185 -0.04341703
  0.02152224  0.02001671  0.01581737  0.01682041 -0.03189949 -0.05092682
  0.05259578  0.04229922 -0.03619516 -0.08522635 -0.00826746 -0.02847756
 -0.02859509  0.06355158  0.01671572 -0.02465946  0.04100871  0.06329369
  0.032418    0.01809203 -0.00518199  0.03388799 -0.00168771 -0.0274215
 -0.00805178 -0.08025882  0.03564393 -0.00607574  0.00991269 -0.04273544
 -0.03905323  0.025955    0.02700281  0.01662843  0.01797001 -0.04257671
 -0.05441848  0.00529477  0.00183691 -0.01002465 -0.03610161 -0.01545183
  0.0018447  -0.02965503 -0.02573135 -0.04307824 -0.01502622 -0.00393316
  0.00062377  0.02639889 -0.03479166  0.04803196  0.01966417  0.00468496
 -0.0303362   0.0043907   0.02304453  0.01202094  0.02360661  0.02894518
 -0.0073916   0.00301201 -0.03776812 -0.01395954]
tensor_name:  TemporalFusionTransformer/time_distributed_6/kernel
[[-0.13003233 -0.1429477  -0.13529715  0.10247116 -0.13283625  0.13868815
   0.02366984 -0.15825479  0.14846554  0.01765078 -0.18725148  0.23073779
  -0.01374288  0.02200529 -0.020844   -0.01298459  0.19920915  0.09940804
  -0.02453769  0.15258065  0.1131608  -0.09330007 -0.06630614  0.04002961
   0.17501627 -0.0458281  -0.10025545  0.02910875  0.02135541 -0.16751315
  -0.02040447  0.07505597  0.05762751 -0.15949519 -0.12107094 -0.00033055
   0.06658443 -0.07182909  0.17783897 -0.140371   -0.01039989  0.12082824
   0.18224934  0.07961943 -0.0491655  -0.06433723  0.07794367  0.0366096
   0.1612333   0.14986348 -0.05161882  0.10692736  0.01738231 -0.04154567
   0.05834547  0.11390126 -0.19133566 -0.17291118 -0.09419184 -0.13809219
  -0.00895749 -0.0159933   0.16514733 -0.10687122 -0.19363171 -0.09832219
  -0.18450049  0.12585977  0.1362408   0.00449034 -0.09042536  0.20696685
  -0.0649901  -0.17535354  0.08489106 -0.00102745 -0.16157003  0.03875377
  -0.18070365 -0.01800744  0.12292106 -0.05008227 -0.06474598  0.00432096
  -0.12605469  0.18887675 -0.10469779 -0.17143631 -0.09580506 -0.09604959
   0.00562351 -0.01950104  0.02553564  0.06485461 -0.15128255 -0.20805448
   0.16740564  0.10780812  0.1270354   0.06611343 -0.18573545 -0.08717047
   0.18309447 -0.00655754 -0.09182882 -0.19716978 -0.18957137  0.12534676
  -0.04912343  0.21035784  0.19825913  0.13208482  0.16920924  0.22075789
   0.18465464 -0.08419162  0.02515977  0.16476528  0.17571469 -0.13578896
  -0.16630216 -0.2255312   0.07099666  0.1444949  -0.13799232 -0.10296319
  -0.04664106  0.1940852   0.18045181 -0.03989201  0.09644391 -0.03912494
  -0.050721    0.17307389 -0.09944723  0.00042    -0.13971274 -0.19098254
   0.01391773  0.00426553  0.00193948 -0.11865626 -0.0837866  -0.22217196
  -0.11858445  0.13741186 -0.10757624  0.11861031  0.18481731  0.12527317
   0.01411282  0.06386741  0.07648353  0.21164155  0.21637663  0.06844474
  -0.089911   -0.12726809 -0.156063   -0.21079057]]
tensor_name:  TemporalFusionTransformer/time_distributed_60/bias
[-7.2039813e-02  1.2984667e-02 -1.9520927e-02  4.7257788e-02
  4.5903556e-02 -1.5175989e-02 -1.5803423e-02 -3.5623450e-02
  4.9083356e-02 -7.9381885e-03  4.2750612e-03  3.4902930e-02
 -9.4164433e-03 -1.9105693e-02 -4.7951318e-02 -1.5092177e-02
 -1.9458167e-02  3.0431092e-02 -4.5766853e-02  1.1712829e-02
 -5.1640882e-03  1.0373914e-03 -6.6227064e-02 -2.9673936e-02
  5.3014789e-02 -5.7812016e-02  2.1031674e-02  1.1458935e-02
 -4.9086951e-02 -2.0666843e-02  5.4390579e-02  8.4201302e-03
  4.8163872e-02 -3.5484646e-02  5.6484133e-02 -3.5330802e-02
  8.6966557e-03  3.7740786e-02 -3.8832251e-02  2.5810853e-02
 -1.9530486e-02 -6.1654169e-02 -2.9853492e-03 -2.7522819e-02
 -2.6123377e-02 -2.9047413e-05  4.2181529e-02  1.0643394e-02
  5.2383170e-02 -4.5894630e-02 -4.4470653e-02  1.8013585e-02
  3.2078307e-02 -5.6893010e-02 -2.2169361e-02  2.2152506e-02
 -3.4570843e-02  2.6020214e-03 -1.2454737e-02  4.9720169e-03
  1.0880298e-02  1.8611556e-02 -6.2051099e-02 -1.3148457e-02
  4.5650594e-02  3.4276154e-02 -2.3107165e-03  1.9638464e-02
  7.9448931e-02  3.6158707e-04  1.9446538e-03  3.0074865e-02
  2.8294318e-03 -6.3671806e-04  5.9149438e-03 -6.5990619e-02
  1.5955539e-02 -6.2675186e-02 -1.1769567e-02  3.2294635e-02
 -1.5938327e-02  5.9880909e-02  3.1734731e-02 -2.8240623e-02
 -3.8798396e-02 -3.8624059e-02  3.3278950e-02 -8.7064635e-03
  4.9364209e-02  3.3571832e-02  4.1587427e-02 -1.9508947e-02
 -2.6012214e-02 -2.0559523e-02  1.7213723e-02  5.5949939e-03
  3.1658307e-02  5.6384970e-03 -6.2683746e-02  5.1175814e-02
  6.1413497e-03 -3.2912113e-02  3.4162108e-02 -3.3704396e-02
  7.0393264e-02  8.2950164e-03  3.6076963e-02 -5.4476004e-02
  1.4388470e-02  1.8147964e-02 -2.0264126e-02  3.9712187e-02
 -8.6767813e-03  5.3381320e-02  5.0753304e-03  2.0706225e-02
  3.6196627e-02  6.1803661e-02  1.5940482e-02 -2.1563536e-02
  7.1499177e-04 -6.3366756e-02 -3.8580764e-03 -5.7551689e-02
 -3.3268806e-02 -3.6135621e-02 -3.4382571e-02  4.1981276e-02
  3.0229690e-02  1.8007617e-02  1.8992528e-02 -2.3594053e-02
  2.0915044e-02 -4.4763118e-02 -3.6711469e-03 -1.0469644e-02
  2.3762402e-03 -2.7396444e-02 -3.0006951e-02 -5.4558355e-02
 -5.5451199e-02  7.3469551e-03  2.2001627e-03  2.3407670e-02
 -5.5337925e-02 -5.8528990e-04 -1.6383822e-03 -3.1214682e-02
  1.5784392e-02 -1.5356386e-02 -5.6029931e-03 -2.9781867e-02
 -2.5765434e-02 -4.8570521e-02 -5.2721228e-02 -5.1649380e-03
  5.3298399e-03 -6.1738256e-02 -2.9649049e-02  2.7533455e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_60/kernel
[[-0.07396409 -0.0635621  -0.08750915 ...  0.1628846   0.00604279
  -0.13308445]
 [ 0.10444635 -0.10876849 -0.09381553 ... -0.01282217 -0.00605354
  -0.02034449]
 [-0.12217063 -0.13086    -0.02409538 ... -0.02570256  0.04516953
   0.01765767]
 ...
 [ 0.03526583 -0.05531879  0.08806416 ...  0.10173299 -0.04520744
   0.09527838]
 [-0.0314827   0.05544327 -0.03385656 ... -0.05786517 -0.10938589
   0.06961532]
 [-0.04157199  0.06539024 -0.13387008 ...  0.06962635 -0.09293469
   0.01136897]]
tensor_name:  TemporalFusionTransformer/time_distributed_61/bias
[-2.24182066e-02 -4.77912799e-02  3.13779637e-02  5.07755578e-03
 -4.61743549e-02 -2.32772455e-02  1.53832044e-02  3.20697688e-02
  5.25870919e-02 -5.89926764e-02 -6.20286725e-03  6.27343357e-02
  1.49863260e-02 -1.31486915e-02 -6.36924654e-02  2.46324744e-02
 -3.57004441e-02  3.35813612e-02  2.66980678e-02  1.69026107e-02
  9.69462935e-03  7.65175465e-03 -1.51274251e-02  2.41994206e-02
  2.36989912e-02  7.33013358e-03  2.20434256e-02 -1.22900195e-02
  1.50986221e-02  1.08684683e-02  1.74017046e-02  1.20171998e-02
  4.38083448e-02 -5.49894664e-03 -3.20114680e-02  1.37113845e-02
 -6.67734537e-03  8.63836240e-03  9.50694364e-03  3.38954441e-02
 -4.26486731e-02 -4.77873441e-03 -1.29231280e-02 -2.46716589e-02
 -2.43411660e-02  3.24234925e-02  2.46579666e-02 -2.25472003e-02
 -4.62270118e-02 -1.17833738e-03  1.62502006e-02  3.63799185e-02
 -1.96536630e-02 -3.53592038e-02 -1.63415391e-02  1.79449301e-02
 -3.85666341e-02  1.22726969e-02 -2.20881458e-02  1.10786386e-01
  6.05104528e-02 -2.75686625e-02 -5.93872219e-02  2.20086444e-02
  1.43697076e-02  3.63640161e-03  2.66334191e-02  2.81795971e-02
  4.92808074e-02  1.21432655e-02  2.26066890e-03  3.06433924e-02
 -1.60876028e-02 -2.14330144e-02  7.46308491e-02  3.24892662e-02
 -3.42920758e-02 -1.99116934e-02 -2.42812298e-02  6.48362413e-02
  1.98644176e-02  2.50162315e-02 -8.02616868e-03  3.20247188e-02
  2.15555523e-02 -2.26617455e-02 -4.31667157e-02 -6.13853475e-03
  4.76063509e-03 -1.83628220e-02  1.20015452e-02  2.14782003e-02
 -3.70213911e-02 -2.24664574e-03 -3.19419615e-02  7.25923618e-03
 -3.02352570e-02 -2.29485449e-05 -8.61432776e-03  1.36970952e-02
 -2.85548214e-02  3.96168828e-02 -5.76719157e-02 -1.32668216e-03
  2.81343739e-02  2.17149896e-03 -4.09221351e-02  7.38781178e-03
  2.79541630e-02 -4.40526642e-02  1.39458748e-02 -6.44302517e-02
 -2.25750264e-02  1.26220714e-02  4.88372110e-02  3.80787142e-02
 -7.94343278e-03 -7.24905217e-03  1.65391583e-02  2.99838912e-02
 -4.85820062e-02  1.07220769e-01 -3.61065827e-02  2.68386900e-02
  1.89141538e-02  1.99768394e-02  4.94426563e-02  1.85167342e-02
 -4.14053723e-02 -3.28802504e-02 -6.17625415e-02 -5.69145568e-02
  3.38599645e-02  4.24627885e-02 -3.19246463e-02  2.48316713e-02
  8.53553507e-03  5.62455498e-05 -9.74894688e-03 -4.65509593e-02
 -8.79120897e-04  5.31040505e-03 -2.02776864e-02  7.52512319e-03
  4.77089453e-03 -6.95885532e-03  1.24422805e-02 -2.14273948e-02
  2.33563911e-02 -5.74907176e-02  1.58453570e-03  8.21588337e-02
 -4.81047928e-02 -9.45146137e-04 -2.28495765e-02 -3.31093594e-02
  4.06760685e-02  1.46377767e-02 -7.50661790e-02 -1.55745745e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_61/kernel
[[ 0.08191331  0.04918457  0.0551326  ...  0.05643587  0.13748658
   0.0428167 ]
 [ 0.12896612 -0.12832697 -0.01112121 ...  0.09457609  0.06016645
   0.02881746]
 [ 0.03305028 -0.01257809 -0.03872809 ... -0.11434986 -0.06058862
  -0.10256932]
 ...
 [-0.12438153  0.05005917  0.09661206 ...  0.03098555  0.0634454
   0.15300584]
 [ 0.07376784 -0.02169275  0.12677239 ...  0.09727059  0.12094519
   0.03304798]
 [-0.03688069 -0.09343746 -0.12508278 ... -0.01740687  0.05485938
  -0.06572055]]
tensor_name:  TemporalFusionTransformer/time_distributed_62/bias
[ 1.29231848e-02 -1.49972718e-02  3.29358838e-02 -1.38619961e-02
 -1.31478859e-02  8.42773635e-03 -2.51832251e-02 -6.31532446e-03
 -1.50731755e-02  1.99260153e-02 -7.25226989e-03  1.24836725e-03
 -1.66658703e-02  1.80964638e-02 -5.13207493e-03 -1.30888063e-03
  6.31088531e-03  8.67756903e-02 -1.81802958e-02  2.21029595e-02
 -9.05498117e-03  1.10673429e-02 -2.82293861e-03 -1.20608866e-01
  1.15220975e-02 -2.71774828e-02  3.95405963e-02 -3.24423648e-02
 -3.69728543e-03  1.81510374e-02 -6.23259135e-03 -2.13445653e-03
 -1.24196969e-02  2.26831567e-02 -2.92496756e-02  1.02215642e-02
  1.79511160e-02 -1.38504396e-03  2.41821706e-02  2.17935815e-02
 -1.05678085e-02  1.98855009e-02 -1.28078982e-02  1.68668404e-02
  9.08135087e-04  1.68920010e-02 -2.17446908e-02  1.19972881e-02
 -2.63185315e-02  1.93161257e-02 -7.01675797e-03  5.47184609e-02
  2.97816992e-02  1.48518779e-03 -2.32930966e-02  5.49785094e-03
  2.10978948e-02 -6.36337101e-02 -1.27970213e-02  4.26966958e-02
  2.64998805e-03  2.22217217e-02  3.24510671e-02 -4.11432143e-03
  9.03166481e-04 -5.32147614e-03 -1.17865195e-02  1.73074920e-02
  5.64414868e-03 -9.74706747e-03 -1.68396663e-02  2.05819663e-02
  1.43494224e-02  2.91509815e-02 -1.46528492e-02 -2.32212245e-02
  3.31429280e-02  1.33353192e-02  8.14839173e-03 -3.30476416e-03
  7.07106246e-03  3.03742755e-02 -2.19907667e-02 -5.33879083e-03
  7.92326499e-03  1.41791822e-02 -2.90801693e-02 -9.28988331e-04
  1.93370786e-02 -1.39520746e-02  2.41026841e-02 -6.60969922e-03
 -1.42445853e-02  4.84624924e-03 -7.94468448e-03  1.99942458e-02
  1.73211396e-02  1.52274398e-02 -9.59641300e-03 -6.14758255e-03
 -1.80733372e-02 -1.02149015e-02  3.30511294e-02  2.31221877e-02
 -3.02051107e-04  2.32215244e-02 -9.12136515e-04  2.83345208e-02
 -4.10826057e-02  1.37527473e-03  5.18352306e-03 -2.77928840e-02
  9.98013094e-03  4.30904888e-02 -3.70642310e-03 -6.59600412e-03
  1.09648369e-02 -3.49312760e-02  2.64415350e-02  1.61376689e-02
 -4.22110315e-03 -5.42348204e-03 -1.95509866e-02 -1.82674900e-02
  6.57036901e-02  9.21901490e-04  1.02613857e-02  2.03173049e-02
  4.63157659e-03  1.67696569e-02 -6.37489278e-03  2.08863150e-03
 -3.35249864e-02 -3.65808979e-02 -2.24273391e-02 -8.03687982e-03
  3.83328996e-03  1.26832165e-02 -4.07661172e-03 -2.13862192e-02
 -6.28056051e-03  2.53163408e-02 -1.54119013e-02 -1.17081967e-04
 -9.27403755e-03  1.23317121e-02  7.75729073e-04 -2.04278436e-02
 -4.49698009e-02 -9.96194221e-03 -4.40579792e-03  4.50089108e-03
 -3.61472629e-02 -2.58424599e-02  8.90469365e-03  2.50728782e-02
 -1.58023108e-02 -9.93377063e-03 -3.40400748e-02 -6.18333789e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_62/kernel
[[-0.1153898   0.06433816  0.00509193 ...  0.03483211 -0.06505509
   0.0612439 ]
 [-0.01645477  0.05209639 -0.15358151 ...  0.11306288 -0.06375643
  -0.01287832]
 [ 0.16792937  0.03138305  0.16999398 ...  0.0926239  -0.12440995
  -0.00524141]
 ...
 [-0.00338261 -0.05306118 -0.08088593 ...  0.13654315 -0.01332927
  -0.11172031]
 [ 0.009098   -0.08656298  0.06859072 ...  0.06813223  0.02179705
  -0.09576246]
 [ 0.00550566  0.11706126  0.06197876 ... -0.13111143 -0.05167624
  -0.06615365]]
tensor_name:  TemporalFusionTransformer/time_distributed_63/bias
[ 7.04944804e-02  3.75283911e-04  3.63405906e-02 -2.03075800e-02
 -1.10188769e-02 -3.38843092e-02  1.49118379e-02 -2.70489138e-02
 -1.04251830e-02 -1.87257826e-02 -6.37981743e-02  1.78754739e-02
 -3.62216793e-02 -1.49988313e-03 -2.03854050e-02 -2.71824393e-02
  3.56810391e-02  9.03939828e-02 -1.25232693e-02  4.03828807e-02
 -2.52243355e-02 -2.35570595e-02 -3.37474910e-03  1.69982985e-01
 -3.56617607e-02 -1.13451527e-02  9.05435346e-03  5.23800999e-02
 -1.20273624e-02 -5.62153105e-03 -2.81563178e-02 -1.05053652e-02
 -1.44492900e-02 -1.52856084e-02  2.32341569e-02 -3.02594192e-02
 -3.05000748e-02 -4.92626838e-02 -4.91314940e-03  3.96156982e-02
  1.34099750e-02  1.05757115e-03 -5.29356226e-02  1.67135932e-02
 -3.62602845e-02 -3.82597931e-02 -1.79583766e-02 -3.43127325e-02
  4.54335473e-02 -2.30518989e-02 -3.56033780e-02  5.71000651e-02
  6.81380788e-03  5.46068419e-03  2.66339350e-02 -2.36503575e-02
 -3.97521183e-02  1.19493566e-01 -1.44979879e-02  1.76075026e-02
 -2.47277170e-02 -1.40568521e-03  2.82739624e-02 -2.17397660e-02
 -5.48503995e-02 -4.04474065e-02  1.11016957e-02 -4.45621647e-03
  6.18522614e-03 -4.96655144e-03 -1.89743806e-02 -9.27839195e-04
 -1.57957431e-02  7.11421622e-03  1.10863913e-02 -1.50631601e-02
  2.12609991e-02 -1.26088895e-02 -4.65487018e-02 -1.67183706e-03
 -1.28325960e-03  9.03779524e-04  1.72423050e-02 -3.64481658e-02
 -1.02181425e-02 -3.19978148e-02 -1.65911787e-03 -5.43964095e-02
  3.00109945e-03 -1.66496206e-02  2.76968535e-02 -3.03390082e-02
 -3.18812430e-02 -6.25344412e-03 -1.12453662e-02  4.53795046e-02
  1.28538273e-02 -6.00960047e-04 -1.85592398e-02 -5.61561398e-02
 -3.11058294e-03  1.76396426e-02 -1.39260469e-02  9.49204806e-03
 -2.06933748e-02  4.06932924e-03 -7.19612464e-02  2.80521344e-02
  1.80333946e-02  1.51532531e-01 -2.15272810e-02 -7.17504416e-03
 -3.54238972e-02  3.75399962e-02 -2.33895201e-02 -6.76749088e-03
 -1.39079401e-02  2.64026504e-02 -2.94035766e-03 -4.61647101e-03
 -5.14231920e-02 -7.11258908e-05 -5.71464654e-03 -4.51244367e-03
  3.45508605e-02 -1.65577661e-02  1.55138620e-03 -5.91977360e-03
  6.00632560e-03 -2.62375944e-03  1.90842170e-02  3.87114249e-02
  3.84259112e-02  5.85400872e-02  7.07132102e-04 -4.35111783e-02
 -2.86905244e-02 -1.84561219e-02 -2.46739127e-02  1.36236101e-03
 -4.90633771e-02  3.78101654e-02 -8.42923112e-03 -1.52919358e-02
 -3.73447314e-04 -1.54567920e-02 -5.11625670e-02  3.14301960e-02
  3.91218662e-02 -1.60730053e-02 -5.99114038e-03 -1.31567251e-02
  3.92178595e-02  2.84990985e-02 -9.15301312e-03 -3.42021027e-04
  4.39691031e-03 -4.71953042e-02  9.94953699e-03 -2.28420179e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_63/kernel
[[-0.14442019  0.14139603 -0.02929449 ... -0.09056324 -0.11091612
   0.00966676]
 [ 0.00118597  0.12166728  0.13608009 ... -0.04565879 -0.12235902
  -0.05361189]
 [ 0.15519767  0.03953853 -0.0755593  ...  0.01096754  0.14732754
   0.1512582 ]
 ...
 [-0.08226409  0.06351855 -0.07652515 ... -0.1183371  -0.09737446
  -0.08445121]
 [-0.08389795  0.01180237  0.09341954 ... -0.03476588 -0.13202417
   0.02353889]
 [ 0.10436794 -0.0385345  -0.04334163 ...  0.00717303  0.15021329
  -0.05353283]]
tensor_name:  TemporalFusionTransformer/time_distributed_64/bias
[-0.0215505   0.04822293 -0.06400059 -0.01559413  0.02988597 -0.04226139
 -0.02500372  0.00061558  0.11128684  0.04476     0.00136931  0.01952428
  0.0761297  -0.01165355 -0.03800306  0.05229454  0.03459705 -0.02304849
 -0.04022517 -0.02197908 -0.06274914 -0.0098203   0.03518362 -0.0262052
  0.02348434  0.00349205 -0.045492    0.06260578 -0.03644472  0.01812222
 -0.04849415  0.08817052  0.01879211 -0.05723299  0.01122355  0.02832522
 -0.03987925 -0.00284592  0.07745141 -0.06981852 -0.11560441  0.00585505
 -0.00684787 -0.01810351  0.02760554 -0.03290691 -0.09632061  0.05931191
 -0.04993567  0.03871993 -0.0828971  -0.06462634  0.05077324 -0.05249616
 -0.02748089 -0.04511718  0.01385991  0.03250669 -0.03052942  0.01858529
 -0.03639656 -0.02976788  0.04342021 -0.09207699 -0.02610062  0.00782657
 -0.00435341 -0.00272403  0.02725211 -0.00666414 -0.02531472  0.06087221
  0.06494922  0.05652437  0.00047399 -0.00069187 -0.03598684 -0.02341984
 -0.04838532  0.00404442 -0.02690913  0.05118386 -0.03385579 -0.0072982
  0.0538847  -0.04280221  0.01215259 -0.00927646 -0.0355665   0.04577485
  0.03711202 -0.04249183  0.0145624  -0.02733054 -0.04842503 -0.01228848
  0.04643988 -0.0329094  -0.08072717 -0.04263526 -0.0073062   0.00247263
 -0.03078635  0.02381033  0.01895051  0.01605924 -0.06820054  0.06844441
  0.02781831 -0.00904108  0.03126721  0.06936871  0.0549361   0.048857
  0.02328569 -0.03369444 -0.01367124 -0.01226516 -0.00490904 -0.00236254
 -0.00184476 -0.04080528  0.02123436  0.0013211  -0.01856203  0.03424492
 -0.02885522  0.03752237 -0.05112643  0.08420111  0.02106936 -0.05581318
 -0.0328773  -0.02608647  0.00788251 -0.02370731 -0.04402626 -0.01702163
  0.00904553  0.0825195  -0.04260031  0.00946273 -0.01794238  0.00416886
  0.01189283  0.02183154  0.02298575 -0.00029692 -0.02182823  0.00709735
  0.03729576 -0.0107968   0.00430718  0.03707531 -0.05707849 -0.02667988
  0.00595052  0.03390919  0.01135112 -0.08127549]
tensor_name:  TemporalFusionTransformer/time_distributed_64/kernel
[[ 0.0077698   0.13872759  0.06605686 ...  0.05327733  0.03867806
   0.0418833 ]
 [ 0.10016767  0.06076343  0.09658749 ...  0.05515871 -0.12942602
  -0.03361678]
 [-0.00118599 -0.13071087  0.12116905 ...  0.10195833 -0.14111784
  -0.0965232 ]
 ...
 [ 0.03118299 -0.04979298  0.1500182  ... -0.11781064  0.03407376
   0.14640374]
 [-0.059515    0.13466512  0.02305627 ... -0.09386472 -0.08887704
  -0.02855857]
 [-0.08179299  0.09008525  0.0240427  ...  0.09218341  0.16325939
   0.04026884]]
tensor_name:  TemporalFusionTransformer/time_distributed_65/bias
[ 1.63033623e-02  4.47564796e-02  3.61435898e-02  7.93230254e-03
 -2.81690285e-02  2.29851734e-02  4.57593575e-02  3.01986430e-02
 -2.58789565e-02  4.16018590e-02 -3.53560150e-02  3.09269931e-02
  9.16282646e-03  3.05554247e-03 -2.31110454e-02  2.17258669e-02
 -1.89869702e-02 -3.16060870e-03  1.95316542e-02 -1.75050870e-02
 -4.22919430e-02  7.76465284e-04  3.59794945e-02  1.20040141e-02
  2.95663476e-02  2.34720055e-02  1.93823911e-02 -3.98541652e-02
 -9.25256219e-03 -8.19515157e-03 -1.80921573e-02 -1.52604273e-02
  2.34216470e-02  2.36314498e-02 -4.87515004e-03  2.38319039e-02
 -1.58955324e-02 -2.93424986e-02 -3.05691380e-02 -2.73342375e-02
  3.18952799e-02 -5.41111380e-02  2.69993413e-02  1.55961765e-02
  1.19995428e-02 -3.49528715e-02 -2.20523663e-02 -2.80091102e-04
 -2.98708938e-02  5.75520890e-03 -8.31721257e-03 -4.64367941e-02
  2.45190132e-02  2.23241374e-02 -4.66618985e-02 -5.36443293e-02
  1.77756157e-02  4.98518497e-02 -3.72341722e-02 -7.37884984e-05
 -6.25069961e-02  6.98662028e-02  1.85803007e-02  3.39490213e-02
  3.08540910e-02 -7.14440085e-03 -2.80241016e-02  3.26316059e-02
  1.49947396e-02 -4.69263755e-02  1.38630448e-02  6.21062424e-03
  3.25489626e-03  4.00294736e-02  1.69004966e-02 -1.06319189e-02
 -2.09661257e-02  6.97753355e-02  3.22062150e-03 -2.27364320e-02
 -7.34332425e-04 -1.88143142e-02  4.87772329e-03  2.54746880e-02
 -8.28789081e-03  3.92669514e-02  5.29662780e-02 -6.86010858e-03
 -2.34832391e-02 -2.80767959e-02  1.10783195e-02 -1.45103410e-02
 -5.19660227e-02 -5.19651314e-03 -3.68764624e-02 -2.03635022e-02
  1.08503988e-02  1.03539620e-02 -2.10685208e-02 -4.72898111e-02
  2.80863754e-02  6.87351543e-03 -4.05483805e-02 -9.26294422e-04
  6.50319830e-02  5.96161839e-03  1.34026427e-02 -2.47706044e-02
 -4.48859632e-02 -5.12639359e-02 -3.24284844e-02  1.26010727e-03
 -6.98268926e-03 -3.77388336e-02 -1.05498163e-02 -1.62251592e-02
 -2.10605655e-02 -4.05130759e-02 -3.10860220e-02  1.66607928e-02
  1.25471428e-02 -3.31001170e-02 -9.08395182e-03  1.06592542e-02
  5.53043224e-02 -2.71056928e-02 -6.58585131e-02 -1.82903558e-03
  8.33079859e-04 -3.48523445e-02  4.40905318e-02 -4.90534417e-02
  1.35730412e-02 -9.01816115e-02 -2.23548114e-02  2.52904389e-02
 -2.26836465e-02  3.09355732e-04  2.23388318e-02 -1.23636629e-02
  1.02722868e-02  2.68066972e-02  1.25293136e-02 -5.53123094e-02
  3.31570320e-02 -4.88875136e-02  2.83462889e-02  3.35274125e-03
 -1.04934387e-02  1.73191968e-02 -2.87835095e-02 -3.97962518e-02
  2.21309848e-02 -2.37832032e-02  1.31689887e-02  5.56594804e-02
 -2.96537206e-02 -9.39791929e-03 -1.63119696e-02 -2.90178563e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_65/kernel
[[-0.00817494 -0.09612385 -0.06108722 ... -0.04397742 -0.00983729
  -0.04198326]
 [ 0.00315159 -0.11448904  0.01034179 ...  0.09337227 -0.01158732
  -0.00446574]
 [-0.08937391  0.04171583 -0.18097138 ... -0.06769978  0.04517877
   0.00868009]
 ...
 [ 0.11467082 -0.1211003   0.05633982 ... -0.09971566  0.08490551
   0.03573472]
 [-0.07705864  0.01962366  0.05416337 ...  0.11628467 -0.12093551
  -0.04201134]
 [-0.04584125 -0.15241872  0.05246816 ... -0.01953889  0.11857238
  -0.03928779]]
tensor_name:  TemporalFusionTransformer/time_distributed_66/bias
[ 1.25713293e-02 -1.68792822e-03  1.62408557e-02  6.35552779e-03
 -2.05898490e-02  1.08442865e-02 -1.63237788e-02 -1.08988788e-02
  2.43958514e-02  9.19909403e-03 -7.58205540e-03 -3.64946350e-02
 -8.52893200e-03  1.78669784e-02  1.70577373e-02  1.55394729e-02
  6.95068669e-03  1.07631497e-02 -1.03251906e-02  1.92635860e-02
  2.79840824e-05 -2.05384176e-02 -9.80950613e-03  5.17339073e-02
  8.49723816e-04 -5.31867472e-03  2.49805953e-02  1.45342303e-02
 -2.19684350e-03 -3.20176873e-03 -1.07156467e-02  1.24176089e-02
 -1.16911735e-02  1.25132371e-02 -2.79799104e-02 -1.25432443e-02
 -2.40086094e-02 -3.79841067e-02  2.34937966e-02  2.78577041e-02
 -1.28886441e-03  3.02162953e-04 -2.86249258e-02  2.77374033e-02
 -5.41929994e-03 -1.19685829e-02 -2.38470361e-03 -2.62390263e-03
 -8.12101916e-06  3.51116322e-02 -2.45300252e-02  4.63732481e-02
  2.52961423e-02  2.90028136e-02  3.79412156e-03  2.41717370e-03
  2.19444260e-02  1.12684397e-02  7.01927301e-03  1.68388318e-02
  1.19146323e-02 -9.45374183e-03  1.72413196e-02 -2.20195167e-02
 -1.21392105e-02  1.68392509e-02 -1.58089418e-02 -3.98088559e-05
 -2.12158021e-02 -9.38245852e-04 -5.92669751e-03  1.50600364e-02
 -6.32798625e-03  1.07256882e-02 -2.02078745e-02 -2.66355406e-02
  3.46891582e-02  2.79798321e-02 -2.28893268e-03  2.96299085e-02
  3.15033738e-03  3.07301357e-02 -2.74922769e-03  7.24764541e-03
 -5.01181372e-02 -4.47824644e-03 -2.90724151e-02  4.55392618e-03
  1.65582001e-02  4.44962381e-04 -6.35960978e-03 -1.06484247e-02
 -3.01262252e-02  3.28272348e-04 -1.44197419e-02  4.67984080e-02
 -1.30669260e-03  5.04418276e-03  1.18526965e-02 -1.50923366e-02
  3.56725673e-03 -1.21889878e-02  2.74797641e-02 -4.79037268e-03
  1.94637273e-02  1.70550670e-03 -6.90942490e-03 -7.33080786e-03
 -4.22073714e-02 -3.45834810e-03 -8.36568605e-03 -1.16321938e-02
  3.07357516e-02  5.78756386e-04  1.66743062e-02 -3.58204031e-03
  3.09086964e-02 -4.70214002e-02  4.62480746e-02 -2.08164705e-03
  8.54420662e-03 -1.39491372e-02 -1.71364062e-02 -2.85096411e-02
  1.56580638e-02 -1.84895024e-02  2.04021670e-02  3.75943184e-02
 -3.69583396e-03  1.28930042e-04 -1.51664400e-02 -5.51917497e-03
  6.11951342e-03 -5.07691689e-02 -7.29383389e-03  1.03401151e-02
  9.20471444e-04  1.01593742e-03  1.86633971e-02 -1.33168548e-02
 -9.43674613e-03  2.52369493e-02  2.29396094e-02  2.64232308e-02
 -3.19757052e-02 -7.14931265e-03  3.55217257e-03 -2.57212948e-02
 -5.17251901e-02 -1.37613313e-02 -1.00626971e-03  2.06182543e-02
 -2.94381417e-02  8.54048692e-03  4.20382991e-03 -8.72239191e-03
 -3.14500779e-02  2.34423555e-03  1.71229821e-02 -1.07680364e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_66/kernel
[[ 0.10584939  0.1196997   0.07382724 ... -0.02526905 -0.11405509
  -0.10247879]
 [-0.00449869  0.02970818  0.01474672 ... -0.093224   -0.1327458
   0.0108826 ]
 [-0.12121847  0.1287112   0.12272386 ...  0.03331291  0.04327338
  -0.09308542]
 ...
 [ 0.10875764  0.12632954 -0.01317897 ... -0.07308013 -0.09662536
  -0.00964278]
 [-0.04376438 -0.06734655  0.09763001 ... -0.10655562 -0.08712476
   0.02311124]
 [-0.05837369  0.05828932 -0.09590882 ... -0.10927779 -0.10041865
  -0.05731082]]
tensor_name:  TemporalFusionTransformer/time_distributed_67/bias
[-2.62773316e-02  3.38130561e-03  1.99064985e-02 -3.18938047e-02
 -2.93282568e-02  5.35488478e-04 -1.48895206e-02  1.94664078e-03
 -6.73868582e-02 -3.92314307e-02 -1.50299072e-03  4.17831820e-03
 -2.56621763e-02 -3.67933139e-02 -4.02209237e-02  8.27847514e-03
 -1.82324983e-02  3.22856493e-02 -4.29536775e-02 -5.29539119e-03
 -5.37470467e-02 -7.34638423e-03 -1.20915531e-03 -5.16805686e-02
 -1.36862714e-02 -3.36428806e-02 -4.48247455e-02  9.68388654e-03
 -2.92748623e-02 -1.98535789e-02 -2.01446768e-02 -4.27818447e-02
 -9.89956688e-03 -2.26172023e-02 -1.92775857e-02 -6.42093783e-03
 -2.50461907e-03  9.44951456e-03 -1.54627664e-02  1.40074082e-02
 -2.78564151e-02 -3.31647098e-02  1.57325789e-02 -2.39665247e-02
 -5.72037976e-03 -3.23691443e-02 -1.77931171e-02  1.57518107e-02
 -1.49202980e-02 -1.14364978e-02 -2.69131456e-03 -4.24115174e-02
 -6.52988674e-03  1.74531736e-03 -2.15373188e-02 -1.91556923e-02
  5.44540677e-03  2.97571663e-02 -7.53695006e-03  6.05435390e-03
 -5.98307848e-02 -1.84825659e-02  1.14530092e-02 -2.30921805e-02
  1.98093448e-02 -2.45626532e-02 -1.83316842e-02 -6.30261190e-03
 -7.57761970e-02 -7.72647411e-02 -5.34893312e-02 -4.13811691e-02
 -2.89983526e-02 -8.69152282e-05 -3.79637210e-03 -4.72884811e-02
 -1.44676417e-02 -1.30851706e-02 -1.48962336e-02  1.26947567e-03
 -1.70728229e-02 -9.85469855e-03 -3.90606336e-02  5.25371777e-03
  1.68328322e-02 -3.47964279e-02  5.11428565e-02 -3.05055212e-02
  5.65125188e-03 -1.44184520e-02 -3.35035622e-02 -1.24262376e-02
 -4.24806541e-03 -1.66201789e-03  5.34548657e-03  2.16481872e-02
  3.74013223e-02  1.88201256e-02 -5.58552481e-02 -2.35252213e-02
  8.68143737e-02 -3.51144164e-03 -1.51074370e-02 -2.88389996e-02
 -3.39523293e-02  9.44595039e-03 -3.83741856e-02 -3.04745995e-02
  2.82846559e-02 -1.35515863e-02 -4.28573526e-02 -1.45389941e-02
 -1.16152707e-02 -4.21653427e-02 -3.41327228e-02 -5.33864601e-03
  3.51429917e-03  2.98483390e-02  3.78629863e-02 -4.64591384e-02
 -1.53752537e-02  3.02563887e-02  1.49682108e-02 -8.91776849e-03
 -7.99268577e-03 -2.81139445e-02 -1.33654298e-02  1.11993775e-02
 -2.19899360e-02 -8.40659160e-03 -3.40608805e-02 -1.67905428e-02
 -3.96605767e-02 -2.28500571e-02  1.03341322e-02 -3.42393629e-02
 -1.91596560e-02 -1.29651399e-02  3.98668051e-02  7.91439135e-03
 -1.84621830e-02 -1.80078950e-02 -3.75002921e-02 -1.18038096e-02
  8.29433184e-03 -4.40106839e-02 -2.21272446e-02 -1.78341405e-03
  2.20229980e-02 -2.96259392e-02 -2.46549342e-02 -3.08928322e-02
  2.57239677e-03 -7.86973350e-03 -1.37497429e-02 -2.75029466e-02
  3.36560495e-02 -4.60787006e-02 -2.46903934e-02 -9.81929060e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_67/kernel
[[ 0.04767111  0.14070629 -0.00806746 ... -0.18132159  0.07001687
  -0.0186796 ]
 [ 0.03015976 -0.07038971  0.18592177 ... -0.07664144 -0.02302212
  -0.13061473]
 [-0.0298415  -0.00345491 -0.03640995 ... -0.0854885   0.08672438
  -0.05131118]
 ...
 [-0.05082934  0.02750563  0.12329749 ... -0.04608881  0.0616186
   0.12306318]
 [-0.08027521 -0.12819411 -0.04454022 ...  0.13939087 -0.02792749
   0.11396771]
 [-0.04095294  0.01687574 -0.12393724 ... -0.00333386  0.01862793
   0.13611314]]
tensor_name:  TemporalFusionTransformer/time_distributed_68/bias
[ 0.01957721 -0.00089558  0.01871612 -0.00517409 -0.00409132  0.02567379
 -0.00779203  0.00320598 -0.04172162 -0.03369805  0.03206472  0.02891028
 -0.01365931 -0.00039622  0.01158547  0.02600623  0.00451006  0.01448919
  0.04182492 -0.02230776 -0.00420949 -0.0197638  -0.01178971 -0.02025561
  0.0092831   0.04285878  0.00487943  0.02100243 -0.03726524  0.0139938
  0.03405492  0.01433639 -0.00773273 -0.01424592  0.04946862 -0.00118545
 -0.02651783 -0.05773545  0.04002711  0.03946887 -0.04130461 -0.01602028
  0.0039621   0.01090241 -0.01261074 -0.01313625  0.03913048  0.05017315
  0.0239614   0.0121884   0.04469182 -0.01009864 -0.03844893  0.04470982
 -0.00257167 -0.06521992  0.02772601  0.003111   -0.03514715  0.01706662
 -0.01702077 -0.03597046 -0.03798154  0.00361923 -0.02831279 -0.02708149
  0.00621525  0.02730836  0.00404314  0.02296393  0.03397816  0.00395081
  0.02424703  0.00010991  0.00070032 -0.00065472  0.01472416  0.00408625
 -0.01928487 -0.00375417 -0.00071947  0.0198651  -0.03836869 -0.00163388
 -0.0367205   0.01424945 -0.00243043 -0.00407785 -0.005204   -0.04959093
  0.0378055  -0.00013528  0.01005124 -0.01690723  0.02233021 -0.03929908
 -0.02530852  0.02166114  0.00992371  0.00887852  0.01203421  0.04566678
 -0.01772274 -0.05601236 -0.03063106 -0.02235851 -0.01108827 -0.01345973
  0.01007084 -0.02017188 -0.01608747 -0.01685906 -0.02590417  0.02125101
  0.04959226  0.01795872 -0.00309543  0.01228737 -0.03521845  0.0194391
  0.00333915 -0.00807489  0.01491155 -0.03175116 -0.03238875  0.01170283
 -0.01706787 -0.02007511  0.00102276  0.00197008 -0.0311799   0.03357306
 -0.03756583 -0.01985659 -0.01428121 -0.03077263 -0.00930716 -0.02392245
  0.02551404 -0.03848968 -0.0227379   0.03630682  0.01323698 -0.02960848
  0.04615837 -0.01262143 -0.00918768 -0.00746038 -0.0162475  -0.03079312
  0.00860812  0.07041278  0.01683123  0.03111152  0.00203268 -0.00626056
 -0.01083797  0.02354443  0.01075799 -0.00488242]
tensor_name:  TemporalFusionTransformer/time_distributed_68/kernel
[[-0.0243698  -0.00282952 -0.07557923 ... -0.05012918  0.01847132
   0.05275261]
 [ 0.0858988   0.03828054 -0.04603715 ... -0.08475086 -0.10805923
  -0.13587739]
 [ 0.048321   -0.08899727  0.06452373 ...  0.1183232   0.11191005
   0.06716062]
 ...
 [-0.10736212 -0.00802494  0.07558058 ...  0.09060089 -0.05503304
  -0.08344867]
 [-0.05504976 -0.09407783  0.04087942 ...  0.0724012   0.09098183
  -0.02690402]
 [ 0.02579155  0.096528    0.07629191 ... -0.004084   -0.10240824
  -0.04332375]]
tensor_name:  TemporalFusionTransformer/time_distributed_69/bias
[-0.02295304  0.03156063  0.0152324  -0.01918502 -0.02540645  0.0387021
  0.01578291  0.04448725  0.02411577  0.03994177  0.02377388 -0.00597187
  0.00170665  0.03076329 -0.03728207  0.00141539  0.02419443  0.02276687
  0.01693163 -0.01291375 -0.00887341 -0.00994309  0.04567844  0.01770347
 -0.01883845 -0.02792158 -0.05200421 -0.010783   -0.00354822 -0.01791467
 -0.00114837 -0.02689074 -0.03695516  0.01010381 -0.05403331  0.00834422
 -0.04949678  0.01736798  0.02757437 -0.00872981 -0.00791762  0.02348138
 -0.04301143  0.01088438 -0.02507501  0.02039651 -0.01108576 -0.04690861
 -0.01857757  0.02357679  0.01707393  0.01273613  0.03409373  0.03991724
  0.02094678  0.00285928  0.04240399  0.00530864 -0.03855847 -0.01883519
  0.03124036 -0.01173991  0.0363108  -0.00065299 -0.00362272 -0.00247614
  0.00985823 -0.00133581  0.01754072 -0.035744    0.03835052  0.01083038
  0.01982864  0.01782324 -0.00016148  0.03852075 -0.02889285  0.05202666
 -0.04651042 -0.0141358   0.00486473 -0.03182327 -0.02250813 -0.02409285
  0.00650177 -0.00837754 -0.02094254  0.00266197  0.0292932  -0.0032497
  0.0074341   0.02461299  0.02111797  0.03526171 -0.0015766   0.0402355
  0.02733781 -0.02710373  0.01750338 -0.0201089   0.03906048 -0.03409286
  0.04606424  0.03489626  0.02035085 -0.00095879  0.0042876  -0.04373026
 -0.00796463 -0.04067573 -0.01918311  0.02310323 -0.01371798 -0.00600126
  0.00412685 -0.03130231  0.01139403 -0.03317475  0.01441532 -0.0116739
  0.03599927 -0.00938749 -0.02266867  0.03711839 -0.02304202 -0.01285336
 -0.01827886  0.02372672  0.02121493 -0.0731641  -0.01110355  0.01665952
 -0.0042545  -0.04225941 -0.01636319 -0.02445495 -0.06416231 -0.00432807
  0.04572769  0.01609805 -0.02734425  0.03506185 -0.04520853  0.01067847
 -0.01477882  0.03122789 -0.02275533  0.01599251  0.01992401 -0.01193868
 -0.04668748  0.01822018 -0.043431   -0.03476758  0.04872372  0.0042314
  0.01332536  0.0055232  -0.02887175 -0.01029039]
tensor_name:  TemporalFusionTransformer/time_distributed_69/kernel
[[-0.09998067 -0.06924003  0.04987689 ...  0.07591011  0.11254673
  -0.03803748]
 [-0.01097666 -0.14491545  0.13139448 ...  0.09405618 -0.12900354
  -0.09060641]
 [-0.12519436  0.13363278 -0.13556987 ...  0.0083178   0.07533317
   0.09583785]
 ...
 [ 0.09144558 -0.04660896  0.08672252 ...  0.0711979  -0.07076401
  -0.13385922]
 [ 0.11338981 -0.11517453  0.09348026 ...  0.07926117  0.02453158
   0.04858017]
 [-0.10528467  0.06734408 -0.01656127 ...  0.07214489  0.10680572
  -0.08323519]]
tensor_name:  TemporalFusionTransformer/time_distributed_7/bias
[ 0.02142765  0.01368985  0.0762169   0.00385829 -0.00752942 -0.01037098
  0.0327356  -0.03555417 -0.03179615  0.06433774  0.0017993  -0.0351404
 -0.02891405  0.02869039 -0.00030038  0.00381662  0.06577018  0.03878623
  0.01075519  0.02138873 -0.02330015  0.04623668  0.01375196  0.0467725
 -0.00513401  0.01776305  0.10116213 -0.06606195 -0.02787394  0.04518948
  0.0049282  -0.02390414 -0.04836363  0.02141215 -0.03787594 -0.05822551
 -0.0233239  -0.03187051  0.06119365 -0.01244768  0.09747701  0.02404626
 -0.04364797  0.00764908 -0.00988564  0.03397909 -0.0093694  -0.01513979
  0.00513467  0.07488027 -0.03990865  0.04494076 -0.00950475 -0.00245564
 -0.02252709  0.02453977 -0.03752063 -0.08418132 -0.00532522 -0.01077697
  0.00663979  0.01483144  0.04116796 -0.02086236 -0.06341415  0.01717222
  0.02043566  0.02684056 -0.02493277 -0.02331633 -0.00841186  0.00748991
 -0.00473191  0.03546608 -0.08217849 -0.0356008   0.06382465  0.09596467
 -0.0093407   0.02385733  0.00955507  0.03938932 -0.06515015 -0.06070324
  0.00473873 -0.05014268  0.00014613  0.03353945 -0.0035839   0.0416296
 -0.10378312  0.09421326 -0.01478187 -0.03969311  0.01968936 -0.02089643
  0.01040806 -0.01442491  0.02314621 -0.03680209 -0.00505622 -0.02002071
  0.04686298 -0.03835483  0.01163865 -0.09800322 -0.01714385 -0.01237952
 -0.02230344  0.09143145  0.0318031  -0.02698966  0.02568169  0.02953391
 -0.00942445  0.00963345  0.02629646 -0.0609794   0.01634722 -0.00596885
 -0.01662459 -0.11917116 -0.03715742 -0.02892553 -0.03980157 -0.04818114
  0.02452424  0.03212018  0.02693544  0.02119888 -0.05180067  0.00816264
 -0.00210493  0.02117712  0.00099006  0.01893324  0.05064894  0.00724613
 -0.00021632 -0.05819576 -0.04574585  0.01708496  0.00815648  0.06622268
 -0.02897315  0.0144225   0.02133376 -0.02639532 -0.04925622 -0.01827743
  0.01649498 -0.04364603  0.03744575 -0.03653828 -0.02180062 -0.01526609
  0.0657286   0.02967929 -0.01255348 -0.04325918]
tensor_name:  TemporalFusionTransformer/time_distributed_7/kernel
[[ 1.17809027e-01  9.92616266e-02 -3.05658057e-02  1.41814187e-01
   1.87233984e-01  2.92448606e-02  2.17343360e-01  1.98414892e-01
  -1.61627695e-01 -1.13126405e-01  1.26981989e-01  6.88316524e-02
  -1.83579817e-01 -6.49546552e-03 -3.91687341e-02  1.00200064e-01
   1.83155224e-01 -1.44741133e-01  2.45436952e-02 -1.93098858e-01
   9.85485017e-02  8.61399472e-02  7.09272102e-02 -2.51188390e-02
  -6.70975819e-02  1.83905154e-01 -1.56496435e-01 -1.10279866e-01
  -1.13081612e-01  1.50397003e-01  1.98115632e-01 -1.99805215e-01
  -6.29510358e-02 -1.80268422e-01  3.58191915e-02  1.73993763e-02
   1.23419121e-01  6.72091991e-02 -1.24727249e-01  8.87548253e-02
  -1.07380025e-01  1.65709481e-01 -6.47329688e-02 -2.34038576e-01
  -1.60770655e-01  8.30627531e-02  1.69229761e-01  2.09915712e-01
  -1.90178111e-01  4.84189130e-02  1.07555784e-01 -1.43438175e-01
  -1.05326824e-01 -7.84233585e-02 -1.78148061e-01 -1.73236558e-03
  -6.43549562e-02  6.10015281e-02 -5.44696487e-02 -1.02083378e-01
   9.59117860e-02  1.71233535e-01  1.23717189e-01  2.17340946e-01
  -1.94838532e-04  1.38289362e-01 -1.72870860e-01  1.63586065e-01
   2.31300890e-01 -9.64611024e-02 -1.16951860e-01 -4.34328094e-02
  -1.70870095e-01  4.21945266e-02  3.81306373e-02  1.62595019e-01
  -5.62971504e-03 -1.89131632e-01 -6.89633042e-02 -2.16542587e-01
   3.61031778e-02 -1.68872356e-01  1.49506539e-01 -1.46173999e-01
   1.33241057e-01 -1.00213464e-03  7.90520757e-02  7.63976052e-02
  -1.91711456e-01  3.29619925e-03  8.14701393e-02  5.13985977e-02
   1.38207793e-01  1.43752694e-01 -1.61581829e-01 -1.20922484e-01
   1.62321523e-01 -1.52524203e-01 -9.88253132e-02 -1.37721837e-01
  -1.78676665e-01  2.03774404e-02 -5.83577827e-02  3.60777490e-02
  -4.92713638e-02 -2.21288316e-02 -1.10391982e-01  2.11972773e-01
   1.78977311e-01  7.21978545e-02  1.34939939e-01  7.77117610e-02
  -1.54390052e-01 -5.32120615e-02 -1.50406078e-01 -2.03812703e-01
  -7.56869465e-02  2.34729454e-01 -1.54664531e-01 -3.35084833e-02
  -1.51838854e-01  1.01312190e-01  1.33534417e-01  9.19500813e-02
  -9.63175818e-02  6.75332919e-03  8.92846733e-02 -1.18789800e-01
   7.22625256e-02  1.12229429e-01 -1.39050305e-01  1.71006754e-01
  -2.48031821e-02  1.45060971e-01  5.00858575e-03  3.73079330e-02
   1.64548948e-01  2.30375215e-01  9.87059772e-02 -1.51182204e-01
  -5.74036315e-02 -1.91401020e-01 -1.39977738e-01  2.64888518e-02
   2.30690733e-01  1.71656743e-01  1.93513960e-01  1.70706838e-01
  -7.55938739e-02  2.19294190e-01  1.08789049e-01 -1.01852670e-01
   9.98238660e-03 -5.39369956e-02 -1.64050132e-01  1.55821145e-01
   8.22656229e-02  8.30152482e-02  8.95038620e-02 -1.09638363e-01]]
tensor_name:  TemporalFusionTransformer/time_distributed_70/bias
[ 2.11465657e-02 -1.23143578e-02  3.78146558e-03 -9.59896424e-05
 -2.24173050e-02  4.90655052e-03 -3.78529920e-04 -1.08492291e-02
  3.64592439e-03  2.50220615e-02 -1.53538426e-02 -4.72163744e-02
 -5.57117863e-03  1.71761215e-02  4.24863324e-02  1.10595915e-02
  1.89993773e-02  6.09468445e-02 -9.82480589e-03  2.20491569e-02
 -5.28508006e-03 -2.36149281e-02 -1.04054762e-02  3.38132866e-02
 -7.15817267e-04 -1.32664107e-02  5.57255447e-02 -3.15595511e-03
  1.80839945e-03  1.19290687e-02 -3.13758031e-02  7.48235174e-03
 -1.40960552e-02  1.62277129e-02 -3.35843004e-02 -1.73950363e-02
 -2.60254182e-03 -3.68382633e-02  3.98319028e-02  2.92197578e-02
  8.38741008e-03 -3.54097388e-03 -3.14785466e-02  3.08661629e-02
 -9.46535543e-03 -1.50196729e-02 -3.45243933e-03 -1.74355377e-02
  1.55332927e-02  5.24546951e-02 -1.46759478e-02  1.16032049e-01
  5.18866768e-03  3.06881126e-02 -9.67276283e-03  1.20118223e-02
  8.33219197e-03 -7.98501167e-03 -6.95831282e-03  1.01700760e-02
  8.76454543e-03 -1.13518182e-02  1.48777207e-02 -2.23894622e-02
 -1.07828341e-02  2.09516697e-02 -2.58664116e-02  7.63272913e-03
 -2.05115788e-02 -1.51892221e-02 -3.99081968e-03  1.09842243e-02
 -5.41322352e-03  2.54586451e-02 -3.86813730e-02 -1.95393618e-02
  2.55815536e-02  4.17329296e-02 -1.08389230e-02  4.94406521e-02
  4.83161211e-03  4.58987728e-02 -2.27961484e-02 -2.46831942e-02
  3.56630683e-02 -9.38032009e-03 -2.60755885e-02  4.61681886e-03
  9.52712353e-03 -1.29118403e-02 -1.06948316e-02 -3.66294547e-03
 -3.60989869e-02 -6.28101965e-03  2.43374205e-04  2.76595205e-02
 -1.13294292e-02  2.19883583e-03  1.36865275e-02 -1.27885202e-02
  1.67976283e-02 -2.20898483e-02  4.69457135e-02 -1.35815144e-02
  3.74482982e-02 -7.16373464e-03 -6.26410311e-03 -1.38496037e-03
 -3.64596359e-02 -5.88606764e-03  1.08280277e-04 -1.21001722e-02
  2.90517975e-02  5.18327300e-03  1.73439141e-02 -6.94751507e-03
  4.74391915e-02 -3.57265547e-02  5.04441150e-02  3.00445547e-03
  5.85940341e-03 -6.45200834e-02  9.00837360e-04 -3.50096859e-02
  9.97563358e-03 -2.75421748e-03  1.82796810e-02  2.97398251e-02
  3.58774327e-03 -8.13540258e-03 -1.00302417e-02 -2.27942560e-02
  8.15138861e-04 -3.79124731e-02  2.76613818e-03  1.68832671e-02
  1.68391410e-02  3.90103483e-03 -1.01088854e-02 -2.48065572e-02
 -1.67856794e-02  2.52571758e-02  2.59155147e-02  2.99469307e-02
 -3.38472053e-02 -8.92981049e-03  2.22375914e-02 -2.39954740e-02
 -4.89511937e-02 -2.96713989e-02  5.96966129e-03 -2.45438307e-03
 -3.08376327e-02  8.88205599e-03  9.02826060e-03 -1.61461867e-02
 -3.37902680e-02  2.02940200e-02  6.04877900e-03 -2.78236847e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_70/kernel
[[-0.08925894  0.09084082 -0.01290439 ... -0.09177984 -0.07679789
   0.1267426 ]
 [ 0.09964073 -0.00951021  0.05061876 ... -0.09897064  0.03050303
   0.01435199]
 [-0.06699556 -0.15373972 -0.15458299 ... -0.1165407  -0.02161087
  -0.06292102]
 ...
 [-0.09070788 -0.1333794  -0.14137553 ... -0.05021747 -0.09959696
   0.04724862]
 [ 0.05974068  0.09349464 -0.13377161 ...  0.03172573  0.1037572
  -0.0787243 ]
 [ 0.06310277 -0.02088078  0.08952158 ... -0.05311957 -0.01545419
  -0.0703662 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_71/bias
[-0.03064751 -0.00933878 -0.00371368 -0.03234343 -0.00064002 -0.04035844
 -0.06063537 -0.03403092 -0.02111704 -0.00352747 -0.03324441  0.03524695
 -0.01929308 -0.02509703  0.02065765  0.00988597 -0.03508066  0.02507225
  0.00403688 -0.03651443 -0.03493448 -0.00874317  0.01801116 -0.02084045
 -0.04300365  0.02882662  0.0245736  -0.0012871  -0.03979789 -0.04661574
  0.02105186 -0.01797269 -0.03234739 -0.01252459 -0.00660213 -0.01355604
 -0.00032745  0.05270622  0.0039221  -0.01413061 -0.00140463  0.0023364
  0.02483392  0.00423822 -0.0279106  -0.04009094 -0.01349503 -0.04611638
 -0.02772547  0.03759315 -0.01853471  0.11940544  0.01928973  0.00612144
 -0.03364375 -0.00804495 -0.02099571 -0.00711129 -0.01169399 -0.00862405
 -0.02903585 -0.04888352 -0.01423253 -0.06781054 -0.01393486 -0.0250128
  0.00112143 -0.03288278 -0.01712977 -0.02997586  0.00660428 -0.00819921
 -0.03387301 -0.00426331  0.02604651 -0.05503698  0.02668841 -0.00508899
 -0.0456989   0.01547423 -0.04005006  0.0104669   0.02551278  0.00217569
  0.03367872 -0.05174726  0.01587469 -0.0158397  -0.04163662 -0.00083832
 -0.00286968 -0.03037558 -0.01751831 -0.0320243  -0.0501554  -0.09369156
 -0.01548867  0.00459764 -0.03422864 -0.01041275 -0.00952234  0.01050478
  0.00147164 -0.01000809 -0.01434274 -0.03025244 -0.00335238 -0.04801605
 -0.02019409 -0.02755138 -0.00013011 -0.01470386 -0.03897823 -0.02793637
 -0.03835224 -0.04912827  0.05394044  0.01036185  0.03539748 -0.01382864
 -0.02604049  0.00946328 -0.03455297 -0.00619438 -0.00748091 -0.02499379
 -0.02610555 -0.00324113 -0.01715724 -0.02244073 -0.0063588  -0.03047954
 -0.0797433   0.01897689  0.00818412 -0.00501065  0.00235227 -0.04223679
 -0.03990858 -0.00299819 -0.01413103 -0.00980977  0.00659196 -0.0203506
  0.00563121 -0.03682676  0.00942638 -0.01044059  0.01411549 -0.00864936
 -0.04673303 -0.02764018  0.00092742 -0.03669199 -0.02563579 -0.01989764
  0.00094131 -0.08920322 -0.01839564 -0.01923089]
tensor_name:  TemporalFusionTransformer/time_distributed_71/kernel
[[ 0.13780454  0.01612416 -0.05371298 ...  0.06534803 -0.01945185
   0.1082215 ]
 [ 0.04330081 -0.02526368 -0.09039482 ... -0.09658861 -0.07285619
  -0.10566669]
 [-0.14319503  0.04550714 -0.04647808 ... -0.08508695  0.00667552
  -0.11413795]
 ...
 [-0.06736576 -0.0301061  -0.07250456 ... -0.07744509 -0.04672866
  -0.0927956 ]
 [ 0.10568079 -0.14871982  0.09528302 ... -0.05207456  0.06608836
  -0.01827419]
 [ 0.10294902  0.00575765  0.17777917 ...  0.12530328 -0.11552449
  -0.04910748]]
tensor_name:  TemporalFusionTransformer/time_distributed_72/bias
[-3.89261395e-02 -1.34267993e-02 -5.84982447e-02 -3.97982188e-02
  2.53572557e-02 -4.30309959e-02 -4.42905501e-02  4.69803344e-03
 -5.23776654e-03  2.82282215e-02 -4.70232368e-02  3.81941833e-02
 -5.19812852e-02  4.14016731e-02  1.00810686e-02 -3.47597268e-03
  2.58149989e-02 -7.50697851e-02  3.68316099e-02 -1.43631711e-03
 -3.31363128e-03  3.06542255e-02 -1.13405334e-02 -5.16506992e-02
  9.90054850e-03 -1.80141125e-02  3.71989720e-02  1.43227456e-02
  1.49529204e-02 -1.96871534e-02  1.61114540e-02  1.38334697e-02
  4.93183453e-03  1.51012819e-02 -5.10646515e-02  1.75313428e-02
 -1.03711598e-02  3.69263552e-02 -5.07762767e-02 -7.36520952e-03
 -3.93802635e-02 -5.30968830e-02  2.65291966e-02  8.78487062e-03
  1.86526403e-03 -2.96539664e-02  9.13278013e-03 -3.41203287e-02
  1.12879016e-02  6.03001053e-03  3.52144502e-02 -4.02526520e-02
 -3.01932413e-02  4.00782339e-02  9.64549370e-03 -2.99157873e-02
 -2.47445069e-02 -3.33484448e-02  1.83882676e-02  6.39725756e-03
 -2.97359619e-02  9.08878259e-03  3.10161021e-02 -1.03527158e-02
  6.39582518e-03 -2.63240132e-02  7.17198476e-02  3.46279442e-02
  1.56501066e-02 -2.98479293e-02 -2.00448669e-02  2.47486122e-02
 -1.13884462e-02 -3.33539844e-02 -2.29634065e-03 -3.59355435e-02
 -6.68500364e-02 -3.64121199e-02  1.10659096e-02 -5.66922426e-02
  4.77679521e-02 -1.43188611e-02  4.02072407e-02  1.85407847e-02
 -6.54344186e-02 -5.02662770e-02  4.02158611e-02 -3.95666016e-03
 -4.41845022e-02 -4.17694151e-02  1.70059018e-02 -1.32443365e-02
  1.07117742e-02  3.43819917e-03  7.55989691e-04  3.67940851e-02
  2.47227158e-02 -1.35670723e-02 -2.49679741e-02 -3.86540741e-02
  2.20126715e-02  1.36318430e-02  4.31990549e-02  3.52340937e-02
  2.02138023e-03  1.12843318e-02  5.51342592e-03  2.38645729e-02
  3.24122012e-02  5.96965142e-02  5.87855291e-04 -2.93917954e-02
 -7.28807524e-02  5.33308648e-02  8.86116549e-03 -7.90665206e-03
 -2.50834338e-02 -6.94706710e-03 -1.93663351e-02 -3.01504508e-02
  2.04043426e-02  4.01390307e-02 -1.30110960e-02  1.27350315e-02
 -6.62836246e-04  4.35755812e-02 -3.07406788e-03  6.58546016e-02
  4.53728475e-02 -2.06418280e-02 -2.44189613e-03 -4.72568013e-02
 -1.47493519e-02 -1.74194016e-02  4.10918184e-02  3.90774757e-02
  3.68043706e-02  3.33648063e-02 -1.64708111e-03  1.28890770e-02
  5.72684174e-03  3.17757875e-02  6.19504526e-02  4.14042585e-02
 -5.42927487e-03 -5.38630818e-04  1.72613803e-02  2.99381614e-02
  2.40356382e-02  2.54330058e-02  5.46132140e-02  4.17462736e-02
  1.08181564e-02 -1.68933794e-02 -5.95583078e-05  3.24566364e-02
  4.70217839e-02  3.56993787e-02 -3.18872780e-02  7.17583299e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_72/kernel
[[-0.06376249  0.09054156 -0.07703599 ... -0.12073914  0.07431854
  -0.11176117]
 [-0.0661524   0.08512643 -0.06373622 ...  0.09364527  0.00283976
  -0.01786261]
 [ 0.00783094 -0.09765346  0.12808613 ...  0.12888484 -0.07565584
  -0.00998187]
 ...
 [-0.03761376 -0.12696823  0.0700842  ...  0.00014338 -0.13753864
  -0.10572283]
 [-0.09551285  0.03096996  0.14125495 ... -0.09313183 -0.06193223
  -0.04845722]
 [-0.02452164 -0.0659239   0.01126953 ...  0.05287302  0.06650152
   0.12117198]]
tensor_name:  TemporalFusionTransformer/time_distributed_73/bias
[ 5.14814034e-02  1.04304757e-02  7.14882789e-03 -5.34544792e-03
 -9.82445478e-03  2.13043182e-03  1.38422139e-02  7.08631333e-03
 -1.06987730e-02  1.58037096e-02 -2.41059233e-02 -1.32589589e-03
  1.24636777e-02 -1.19469669e-02 -2.80210394e-02  7.35104084e-03
 -6.71623601e-03 -1.23615162e-02  1.45234657e-03  1.99944116e-02
 -2.93212738e-02  3.82868350e-02 -2.69773807e-02 -3.74436262e-03
  5.19411918e-03 -2.40114089e-02  3.30995768e-02  1.01951724e-02
 -3.44497487e-02 -5.37022501e-02  1.51954275e-02 -1.55352568e-02
  2.13891435e-02 -8.21264554e-03  2.12928317e-02  4.44827713e-02
 -5.34079969e-03 -1.65495761e-02 -1.93410516e-02 -1.20439101e-02
 -2.82554384e-02 -2.19368972e-02 -2.62991264e-02 -1.26012638e-02
 -1.81588624e-02  2.52931491e-02  2.68980186e-03 -1.43069653e-02
  1.08312787e-02  1.28341764e-02 -3.67024355e-02  2.26636771e-02
  3.98572441e-03  7.78572774e-03 -5.66082727e-03 -3.46924402e-02
  1.45872524e-02 -1.65618281e-03  9.97993164e-03  1.94199756e-02
  1.95487011e-02  1.96815585e-03  2.85430066e-02 -5.36299385e-02
 -1.92756336e-02  1.06159886e-02 -5.05668558e-02  2.69894376e-02
  3.34676006e-03 -4.00806181e-02  2.07031667e-02  1.12752765e-02
  3.43313697e-03  1.90623384e-02 -2.12977696e-02 -3.15496065e-02
  2.52843238e-02  1.68227609e-02 -2.03369502e-02  5.59306629e-02
 -1.05843944e-02  1.04303786e-03  1.65481996e-02 -1.32338945e-02
 -3.09838001e-02 -1.74059086e-02 -1.83582120e-02 -1.57197621e-02
 -4.60236482e-02 -8.49791430e-03  5.78057393e-02  1.46377664e-02
  2.12364197e-02 -7.76637904e-03  1.54402517e-02  3.42582725e-02
  6.19022781e-03  2.41912697e-02  1.93103421e-02  2.03284211e-02
  3.71017214e-03 -9.79977567e-03 -3.28785293e-02  4.48393077e-02
 -3.62190157e-02 -2.06605960e-02  5.39623983e-02  1.28067061e-02
  2.29865015e-02 -6.78446749e-03 -3.80799472e-02 -1.07421838e-02
 -5.49622588e-02 -1.53529728e-02  1.33170106e-03 -2.06915978e-02
 -3.79151702e-02 -4.08864506e-02 -5.52912392e-02  4.70302859e-03
 -1.27427699e-02  4.61674929e-02  7.10880458e-02  1.07345534e-02
 -5.43457866e-02  4.75561768e-02 -5.60089480e-03  4.54610921e-02
  9.43724159e-03  3.18021774e-02  1.54131874e-02  1.94686688e-02
  3.90829816e-02  3.02986969e-04 -6.40434725e-03 -1.88613795e-02
 -2.68467236e-03 -4.79163192e-02  2.03106739e-02 -8.82185902e-03
  2.40439009e-02 -4.69169812e-03 -8.72159377e-03 -2.48818640e-02
  1.28083918e-02  1.55040734e-02 -5.29088080e-02 -2.40181219e-02
 -1.21841468e-02 -2.24736463e-02  1.13913156e-02 -4.62931916e-02
 -8.11727587e-05  1.79172847e-02  1.06370042e-03 -4.27360088e-02
  5.23901135e-02  6.88851951e-03 -8.51857476e-03  1.40645995e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_73/kernel
[[-0.12386109 -0.01699401  0.02096074 ...  0.01279058  0.02226061
   0.05074091]
 [-0.04673437  0.06132341 -0.0661969  ... -0.12035842 -0.12147173
   0.05380866]
 [-0.10175677 -0.06200599 -0.00733137 ... -0.09623176 -0.05582592
  -0.08491112]
 ...
 [ 0.01767756 -0.13141993 -0.08620817 ...  0.14393727  0.13024074
  -0.11804928]
 [-0.02076702  0.05430793  0.00715604 ...  0.07745205  0.11541652
   0.13289702]
 [ 0.11232354 -0.05342203  0.01600592 ... -0.03923042 -0.11913136
   0.05740944]]
tensor_name:  TemporalFusionTransformer/time_distributed_74/bias
[ 8.40750430e-03 -1.11882631e-02  4.47803672e-04  2.84807407e-03
 -1.81575492e-02  5.75996964e-05  1.36889508e-02 -1.77837797e-02
 -1.41561991e-02  3.10905389e-02 -9.52609756e-04 -1.22973798e-02
 -5.40889893e-03  7.20949331e-03  5.66420332e-02  6.72423141e-03
  2.42715180e-02  6.30562156e-02  2.90020811e-03  9.54501983e-03
 -4.11268417e-03 -5.95170166e-03 -7.57441903e-03  3.56909004e-03
  6.72708126e-03 -1.45846298e-02  3.87143791e-02 -2.01429501e-02
  4.50165989e-03  5.01758838e-03 -3.14245336e-02  8.56792496e-04
 -1.41957570e-02  1.27157634e-02 -2.67659612e-02 -4.82202601e-03
  5.68617543e-04 -2.30376283e-03  2.74181366e-02  1.15758600e-02
  1.02664484e-02  2.34664092e-03 -1.18206367e-02  9.14165471e-03
 -3.32557713e-04  1.88983753e-02 -6.84412569e-03 -1.09843910e-03
 -6.72973273e-03  3.43971699e-02 -9.28601832e-04  6.81047961e-02
 -2.97087827e-03  1.04551166e-02 -1.91473495e-02  1.71681456e-02
  5.44730341e-03 -3.02989706e-02 -4.50819312e-03  1.60732865e-02
 -6.02347590e-03  1.54708605e-02  1.63361114e-02 -9.83936433e-03
  2.67320022e-04  1.21786837e-02 -2.41692066e-02  2.20639035e-02
  1.00527620e-02 -2.85038119e-03 -8.55815411e-03  1.53504005e-02
  1.52927116e-02  1.94326602e-02 -2.08633542e-02  2.09156913e-03
 -1.27741927e-03  2.04701964e-02 -1.57100428e-02  2.91113425e-02
  8.47173762e-03  2.41702031e-02 -2.55573727e-02 -4.01118807e-02
  2.53694095e-02  4.83048474e-03 -2.14643069e-02 -7.25674303e-03
  1.14813466e-02 -5.27434424e-03 -1.32795880e-02  1.77807603e-02
 -2.84240115e-02  3.79850436e-03 -8.95928591e-03  4.76902910e-03
 -5.65743912e-03  1.04554894e-03 -3.59480432e-03 -8.76836665e-03
 -5.81855932e-03 -2.12876238e-02  3.79374102e-02 -6.95563387e-03
  2.02853624e-02 -2.81473156e-02  5.75314136e-03  2.26930734e-02
 -1.34521173e-02 -8.67353845e-03  7.26723438e-03 -6.04624348e-03
  2.32996903e-02  2.18156725e-02 -2.89115054e-03 -8.22349265e-03
  1.07652405e-02 -1.43659851e-02  3.59059423e-02  7.61272665e-03
 -5.72114345e-03 -3.14247832e-02 -8.46308563e-03 -3.40761393e-02
  1.59763312e-03  1.83312222e-02  1.46944234e-02  2.01152526e-02
  3.03770867e-05  1.02879750e-02 -5.41794533e-03 -1.64739080e-02
 -1.49919242e-02  2.10279766e-02 -9.24919639e-03  1.06537202e-03
  1.63859762e-02  2.05935910e-02 -1.68046411e-02 -3.18676904e-02
 -1.80730186e-02  2.04472039e-02 -1.25284381e-02  4.75510278e-05
 -1.09220520e-02 -7.58180395e-03  2.77987495e-02 -1.48112616e-02
 -2.62175463e-02 -9.20800213e-03 -1.24132978e-02 -7.08798645e-03
 -2.25921441e-02 -2.14879564e-03  1.69682298e-02  5.26407128e-03
 -2.58457363e-02  1.10253943e-02 -1.81097966e-02 -3.02277226e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_74/kernel
[[-0.03295509  0.06798492 -0.11301581 ... -0.02639706  0.07117634
   0.05431694]
 [-0.01600709 -0.06737746 -0.04731038 ... -0.09066868 -0.03051448
   0.1313008 ]
 [ 0.05335148  0.07834312 -0.07136305 ...  0.09413947  0.0047472
   0.0870086 ]
 ...
 [ 0.103907   -0.13141307 -0.11937308 ...  0.07626862 -0.07192368
  -0.04847082]
 [ 0.13981278 -0.01235633  0.05406637 ...  0.0984496   0.09563783
   0.07375352]
 [ 0.0956249   0.03418166  0.10631011 ...  0.00582171  0.10719693
  -0.03217866]]
tensor_name:  TemporalFusionTransformer/time_distributed_75/bias
[-0.01490179 -0.01587925 -0.02773723 -0.02051097  0.01580366  0.01171776
  0.01230008  0.0190291   0.01176062  0.03161681 -0.06551801 -0.00566726
 -0.02600571  0.01086948  0.07737774 -0.06011792  0.03461416  0.08401062
 -0.03820027  0.01217054 -0.04021292 -0.01793567 -0.03594278 -0.05626239
 -0.05802698 -0.04200698  0.02597109 -0.05508815 -0.07381247 -0.09406632
  0.06344838 -0.04827708 -0.04161757 -0.04424242 -0.00401445 -0.03048263
  0.06357104 -0.05082365  0.0127372  -0.06734786 -0.03711688 -0.01720499
  0.02035616 -0.01975523 -0.05325091  0.02230139 -0.05724367 -0.02180745
 -0.05851702  0.01100651 -0.03149303  0.11507578 -0.01941431 -0.00016675
 -0.00895685  0.01862504 -0.06667594  0.00064232  0.00490108 -0.0419095
 -0.04034612  0.02218854 -0.01204121 -0.04126405 -0.03694215  0.00254312
  0.01447331 -0.01081754 -0.02958006 -0.02377841 -0.04731749 -0.00661276
 -0.01682096 -0.0291332  -0.00305793 -0.01973056 -0.04256589  0.00480543
  0.02361978  0.01102744 -0.02590192  0.01632307 -0.01098173  0.066411
  0.01494463 -0.03463081  0.00131295 -0.03640584  0.0126072  -0.03132405
 -0.01668024 -0.03211756  0.01797383 -0.04046682 -0.00406558  0.08723814
 -0.09436336 -0.04749744 -0.03797313 -0.07731328 -0.03624692 -0.00981417
  0.01762033 -0.02282162  0.02131577  0.03167368 -0.01112354 -0.00065619
 -0.04999163 -0.01660056 -0.03897445 -0.03115526  0.00646652  0.01688145
 -0.06648354 -0.05390092 -0.00545484 -0.0389162   0.04134544  0.00102995
 -0.04779834  0.05258259 -0.01116029  0.04487385  0.02491028 -0.02225421
  0.0227561  -0.03238199 -0.02253937 -0.03590445  0.01748998  0.01279815
  0.00106447  0.05804875 -0.01507039 -0.03272438  0.00729402  0.01012656
  0.00608789  0.01733952 -0.00691779  0.01442189 -0.04247442  0.04714863
 -0.05516941 -0.02732476  0.02914733 -0.05631246 -0.00488516 -0.07330157
 -0.03014723 -0.05222464 -0.00600363 -0.01007072 -0.00309365 -0.02884951
  0.0131312   0.00290013 -0.01820942  0.00296955]
tensor_name:  TemporalFusionTransformer/time_distributed_75/kernel
[[ 0.06281061 -0.09080297 -0.1075746  ...  0.12990044 -0.09076022
   0.05005155]
 [ 0.10420113 -0.01550709 -0.01694457 ...  0.10700803 -0.02873002
  -0.10182673]
 [ 0.07452587  0.11379379  0.2454484  ... -0.10366995 -0.10478076
  -0.13513121]
 ...
 [ 0.13371086  0.03182029 -0.22216219 ...  0.09983989 -0.07359443
  -0.03336659]
 [-0.04495347  0.04040176 -0.13136396 ... -0.01547035 -0.14798538
   0.17660166]
 [ 0.09165771  0.17687084  0.14942053 ... -0.06484985  0.1422922
  -0.05843139]]
tensor_name:  TemporalFusionTransformer/time_distributed_76/bias
[-0.00781876 -0.02128859 -0.05063631 -0.04619905 -0.00927474 -0.02365293
 -0.022773   -0.01500246  0.01893483 -0.04257425 -0.00685176 -0.09330703
 -0.00018638 -0.00498744 -0.05814039  0.00525871 -0.0951569  -0.00158711
  0.03393847  0.01738131 -0.08486782  0.04501558 -0.01133239  0.00999833
 -0.02780675  0.01888456 -0.02140634  0.00568411  0.00790892  0.07722688
 -0.02053628  0.06085972 -0.04470767  0.06493166 -0.00569235 -0.04793673
 -0.0447323  -0.04446773 -0.0179971  -0.06174953  0.00375661 -0.0054483
  0.05309338 -0.05554618  0.06363945 -0.01236593  0.01835528  0.05201329
 -0.04428579 -0.04770784 -0.03697684 -0.03884493 -0.03654278  0.06927793
  0.05915042  0.05992548 -0.03038622 -0.03302528  0.01098925 -0.01961762
 -0.00649531 -0.03482147  0.01662166 -0.0180771  -0.03899222  0.06610537
 -0.01856063  0.06338565 -0.03274927 -0.08199932  0.01841321  0.02445749
  0.02981853  0.0061725  -0.0196012   0.0435769   0.12135571 -0.01584675
 -0.0358031  -0.01531776  0.07773418  0.10038534 -0.01533411  0.06919797
  0.00465043 -0.01947351 -0.03488052 -0.03089596  0.00071698 -0.05756586
 -0.05700171  0.08665718  0.0284412   0.03561433  0.00557917 -0.02805802
 -0.00263901  0.05192304 -0.06650137 -0.0458155   0.00680139  0.00744176
  0.05859563  0.01651319  0.02511067 -0.0427512  -0.01577617 -0.01956431
  0.05284932 -0.02430856  0.03749802  0.00406326 -0.01645636  0.01868789
 -0.04752726  0.0360532  -0.02429569 -0.0772511  -0.04387698 -0.00493503
  0.08787874 -0.01896379 -0.08938099 -0.02850911  0.05615925  0.04659954
 -0.04956454 -0.08426329  0.00254206  0.0544067   0.10218646  0.0259343
  0.00695499 -0.06334456 -0.0093457   0.03113355 -0.02259999  0.0049588
 -0.01124662  0.04822905 -0.01453371 -0.03020005 -0.0406589  -0.00630346
  0.01336304 -0.04024862  0.0593082   0.02405261 -0.06151802 -0.06775668
 -0.05155364  0.03672891 -0.01360279 -0.03239031  0.05582999 -0.05808513
 -0.05376352  0.09278586 -0.01139264 -0.04613977]
tensor_name:  TemporalFusionTransformer/time_distributed_76/kernel
[[ 0.0026204   0.11816707  0.06336161 ... -0.07517429 -0.03764515
  -0.06807142]
 [-0.0976861  -0.0971075  -0.06252748 ...  0.08107303 -0.13646097
   0.14093786]
 [-0.0681662  -0.09765069 -0.14236405 ...  0.14915307  0.10004913
  -0.04212153]
 ...
 [-0.05831034 -0.0089503  -0.04455747 ...  0.02988768 -0.01975215
   0.0971039 ]
 [-0.13023101  0.04729583  0.07207101 ... -0.03800696  0.08006684
  -0.11927017]
 [ 0.12729348 -0.13255328  0.10791814 ... -0.11856873  0.12637952
  -0.0362446 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_77/bias
[-0.03552076 -0.00160923 -0.01805792  0.02818452 -0.07312325  0.0193399
  0.01442307 -0.0033068   0.00967604  0.01181482  0.04491872  0.04362109
 -0.02464698 -0.01254542  0.05410646  0.01526574 -0.04292655 -0.00455018
 -0.06226732  0.07331301 -0.00230072  0.0413207  -0.010062   -0.05095044
 -0.02533355 -0.00942421 -0.0108531  -0.02215796 -0.04705109 -0.03846078
 -0.03637487 -0.02656393  0.04915282 -0.00635544 -0.04281778  0.04164218
 -0.0313773  -0.01195136 -0.01828367 -0.00326557  0.00214437  0.01659732
 -0.0020743  -0.06289069  0.01805356  0.01475316  0.07882461  0.04586781
 -0.01684925  0.01751376  0.00835155 -0.00340792 -0.0531409   0.02662592
 -0.012571   -0.01310668 -0.04640465  0.04014665 -0.03641465  0.03731751
 -0.01204364  0.00344979 -0.01990591 -0.01592279  0.02416163 -0.02246629
  0.0003644  -0.06700133 -0.02285942 -0.00764159 -0.00477992  0.00918963
  0.04679975 -0.05486703 -0.04855943  0.00554617 -0.01250396  0.01103016
 -0.02413901 -0.01562875  0.01182554  0.04244712  0.01358643  0.06743257
 -0.05186669  0.0266355  -0.01765581  0.01610465  0.0138382  -0.02370541
 -0.02038275  0.02409386  0.04527949 -0.02756731 -0.00042928 -0.01418299
  0.02852732 -0.03762921  0.07286083 -0.00392119  0.01408929  0.05355468
  0.01664157  0.01282193  0.02129853  0.02920144 -0.04132432 -0.03032417
 -0.00448913 -0.03693033 -0.01102452  0.03480998  0.04043083  0.00324293
 -0.06331756 -0.02146646  0.05266673  0.01939154 -0.01775806  0.03651262
 -0.08038676 -0.00581816 -0.00872879  0.01581334  0.04482992 -0.00802227
 -0.01804547 -0.0105378  -0.05036616 -0.02930387  0.04309115  0.0350592
 -0.01815992  0.01697989 -0.01704515 -0.02103538  0.03349345  0.00851949
  0.01553774 -0.03147632  0.01447703 -0.06249012  0.0346179   0.07925731
  0.00153803  0.00746514  0.04698349  0.03942491  0.03155259 -0.01551002
  0.01608546  0.04154867 -0.02489494  0.00106709 -0.02932434  0.02134064
  0.02146289  0.00866422 -0.00012485 -0.01873804]
tensor_name:  TemporalFusionTransformer/time_distributed_77/kernel
[[-0.14957078  0.06147806  0.02282852 ... -0.04323348 -0.10427509
   0.01709129]
 [-0.06083456  0.10104533  0.03500406 ...  0.14419883 -0.05887857
  -0.10590412]
 [ 0.00294072 -0.032121    0.030827   ... -0.11152796 -0.10647014
  -0.05322419]
 ...
 [-0.0112748   0.05384879 -0.02683419 ...  0.08499737  0.00543247
  -0.14679334]
 [ 0.0071218   0.08060722 -0.11346809 ...  0.09063557 -0.11326297
  -0.09921227]
 [ 0.14189863  0.07500077 -0.03056509 ... -0.09841112 -0.10915996
   0.12216666]]
tensor_name:  TemporalFusionTransformer/time_distributed_78/bias
[ 0.01421664  0.00719144  0.0373049   0.00388635 -0.00548999  0.02328975
  0.02501411 -0.00676408 -0.02106301  0.02424436 -0.00454721 -0.03451369
 -0.01105751 -0.00483574  0.03607514  0.00623162  0.0205902   0.03335289
 -0.00865916  0.02092468 -0.01373687 -0.01783791 -0.01475791  0.02063451
  0.00352998 -0.0086322   0.04973241 -0.02813949 -0.0161308   0.02986627
 -0.04093171 -0.00669412 -0.03291326  0.020748   -0.02628508 -0.01061109
 -0.01426817 -0.02977162  0.0380691   0.01669486  0.0025209   0.01033614
 -0.02406528  0.00927933 -0.00504681  0.03479955 -0.01161435 -0.01532287
 -0.01654141  0.03850465 -0.02370616  0.10122533  0.01205008  0.01262122
 -0.01425348  0.02198059  0.01406739 -0.00530618 -0.01407241  0.00901188
 -0.0021723  -0.00490529  0.02899287 -0.01541002 -0.01618961  0.02657101
 -0.02634289  0.03465147  0.00533043 -0.03879482 -0.01463811  0.02555593
  0.00227253  0.0415635  -0.03142447 -0.01263524  0.01565683  0.03780752
 -0.0088193   0.04753276  0.0055037   0.04544446 -0.03067004 -0.02011522
  0.00392839 -0.00868226 -0.01865048 -0.00743341  0.02402139 -0.00778119
 -0.02067791  0.00626277 -0.0373842  -0.00454603  0.00368963  0.02969307
  0.00948736 -0.00306851 -0.00036222 -0.01519144 -0.00431144 -0.00391298
  0.03623108 -0.00703516  0.02867088 -0.00746724 -0.01177954  0.02236495
 -0.02381164 -0.00254443  0.02245633 -0.01603626  0.04148819  0.02691284
 -0.01325978 -0.0087087   0.0176229  -0.03232509  0.04533091  0.00859925
 -0.00709448 -0.03887961 -0.00575245 -0.03094715 -0.01174314  0.02733418
  0.01718363  0.03869372  0.00077199  0.02463254 -0.02932112 -0.02667872
 -0.02125866  0.02854822 -0.00441229 -0.00271778  0.01283804  0.02671793
 -0.00973119 -0.04714913 -0.00880155  0.03364203 -0.00071731  0.01516943
 -0.04033335  0.00322939  0.02487883 -0.02438723 -0.03716538 -0.0232841
 -0.00454928 -0.00522775 -0.01825868  0.00408799  0.02253554  0.00545257
 -0.02831754  0.02341177 -0.00777653 -0.03689241]
tensor_name:  TemporalFusionTransformer/time_distributed_78/kernel
[[ 0.04384678  0.03376521  0.09160902 ... -0.04099971 -0.03284236
   0.03048504]
 [-0.08635062 -0.05621281  0.13224427 ... -0.04727954 -0.13216284
  -0.03586708]
 [ 0.04962942  0.01414414 -0.03741684 ...  0.01339214  0.11854646
  -0.06769622]
 ...
 [-0.11503191  0.02755314 -0.02664598 ... -0.00702463  0.05723904
   0.12415274]
 [ 0.10316078  0.12140644  0.01434027 ...  0.09395666 -0.07453068
  -0.1400557 ]
 [ 0.0711195  -0.00870791 -0.04332918 ... -0.01684942 -0.01943133
   0.11131556]]
tensor_name:  TemporalFusionTransformer/time_distributed_79/bias
[-0.01768119 -0.04012296  0.0105774  -0.01358518 -0.01442579 -0.00726295
  0.05051919 -0.00796957 -0.01948362 -0.00995256 -0.04063059  0.00154024
 -0.01682379 -0.05375209 -0.01627441 -0.05085278 -0.01529328 -0.0463625
 -0.0178624   0.03204034 -0.03302909 -0.03264201  0.01235205  0.00333972
 -0.01940579 -0.09239631  0.03422776  0.01802444 -0.00480827  0.0129276
  0.00206662 -0.04279583  0.03195449  0.01775898 -0.01145612 -0.00600649
 -0.02404057 -0.02938891  0.01901296 -0.01235832 -0.0537691  -0.012295
  0.02184625 -0.02171624 -0.0238607   0.00180979 -0.00724152 -0.02572153
  0.01857606  0.03712047  0.00879443  0.09008324 -0.0241855  -0.0110176
 -0.04455806 -0.02993603  0.01125881 -0.00590909  0.01270975  0.00419556
 -0.03989966  0.0020299   0.00766493 -0.0036826   0.00597698  0.00028047
 -0.00450046  0.0264683   0.00890567  0.05909915 -0.00176186  0.02470666
 -0.06669445  0.01740852  0.00303879  0.00776602 -0.03752445  0.02779392
 -0.02445274  0.01597196 -0.01192863  0.00525708  0.02562691 -0.01585639
  0.01587076 -0.03579461  0.01074274 -0.00589969 -0.03121081  0.01512105
 -0.01114135 -0.00502354  0.02139358 -0.0446618  -0.01694116 -0.00173196
 -0.00996779 -0.02366174 -0.03001036 -0.00052761 -0.00070897 -0.0146651
  0.05868924 -0.01920974 -0.02135526  0.00271576 -0.02879208  0.01008266
 -0.0232845  -0.00458617 -0.00498103 -0.0007668   0.03423176  0.00110208
 -0.00744337 -0.01416953  0.00557564  0.03828557  0.00759286 -0.03661525
  0.01007129 -0.00066532 -0.06156926  0.00955059 -0.01066978 -0.0154236
 -0.01705134  0.0197366  -0.02239585 -0.00598083  0.01072846 -0.00241014
 -0.01046696  0.0490963  -0.01494217 -0.00509885 -0.00751905 -0.00709532
 -0.01954899  0.04106895 -0.02317484  0.01411213 -0.02266364  0.04922301
  0.01715137 -0.02203245 -0.01708886 -0.00856025  0.01241602 -0.01549929
  0.00065517 -0.04458566 -0.01820729 -0.01766095 -0.01293576 -0.02736575
 -0.00912874 -0.00841494 -0.00793686  0.03458332]
tensor_name:  TemporalFusionTransformer/time_distributed_79/kernel
[[-0.05034352  0.04470202  0.09103636 ... -0.07975705  0.13974543
   0.079998  ]
 [ 0.13047943 -0.02719396  0.08707869 ... -0.11117298  0.03325788
  -0.13625358]
 [-0.08921068 -0.0950748  -0.08268162 ...  0.01135764  0.00146571
  -0.08912912]
 ...
 [-0.05067864 -0.00732103  0.01970137 ... -0.14887577  0.09349924
  -0.02433165]
 [ 0.04782316  0.08045085  0.05639742 ...  0.01874179  0.11337847
  -0.05601403]
 [ 0.03894844 -0.13632514 -0.13888818 ... -0.01123683  0.0517744
  -0.1396142 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_8/bias
[-0.05461174  0.02052458  0.02608045  0.02466055 -0.04298311  0.00163535
  0.00986055 -0.00457512]
tensor_name:  TemporalFusionTransformer/time_distributed_8/kernel
[[ 0.06407177  0.06818382 -0.05223078 ...  0.04250147  0.03719264
  -0.01066873]
 [-0.08232132  0.03608792  0.06388739 ... -0.08068009  0.06309106
  -0.03895254]
 [-0.07189956 -0.01000389  0.083548   ... -0.01883828 -0.07469013
  -0.08326422]
 ...
 [-0.00518737 -0.02495101  0.11327916 ...  0.1721567  -0.2241955
  -0.09821915]
 [ 0.14068234 -0.07481349 -0.09477047 ...  0.24346125 -0.05152538
   0.11017063]
 [ 0.09802673 -0.10969167  0.06756812 ... -0.11802077  0.01082649
   0.05207578]]
tensor_name:  TemporalFusionTransformer/time_distributed_80/bias
[ 0.01946103  0.00897074  0.02861374  0.00032599 -0.0177945   0.02187848
  0.00917594 -0.04360621 -0.02150199  0.08013266  0.01832765 -0.04779185
 -0.00793913  0.03650865  0.08551518  0.01305646  0.00799336  0.16304284
  0.00668837  0.01001504 -0.00344732 -0.012596    0.03798492  0.01352835
  0.00037929 -0.08695061  0.06491737 -0.06777418 -0.01577428  0.02847481
 -0.05128467  0.00348451 -0.02291798  0.01391444 -0.05904895 -0.01392798
 -0.00666918 -0.02891554  0.04679698  0.03692075  0.0080067   0.00317741
 -0.02835204  0.01823409 -0.00273968  0.03450945 -0.00891353  0.00213189
 -0.01001523  0.10258336 -0.01327872  0.14156279 -0.00857197  0.03198671
 -0.02479474  0.04539023  0.02527339 -0.03973677 -0.00397191  0.07463104
 -0.0135325   0.05181124  0.02740297 -0.01803585 -0.00407338  0.02802597
 -0.03460704  0.03216665  0.03322995 -0.03331486 -0.00208807  0.02737618
  0.05690176  0.03820569 -0.04658609  0.04386422 -0.00277447  0.02147629
 -0.01184583  0.06848229  0.01961969  0.03215288 -0.07973288 -0.08972473
  0.08596525  0.00726776 -0.04631292 -0.01116079  0.01161969 -0.01128012
 -0.04301586  0.01401563 -0.05382717 -0.0358237  -0.01391588  0.02610337
  0.01095077  0.02030198 -0.02241159 -0.04930295 -0.00355393 -0.02609934
  0.03882599 -0.0174947   0.03871688 -0.02606129  0.00199618  0.02673103
 -0.00819378 -0.02045367  0.0239671  -0.01710152  0.03044176  0.01214833
 -0.01386239 -0.02191938  0.0271072  -0.05248574  0.04229236  0.03234852
 -0.00186487 -0.02764354 -0.02501104 -0.07406719  0.00736884  0.06592234
  0.02273406  0.04298099 -0.02379712  0.02165418 -0.02131041 -0.02891513
 -0.02455701  0.02595785 -0.01371637 -0.01122596  0.00944204  0.02839732
 -0.01892018 -0.0551687  -0.01226065  0.04320594 -0.04565901  0.04235484
 -0.03787278 -0.01210307  0.03172037 -0.03447377 -0.05503127 -0.02033173
 -0.01524727 -0.00404433 -0.07822546 -0.02769851  0.02378811  0.0033815
 -0.01253263 -0.01574942 -0.02560399 -0.04796215]
tensor_name:  TemporalFusionTransformer/time_distributed_80/kernel
[[-0.11132031  0.10261247  0.11836519 ... -0.12717678  0.0002754
  -0.06742879]
 [-0.06433225  0.06648157  0.0034115  ...  0.11017316 -0.02178711
  -0.07634552]
 [-0.12373579 -0.01002217 -0.07629203 ...  0.05001975  0.08011083
  -0.03004917]
 ...
 [-0.01873535 -0.11442923 -0.19139944 ...  0.17149359 -0.08115986
  -0.10895971]
 [-0.01214541  0.01001946 -0.13411885 ... -0.05841831 -0.07250001
   0.02403526]
 [-0.05926283  0.11599862  0.10146569 ... -0.19059034 -0.14400472
  -0.02194181]]
tensor_name:  TemporalFusionTransformer/time_distributed_81/bias
[-4.77693044e-02 -1.72535498e-02 -6.86290115e-02 -6.43905699e-02
 -6.16841093e-02 -9.61723030e-02 -4.79718000e-02  4.20870073e-02
 -4.16810736e-02  7.26875737e-02 -2.07991321e-02 -1.38259185e-02
 -7.46472180e-02  3.71769778e-02  4.56523187e-02 -5.38587458e-02
  2.54444517e-02  6.51584044e-02 -9.03735906e-02 -3.45195457e-02
 -5.99086471e-02 -6.24748394e-02  6.83452794e-03  3.84571739e-02
 -2.02014353e-02  2.27069855e-02  6.20253757e-02  8.22057128e-02
 -2.02685464e-02 -5.54534160e-02 -3.53268273e-02 -6.61565736e-02
  8.06940254e-03 -6.45335987e-02 -2.15437356e-02 -7.11919889e-02
 -1.18625965e-02 -8.87408331e-02  2.44489536e-02 -7.49903470e-02
 -3.28191370e-02 -4.47652079e-02  3.68079245e-02 -2.23769359e-02
 -3.18772346e-02 -3.43347304e-02 -3.47317755e-02 -7.45628681e-03
 -5.22900410e-02  6.58420026e-02 -7.83097669e-02  1.51430964e-01
 -3.84851312e-03 -8.77334028e-02 -6.61129877e-02 -1.28700742e-02
 -1.52408592e-02 -1.58853512e-02 -1.57634802e-02 -8.74833568e-05
 -5.36683723e-02  3.83021198e-02 -1.33065552e-01 -4.15247194e-02
 -2.06889492e-02 -9.01890397e-02 -1.08284928e-01 -6.10577948e-02
  2.29350794e-02 -9.76378024e-02 -4.53486741e-02 -4.24407097e-03
 -9.94602218e-03 -8.62122029e-02 -5.70627786e-02  5.35607934e-02
 -2.27643494e-02  5.20581640e-02 -1.79615859e-02  4.22379449e-02
  1.34395771e-02  1.60878226e-02  4.55449447e-02  1.17252782e-01
  9.53662768e-02 -1.27460826e-02 -1.37105053e-02 -6.19997131e-03
 -1.47148505e-01 -4.33692783e-02 -2.05214750e-02  3.31450589e-02
 -1.01893479e-02 -3.25057320e-02 -2.88067502e-03 -3.51974703e-02
 -7.03179464e-02 -6.97662774e-03  3.80809838e-03  3.50421518e-02
 -1.10279899e-02 -3.12366448e-02  9.55699682e-02  2.38311826e-03
 -4.10697982e-02 -4.36594673e-02 -7.45425792e-03 -4.45835814e-02
 -2.99781319e-02 -1.75503083e-02 -3.83357592e-02 -1.10917287e-02
 -1.23660892e-01 -5.39667457e-02 -7.66877457e-02 -8.13716576e-02
 -6.04541004e-02 -3.23999450e-02 -7.74449995e-03 -1.23651070e-03
 -1.88946780e-02  6.52155727e-02  7.85919651e-03  7.00954869e-02
 -1.48972757e-02 -5.09529142e-04 -3.40702534e-02 -6.94799870e-02
  3.98624018e-02 -3.59458663e-02 -7.52883852e-02  4.02891822e-02
 -9.52779129e-02  7.73126632e-03 -1.03862427e-01 -5.04057109e-02
 -6.78637698e-02 -8.53572115e-02  7.15227053e-03  7.39198120e-04
 -1.89514346e-02 -4.57734019e-02  1.70071609e-02 -3.64650637e-02
 -3.47926132e-02 -5.17312251e-02 -8.95392820e-02 -8.60795677e-02
  1.09056709e-02  4.70942669e-02 -3.34088132e-02 -3.67489681e-02
  6.47008419e-02 -8.18324089e-03 -1.12155236e-01 -2.17233896e-02
 -1.25100598e-01  8.27161819e-02 -4.53999341e-02  5.22999391e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_81/kernel
[[-0.01539858  0.00393544 -0.0341926  ...  0.09724337 -0.13023415
   0.04048237]
 [ 0.00041267 -0.02809104  0.19062342 ... -0.13546284 -0.02159233
   0.08355906]
 [ 0.05884659  0.03127621  0.13586324 ... -0.07390512  0.21835491
   0.03637351]
 ...
 [ 0.01441709 -0.10555373 -0.00333316 ... -0.1515659  -0.02440507
  -0.17785722]
 [-0.01666488  0.07004545 -0.14576349 ... -0.12972838 -0.06678288
  -0.08801655]
 [ 0.04075518 -0.10141248 -0.0029847  ...  0.09627308  0.02038076
   0.00399785]]
tensor_name:  TemporalFusionTransformer/time_distributed_82/bias
[-0.01197757 -0.00261443 -0.00217654 -0.00701729  0.00739384 -0.00725777
  0.00717861  0.01421306 -0.01536115 -0.004981   -0.00713854  0.01359347
 -0.01125814 -0.00077655 -0.01629024 -0.01402801 -0.00810283  0.01155917
 -0.00184805  0.00153995  0.01145715 -0.0305846  -0.00582849 -0.00378026
  0.00908567 -0.00296536 -0.01703389 -0.00671633 -0.00444476  0.00387042
 -0.01091131  0.00250599 -0.00224445 -0.0107242  -0.00020542  0.00640205
  0.00102404  0.00357891  0.00118516 -0.00194216 -0.00170256  0.00572167
 -0.01949415 -0.00139689 -0.00983617  0.00416501 -0.01272256 -0.00483201
 -0.00868912 -0.00703623 -0.00085308 -0.01531163 -0.01023793  0.00441374
 -0.0096065  -0.01790108 -0.00188236 -0.02135143 -0.01169634 -0.00712952
 -0.0144923  -0.01440545  0.00346387 -0.00100318 -0.01222173 -0.01007542
  0.00749974  0.00203567  0.00356789 -0.00514608 -0.0014084  -0.01934378
  0.00548303 -0.00218483  0.01794554  0.00822488 -0.01401549 -0.00448853
  0.00799603  0.00202958 -0.00868967 -0.01837206 -0.0117309  -0.01389461
 -0.01278694 -0.02541854  0.00434916 -0.01989448 -0.0031444  -0.0142906
  0.00231138 -0.00320783  0.01268894 -0.00582718 -0.00097297  0.00775757
 -0.00871684 -0.01510394 -0.00222133 -0.00619851  0.00894178  0.00441442
 -0.0104581  -0.01428736 -0.00104145 -0.00345555 -0.02526453  0.00576218
  0.00533443 -0.02017618  0.00669956 -0.00283206 -0.01305837 -0.00286884
 -0.01197737 -0.00043962  0.00260542 -0.00749501 -0.00962936  0.00441675
 -0.00310505 -0.00888054  0.00471143  0.00751785 -0.00013624 -0.01179086
  0.01641203 -0.00215496  0.00061383 -0.0101534  -0.0035361   0.00024168
  0.00799929 -0.00364575  0.00948906  0.00443003 -0.00546784  0.01707716
  0.0050382  -0.01674799 -0.00364438 -0.00602644 -0.01329929  0.00728271
  0.00525404  0.00511236  0.01203526 -0.00258984  0.00698528 -0.00867736
 -0.01217613 -0.00074521 -0.00586317 -0.00464198  0.00019364 -0.00666355
 -0.00576047 -0.00393062 -0.01327809  0.01089364]
tensor_name:  TemporalFusionTransformer/time_distributed_82/kernel
[[-0.05225989  0.02458802 -0.09039369 ...  0.06055648 -0.01657859
   0.11545411]
 [ 0.15586384  0.00079648 -0.03600528 ... -0.02408311 -0.04628505
  -0.02427381]
 [ 0.04845607  0.05729213 -0.00030921 ...  0.02756727  0.00678319
   0.11967055]
 ...
 [ 0.05649742 -0.07943755  0.0590626  ... -0.12800059 -0.081886
  -0.13973661]
 [-0.16552629 -0.09032477  0.04234255 ... -0.00427754 -0.09100827
  -0.01238557]
 [ 0.06247106  0.04620684 -0.09941565 ...  0.12981743 -0.08482226
   0.07992242]]
tensor_name:  TemporalFusionTransformer/time_distributed_83/kernel
[[-0.03436746  0.00310108 -0.11930177 ... -0.06702275 -0.05206075
  -0.13696063]
 [ 0.08863845  0.00077273 -0.07595709 ...  0.09393208  0.13529699
  -0.11729543]
 [ 0.05869017 -0.09430221  0.05780454 ...  0.07620813 -0.07242101
   0.04426857]
 ...
 [ 0.07540324 -0.04008798 -0.06335148 ... -0.01111929 -0.01747562
  -0.06742454]
 [-0.13103683 -0.04854746 -0.09697564 ... -0.11534871  0.08236545
  -0.027805  ]
 [-0.10925129  0.00739205  0.08587009 ... -0.06153956  0.07203033
  -0.03655229]]
tensor_name:  TemporalFusionTransformer/time_distributed_84/bias
[ 0.00525705 -0.01174688  0.00475229 -0.01607866  0.00855465 -0.01830813
  0.00782298 -0.01515641 -0.01210639 -0.01311105 -0.0149675   0.00643725
  0.00558333 -0.01367884 -0.00724076 -0.01262824  0.00097492  0.01434286
 -0.00095352 -0.0014083   0.00295103  0.01694349  0.00131399  0.0045744
  0.00456952 -0.003128    0.00352806 -0.00118967 -0.01032551 -0.01078184
 -0.0058826   0.01135269 -0.00488085  0.00104552 -0.00340046  0.00250694
 -0.00848574 -0.00401089  0.00108245  0.00157011  0.0159684  -0.01692596
  0.00094717  0.00191285 -0.01483928 -0.01412444  0.00685926  0.01305257
  0.01179217  0.0026108  -0.00469705  0.00609206  0.01325567  0.0115902
 -0.00234802  0.00630563  0.00442192  0.00579132 -0.00842642 -0.00911255
 -0.00923084 -0.00320464  0.00673874  0.00192385  0.01050424  0.00640153
 -0.00111763  0.00893365 -0.0055701   0.01332139  0.00116337  0.00784384
  0.00420191  0.002854   -0.01278086  0.01491403 -0.00835122  0.0012494
 -0.01483149  0.00426707 -0.00638009 -0.0024368  -0.01589826 -0.02003721
  0.01985475  0.0048842   0.03182164 -0.00336134  0.00538549  0.00640333
 -0.00864004 -0.00291604 -0.00040746 -0.00372423 -0.01008189  0.00639935
  0.00257118  0.00091685 -0.00985805 -0.00911448  0.00950213  0.01420584
 -0.01848264 -0.00887387  0.01089865  0.02230371  0.0072965  -0.00445287
  0.0125167  -0.00687883 -0.00190893 -0.02027986 -0.00256826 -0.00074423
  0.01028768 -0.00338135  0.00401552  0.00096351 -0.00334024  0.00017571
 -0.00663413 -0.01629108  0.00437237 -0.00134323 -0.00330137  0.015154
  0.00186154 -0.00590785 -0.0116511   0.00548154 -0.0045837   0.01393234
 -0.01414394 -0.0063386  -0.01598531 -0.00324825 -0.00798965 -0.00276344
 -0.0217438   0.00511159  0.00463072 -0.01262944  0.00989466  0.0072716
  0.00782295  0.00379051  0.0009603   0.00394837  0.00560635 -0.00572929
 -0.00833538 -0.01327768  0.01106463  0.0018951   0.01828353 -0.00835679
 -0.01084599 -0.00296658 -0.00013318 -0.00294871]
tensor_name:  TemporalFusionTransformer/time_distributed_84/kernel
[[ 0.10244914  0.07966264 -0.02815102 ...  0.07605288  0.07086232
   0.02405245]
 [ 0.03162743  0.04848083 -0.12200797 ... -0.06945127  0.02653495
   0.1210774 ]
 [-0.03952856 -0.06405453  0.05415862 ...  0.11148242 -0.01697263
  -0.00493948]
 ...
 [ 0.00687568 -0.09447687  0.06428561 ... -0.05845092  0.11506373
  -0.03978789]
 [-0.07642818  0.03673474  0.07058696 ...  0.07058679 -0.02918813
  -0.00253589]
 [ 0.15275389 -0.14724165  0.06144859 ...  0.11640517  0.08545649
   0.07620786]]
tensor_name:  TemporalFusionTransformer/time_distributed_85/bias
[ 1.04954410e-02 -1.11227566e-02 -7.25229364e-03  9.41049773e-03
  9.58225864e-05 -7.86044542e-03 -6.32255152e-03 -1.52936876e-02
  2.58803722e-02  1.01956073e-02  5.16215398e-04  1.16961636e-02
  8.20262916e-03  2.85900617e-03 -5.47905313e-03 -1.71227511e-02
 -1.80906511e-03  9.67703201e-03 -5.45198470e-03 -7.19245151e-03
 -1.03387586e-03  8.22470244e-03 -2.07248307e-03 -2.44649174e-03
  5.50028542e-03  7.10811280e-03  1.47650507e-03 -9.56964493e-03
  1.61982272e-02 -1.20919477e-02 -3.85634555e-03  3.84638365e-03
  1.53650704e-04  1.91321559e-02  4.24712989e-03 -7.17634242e-03
  7.34652020e-03  6.71921577e-03  1.65014528e-02 -7.29737151e-03
  1.29609965e-02  6.93571614e-03  6.21640356e-03  9.43877455e-03
 -8.56409688e-03 -1.84014591e-03 -1.08945053e-02  5.00280084e-03
 -7.97778339e-05 -4.18510102e-03 -1.85387507e-02  4.50524408e-03
 -1.06729781e-02  7.91595224e-03  8.61127395e-03  8.00241902e-03
 -1.10924721e-03  3.50266026e-04 -4.95536393e-03  1.69874914e-02
 -4.01887745e-02 -1.39380256e-02 -3.51413642e-03  3.81635781e-03
  3.96638038e-03 -6.05497044e-03 -8.90599471e-03 -3.66930896e-03
  8.53727513e-04  5.42801339e-03  1.27371550e-02  2.14135065e-03
  5.11876028e-03 -5.44331619e-04 -3.77012882e-03  1.35775646e-02
  4.81755100e-03 -2.00587860e-03 -5.15526487e-03 -5.72256511e-04
 -2.77337246e-03 -3.02079432e-02  7.88541883e-03  1.78721491e-02
  2.62568202e-02  1.25125714e-03  1.38337975e-02 -4.83629899e-03
 -6.65322552e-03  7.09724263e-04  4.84540965e-03 -5.71005698e-03
 -6.86127041e-03 -1.14634829e-02  7.36286258e-03  5.20052575e-03
 -9.44864284e-03 -2.62566796e-03  8.34062882e-03  1.64400022e-02
  5.12529537e-03  2.78643682e-03  4.24122401e-02 -5.88105712e-03
  7.01842946e-04 -6.89874636e-03  8.43641721e-03 -1.74424872e-02
  2.49134190e-03 -9.77053214e-03  2.71913619e-03 -7.48513499e-03
 -2.03670952e-02 -1.50972120e-02  1.14543904e-02  2.51131263e-02
 -4.46766755e-03 -6.80942927e-03  6.22201199e-03  2.58018204e-04
  3.75029910e-03  2.91739008e-03 -2.36315262e-02  1.00079190e-03
  5.80979092e-03 -7.55076110e-03  3.13892751e-03 -9.33914736e-04
 -7.80222146e-03  5.91353886e-03  4.90931561e-03 -8.08420219e-03
 -8.85437895e-03  1.26953481e-03 -3.91538907e-03  3.88740888e-03
 -9.40665021e-04 -1.56683871e-03 -9.89585184e-04 -1.60993903e-03
  4.52991482e-03 -9.86142922e-03  9.56292916e-03 -1.48541108e-02
  1.23430397e-02  1.04788784e-02 -1.09091997e-02 -7.38300756e-03
 -3.64370586e-04 -4.03259788e-03  4.61166305e-03 -7.42966495e-03
 -1.50116161e-03 -9.00380954e-04 -7.78587128e-04  3.96308908e-03
  1.11619337e-02 -4.22592042e-03 -7.24468473e-03  1.49175720e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_85/kernel
[[ 0.04790635  0.0167245  -0.10545132 ... -0.06364456 -0.03699665
  -0.09940242]
 [ 0.08058932  0.06907243 -0.04186907 ...  0.09271943  0.05892596
  -0.12880385]
 [-0.00429239 -0.03678478  0.04250751 ...  0.13420369  0.03673923
  -0.03181317]
 ...
 [ 0.08557598 -0.11312033 -0.0791445  ... -0.085171   -0.07867996
   0.03312059]
 [ 0.10847551  0.10083777 -0.01712027 ...  0.12409282 -0.11816256
  -0.02861449]
 [-0.01767314 -0.16931936 -0.04118981 ...  0.10116652  0.03863591
   0.11703986]]
tensor_name:  TemporalFusionTransformer/time_distributed_86/bias
[-1.96280107e-02 -1.15831103e-02 -2.17303820e-02 -8.14873818e-03
 -4.51801810e-03 -2.56870203e-02  8.69431067e-03  4.92724823e-03
  1.22859124e-02 -7.62990152e-04  8.76776525e-04 -9.16310772e-03
 -6.78567495e-03 -1.08942343e-02 -2.96408171e-03  5.42229647e-03
  1.09131949e-03  2.26798397e-03 -2.01018061e-02 -1.39301550e-02
  6.55086304e-04 -2.08016671e-03  6.66671898e-03 -8.34015571e-03
 -2.80391996e-05  4.85969801e-03  9.88870673e-03 -1.28425267e-02
  1.54817319e-02  1.60596718e-03 -8.23076721e-03 -1.66256223e-02
 -1.08079324e-02  1.09769730e-02 -3.24053643e-03 -4.82637156e-03
 -4.64012008e-03 -1.09259384e-02 -1.02752401e-02 -1.05246631e-02
  3.11431056e-03 -1.05710793e-02 -1.32369446e-02 -2.16216668e-02
 -1.12819551e-02 -4.12070798e-03 -3.83838336e-03 -9.25389584e-03
 -1.98560487e-02 -1.65421236e-02 -6.44502323e-03  6.68998389e-03
 -1.85438916e-02  3.05957673e-03  7.10176444e-03 -9.08980705e-03
 -1.10940570e-02 -6.50427211e-03 -8.49358831e-03 -6.32023613e-04
  2.66088117e-02 -1.69209354e-02 -1.40760206e-02 -3.11831897e-03
 -1.21170208e-02 -9.63482913e-03 -2.21926142e-02 -3.83987557e-03
 -2.43132878e-02 -2.05152947e-02  2.09737290e-03 -1.03681944e-02
 -7.40028871e-03 -1.46640148e-02 -2.70695356e-03 -2.25961749e-02
 -1.01265479e-02 -1.06877722e-02 -8.36940948e-03 -1.88863296e-02
 -1.02770021e-02  5.76330768e-03 -2.11509075e-02 -6.94079092e-03
  1.80650763e-02 -1.20151294e-02 -1.60374157e-02 -2.56146863e-02
  1.67390285e-03 -7.20633799e-03  9.42093879e-03 -7.66848214e-03
 -4.16262803e-04 -9.08159465e-03 -1.44239515e-03 -1.17823025e-02
 -2.03366466e-02 -1.12218875e-02 -1.19893132e-02  6.53002737e-03
 -1.77336985e-03 -4.68178140e-03 -1.23742307e-02 -9.40973125e-03
 -2.65252660e-03 -1.25656789e-02 -2.13172901e-02  1.72525982e-03
 -6.60043117e-03  9.33980197e-03 -2.94040907e-02 -9.01089422e-03
  1.23358574e-02 -3.45612899e-03 -9.63487849e-03 -1.14265233e-02
 -2.83311643e-02 -8.44576024e-03 -1.85520332e-02 -2.47751549e-02
 -1.66473538e-02 -3.18093947e-03  1.21713476e-02 -9.15125757e-03
 -1.23978527e-02 -1.28442300e-02 -9.84683167e-03 -2.29852963e-02
 -1.40337413e-02  3.73987434e-03 -1.24902446e-02 -8.35962594e-03
 -1.14223240e-02  2.28188792e-03 -4.32192627e-03 -8.01245589e-03
 -1.28799202e-02  2.80291610e-03 -9.73636471e-03 -1.12858601e-02
 -1.42614124e-02 -8.34245607e-03 -8.57832748e-03  4.34263051e-03
 -2.46752356e-03 -1.36161614e-02 -3.04736604e-04 -6.00596005e-03
 -1.22707691e-02 -2.64191423e-02 -9.59396455e-03 -4.08846419e-03
 -4.50826949e-03 -1.19913090e-03 -6.47163484e-03 -1.28669869e-02
  1.08927097e-02 -1.66034978e-02 -5.61411120e-03 -2.31342949e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_86/kernel
[[ 0.03166043 -0.11251229 -0.06166818 ...  0.01373128  0.1090394
  -0.00114764]
 [ 0.01639322  0.03592782  0.04088449 ...  0.09165795  0.10105922
   0.09712896]
 [ 0.09793558  0.07014209 -0.11996508 ... -0.11514329  0.14885756
   0.02938001]
 ...
 [-0.16266371 -0.114357   -0.09930356 ...  0.12258404  0.01610225
  -0.09685469]
 [ 0.0427784  -0.11542007 -0.12110686 ...  0.0797516  -0.00892163
   0.01579464]
 [ 0.02209327  0.01119073  0.08177672 ...  0.17723008 -0.15046372
   0.01885351]]
tensor_name:  TemporalFusionTransformer/time_distributed_87/bias
[ 2.2167154e-03 -2.6268823e-02  7.1945260e-03  2.0699164e-02
  5.9985375e-04 -2.4534687e-02  7.7242628e-03 -1.7064501e-02
  3.3714645e-02  1.5761822e-02 -4.9990118e-03 -2.2735857e-04
 -9.4005046e-03  6.8821791e-03 -1.2177546e-02 -2.4582148e-02
  5.6002545e-03  2.5630185e-02 -2.3782365e-03 -1.8835381e-02
 -9.2567205e-03  1.5400722e-02 -2.1527046e-03  1.1404750e-02
  2.0670133e-02 -2.8157411e-03  1.8557718e-03 -3.2168362e-02
  1.9982280e-02 -6.6297757e-03  1.8358558e-02  6.4256594e-05
 -5.4533607e-03  3.9788026e-02  2.2279462e-02 -6.8300189e-03
 -5.0335512e-03 -1.8112097e-02  1.2341185e-02 -1.5855266e-02
  9.9868495e-03  6.9259686e-06  4.8201885e-03 -2.7534282e-03
  6.1597037e-03 -6.3248170e-03 -2.0024898e-02  1.8539468e-02
  3.4540852e-03 -1.7453105e-03 -2.2670638e-02  2.2694620e-03
 -1.0664890e-02  1.6181476e-02  2.7835241e-02  1.2738370e-02
  1.3415752e-03 -1.6827883e-02 -7.1107126e-03  2.8753778e-02
 -2.0664748e-02 -1.4262018e-02 -4.5831408e-03 -2.9065434e-03
  7.1059680e-03 -1.0718070e-02 -2.8657164e-02 -7.3558260e-03
 -3.6970114e-03  1.1409326e-02  1.2858766e-02 -7.2509060e-03
  1.5603390e-02 -5.1446492e-03 -1.1147688e-02  6.5728258e-03
  4.3748488e-04 -7.7162324e-03 -1.5973760e-02  6.0665666e-04
 -4.5721154e-03 -3.2645222e-02  1.7568497e-02  1.5054779e-02
  2.0418404e-02  2.1034102e-03  2.8452273e-02 -1.1684089e-02
 -1.9222556e-02  1.3714216e-02 -9.8950239e-03  9.6736625e-03
 -6.9324793e-03  1.4595664e-03  2.0875927e-02  6.8992940e-03
 -2.3111986e-02 -3.0527558e-02 -3.1931330e-03 -1.7876669e-03
  2.3074444e-02 -1.8469136e-03  5.6405354e-02 -3.9360445e-02
  7.5920308e-03 -1.3246985e-02  1.0133823e-02 -1.0705498e-02
  5.1645222e-03  5.2500386e-03  1.1613336e-03  9.5934747e-03
 -1.9182919e-02 -5.2859257e-03  1.5112520e-02  2.9072547e-02
 -2.0728355e-02 -1.2671136e-02  2.7331306e-02  1.8329691e-02
 -2.3198506e-02 -1.3831779e-04 -4.8257735e-02  8.3790887e-03
 -1.1753014e-03  8.0471290e-03  3.1916036e-03 -5.7979468e-03
 -1.3173929e-02  1.4894853e-02  8.6825946e-03 -2.4707489e-02
 -3.7076431e-03 -5.6094998e-03  2.5504692e-03  5.5127302e-03
  9.7654639e-03 -1.4984273e-02 -7.2635598e-03 -9.2179216e-03
  6.6157430e-03 -1.6806168e-02  9.4424635e-03 -2.8100792e-02
  1.4086562e-02  1.4232878e-02 -3.2573581e-02  4.7302740e-03
 -3.3700306e-03  5.6425286e-03 -9.6666496e-03 -6.3582296e-03
  1.4778330e-02 -5.8087353e-03 -1.9437928e-02  1.9950544e-02
  1.7266698e-02 -6.1418740e-03 -3.0301083e-02  3.0039681e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_87/kernel
[[ 0.0659382  -0.02063441  0.02512528 ...  0.12949157  0.03466886
   0.0991745 ]
 [ 0.00516284  0.12864089  0.05201456 ...  0.10660402  0.12874356
   0.10694844]
 [-0.03013639  0.03275948  0.07416909 ...  0.1202881  -0.06795994
   0.04221495]
 ...
 [-0.03609175 -0.08100765  0.08265395 ...  0.10801649  0.014329
  -0.03290712]
 [-0.14027184  0.10377651 -0.04450646 ...  0.00667475 -0.11435062
  -0.05214389]
 [-0.02627305  0.11775192 -0.04607476 ...  0.03029271 -0.00343236
  -0.0617259 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_88/bias
[-1.69576742e-02 -5.21065108e-03 -1.61362272e-02  6.86481362e-03
 -4.65942593e-03  8.17336421e-03 -1.71609335e-02 -1.20105231e-02
  8.88333842e-03 -1.23357950e-02 -1.94143299e-02 -9.76037793e-03
 -1.91130619e-02 -1.59358215e-02 -2.72621890e-03 -8.02396983e-03
 -1.21629545e-02  1.53824396e-03 -7.78657105e-03  2.65690545e-03
 -1.89574510e-02 -8.14789347e-03 -1.83549039e-02 -1.29737863e-02
  7.24004488e-03 -6.67049317e-04 -2.77358647e-02  6.15749881e-03
  6.51611947e-04 -3.04801599e-03 -1.98997799e-02 -6.17644377e-03
  5.21560258e-04  2.52274815e-02 -2.16950988e-03 -1.61442440e-02
 -2.71928366e-02 -6.88666152e-03 -8.49978416e-04 -2.04335321e-02
  1.53467935e-02 -3.12804542e-02 -1.97965913e-02 -1.19999787e-02
 -6.84361346e-03 -1.72140729e-02  1.29736830e-02  8.83787125e-03
 -2.22355500e-02 -2.27688197e-02 -6.94390945e-03 -3.17112380e-03
 -1.29353702e-02  3.50048882e-03  2.55246721e-02 -9.56958625e-03
 -1.71184838e-02  7.75474124e-03 -2.63204635e-03 -1.32905422e-02
  4.64664400e-03 -1.00428909e-02 -2.06195414e-02 -1.71373934e-02
 -3.23121622e-02 -5.71945682e-03 -1.86149811e-03 -9.93175711e-03
  2.35087937e-03 -1.35714579e-02 -1.27977021e-02  8.53356614e-04
 -1.32487770e-02 -1.30309938e-02 -9.35003813e-03 -1.02004921e-03
 -1.53465103e-02 -2.14599650e-02 -8.84609856e-03 -2.02599335e-02
 -7.83904828e-03  9.72995069e-03  2.24727974e-03 -4.11189534e-03
 -6.37777243e-03 -2.26729251e-02 -1.73626821e-02 -1.67131908e-02
 -1.31553626e-02 -5.05008921e-03 -1.35769546e-02 -4.24603326e-03
 -9.28958785e-03 -1.37419552e-02 -3.41690034e-02 -1.97002199e-02
  4.45722602e-03 -2.52260850e-03 -2.11976375e-02 -1.46587873e-02
 -4.88439063e-03  6.76845157e-05  2.92190965e-02 -1.74956191e-02
  9.33099713e-04 -1.62183698e-02 -9.14680399e-03 -1.05986381e-02
 -3.05765704e-03  2.93680909e-03 -9.16942302e-03  4.30381950e-03
 -1.34690618e-02 -7.82017037e-03 -2.53974851e-02 -1.36963967e-02
 -6.97246846e-03 -7.90605973e-03  5.22281229e-03 -7.51851732e-03
  2.29898444e-03  9.56829230e-04 -1.28409471e-02 -9.77039058e-03
 -8.10050685e-03 -1.13068298e-02 -1.23566724e-02 -9.58997384e-03
 -8.54553282e-03  4.70012706e-03 -1.48739303e-02  7.15409312e-03
 -2.04852000e-02 -5.52756572e-03 -1.95387471e-02 -1.34680383e-02
 -1.81975262e-03 -1.29735535e-02 -1.14535037e-02 -1.92409661e-02
 -1.73923634e-02 -4.39673895e-03 -7.66215194e-03  1.12827150e-02
 -1.10851731e-02 -1.25237126e-02  9.37312096e-03 -1.34611409e-02
 -9.26878769e-03 -9.99284349e-03 -1.36166448e-02 -1.12082474e-02
 -2.24158298e-02 -4.41593351e-03 -1.74774025e-02 -1.80578213e-02
  3.95112624e-03 -8.70078895e-03  1.84248891e-02  1.15650268e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_88/kernel
[[ 0.02235919  0.04729583  0.12895718 ...  0.03682377  0.07728188
   0.05909923]
 [-0.10261974 -0.09665301 -0.09286524 ... -0.0674546  -0.13508172
  -0.01479354]
 [ 0.1220667  -0.05414516  0.02932681 ...  0.07115435  0.01014209
   0.04697812]
 ...
 [ 0.09489528 -0.03774452 -0.00280709 ...  0.04391078 -0.10792232
   0.09422741]
 [ 0.11441253 -0.14222474 -0.01825801 ... -0.1383513  -0.05912591
  -0.09610125]
 [-0.0007908   0.11250938 -0.08373643 ...  0.11656635  0.01388215
   0.05533563]]
tensor_name:  TemporalFusionTransformer/time_distributed_89/bias
[-1.67820102e-03 -1.42708616e-02  1.90595761e-02  1.50181574e-03
 -1.14579191e-02  8.48596822e-03 -3.26127512e-03 -1.67098753e-02
 -2.44482700e-02 -1.04470216e-02  2.73660780e-03 -4.63655591e-03
 -1.24507425e-02  3.34482081e-03 -5.82933892e-03  1.34387678e-02
 -2.29243785e-02  1.64930169e-02  9.86209605e-03 -1.67767163e-02
  1.52950594e-02 -8.49400554e-03 -1.65467162e-03 -3.18505662e-03
  8.35277420e-03  7.82425515e-03  2.10306863e-03 -9.67411138e-03
  2.80927103e-02  4.21973644e-03 -5.62376948e-03 -2.42079403e-02
  2.69707646e-02  1.15653556e-02  9.00536031e-03  3.28194052e-02
 -4.59364755e-03  1.70971022e-03  1.50731225e-02 -3.07936221e-02
 -2.07130052e-02 -1.98406000e-02  2.04733629e-02 -1.12906741e-02
 -1.23979745e-03 -1.56275760e-02  2.44133659e-02 -4.24159551e-03
 -1.96246970e-02 -5.69380680e-03 -4.77403551e-02  1.31123029e-02
 -1.40682794e-02  2.65061725e-02 -2.43845601e-02 -1.94104593e-02
 -9.79995821e-03 -2.05759946e-02  4.49237833e-03 -3.17766480e-02
  2.53576934e-02 -7.94371404e-03 -1.24526452e-02  3.33565958e-02
  9.13468748e-03 -2.94599216e-03  2.21242849e-02  3.10526229e-03
 -1.09927049e-02  1.96395721e-02 -3.61426082e-03  2.07324307e-02
  2.42916550e-02 -1.81818437e-02 -2.51112171e-02  1.39906851e-03
  8.91598640e-04  1.47046689e-02 -4.44638496e-03 -7.88262859e-03
  2.05416046e-02 -1.80768445e-02  4.13602684e-04  1.12931682e-02
  8.12471937e-03 -3.01318651e-04  1.67413540e-02  9.41767357e-03
 -1.49767529e-02  2.21657082e-02 -1.93889439e-03 -7.68813910e-03
  3.35302018e-03 -1.18133584e-02  2.51482986e-03 -9.69603751e-03
 -1.29952654e-02 -1.46159455e-02 -6.03100611e-03  2.37105079e-02
  4.86730272e-03  9.53278225e-03  7.92279094e-03  1.13044437e-02
  1.15455538e-02  4.10032505e-03 -1.17634350e-04 -3.02204490e-03
 -5.36457356e-03 -1.38572063e-02  1.51190190e-02  1.01385843e-02
  3.24928388e-02 -1.04135759e-02  5.85805485e-03 -2.88806460e-03
  2.72081271e-02 -3.77791077e-02  1.98225286e-02 -1.53865181e-02
 -1.96691044e-02  9.17087600e-04  3.04402523e-02  1.41206877e-02
  9.03663039e-03  7.49997329e-03 -3.29592228e-02 -1.12728607e-02
 -9.37266450e-04 -7.27960467e-03 -3.65249696e-04 -2.99236318e-03
 -1.41559811e-02 -1.14516253e-02 -2.44842586e-03  2.54051462e-02
 -8.73036159e-04  1.31639827e-03 -1.23067815e-02  6.08758023e-03
 -1.91338435e-02  2.53362861e-03  8.87094345e-03  1.96612999e-02
  5.22756856e-03  1.50895286e-02  2.11731344e-02  7.87042174e-03
  7.86942989e-03  3.83209833e-03 -2.36767065e-02 -2.00066362e-02
 -1.30792689e-02 -2.69861892e-02 -2.97638355e-03 -2.18570363e-02
  3.83024686e-04 -6.81939200e-05  1.43174622e-02  1.21487770e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_89/kernel
[[-0.08055589 -0.10501594 -0.06855969 ...  0.14186525  0.127333
  -0.06973834]
 [-0.11533028  0.07105293  0.09013344 ...  0.08253098  0.00990149
  -0.11495961]
 [-0.00450272  0.14780658 -0.11779474 ...  0.06654406  0.02319323
  -0.04860084]
 ...
 [ 0.03875602  0.0267764  -0.04463026 ... -0.1311831  -0.0150477
   0.07353396]
 [ 0.142018    0.1086921   0.10920867 ... -0.02924146  0.11235186
   0.10792843]
 [ 0.11657103  0.07450737  0.15478553 ...  0.13084863  0.08679074
  -0.00756585]]
tensor_name:  TemporalFusionTransformer/time_distributed_9/bias
[-6.42008567e-03  2.54366659e-02 -8.86412636e-06 -3.03189233e-02
 -3.40107339e-03  3.84014063e-02 -2.37219892e-02  4.57288213e-02
 -2.85955779e-02  2.80735474e-02  8.00958741e-03 -3.52217257e-02
 -1.13233114e-02 -2.42771916e-02 -3.26108397e-03 -1.82172470e-03
 -3.33325453e-02  2.47273166e-02 -2.21602656e-02  1.44214521e-03
 -2.62613036e-02  2.39691138e-02  1.88926863e-03 -4.47166199e-03
 -1.30559467e-02  1.33998413e-02  1.10215312e-02 -9.49726347e-03
  3.43193561e-02 -2.99716070e-02 -1.73202269e-02 -1.06423087e-02
  3.32507677e-02 -3.21367420e-02 -2.30731964e-02 -1.90065093e-02
  2.38912646e-02  4.92219348e-03 -4.25309082e-03 -3.66416015e-02
 -1.73468911e-03  2.40288917e-02 -2.54589878e-02 -2.58113984e-02
 -1.83897931e-02  4.67753150e-02 -1.41746365e-02 -6.72857696e-03
 -1.17448848e-02  8.08213558e-03 -1.82235222e-02  5.18567045e-04
 -9.36378911e-03 -8.89559742e-03 -3.96015644e-02 -5.65529391e-02
  1.75849367e-02 -1.06410943e-02 -1.48695260e-02 -3.66677887e-06
  9.04429983e-03  1.53453443e-02 -4.10235561e-02  2.94740088e-02
 -1.70762669e-02 -1.16740745e-02 -2.74565071e-02 -3.25853238e-03
  1.82697810e-02 -3.92389596e-02  6.05228264e-03 -1.29876146e-02
  1.98732745e-02 -3.09367031e-02 -5.15278382e-03  3.90414298e-02
 -6.29951712e-03  2.18987316e-02 -4.47778497e-03 -3.18337269e-02
  3.42014246e-02 -2.96622794e-02 -7.69182807e-03  4.18420061e-02
 -1.77280474e-02  5.05753502e-04 -1.29995942e-02 -1.49701703e-02
 -2.73400126e-03 -1.00265173e-02 -9.81136342e-04  3.87635045e-02
  1.26579795e-02 -4.26996574e-02 -2.84762098e-03 -2.16201022e-02
 -3.98269109e-02 -1.95339043e-02  2.36935839e-02  1.27264885e-02
 -1.71631575e-02 -1.84759609e-02  3.00126020e-02  3.30242999e-02
  2.59469971e-02 -1.40403211e-02 -1.96436811e-02  1.72006134e-02
 -4.13219891e-02 -2.21696377e-04 -9.92803741e-03 -2.69544739e-02
 -1.38908741e-03 -6.29092753e-03 -1.03628915e-02 -3.10578961e-02
  1.46849768e-03  1.70090832e-02 -1.04948226e-02 -9.44594853e-03
 -6.83487952e-03  3.71105075e-02  3.35622355e-02 -1.21418685e-02
 -4.09639366e-02 -3.16106714e-02 -1.25475414e-02 -1.06378654e-02
  7.19693489e-03  5.57227526e-03 -2.93718856e-02 -1.03464443e-02
 -2.12335289e-02  2.22572181e-02 -1.09125506e-02  3.93326953e-02
 -4.84773926e-02 -1.66853573e-02 -1.25353178e-03 -1.62943136e-02
  1.66514814e-02  9.17124934e-03 -2.96660066e-02  1.07175787e-03
 -4.03398126e-02  2.48487163e-02 -1.98193826e-02 -3.36435400e-02
  1.40238842e-02  3.79575491e-02  1.86570361e-02  7.90694542e-03
 -2.16803327e-02 -2.33926959e-02  3.47348526e-02  1.34548463e-03
 -1.40730962e-02 -3.00653308e-04 -2.41122060e-02 -3.02200317e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_9/kernel
[[-0.01576956 -0.03416606  0.0237277  ... -0.02701666  0.02866406
   0.0404679 ]
 [-0.00986315 -0.07475023 -0.11301293 ... -0.03384806 -0.02350925
  -0.03399072]
 [ 0.05248089  0.14601913  0.00398978 ...  0.03702976  0.01188489
  -0.03480605]
 ...
 [ 0.09729461 -0.03688134 -0.08784731 ...  0.11884814 -0.07204919
   0.0136533 ]
 [ 0.01059911 -0.04432509 -0.02177833 ...  0.00676218  0.09188917
   0.07518988]
 [-0.04209296 -0.09731345 -0.05217594 ...  0.00493975 -0.04233121
  -0.0484986 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_90/bias
[ 1.4532507e-02  1.5933419e-02  4.3033878e-03 -2.7489820e-02
 -9.5450832e-03  2.6637539e-02  9.0781925e-03 -1.0314010e-02
 -1.6970435e-02 -1.5742252e-02 -8.0154771e-03 -5.4627410e-03
  1.9107578e-02 -3.5001863e-02  1.1149686e-02 -3.4618156e-03
  2.4819967e-05 -2.6486139e-03 -2.2236740e-03  9.2266309e-05
  8.9018652e-03 -1.8846577e-02  6.3985738e-04 -1.6301498e-02
  1.0454546e-02  7.5482805e-03 -1.0877354e-02 -1.9710297e-02
  1.5785492e-03 -1.8503640e-02 -8.7939426e-03  3.6104626e-03
 -2.5951724e-02  7.6346025e-03  6.9203014e-03 -1.0025599e-02
 -5.0552166e-03 -1.1186162e-02 -3.2900382e-02 -8.9225173e-03
 -8.7658186e-03 -3.0172504e-02 -9.4502997e-03  3.2420106e-02
  2.8814387e-02  1.9099150e-02  2.2148019e-02  1.7076273e-02
  1.0223407e-02 -2.6608132e-02 -1.2182771e-02  8.5152565e-03
  1.9476229e-02  1.7175896e-02  1.1107781e-03  2.0145083e-02
 -6.9129132e-03  1.9692464e-02 -4.4137156e-03  1.5281123e-02
  9.6188160e-03  1.4788385e-02  2.7871242e-02 -2.0601187e-02
 -2.9197751e-02 -5.5932398e-03  1.1156661e-02  6.9912425e-03
 -1.7562844e-02 -3.1900689e-02 -2.7790725e-02  2.9966531e-02
  1.1526374e-03  3.6893990e-02  2.1683665e-02 -3.5568860e-03
  2.0917214e-02  4.7027059e-03  1.8141611e-02  4.2674490e-03
  1.4795145e-02 -2.1494783e-02  2.8399131e-03  2.2315182e-02
  1.6832529e-02  2.6717266e-02  1.0753247e-02  5.5841549e-04
 -8.9484435e-03 -2.9379236e-02 -3.5624984e-03 -2.8365482e-02
  2.5213512e-02 -4.0349639e-03 -1.6580231e-02  2.4791338e-02
 -1.1620560e-02 -3.3451952e-03 -1.0072911e-02 -4.0911431e-03
  6.7512048e-03  3.9000339e-03 -4.8505766e-03  2.5489746e-02
  1.5077311e-02 -1.2928399e-02  8.3828298e-03  1.9308891e-02
  2.3927647e-03  1.8426800e-02 -3.2661194e-03  1.2635214e-02
 -8.4687378e-03 -5.5708475e-03  6.5055857e-03 -2.5708857e-03
  2.1131948e-02  7.5421734e-03 -4.8609399e-03  1.2470929e-02
  6.4306534e-03 -2.2427078e-02 -8.3907871e-03  1.5774880e-02
  1.6007410e-02  2.9603966e-02  9.6271764e-03  1.5707565e-02
 -1.7409978e-02 -4.3842988e-03 -1.4109775e-02  9.0118777e-03
  5.1997259e-04 -2.4842078e-02 -1.1231036e-02  2.0671597e-02
 -5.0045406e-03  4.5085658e-04 -1.0945679e-02  8.2330750e-03
 -5.0114249e-03 -1.6644159e-02 -8.5887844e-03 -8.0259787e-03
 -2.0658014e-02 -1.7581087e-02 -1.4892736e-02 -3.1844337e-02
  6.7401109e-03  7.0436560e-03  2.1227002e-02  3.4711300e-04
 -1.6153414e-02 -2.3281803e-02 -2.1908760e-02  8.6604152e-03
 -5.3266077e-03  7.2068209e-04  6.9446145e-03  1.6544512e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_90/kernel
[[-0.01580115 -0.10227008  0.12195726 ...  0.09440602 -0.13644832
   0.03320378]
 [ 0.12811327 -0.01743569  0.10818593 ... -0.00368947 -0.16575974
  -0.11514798]
 [-0.09193154  0.08804961  0.02435511 ... -0.06014584 -0.10385082
   0.01371218]
 ...
 [-0.05057784  0.13401489  0.01356594 ...  0.0675845  -0.12437756
   0.02921615]
 [ 0.0425272  -0.10172818  0.10637577 ...  0.07240535 -0.00867403
  -0.02123569]
 [-0.12377439  0.01984225 -0.02246546 ... -0.13850053  0.08096924
   0.14942023]]
tensor_name:  TemporalFusionTransformer/time_distributed_91/bias
[ 1.72108843e-03 -1.16617270e-02  1.06257189e-03  4.66002636e-02
 -3.45913600e-03 -1.80055406e-02  1.05820084e-02 -5.20717027e-03
  4.20314111e-02  7.24038063e-03 -6.18189294e-03 -8.60776869e-04
 -1.86820831e-02  3.17734157e-05 -1.35014290e-02 -4.15619463e-02
  8.89876392e-03  4.59082946e-02 -1.30439736e-02 -2.53374558e-02
  3.28234956e-02  1.00899059e-02  3.04666138e-03  6.09388808e-03
  3.03746909e-02  2.52769352e-03 -6.12066034e-03 -8.02120380e-03
  5.65036759e-02 -4.21765912e-03  9.96018946e-03 -9.68534127e-03
  1.57055096e-03  5.22735380e-02  4.34861612e-03 -1.24465991e-02
  1.41904224e-03  4.11400013e-03  1.27221812e-02 -1.17345350e-02
  1.83566939e-02  2.01463746e-03  1.00712106e-02 -2.78077088e-03
 -3.80901154e-04  2.07406096e-03 -1.30185410e-02  1.42968222e-02
  8.93430959e-04  7.31383031e-03 -2.87071932e-02  1.66731533e-02
 -6.40607672e-03  7.30691198e-03  5.73737286e-02  1.62319280e-02
  1.52107319e-02 -2.60672681e-02 -1.42281991e-03  4.02904116e-02
 -2.35935654e-02 -1.73361432e-02 -4.55157924e-03 -6.48537825e-04
  4.97203274e-03 -2.22691987e-03 -8.55897591e-02 -9.67250578e-03
 -1.01425070e-02  1.67468395e-02  1.69061571e-02 -8.34297761e-03
  1.79434512e-02  1.54379476e-03 -1.63202379e-02  4.71127080e-03
 -5.57677762e-04 -1.62864681e-02 -1.18154911e-02  4.37046448e-03
  6.83085178e-04 -2.84169894e-02  2.29869764e-02  6.63422886e-03
  2.79529132e-02  8.60246923e-03  3.72722046e-03 -2.09315717e-02
 -3.32547612e-02  1.11346105e-02 -1.24991192e-02  1.54114487e-02
 -1.41855199e-02 -4.06917557e-03  2.71432940e-02  1.13369012e-03
 -1.21736117e-02 -1.79530345e-02 -1.03264619e-02 -6.74042013e-03
 -1.92987826e-03  1.48257036e-02  8.80969837e-02 -1.48666948e-02
  7.70063698e-03 -8.17710534e-03 -1.80962682e-03 -7.68897962e-03
  8.31842981e-03  9.53835808e-03  3.01256627e-02  1.02501614e-02
 -1.72877461e-02 -8.12381692e-03  1.57013070e-02  1.66287813e-02
 -2.04562712e-02 -6.67280052e-03  3.27631310e-02 -2.23155832e-03
 -2.46904679e-02 -1.90061843e-03 -6.18996061e-02  4.98595228e-03
  1.81962200e-03 -8.94213968e-04  4.24173987e-03 -5.08078048e-03
 -5.57777239e-03  1.64077729e-02  9.37491469e-03 -9.14453343e-03
 -6.53498853e-03 -1.83534753e-02 -1.70152227e-03  5.16923191e-03
  1.05916820e-02 -3.83078889e-03 -6.79012714e-03 -1.30867148e-02
  6.85116835e-03 -4.65483740e-02  2.27811038e-02 -3.73187097e-04
  1.03987651e-02  3.09341587e-03 -4.75640707e-02 -1.81010123e-02
 -2.00105901e-03  1.75437313e-02  2.91953649e-04 -4.18802351e-03
  1.36339646e-02  3.83637822e-03 -1.02506941e-02  1.68418344e-02
  2.28245202e-02 -1.13536296e-02 -4.75145765e-02  1.89693421e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_91/kernel
[[ 0.10020252  0.05860746  0.00855907 ...  0.02957089 -0.05843597
  -0.00255374]
 [-0.06148737 -0.02817302  0.03501644 ... -0.11413876 -0.00208321
  -0.03282554]
 [-0.02845487 -0.05320043 -0.11899141 ... -0.01113689 -0.09108569
   0.12203692]
 ...
 [-0.0424367   0.07716443 -0.02804041 ...  0.07281586  0.09881896
  -0.09930846]
 [-0.11042656  0.11509537 -0.1127892  ... -0.12560423 -0.08143494
  -0.02267022]
 [ 0.04048809 -0.01595801  0.07070536 ...  0.03473    -0.15178032
   0.04995868]]
tensor_name:  TemporalFusionTransformer/time_distributed_92/bias
[-0.00069118 -0.01544308 -0.0185089   0.02480002 -0.00137075  0.01738892
  0.00415624 -0.01002485  0.02351476 -0.01038705 -0.01259038  0.01037983
 -0.00972019 -0.01010811 -0.01097627  0.01549227  0.00246221  0.0151936
  0.01069685  0.01438236  0.00932717  0.00087075 -0.01668758  0.00253407
  0.01706998 -0.00667135 -0.0100539  -0.00538148  0.01869869  0.00202088
 -0.02479631 -0.00279714 -0.01802533  0.03436699 -0.02107284 -0.00981941
 -0.01331604  0.00701278 -0.00970768 -0.01115745  0.00783141 -0.01781722
 -0.02608413 -0.0161524  -0.01046041 -0.01827951  0.01395284  0.02450119
  0.0090236   0.00569115  0.02162733  0.00518785 -0.0203901   0.01785755
  0.02528584 -0.01870294  0.01467037  0.00515946 -0.00551684  0.02402159
  0.03307478 -0.01368915 -0.00288484 -0.00270379 -0.00982784 -0.01564889
  0.02097947 -0.01156468  0.00501492 -0.00783673 -0.00974096 -0.00025866
  0.00718905 -0.01212826 -0.0265874  -0.0083616  -0.00528489 -0.01881244
 -0.01622686 -0.00511075  0.00211665  0.00357289  0.01012375 -0.02468708
  0.00698827 -0.00868465 -0.00761898 -0.00138819 -0.00503407  0.01071826
 -0.01605512  0.01432421  0.00573224 -0.0192237   0.00353773 -0.00441937
  0.00796098 -0.00590675 -0.00281722 -0.0017251   0.00778355 -0.00071144
  0.02391276 -0.02137153 -0.00180515  0.00294852 -0.01825088 -0.01190523
 -0.00623927 -0.00432089  0.00560138  0.00110127 -0.000305   -0.00517148
  0.01814418  0.00596506 -0.0056412  -0.01303424  0.03753151  0.00980813
 -0.01137295 -0.00341911  0.02522724 -0.01767323 -0.00491435 -0.01172385
 -0.00991162 -0.01156565 -0.00355671 -0.00320098 -0.00100329 -0.00124216
  0.00513127  0.01122155 -0.01000419 -0.02125281 -0.03014392  0.00158723
 -0.00106003 -0.01248499 -0.01537262  0.01803681  0.01118984  0.02253351
 -0.00977372 -0.00832699  0.02162726  0.00291335 -0.01669137 -0.00930416
 -0.00960355 -0.0071273  -0.02280268 -0.01497142 -0.00982999 -0.03510837
  0.00020149  0.00767739  0.02132079 -0.00945872]
tensor_name:  TemporalFusionTransformer/time_distributed_92/kernel
[[-0.12910438 -0.1417646   0.12685107 ... -0.11661807  0.03998004
   0.07977762]
 [-0.05706165  0.05554059  0.06141257 ...  0.05985629  0.09679262
   0.00660511]
 [ 0.03087969  0.05824357 -0.04066396 ... -0.0534142   0.03153856
  -0.02364943]
 ...
 [ 0.0348555   0.15089168  0.08140018 ... -0.01834518  0.09044703
  -0.02578544]
 [ 0.05173801  0.1042818  -0.08345562 ...  0.13325529 -0.10223671
   0.00382096]
 [-0.13285252  0.0011786  -0.13227649 ...  0.01126388  0.05623078
  -0.05629161]]
tensor_name:  TemporalFusionTransformer/time_distributed_93/bias
[ 1.18861124e-02  7.89537374e-03  9.25473683e-03 -8.07428919e-03
 -1.66349369e-03  9.22049116e-03  1.07261324e-02 -3.03662457e-02
 -3.83269116e-02  1.37380539e-02 -4.68660984e-03 -1.46670435e-02
  6.14522607e-04 -3.44177103e-03  3.00411209e-02 -5.84569573e-03
  1.81973632e-02  8.43242481e-02  2.40848702e-03  1.27899535e-02
  3.35545815e-03 -1.70135777e-02  7.22848400e-02  1.31922225e-02
 -1.38046490e-02 -4.86821122e-02  6.53716996e-02 -5.79297803e-02
 -6.07872894e-03  9.36129503e-03 -4.24169637e-02  2.50246632e-03
 -1.96198039e-02  1.09763201e-02 -4.99316156e-02 -3.40748229e-03
  1.01544037e-02 -9.98727605e-03  6.06352426e-02  2.89439987e-02
  1.94672160e-02  1.82050075e-02 -6.53516315e-03  7.76960934e-03
  4.76834597e-03  2.43307650e-02 -8.94002616e-03 -1.40600288e-02
  1.44084562e-02  8.12060013e-02 -6.91055506e-03  1.30366579e-01
  1.11735901e-02  8.04251619e-03 -1.80165358e-02  8.07809178e-03
  5.57496771e-03 -5.18939681e-02 -9.03980434e-03 -2.66373041e-03
  7.76850153e-03  3.60253155e-02  3.23712826e-02 -1.77997071e-02
 -1.04853231e-02  2.08919793e-02 -2.31905337e-02  7.04388553e-03
  2.07390520e-03 -1.73552837e-02 -2.66080163e-03  7.68247340e-03
 -8.38125066e-04  1.42638059e-02 -2.21812800e-02  4.73813713e-03
  2.30541080e-02  3.97758968e-02 -3.38473101e-03  5.29184975e-02
  3.81526188e-03  1.34739717e-02 -2.67275330e-02 -4.74432297e-02
  1.09894194e-01 -1.84154492e-02  5.12280595e-03  8.06857459e-03
  2.21556295e-02 -1.29326796e-02 -9.88021307e-03 -6.08035969e-03
 -3.66517007e-02 -6.38859794e-02 -5.81545709e-03  1.58724170e-02
  2.95690028e-03  2.34365300e-03  1.66092406e-03 -2.31039487e-02
  3.91785614e-03 -1.01011442e-02  1.60331577e-02 -1.15371402e-02
  3.27757373e-02 -2.74772290e-02 -1.32747460e-02  1.80216935e-02
 -1.74841788e-02 -1.52094979e-02  2.91777099e-03 -3.08543313e-02
  1.93983745e-02  1.74823646e-02  2.03524600e-04 -1.61263254e-02
  2.07508150e-02 -2.46196818e-02  1.54917752e-02 -4.49185120e-03
  3.33514460e-03 -2.18666270e-02 -6.45621074e-03 -4.60720696e-02
 -7.07008364e-03  2.60249246e-02  1.10146841e-02  1.58056319e-02
 -3.03626806e-03  8.09297338e-03  1.56570852e-04 -8.10236298e-03
 -1.99314915e-02 -2.16050888e-03  1.03473561e-02 -1.77470397e-03
  1.24707157e-02  5.02930302e-03 -1.31485807e-02 -1.22628389e-02
 -9.30423755e-03  1.81418676e-02 -4.03989945e-03  2.65693199e-03
 -4.04767506e-02 -1.11459782e-02  7.53472513e-03 -2.55054981e-02
 -2.38027517e-02 -1.25732487e-02 -6.75777998e-03 -1.21031706e-04
 -3.82883511e-02  1.24432901e-02  2.95953192e-02 -5.53605705e-03
 -2.88502034e-02  2.03103032e-02 -1.07033858e-02 -2.46381573e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_93/kernel
[[-0.12150479  0.11375064  0.11089074 ... -0.06926708 -0.08636335
   0.05932314]
 [ 0.01554179  0.03134933  0.10094021 ... -0.09256537  0.02796909
   0.06512205]
 [-0.1242359   0.05826746  0.14586268 ... -0.11664814  0.10052671
   0.01991138]
 ...
 [ 0.00283268 -0.10398886 -0.09406308 ...  0.01514819 -0.14271046
   0.0725944 ]
 [-0.11264088  0.13344306 -0.03453406 ...  0.10510866  0.10403181
  -0.04756137]
 [-0.10048026 -0.0166346   0.09394532 ... -0.13031158 -0.08778838
   0.04339271]]
tensor_name:  TemporalFusionTransformer/time_distributed_94/bias
[-3.16343084e-02 -2.98044179e-02  3.83495986e-02  5.05511602e-03
 -1.56336688e-02 -4.68811803e-02 -1.95101313e-02 -4.68919426e-02
 -1.25863433e-01  3.77869941e-02 -4.87972051e-02  2.05035936e-02
 -1.79928895e-02 -5.89454547e-02  1.22529678e-02  1.11870607e-02
 -3.45035493e-02  6.77795112e-02 -1.58544052e-02 -6.42649159e-02
 -1.62957646e-02 -1.96758602e-02  4.74567376e-02 -1.86518189e-02
 -2.18754224e-02  6.85957149e-02  6.41705245e-02  7.27572516e-02
 -7.60961846e-02  3.24064270e-02 -1.19712099e-01 -7.62253115e-03
 -1.29925489e-01 -7.82110319e-02  5.84857129e-02 -5.02721668e-05
 -7.10528418e-02  2.59880852e-02  3.10782064e-02 -3.53364535e-02
  3.38692702e-02 -4.02135253e-02  3.19960937e-02 -1.56191895e-02
 -5.81762865e-02 -1.07149951e-01 -2.47890484e-02 -4.47841100e-02
 -7.19733611e-02  7.93694109e-02 -2.31289640e-02  1.08004667e-01
 -1.77208576e-02 -1.33637730e-02 -6.62766844e-02 -2.33353805e-02
 -5.95044158e-02  4.80816439e-02 -2.46282853e-02 -9.26068705e-03
 -1.99573338e-02  2.14951560e-02 -1.00399904e-01 -3.64773795e-02
 -5.68117537e-02 -4.46001776e-02 -5.80963679e-02  5.79241291e-03
 -7.93871135e-02 -1.46733940e-01 -5.81098869e-02 -5.08158915e-02
 -4.28707851e-03 -6.33198619e-02 -6.12809584e-02 -4.57897633e-02
 -2.38784105e-02  7.86949787e-03 -4.80031930e-02  8.00180212e-02
 -4.92576733e-02 -1.44531885e-02  1.30712032e-01  1.89244494e-01
  3.77634428e-02 -1.98181383e-02  5.76930791e-02 -2.71838829e-02
 -6.06513098e-02 -1.52508393e-02  3.19857635e-02  1.15636745e-02
  8.70956704e-02  1.47582171e-02 -7.77440742e-02 -5.24540991e-02
 -1.69885736e-02 -4.03011441e-02 -2.44256072e-02 -4.42268774e-02
 -5.66346794e-02 -1.53916962e-02 -1.57362707e-02 -2.33829692e-02
 -8.69472399e-02  1.32270772e-02 -1.06534082e-02 -1.46761969e-01
 -3.39017734e-02 -9.25648883e-02 -2.05956828e-02  7.95956794e-03
 -2.77682533e-03 -9.45715513e-03 -5.24671562e-02 -6.18976615e-02
 -4.30180132e-02 -1.58561602e-01  5.93078174e-02  6.32297667e-03
 -2.88019106e-02 -5.04724383e-02 -5.29209077e-02  1.13779932e-01
 -2.46809628e-02  6.43068776e-02 -1.92233883e-02  2.91308630e-02
 -5.93294054e-02 -7.81549141e-02 -3.10169458e-02 -3.06576621e-02
 -4.78007384e-02 -5.92534468e-02 -1.35605056e-02 -2.21785437e-02
 -7.15618441e-03 -2.57551335e-02 -2.74806935e-02 -8.34618956e-02
  2.17089732e-03  9.25659761e-03 -1.15724923e-02 -2.81627234e-02
 -1.03336908e-01 -1.72156524e-02 -1.78922713e-02 -4.58831564e-02
  1.25565957e-02 -3.07297595e-02 -4.90226932e-02 -3.69472392e-02
  7.30051845e-02 -1.53983766e-02 -1.32269517e-01 -2.37465333e-02
 -1.05979964e-01  4.47288714e-03  3.69100273e-02  4.51832786e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_94/kernel
[[ 0.02215245  0.10330873 -0.08794734 ... -0.01504324 -0.06164302
  -0.05121797]
 [ 0.00979441 -0.00690642  0.09546267 ... -0.14096701  0.01261337
   0.05109404]
 [-0.00238058  0.1104514   0.03628735 ...  0.07849937 -0.12609853
   0.10794207]
 ...
 [ 0.00985559 -0.02695994  0.13167514 ...  0.00766761 -0.03839478
   0.00435654]
 [ 0.15968716  0.06024303  0.11565135 ...  0.00457991 -0.08053838
   0.10464267]
 [ 0.06400863 -0.00318355 -0.15720093 ...  0.06334664 -0.02325661
  -0.14273575]]
tensor_name:  TemporalFusionTransformer/time_distributed_95/bias
[-0.00300593 -0.00039605  0.02188661]
tensor_name:  TemporalFusionTransformer/time_distributed_95/kernel
[[ 0.06677321  0.14754903  0.1598116 ]
 [-0.05476428  0.06203042 -0.01085745]
 [-0.00954187 -0.0342516   0.10798572]
 [-0.01827963  0.11488021  0.05606395]
 [ 0.14201903 -0.12031279  0.12227008]
 [-0.04704381 -0.08836165  0.1456709 ]
 [ 0.04829231  0.06635406  0.08686565]
 [-0.01516743 -0.01136328 -0.07785983]
 [ 0.08620789  0.01685632 -0.04630266]
 [-0.13492185 -0.00352217 -0.01702878]
 [-0.06634964 -0.06952851 -0.04926011]
 [ 0.12992291 -0.07148612 -0.09864864]
 [ 0.02943189  0.14464349 -0.08476344]
 [-0.10647742  0.01022886 -0.13644585]
 [ 0.01295409  0.03248844  0.1064673 ]
 [-0.11318149  0.12868811 -0.06430795]
 [ 0.09511986  0.02845614  0.12689652]
 [-0.0435595  -0.06489756  0.0317797 ]
 [-0.08003297  0.09348765 -0.10505189]
 [-0.10744574 -0.07892735  0.03343238]
 [-0.00697418  0.12943965 -0.14069425]
 [ 0.05366521 -0.10085172 -0.05816482]
 [ 0.03050595 -0.0040397  -0.03334749]
 [ 0.06977992  0.06358023  0.07571539]
 [-0.15278849 -0.10925883 -0.12225524]
 [ 0.12366667  0.06551674  0.10492693]
 [ 0.00622382 -0.05693122  0.13113448]
 [-0.00238719  0.01976195 -0.06190012]
 [ 0.0825759   0.15916629 -0.05736883]
 [-0.02773612 -0.01414932  0.0548758 ]
 [ 0.0798743  -0.04357011 -0.12396558]
 [-0.0623975   0.10111882 -0.08880773]
 [ 0.12112635  0.0947546  -0.11805613]
 [-0.04885105 -0.11193673  0.11492905]
 [ 0.06968289 -0.09362532 -0.01604895]
 [ 0.05643752 -0.13787274  0.01613103]
 [ 0.10461984 -0.050065    0.00276943]
 [ 0.02910664 -0.06965449 -0.13306817]
 [ 0.06433935 -0.00371606  0.14385064]
 [-0.05983115  0.11689693  0.10123932]
 [ 0.01762201 -0.0514044   0.04003263]
 [-0.02023361 -0.15627117  0.11169581]
 [ 0.07604875  0.08395993 -0.10116506]
 [-0.02691471  0.11003166  0.02809238]
 [-0.12302312 -0.12592721 -0.09496269]
 [-0.07323594 -0.07182194  0.09060562]
 [ 0.02340494  0.10758244 -0.06196022]
 [-0.02714172 -0.13789447 -0.11696459]
 [ 0.1638977  -0.00399939  0.0038654 ]
 [-0.0877535   0.04485217 -0.0489734 ]
 [ 0.06025236  0.11636401 -0.09485594]
 [-0.09647685  0.000202    0.09942573]
 [ 0.04518164  0.01707262  0.09027201]
 [-0.13243142  0.10294645 -0.04711826]
 [ 0.09311148 -0.07611513  0.02228834]
 [-0.04039056  0.02527935  0.08159786]
 [-0.11807575 -0.12475339  0.04850718]
 [ 0.02152995 -0.04991584  0.0781223 ]
 [-0.05617208 -0.01120335 -0.10811261]
 [-0.11913392 -0.0851794  -0.10292418]
 [ 0.03257868 -0.0374493   0.08215687]
 [ 0.02976329  0.06967202  0.0013957 ]
 [-0.12213502 -0.11326686  0.16110915]
 [ 0.02226735 -0.15905447 -0.10057996]
 [ 0.0505629   0.11946724 -0.10041148]
 [-0.06671741  0.14068814  0.17656466]
 [ 0.14242263 -0.13367236 -0.11926928]
 [-0.09419789  0.01626109  0.04464611]
 [-0.16070491 -0.0270307  -0.08921953]
 [ 0.08132233 -0.01156375 -0.04244826]
 [ 0.14837123  0.13575125  0.01250207]
 [-0.11159401 -0.07295428  0.07502512]
 [-0.13883443 -0.05447944 -0.13185394]
 [-0.05720596  0.0157204   0.13125709]
 [ 0.11172627 -0.14047861 -0.12687072]
 [-0.10106934 -0.006404   -0.0530115 ]
 [ 0.05154081  0.05521443  0.12102704]
 [ 0.08616705  0.0910778   0.12579766]
 [-0.03115183 -0.14502032 -0.06602254]
 [-0.03697089  0.0912912   0.14772782]
 [-0.18125364  0.14536761 -0.0454847 ]
 [-0.06867113 -0.02777249  0.13790381]
 [ 0.15257047  0.00460598  0.0531082 ]
 [ 0.13266791 -0.03966051  0.01591107]
 [ 0.10226183  0.04771534 -0.0189554 ]
 [-0.02529604 -0.16181706 -0.09317909]
 [ 0.13128737  0.13563223  0.0140022 ]
 [ 0.09093701 -0.02475023  0.11014239]
 [-0.03105306 -0.0725811   0.11805034]
 [-0.03766889 -0.08740123 -0.0679624 ]
 [ 0.03638545  0.01289942 -0.00563817]
 [-0.04863954  0.03528998 -0.07316181]
 [ 0.13916853 -0.12643766 -0.11400583]
 [-0.1152532   0.03642063 -0.04018546]
 [ 0.18306953 -0.10333925  0.16655698]
 [-0.04633215 -0.00238551  0.15062043]
 [-0.01602231 -0.09589658  0.07404342]
 [-0.08678392 -0.13224004 -0.03800705]
 [ 0.13323298  0.14146982  0.09319538]
 [ 0.09638751 -0.00813259  0.02186893]
 [ 0.17000668  0.1442613   0.10630243]
 [ 0.13950457 -0.10376546  0.14682592]
 [ 0.10338509  0.05530516  0.09941977]
 [-0.03635692 -0.11591829 -0.07109728]
 [-0.0425333   0.01871852  0.12048358]
 [ 0.01206277 -0.09052514  0.11692906]
 [-0.13376297  0.02813172 -0.16452546]
 [-0.13592769 -0.01403818  0.04138706]
 [-0.0336377  -0.05925515 -0.13882443]
 [ 0.06967799  0.04155819  0.01279375]
 [-0.11079074 -0.1758928   0.0896327 ]
 [-0.0791736   0.09838586 -0.11864602]
 [-0.07193118 -0.00203775  0.11494196]
 [ 0.04969888  0.01637554  0.11137626]
 [ 0.02571369  0.06103941 -0.03767563]
 [ 0.11329321 -0.13261023 -0.05193288]
 [-0.01560347  0.05643192  0.0944132 ]
 [ 0.13656111  0.04200417  0.00951174]
 [-0.12071531  0.0281344   0.14386384]
 [-0.14010444 -0.11969482  0.00340926]
 [ 0.12413421  0.1091138   0.08560333]
 [-0.06359054 -0.02910826 -0.04376715]
 [ 0.1521269   0.11877616  0.11050714]
 [ 0.12101489 -0.07468233 -0.00457632]
 [-0.05792642 -0.0779063  -0.05437353]
 [-0.0950635   0.0005082   0.07156152]
 [ 0.02676632  0.07580838  0.09775567]
 [-0.10340951  0.0632816   0.09177928]
 [ 0.15231013 -0.0584417   0.13645557]
 [-0.09645934 -0.13819176  0.0473971 ]
 [ 0.10492497 -0.06022281 -0.02969089]
 [-0.09659185 -0.07758258 -0.10667017]
 [ 0.02679023  0.05205204 -0.08618809]
 [-0.01255177 -0.01379216 -0.00108369]
 [ 0.11466041  0.13719334  0.06583958]
 [ 0.05990651  0.12254282  0.00663862]
 [ 0.04562283  0.1101541   0.13660043]
 [-0.11484712  0.06970336 -0.01544304]
 [ 0.07046562 -0.09737001 -0.00577832]
 [ 0.14297421  0.04658905 -0.05984653]
 [ 0.08639583 -0.13803409  0.07842041]
 [-0.10762484  0.13536648  0.10597005]
 [ 0.13028726  0.06517269  0.05531073]
 [-0.0814978  -0.05885752  0.0316942 ]
 [ 0.10422263 -0.07239338 -0.10584959]
 [ 0.04366389 -0.14439352  0.05407884]
 [-0.13357344  0.06111276  0.04247262]
 [ 0.10062232 -0.15934873 -0.10562494]
 [ 0.13890557 -0.08788285 -0.05365751]
 [-0.11095511 -0.09560107 -0.17068142]
 [ 0.11619055 -0.11490812  0.1028937 ]
 [ 0.0566921   0.03760664  0.00464723]
 [ 0.04688716  0.02941627 -0.02698055]
 [ 0.11977853  0.14982863  0.0940326 ]
 [-0.07642216 -0.03560985  0.10074551]
 [-0.05711108 -0.06747261  0.00371045]
 [ 0.09356245 -0.07984741 -0.12705313]
 [ 0.07911089  0.05195362  0.16323793]
 [ 0.02682946  0.04170501 -0.01999022]
 [ 0.09169868 -0.15142146 -0.13152185]]
# Total number of params: 3534803
WARNING:tensorflow:From /opt/BAA/TFT/libs/utils.py:199: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

Done.
Computing best validation loss
  32/2711 [..............................] - ETA: 17:03 - loss: 0.1387  96/2711 [>.............................] - ETA: 5:34 - loss: 0.1645  128/2711 [>.............................] - ETA: 4:08 - loss: 0.1825 160/2711 [>.............................] - ETA: 3:17 - loss: 0.1659 192/2711 [=>............................] - ETA: 2:43 - loss: 0.1764 224/2711 [=>............................] - ETA: 2:19 - loss: 0.1669 288/2711 [==>...........................] - ETA: 1:46 - loss: 0.1550 320/2711 [==>...........................] - ETA: 1:34 - loss: 0.1514 352/2711 [==>...........................] - ETA: 1:25 - loss: 0.1490 416/2711 [===>..........................] - ETA: 1:10 - loss: 0.1416 448/2711 [===>..........................] - ETA: 1:05 - loss: 0.1418 480/2711 [====>.........................] - ETA: 1:00 - loss: 0.1372 544/2711 [=====>........................] - ETA: 52s - loss: 0.1350  608/2711 [=====>........................] - ETA: 45s - loss: 0.1386 672/2711 [======>.......................] - ETA: 40s - loss: 0.1364 736/2711 [=======>......................] - ETA: 35s - loss: 0.1354 768/2711 [=======>......................] - ETA: 33s - loss: 0.1361 832/2711 [========>.....................] - ETA: 30s - loss: 0.1398 896/2711 [========>.....................] - ETA: 27s - loss: 0.1403 928/2711 [=========>....................] - ETA: 26s - loss: 0.1392 960/2711 [=========>....................] - ETA: 24s - loss: 0.13811024/2711 [==========>...................] - ETA: 22s - loss: 0.13961088/2711 [===========>..................] - ETA: 20s - loss: 0.14291120/2711 [===========>..................] - ETA: 19s - loss: 0.14451152/2711 [===========>..................] - ETA: 18s - loss: 0.14451216/2711 [============>.................] - ETA: 17s - loss: 0.14371280/2711 [=============>................] - ETA: 15s - loss: 0.14211344/2711 [=============>................] - ETA: 14s - loss: 0.14221408/2711 [==============>...............] - ETA: 13s - loss: 0.14281472/2711 [===============>..............] - ETA: 12s - loss: 0.14301536/2711 [===============>..............] - ETA: 11s - loss: 0.14191600/2711 [================>.............] - ETA: 10s - loss: 0.14171664/2711 [=================>............] - ETA: 9s - loss: 0.1416 1696/2711 [=================>............] - ETA: 8s - loss: 0.14181728/2711 [==================>...........] - ETA: 8s - loss: 0.14211760/2711 [==================>...........] - ETA: 8s - loss: 0.14221792/2711 [==================>...........] - ETA: 7s - loss: 0.14191824/2711 [===================>..........] - ETA: 7s - loss: 0.14211888/2711 [===================>..........] - ETA: 6s - loss: 0.14181952/2711 [====================>.........] - ETA: 5s - loss: 0.14172016/2711 [=====================>........] - ETA: 5s - loss: 0.14042080/2711 [======================>.......] - ETA: 4s - loss: 0.14552144/2711 [======================>.......] - ETA: 4s - loss: 0.14482176/2711 [=======================>......] - ETA: 3s - loss: 0.14412240/2711 [=======================>......] - ETA: 3s - loss: 0.14382272/2711 [========================>.....] - ETA: 3s - loss: 0.14482336/2711 [========================>.....] - ETA: 2s - loss: 0.14442368/2711 [=========================>....] - ETA: 2s - loss: 0.14552400/2711 [=========================>....] - ETA: 2s - loss: 0.15422432/2711 [=========================>....] - ETA: 1s - loss: 0.16382464/2711 [==========================>...] - ETA: 1s - loss: 0.16372496/2711 [==========================>...] - ETA: 1s - loss: 0.16282528/2711 [==========================>...] - ETA: 1s - loss: 0.16202560/2711 [===========================>..] - ETA: 0s - loss: 0.16262624/2711 [============================>.] - ETA: 0s - loss: 0.16362688/2711 [============================>.] - ETA: 0s - loss: 0.16212711/2711 [==============================] - 16s 6ms/sample - loss: 0.1619
Computing test loss
Training completed @ 2024-12-23 20:55:26.380512
Best validation loss = 0.16185792674881117
Params:
dropout_rate  =  0.3
hidden_layer_size  =  160
learning_rate  =  0.001
max_gradient_norm  =  0.01
minibatch_size  =  64
model_folder  =  /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_precipitation_duration_day_60min/saved_models/visitors/fixed
num_heads  =  1
stack_size  =  1
total_time_steps  =  32
num_encoder_steps  =  24
num_epochs  =  100
early_stopping_patience  =  3
multiprocessing_workers  =  5
column_definition  =  [('dummy_id', <DataTypes.REAL_VALUED: 0>, <InputTypes.ID: 4>), ('date', <DataTypes.DATE: 2>, <InputTypes.TIME: 5>), ('minute_of_hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('hour_of_day', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('week_of_year', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('month_of_year', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_month', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('Precipitation Duration', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('visitors', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('region', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>)]
input_size  =  9
output_size  =  1
category_counts  =  [1]
input_obs_loc  =  [7]
static_input_loc  =  [8]
known_regular_inputs  =  [0, 1, 2, 3, 4, 5, 6]
known_categorical_inputs  =  [0]

Normalised Quantile Loss for Test Data: P50=0.15583028971675983, P90=0.0801950501968175
