nohup: ignoring input
Using GPU ID: 6
Using output folder /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min
WARNING:tensorflow:From script_train_fixed_params_isolated.py:115: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.

2024-12-23 20:27:53.000964: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-23 20:27:54.031270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla M10 major: 5 minor: 0 memoryClockRate(GHz): 1.0325
pciBusID: 0000:b3:00.0
2024-12-23 20:27:54.032347: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-12-23 20:27:54.035889: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-12-23 20:27:54.092998: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-12-23 20:27:54.108579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-12-23 20:27:54.145437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-12-23 20:27:54.149272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-12-23 20:27:54.202365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-12-23 20:27:54.345542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-12-23 20:27:54.346531: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-23 20:27:54.459232: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz
2024-12-23 20:27:54.467718: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3830690 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-23 20:27:54.467872: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-23 20:27:54.962248: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x35ae590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-23 20:27:54.962356: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla M10, Compute Capability 5.0
2024-12-23 20:27:54.963283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla M10 major: 5 minor: 0 memoryClockRate(GHz): 1.0325
pciBusID: 0000:b3:00.0
2024-12-23 20:27:54.963420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-12-23 20:27:54.963460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-12-23 20:27:54.963488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-12-23 20:27:54.963519: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-12-23 20:27:54.963549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-12-23 20:27:54.963577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-12-23 20:27:54.963606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-12-23 20:27:54.964872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-12-23 20:27:54.965010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-12-23 20:27:54.965819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-23 20:27:54.965856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-23 20:27:54.965870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-12-23 20:27:54.967391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7692 MB memory) -> physical GPU (device: 0, name: Tesla M10, pci bus id: 0000:b3:00.0, compute capability: 5.0)
*** Training from defined parameters for visitors ***
Loading & splitting data...
Formatting train-valid-test splits.
Setting scalers with training data...
*** Loading hyperparameter manager ***
*** Running calibration ***
Params Selected:
dropout_rate: 0.3
hidden_layer_size: 160
learning_rate: 0.001
minibatch_size: 64
max_gradient_norm: 0.01
num_heads: 1
stack_size: 1
model_folder: /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min/saved_models/visitors/fixed
2024-12-23 20:27:55.439056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla M10 major: 5 minor: 0 memoryClockRate(GHz): 1.0325
pciBusID: 0000:b3:00.0
2024-12-23 20:27:55.439464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-12-23 20:27:55.439663: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-12-23 20:27:55.439832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-12-23 20:27:55.439992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-12-23 20:27:55.440138: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-12-23 20:27:55.440309: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-12-23 20:27:55.440466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-12-23 20:27:55.442242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-12-23 20:27:55.442605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-23 20:27:55.442793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-23 20:27:55.442953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-12-23 20:27:55.450043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7692 MB memory) -> physical GPU (device: 0, name: Tesla M10, pci bus id: 0000:b3:00.0, compute capability: 5.0)
WARNING:tensorflow:From script_train_fixed_params_isolated.py:157: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

Resetting temp folder...
*** TemporalFusionTransformer params ***
# dropout_rate = 0.3
# hidden_layer_size = 160
# learning_rate = 0.001
# max_gradient_norm = 0.01
# minibatch_size = 64
# model_folder = /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min/saved_models/visitors/fixed
# num_heads = 1
# stack_size = 1
# total_time_steps = 32
# num_encoder_steps = 24
# num_epochs = 100
# early_stopping_patience = 3
# multiprocessing_workers = 5
# column_definition = [('dummy_id', <DataTypes.REAL_VALUED: 0>, <InputTypes.ID: 4>), ('date', <DataTypes.DATE: 2>, <InputTypes.TIME: 5>), ('minute_of_hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('hour_of_day', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('week_of_year', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('month_of_year', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_month', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('Wind Speed', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('visitors', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('region', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>)]
# input_size = 9
# output_size = 1
# category_counts = [1]
# input_obs_loc = [7]
# static_input_loc = [8]
# known_regular_inputs = [0, 1, 2, 3, 4, 5, 6]
# known_categorical_inputs = [0]
WARNING:tensorflow:From /opt/BAA/TFT/libs/tft_model.py:1044: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /root/.pyenv/versions/3.7.12/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /root/.pyenv/versions/3.7.12/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /opt/BAA/TFT/libs/tft_model.py:947: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.

Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 9)]      0                                            
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           input_1[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32)]         0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
sequential (Sequential)         (None, 32, 160)      160         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 160)]        0           sequential[1][0]                 
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
flatten (Flatten)               (None, 160)          0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 160)          25760       flatten[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
activation (Activation)         (None, 160)          0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 1, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 160)          25760       activation[0][0]                 
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 1, 160)       0           dense_13[0][0]                   
__________________________________________________________________________________________________
dropout (Dropout)               (None, 160)          0           dense_10[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 1, 160)       25760       activation_2[0][0]               
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 1)            161         dropout[0][0]                    
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 1)            161         dropout[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 1, 160)       0           dense_14[0][0]                   
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 1)            161         flatten[0][0]                    
__________________________________________________________________________________________________
multiply (Multiply)             (None, 1)            0           dense_11[0][0]                   
                                                                 dense_12[0][0]                   
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 1, 160)       25760       dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 1, 160)       25760       dropout_1[0][0]                  
__________________________________________________________________________________________________
add (Add)                       (None, 1)            0           dense_8[0][0]                    
                                                                 multiply[0][0]                   
__________________________________________________________________________________________________
multiply_1 (Multiply)           (None, 1, 160)       0           dense_15[0][0]                   
                                                                 dense_16[0][0]                   
__________________________________________________________________________________________________
layer_normalization (LayerNorma (None, 1)            2           add[0][0]                        
__________________________________________________________________________________________________
add_1 (Add)                     (None, 1, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_1[0][0]                 
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 1)            0           layer_normalization[0][0]        
__________________________________________________________________________________________________
layer_normalization_1 (LayerNor (None, 1, 160)       320         add_1[0][0]                      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 1)]       0           activation_1[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_1[0][0]      
__________________________________________________________________________________________________
multiply_2 (Multiply)           (None, 1, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 160)]        0           multiply_2[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 160)          0           dense_17[0][0]                   
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 8)]      0           input_1[0][0]                    
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 160)          25760       activation_3[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 160)          0           dense_18[0][0]                   
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed (TimeDistribut (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 160)          25760       dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 160)          25760       dropout_2[0][0]                  
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160, 7)] 0           time_distributed_1[0][0]         
                                                                 time_distributed_2[0][0]         
                                                                 time_distributed_3[0][0]         
                                                                 time_distributed_4[0][0]         
                                                                 time_distributed_5[0][0]         
                                                                 time_distributed_6[0][0]         
                                                                 time_distributed_7[0][0]         
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160, 1)] 0           time_distributed[0][0]           
__________________________________________________________________________________________________
multiply_3 (Multiply)           (None, 160)          0           dense_19[0][0]                   
                                                                 dense_20[0][0]                   
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 7)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 1)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_2 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_3[0][0]                 
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 8)] 0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
layer_normalization_2 (LayerNor (None, 160)          320         add_2[0][0]                      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 1280)]   0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_2[0][0]      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160, 7)]  0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, 24, 160)      204960      tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, 1, 160)       25600       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 1120)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_2[0][0]      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           time_distributed_9[0][0]         
                                                                 time_distributed_10[0][0]        
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_47 (TimeDistri (None, 8, 160)       179360      tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_48 (TimeDistri (None, 1, 160)       25600       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_14 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_18 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_22 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_26 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_30 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_34 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_38 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_42 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           time_distributed_47[0][0]        
                                                                 time_distributed_48[0][0]        
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, 24, 160)      25760       activation_7[0][0]               
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 24, 160)      0           time_distributed_14[0][0]        
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 24, 160)      0           time_distributed_18[0][0]        
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 24, 160)      0           time_distributed_22[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 160)      0           time_distributed_26[0][0]        
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 24, 160)      0           time_distributed_30[0][0]        
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 24, 160)      0           time_distributed_34[0][0]        
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 24, 160)      0           time_distributed_38[0][0]        
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 24, 160)      0           time_distributed_42[0][0]        
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_52 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_56 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_60 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_64 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_68 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_72 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_76 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 160)      0           time_distributed_11[0][0]        
__________________________________________________________________________________________________
time_distributed_15 (TimeDistri (None, 24, 160)      25760       activation_9[0][0]               
__________________________________________________________________________________________________
time_distributed_19 (TimeDistri (None, 24, 160)      25760       activation_10[0][0]              
__________________________________________________________________________________________________
time_distributed_23 (TimeDistri (None, 24, 160)      25760       activation_11[0][0]              
__________________________________________________________________________________________________
time_distributed_27 (TimeDistri (None, 24, 160)      25760       activation_12[0][0]              
__________________________________________________________________________________________________
time_distributed_31 (TimeDistri (None, 24, 160)      25760       activation_13[0][0]              
__________________________________________________________________________________________________
time_distributed_35 (TimeDistri (None, 24, 160)      25760       activation_14[0][0]              
__________________________________________________________________________________________________
time_distributed_39 (TimeDistri (None, 24, 160)      25760       activation_15[0][0]              
__________________________________________________________________________________________________
time_distributed_43 (TimeDistri (None, 24, 160)      25760       activation_16[0][0]              
__________________________________________________________________________________________________
time_distributed_49 (TimeDistri (None, 8, 160)       25760       activation_17[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 160)       0           time_distributed_52[0][0]        
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 160)       0           time_distributed_56[0][0]        
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 160)       0           time_distributed_60[0][0]        
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 160)       0           time_distributed_64[0][0]        
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 160)       0           time_distributed_68[0][0]        
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 160)       0           time_distributed_72[0][0]        
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 160)       0           time_distributed_76[0][0]        
__________________________________________________________________________________________________
time_distributed_12 (TimeDistri (None, 24, 8)        1288        dropout_6[0][0]                  
__________________________________________________________________________________________________
time_distributed_13 (TimeDistri (None, 24, 8)        1288        dropout_6[0][0]                  
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 160)      0           time_distributed_15[0][0]        
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 160)      0           time_distributed_19[0][0]        
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 160)      0           time_distributed_23[0][0]        
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 160)      0           time_distributed_27[0][0]        
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 160)      0           time_distributed_31[0][0]        
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 160)      0           time_distributed_35[0][0]        
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 24, 160)      0           time_distributed_39[0][0]        
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 24, 160)      0           time_distributed_43[0][0]        
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 8, 160)       0           time_distributed_49[0][0]        
__________________________________________________________________________________________________
time_distributed_53 (TimeDistri (None, 8, 160)       25760       activation_19[0][0]              
__________________________________________________________________________________________________
time_distributed_57 (TimeDistri (None, 8, 160)       25760       activation_20[0][0]              
__________________________________________________________________________________________________
time_distributed_61 (TimeDistri (None, 8, 160)       25760       activation_21[0][0]              
__________________________________________________________________________________________________
time_distributed_65 (TimeDistri (None, 8, 160)       25760       activation_22[0][0]              
__________________________________________________________________________________________________
time_distributed_69 (TimeDistri (None, 8, 160)       25760       activation_23[0][0]              
__________________________________________________________________________________________________
time_distributed_73 (TimeDistri (None, 8, 160)       25760       activation_24[0][0]              
__________________________________________________________________________________________________
time_distributed_77 (TimeDistri (None, 8, 160)       25760       activation_25[0][0]              
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, 24, 8)        10248       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
multiply_7 (Multiply)           (None, 24, 8)        0           time_distributed_12[0][0]        
                                                                 time_distributed_13[0][0]        
__________________________________________________________________________________________________
time_distributed_16 (TimeDistri (None, 24, 160)      25760       dropout_7[0][0]                  
__________________________________________________________________________________________________
time_distributed_17 (TimeDistri (None, 24, 160)      25760       dropout_7[0][0]                  
__________________________________________________________________________________________________
time_distributed_20 (TimeDistri (None, 24, 160)      25760       dropout_8[0][0]                  
__________________________________________________________________________________________________
time_distributed_21 (TimeDistri (None, 24, 160)      25760       dropout_8[0][0]                  
__________________________________________________________________________________________________
time_distributed_24 (TimeDistri (None, 24, 160)      25760       dropout_9[0][0]                  
__________________________________________________________________________________________________
time_distributed_25 (TimeDistri (None, 24, 160)      25760       dropout_9[0][0]                  
__________________________________________________________________________________________________
time_distributed_28 (TimeDistri (None, 24, 160)      25760       dropout_10[0][0]                 
__________________________________________________________________________________________________
time_distributed_29 (TimeDistri (None, 24, 160)      25760       dropout_10[0][0]                 
__________________________________________________________________________________________________
time_distributed_32 (TimeDistri (None, 24, 160)      25760       dropout_11[0][0]                 
__________________________________________________________________________________________________
time_distributed_33 (TimeDistri (None, 24, 160)      25760       dropout_11[0][0]                 
__________________________________________________________________________________________________
time_distributed_36 (TimeDistri (None, 24, 160)      25760       dropout_12[0][0]                 
__________________________________________________________________________________________________
time_distributed_37 (TimeDistri (None, 24, 160)      25760       dropout_12[0][0]                 
__________________________________________________________________________________________________
time_distributed_40 (TimeDistri (None, 24, 160)      25760       dropout_13[0][0]                 
__________________________________________________________________________________________________
time_distributed_41 (TimeDistri (None, 24, 160)      25760       dropout_13[0][0]                 
__________________________________________________________________________________________________
time_distributed_44 (TimeDistri (None, 24, 160)      25760       dropout_14[0][0]                 
__________________________________________________________________________________________________
time_distributed_45 (TimeDistri (None, 24, 160)      25760       dropout_14[0][0]                 
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 160)          0           dense_25[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 160)          0           dense_29[0][0]                   
__________________________________________________________________________________________________
time_distributed_50 (TimeDistri (None, 8, 7)         1127        dropout_15[0][0]                 
__________________________________________________________________________________________________
time_distributed_51 (TimeDistri (None, 8, 7)         1127        dropout_15[0][0]                 
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 8, 160)       0           time_distributed_53[0][0]        
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 8, 160)       0           time_distributed_57[0][0]        
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 8, 160)       0           time_distributed_61[0][0]        
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 8, 160)       0           time_distributed_65[0][0]        
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, 8, 160)       0           time_distributed_69[0][0]        
__________________________________________________________________________________________________
dropout_21 (Dropout)            (None, 8, 160)       0           time_distributed_73[0][0]        
__________________________________________________________________________________________________
dropout_22 (Dropout)            (None, 8, 160)       0           time_distributed_77[0][0]        
__________________________________________________________________________________________________
add_6 (Add)                     (None, 24, 8)        0           time_distributed_8[0][0]         
                                                                 multiply_7[0][0]                 
__________________________________________________________________________________________________
multiply_8 (Multiply)           (None, 24, 160)      0           time_distributed_16[0][0]        
                                                                 time_distributed_17[0][0]        
__________________________________________________________________________________________________
multiply_9 (Multiply)           (None, 24, 160)      0           time_distributed_20[0][0]        
                                                                 time_distributed_21[0][0]        
__________________________________________________________________________________________________
multiply_10 (Multiply)          (None, 24, 160)      0           time_distributed_24[0][0]        
                                                                 time_distributed_25[0][0]        
__________________________________________________________________________________________________
multiply_11 (Multiply)          (None, 24, 160)      0           time_distributed_28[0][0]        
                                                                 time_distributed_29[0][0]        
__________________________________________________________________________________________________
multiply_12 (Multiply)          (None, 24, 160)      0           time_distributed_32[0][0]        
                                                                 time_distributed_33[0][0]        
__________________________________________________________________________________________________
multiply_13 (Multiply)          (None, 24, 160)      0           time_distributed_36[0][0]        
                                                                 time_distributed_37[0][0]        
__________________________________________________________________________________________________
multiply_14 (Multiply)          (None, 24, 160)      0           time_distributed_40[0][0]        
                                                                 time_distributed_41[0][0]        
__________________________________________________________________________________________________
multiply_15 (Multiply)          (None, 24, 160)      0           time_distributed_44[0][0]        
                                                                 time_distributed_45[0][0]        
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 160)          25760       activation_5[0][0]               
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 160)          25760       activation_6[0][0]               
__________________________________________________________________________________________________
time_distributed_46 (TimeDistri (None, 8, 7)         7847        tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
multiply_17 (Multiply)          (None, 8, 7)         0           time_distributed_50[0][0]        
                                                                 time_distributed_51[0][0]        
__________________________________________________________________________________________________
time_distributed_54 (TimeDistri (None, 8, 160)       25760       dropout_16[0][0]                 
__________________________________________________________________________________________________
time_distributed_55 (TimeDistri (None, 8, 160)       25760       dropout_16[0][0]                 
__________________________________________________________________________________________________
time_distributed_58 (TimeDistri (None, 8, 160)       25760       dropout_17[0][0]                 
__________________________________________________________________________________________________
time_distributed_59 (TimeDistri (None, 8, 160)       25760       dropout_17[0][0]                 
__________________________________________________________________________________________________
time_distributed_62 (TimeDistri (None, 8, 160)       25760       dropout_18[0][0]                 
__________________________________________________________________________________________________
time_distributed_63 (TimeDistri (None, 8, 160)       25760       dropout_18[0][0]                 
__________________________________________________________________________________________________
time_distributed_66 (TimeDistri (None, 8, 160)       25760       dropout_19[0][0]                 
__________________________________________________________________________________________________
time_distributed_67 (TimeDistri (None, 8, 160)       25760       dropout_19[0][0]                 
__________________________________________________________________________________________________
time_distributed_70 (TimeDistri (None, 8, 160)       25760       dropout_20[0][0]                 
__________________________________________________________________________________________________
time_distributed_71 (TimeDistri (None, 8, 160)       25760       dropout_20[0][0]                 
__________________________________________________________________________________________________
time_distributed_74 (TimeDistri (None, 8, 160)       25760       dropout_21[0][0]                 
__________________________________________________________________________________________________
time_distributed_75 (TimeDistri (None, 8, 160)       25760       dropout_21[0][0]                 
__________________________________________________________________________________________________
time_distributed_78 (TimeDistri (None, 8, 160)       25760       dropout_22[0][0]                 
__________________________________________________________________________________________________
time_distributed_79 (TimeDistri (None, 8, 160)       25760       dropout_22[0][0]                 
__________________________________________________________________________________________________
layer_normalization_6 (LayerNor (None, 24, 8)        16          add_6[0][0]                      
__________________________________________________________________________________________________
add_7 (Add)                     (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_8[0][0]                 
__________________________________________________________________________________________________
add_8 (Add)                     (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_9[0][0]                 
__________________________________________________________________________________________________
add_9 (Add)                     (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_10[0][0]                
__________________________________________________________________________________________________
add_10 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_11[0][0]                
__________________________________________________________________________________________________
add_11 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_12[0][0]                
__________________________________________________________________________________________________
add_12 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_13[0][0]                
__________________________________________________________________________________________________
add_13 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_14[0][0]                
__________________________________________________________________________________________________
add_14 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_15[0][0]                
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 160)          0           dense_26[0][0]                   
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 160)          0           dense_30[0][0]                   
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 7)         0           time_distributed_46[0][0]        
                                                                 multiply_17[0][0]                
__________________________________________________________________________________________________
multiply_18 (Multiply)          (None, 8, 160)       0           time_distributed_54[0][0]        
                                                                 time_distributed_55[0][0]        
__________________________________________________________________________________________________
multiply_19 (Multiply)          (None, 8, 160)       0           time_distributed_58[0][0]        
                                                                 time_distributed_59[0][0]        
__________________________________________________________________________________________________
multiply_20 (Multiply)          (None, 8, 160)       0           time_distributed_62[0][0]        
                                                                 time_distributed_63[0][0]        
__________________________________________________________________________________________________
multiply_21 (Multiply)          (None, 8, 160)       0           time_distributed_66[0][0]        
                                                                 time_distributed_67[0][0]        
__________________________________________________________________________________________________
multiply_22 (Multiply)          (None, 8, 160)       0           time_distributed_70[0][0]        
                                                                 time_distributed_71[0][0]        
__________________________________________________________________________________________________
multiply_23 (Multiply)          (None, 8, 160)       0           time_distributed_74[0][0]        
                                                                 time_distributed_75[0][0]        
__________________________________________________________________________________________________
multiply_24 (Multiply)          (None, 8, 160)       0           time_distributed_78[0][0]        
                                                                 time_distributed_79[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 8)        0           layer_normalization_6[0][0]      
__________________________________________________________________________________________________
layer_normalization_7 (LayerNor (None, 24, 160)      320         add_7[0][0]                      
__________________________________________________________________________________________________
layer_normalization_8 (LayerNor (None, 24, 160)      320         add_8[0][0]                      
__________________________________________________________________________________________________
layer_normalization_9 (LayerNor (None, 24, 160)      320         add_9[0][0]                      
__________________________________________________________________________________________________
layer_normalization_10 (LayerNo (None, 24, 160)      320         add_10[0][0]                     
__________________________________________________________________________________________________
layer_normalization_11 (LayerNo (None, 24, 160)      320         add_11[0][0]                     
__________________________________________________________________________________________________
layer_normalization_12 (LayerNo (None, 24, 160)      320         add_12[0][0]                     
__________________________________________________________________________________________________
layer_normalization_13 (LayerNo (None, 24, 160)      320         add_13[0][0]                     
__________________________________________________________________________________________________
layer_normalization_14 (LayerNo (None, 24, 160)      320         add_14[0][0]                     
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 160)          25760       dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 160)          25760       dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 160)          25760       dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 160)          25760       dropout_5[0][0]                  
__________________________________________________________________________________________________
layer_normalization_15 (LayerNo (None, 8, 7)         14          add_15[0][0]                     
__________________________________________________________________________________________________
add_16 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_18[0][0]                
__________________________________________________________________________________________________
add_17 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_19[0][0]                
__________________________________________________________________________________________________
add_18 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_20[0][0]                
__________________________________________________________________________________________________
add_19 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_21[0][0]                
__________________________________________________________________________________________________
add_20 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_22[0][0]                
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_23[0][0]                
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_24[0][0]                
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 1, 8)]   0           activation_8[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 8)] 0           layer_normalization_7[0][0]      
                                                                 layer_normalization_8[0][0]      
                                                                 layer_normalization_9[0][0]      
                                                                 layer_normalization_10[0][0]     
                                                                 layer_normalization_11[0][0]     
                                                                 layer_normalization_12[0][0]     
                                                                 layer_normalization_13[0][0]     
                                                                 layer_normalization_14[0][0]     
__________________________________________________________________________________________________
multiply_5 (Multiply)           (None, 160)          0           dense_27[0][0]                   
                                                                 dense_28[0][0]                   
__________________________________________________________________________________________________
multiply_6 (Multiply)           (None, 160)          0           dense_31[0][0]                   
                                                                 dense_32[0][0]                   
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 7)         0           layer_normalization_15[0][0]     
__________________________________________________________________________________________________
layer_normalization_16 (LayerNo (None, 8, 160)       320         add_16[0][0]                     
__________________________________________________________________________________________________
layer_normalization_17 (LayerNo (None, 8, 160)       320         add_17[0][0]                     
__________________________________________________________________________________________________
layer_normalization_18 (LayerNo (None, 8, 160)       320         add_18[0][0]                     
__________________________________________________________________________________________________
layer_normalization_19 (LayerNo (None, 8, 160)       320         add_19[0][0]                     
__________________________________________________________________________________________________
layer_normalization_20 (LayerNo (None, 8, 160)       320         add_20[0][0]                     
__________________________________________________________________________________________________
layer_normalization_21 (LayerNo (None, 8, 160)       320         add_21[0][0]                     
__________________________________________________________________________________________________
layer_normalization_22 (LayerNo (None, 8, 160)       320         add_22[0][0]                     
__________________________________________________________________________________________________
multiply_16 (Multiply)          (None, 24, 160, 8)   0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_4 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_5[0][0]                 
__________________________________________________________________________________________________
add_5 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_6[0][0]                 
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 1, 7)]    0           activation_18[0][0]              
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160, 7)]  0           layer_normalization_16[0][0]     
                                                                 layer_normalization_17[0][0]     
                                                                 layer_normalization_18[0][0]     
                                                                 layer_normalization_19[0][0]     
                                                                 layer_normalization_20[0][0]     
                                                                 layer_normalization_21[0][0]     
                                                                 layer_normalization_22[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           multiply_16[0][0]                
__________________________________________________________________________________________________
layer_normalization_4 (LayerNor (None, 160)          320         add_4[0][0]                      
__________________________________________________________________________________________________
layer_normalization_5 (LayerNor (None, 160)          320         add_5[0][0]                      
__________________________________________________________________________________________________
multiply_25 (Multiply)          (None, 8, 160, 7)    0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
cu_dnnlstm (CuDNNLSTM)          [(None, 24, 160), (N 206080      tf_op_layer_TemporalFusionTransfo
                                                                 layer_normalization_4[0][0]      
                                                                 layer_normalization_5[0][0]      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           multiply_25[0][0]                
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 160)          0           dense_21[0][0]                   
__________________________________________________________________________________________________
cu_dnnlstm_1 (CuDNNLSTM)        (None, 8, 160)       206080      tf_op_layer_TemporalFusionTransfo
                                                                 cu_dnnlstm[0][1]                 
                                                                 cu_dnnlstm[0][2]                 
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 160)          25760       activation_4[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160)]    0           cu_dnnlstm[0][0]                 
                                                                 cu_dnnlstm_1[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 160)          0           dense_22[0][0]                   
__________________________________________________________________________________________________
dropout_23 (Dropout)            (None, 32, 160)      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 160)          25760       dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 160)          25760       dropout_3[0][0]                  
__________________________________________________________________________________________________
time_distributed_80 (TimeDistri (None, 32, 160)      25760       dropout_23[0][0]                 
__________________________________________________________________________________________________
time_distributed_81 (TimeDistri (None, 32, 160)      25760       dropout_23[0][0]                 
__________________________________________________________________________________________________
multiply_4 (Multiply)           (None, 160)          0           dense_23[0][0]                   
                                                                 dense_24[0][0]                   
__________________________________________________________________________________________________
multiply_26 (Multiply)          (None, 32, 160)      0           time_distributed_80[0][0]        
                                                                 time_distributed_81[0][0]        
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160)]    0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_3 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_4[0][0]                 
__________________________________________________________________________________________________
add_23 (Add)                    (None, 32, 160)      0           multiply_26[0][0]                
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
layer_normalization_3 (LayerNor (None, 160)          320         add_3[0][0]                      
__________________________________________________________________________________________________
layer_normalization_23 (LayerNo (None, 32, 160)      320         add_23[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_3[0][0]      
__________________________________________________________________________________________________
time_distributed_82 (TimeDistri (None, 32, 160)      25760       layer_normalization_23[0][0]     
__________________________________________________________________________________________________
time_distributed_83 (TimeDistri (None, 1, 160)       25600       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160)]    0           time_distributed_82[0][0]        
                                                                 time_distributed_83[0][0]        
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 32, 160)      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_84 (TimeDistri (None, 32, 160)      25760       activation_26[0][0]              
__________________________________________________________________________________________________
dropout_24 (Dropout)            (None, 32, 160)      0           time_distributed_84[0][0]        
__________________________________________________________________________________________________
time_distributed_85 (TimeDistri (None, 32, 160)      25760       dropout_24[0][0]                 
__________________________________________________________________________________________________
time_distributed_86 (TimeDistri (None, 32, 160)      25760       dropout_24[0][0]                 
__________________________________________________________________________________________________
multiply_27 (Multiply)          (None, 32, 160)      0           time_distributed_85[0][0]        
                                                                 time_distributed_86[0][0]        
__________________________________________________________________________________________________
add_24 (Add)                    (None, 32, 160)      0           layer_normalization_23[0][0]     
                                                                 multiply_27[0][0]                
__________________________________________________________________________________________________
layer_normalization_24 (LayerNo (None, 32, 160)      320         add_24[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(3,)]               0           layer_normalization_24[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [()]                 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(3,)]               0           layer_normalization_24[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [()]                 0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(1,)]               0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(1,)]               0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(2,)]               0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, None)]       0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, None, None)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 32, 160)      25600       layer_normalization_24[0][0]     
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 32, 160)      25600       layer_normalization_24[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, None, None)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 32, 32)       0           dense_113[0][0]                  
                                                                 dense_114[0][0]                  
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, None, None)   0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_25 (Add)                    (None, 32, 32)       0           lambda[0][0]                     
                                                                 lambda_1[0][0]                   
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 32, 32)       0           add_25[0][0]                     
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 32, 32)       0           activation_27[0][0]              
__________________________________________________________________________________________________
dense_112 (Dense)               (None, 32, 160)      25600       layer_normalization_24[0][0]     
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 32, 160)      0           dropout_25[0][0]                 
                                                                 dense_112[0][0]                  
__________________________________________________________________________________________________
dropout_26 (Dropout)            (None, 32, 160)      0           lambda_2[0][0]                   
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 32, 160)      25600       dropout_26[0][0]                 
__________________________________________________________________________________________________
dropout_27 (Dropout)            (None, 32, 160)      0           dense_115[0][0]                  
__________________________________________________________________________________________________
dropout_28 (Dropout)            (None, 32, 160)      0           dropout_27[0][0]                 
__________________________________________________________________________________________________
time_distributed_87 (TimeDistri (None, 32, 160)      25760       dropout_28[0][0]                 
__________________________________________________________________________________________________
time_distributed_88 (TimeDistri (None, 32, 160)      25760       dropout_28[0][0]                 
__________________________________________________________________________________________________
multiply_28 (Multiply)          (None, 32, 160)      0           time_distributed_87[0][0]        
                                                                 time_distributed_88[0][0]        
__________________________________________________________________________________________________
add_26 (Add)                    (None, 32, 160)      0           multiply_28[0][0]                
                                                                 layer_normalization_24[0][0]     
__________________________________________________________________________________________________
layer_normalization_25 (LayerNo (None, 32, 160)      320         add_26[0][0]                     
__________________________________________________________________________________________________
time_distributed_89 (TimeDistri (None, 32, 160)      25760       layer_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 32, 160)      0           time_distributed_89[0][0]        
__________________________________________________________________________________________________
time_distributed_90 (TimeDistri (None, 32, 160)      25760       activation_28[0][0]              
__________________________________________________________________________________________________
dropout_29 (Dropout)            (None, 32, 160)      0           time_distributed_90[0][0]        
__________________________________________________________________________________________________
time_distributed_91 (TimeDistri (None, 32, 160)      25760       dropout_29[0][0]                 
__________________________________________________________________________________________________
time_distributed_92 (TimeDistri (None, 32, 160)      25760       dropout_29[0][0]                 
__________________________________________________________________________________________________
multiply_29 (Multiply)          (None, 32, 160)      0           time_distributed_91[0][0]        
                                                                 time_distributed_92[0][0]        
__________________________________________________________________________________________________
add_27 (Add)                    (None, 32, 160)      0           layer_normalization_25[0][0]     
                                                                 multiply_29[0][0]                
__________________________________________________________________________________________________
layer_normalization_26 (LayerNo (None, 32, 160)      320         add_27[0][0]                     
__________________________________________________________________________________________________
time_distributed_93 (TimeDistri (None, 32, 160)      25760       layer_normalization_26[0][0]     
__________________________________________________________________________________________________
time_distributed_94 (TimeDistri (None, 32, 160)      25760       layer_normalization_26[0][0]     
__________________________________________________________________________________________________
multiply_30 (Multiply)          (None, 32, 160)      0           time_distributed_93[0][0]        
                                                                 time_distributed_94[0][0]        
__________________________________________________________________________________________________
add_28 (Add)                    (None, 32, 160)      0           multiply_30[0][0]                
                                                                 layer_normalization_23[0][0]     
__________________________________________________________________________________________________
layer_normalization_27 (LayerNo (None, 32, 160)      320         add_28[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           layer_normalization_27[0][0]     
__________________________________________________________________________________________________
time_distributed_95 (TimeDistri (None, 8, 3)         483         tf_op_layer_TemporalFusionTransfo
==================================================================================================
Total params: 3,534,803
Trainable params: 3,534,803
Non-trainable params: 0
__________________________________________________________________________________________________
None
Cached data "train" updated
Cached data "valid" updated
*** Fitting TemporalFusionTransformer ***
Getting batched_data
Using cached training data
Using cached validation data
Using keras standard fit
WARNING:tensorflow:From /root/.pyenv/versions/3.7.12/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Train on 9568 samples, validate on 2711 samples
Epoch 1/100
2024-12-23 20:35:38.000627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-12-23 20:35:41.875687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-12-23 20:35:48.601651: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2024-12-23 20:35:48.604477: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.0'; dlerror: libcupti.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64:
2024-12-23 20:35:48.604803: W tensorflow/core/profiler/lib/profiler_session.cc:213] Encountered error while starting profiler: Unavailable: CUPTI error: CUPTI could not be loaded or symbol could not be found.
  64/9568 [..............................] - ETA: 5:34:53 - loss: 2.41512024-12-23 20:35:49.188330: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 0 kernel records, 0 memcpy records.
2024-12-23 20:35:49.189150: E tensorflow/core/platform/default/device_tracer.cc:70] CUPTI error: CUPTI could not be loaded or symbol could not be found.
 128/9568 [..............................] - ETA: 2:47:02 - loss: 1.7384 192/9568 [..............................] - ETA: 1:50:54 - loss: 1.5600 256/9568 [..............................] - ETA: 1:22:52 - loss: 1.4546 320/9568 [>.............................] - ETA: 1:06:09 - loss: 1.3403 384/9568 [>.............................] - ETA: 54:56 - loss: 1.2600   448/9568 [>.............................] - ETA: 46:57 - loss: 1.1902 512/9568 [>.............................] - ETA: 40:55 - loss: 1.1370 576/9568 [>.............................] - ETA: 36:14 - loss: 1.0796 640/9568 [=>............................] - ETA: 32:30 - loss: 1.0340 704/9568 [=>............................] - ETA: 29:27 - loss: 0.9982 768/9568 [=>............................] - ETA: 26:53 - loss: 0.9650 832/9568 [=>............................] - ETA: 24:44 - loss: 0.9314 896/9568 [=>............................] - ETA: 22:52 - loss: 0.9060 960/9568 [==>...........................] - ETA: 21:14 - loss: 0.88211024/9568 [==>...........................] - ETA: 19:48 - loss: 0.85931088/9568 [==>...........................] - ETA: 18:32 - loss: 0.83691152/9568 [==>...........................] - ETA: 17:25 - loss: 0.81601216/9568 [==>...........................] - ETA: 16:28 - loss: 0.79951280/9568 [===>..........................] - ETA: 15:36 - loss: 0.78571344/9568 [===>..........................] - ETA: 14:49 - loss: 0.77001408/9568 [===>..........................] - ETA: 14:05 - loss: 0.75441472/9568 [===>..........................] - ETA: 13:25 - loss: 0.74021536/9568 [===>..........................] - ETA: 12:47 - loss: 0.72941600/9568 [====>.........................] - ETA: 12:14 - loss: 0.71501664/9568 [====>.........................] - ETA: 11:43 - loss: 0.70301728/9568 [====>.........................] - ETA: 11:13 - loss: 0.69331792/9568 [====>.........................] - ETA: 10:47 - loss: 0.68351856/9568 [====>.........................] - ETA: 10:21 - loss: 0.67301920/9568 [=====>........................] - ETA: 9:57 - loss: 0.6644 1984/9568 [=====>........................] - ETA: 9:34 - loss: 0.65472048/9568 [=====>........................] - ETA: 9:13 - loss: 0.64632112/9568 [=====>........................] - ETA: 8:55 - loss: 0.63772176/9568 [=====>........................] - ETA: 8:36 - loss: 0.62972240/9568 [======>.......................] - ETA: 8:18 - loss: 0.62252304/9568 [======>.......................] - ETA: 8:03 - loss: 0.61552368/9568 [======>.......................] - ETA: 7:47 - loss: 0.60782432/9568 [======>.......................] - ETA: 7:32 - loss: 0.60082496/9568 [======>.......................] - ETA: 7:18 - loss: 0.59342560/9568 [=======>......................] - ETA: 7:06 - loss: 0.58702624/9568 [=======>......................] - ETA: 6:53 - loss: 0.58192688/9568 [=======>......................] - ETA: 6:41 - loss: 0.57732752/9568 [=======>......................] - ETA: 6:29 - loss: 0.57212816/9568 [=======>......................] - ETA: 6:18 - loss: 0.56632880/9568 [========>.....................] - ETA: 6:06 - loss: 0.56042944/9568 [========>.....................] - ETA: 5:56 - loss: 0.55513008/9568 [========>.....................] - ETA: 5:46 - loss: 0.55123072/9568 [========>.....................] - ETA: 5:37 - loss: 0.54643136/9568 [========>.....................] - ETA: 5:28 - loss: 0.54303200/9568 [=========>....................] - ETA: 5:19 - loss: 0.53823264/9568 [=========>....................] - ETA: 5:11 - loss: 0.53313328/9568 [=========>....................] - ETA: 5:03 - loss: 0.52883392/9568 [=========>....................] - ETA: 4:55 - loss: 0.52423456/9568 [=========>....................] - ETA: 4:47 - loss: 0.52123520/9568 [==========>...................] - ETA: 4:39 - loss: 0.51773584/9568 [==========>...................] - ETA: 4:32 - loss: 0.51373648/9568 [==========>...................] - ETA: 4:25 - loss: 0.51023712/9568 [==========>...................] - ETA: 4:18 - loss: 0.50713776/9568 [==========>...................] - ETA: 4:12 - loss: 0.50463840/9568 [===========>..................] - ETA: 4:05 - loss: 0.50203904/9568 [===========>..................] - ETA: 3:59 - loss: 0.49873968/9568 [===========>..................] - ETA: 3:53 - loss: 0.49564032/9568 [===========>..................] - ETA: 3:47 - loss: 0.49284096/9568 [===========>..................] - ETA: 3:41 - loss: 0.48964160/9568 [============>.................] - ETA: 3:35 - loss: 0.48654224/9568 [============>.................] - ETA: 3:30 - loss: 0.48344288/9568 [============>.................] - ETA: 3:25 - loss: 0.48004352/9568 [============>.................] - ETA: 3:20 - loss: 0.47744416/9568 [============>.................] - ETA: 3:15 - loss: 0.47424480/9568 [=============>................] - ETA: 3:10 - loss: 0.47184544/9568 [=============>................] - ETA: 3:06 - loss: 0.46914608/9568 [=============>................] - ETA: 3:01 - loss: 0.46704672/9568 [=============>................] - ETA: 2:57 - loss: 0.46434736/9568 [=============>................] - ETA: 2:53 - loss: 0.46154800/9568 [==============>...............] - ETA: 2:48 - loss: 0.45914864/9568 [==============>...............] - ETA: 2:44 - loss: 0.45674928/9568 [==============>...............] - ETA: 2:41 - loss: 0.45484992/9568 [==============>...............] - ETA: 2:37 - loss: 0.45355056/9568 [==============>...............] - ETA: 2:33 - loss: 0.45225120/9568 [===============>..............] - ETA: 2:29 - loss: 0.45045184/9568 [===============>..............] - ETA: 2:25 - loss: 0.44845248/9568 [===============>..............] - ETA: 2:22 - loss: 0.44715312/9568 [===============>..............] - ETA: 2:18 - loss: 0.44565376/9568 [===============>..............] - ETA: 2:15 - loss: 0.44345440/9568 [================>.............] - ETA: 2:11 - loss: 0.44195504/9568 [================>.............] - ETA: 2:08 - loss: 0.43985568/9568 [================>.............] - ETA: 2:05 - loss: 0.43795632/9568 [================>.............] - ETA: 2:02 - loss: 0.43635696/9568 [================>.............] - ETA: 1:59 - loss: 0.43475760/9568 [=================>............] - ETA: 1:56 - loss: 0.43265824/9568 [=================>............] - ETA: 1:53 - loss: 0.43035888/9568 [=================>............] - ETA: 1:50 - loss: 0.42835952/9568 [=================>............] - ETA: 1:48 - loss: 0.42666016/9568 [=================>............] - ETA: 1:45 - loss: 0.42456080/9568 [==================>...........] - ETA: 1:42 - loss: 0.42266144/9568 [==================>...........] - ETA: 1:39 - loss: 0.42086208/9568 [==================>...........] - ETA: 1:37 - loss: 0.41906272/9568 [==================>...........] - ETA: 1:34 - loss: 0.41726336/9568 [==================>...........] - ETA: 1:32 - loss: 0.41586400/9568 [===================>..........] - ETA: 1:29 - loss: 0.41526464/9568 [===================>..........] - ETA: 1:27 - loss: 0.41356528/9568 [===================>..........] - ETA: 1:24 - loss: 0.41256592/9568 [===================>..........] - ETA: 1:22 - loss: 0.41116656/9568 [===================>..........] - ETA: 1:20 - loss: 0.41026720/9568 [====================>.........] - ETA: 1:18 - loss: 0.40886784/9568 [====================>.........] - ETA: 1:15 - loss: 0.40806848/9568 [====================>.........] - ETA: 1:13 - loss: 0.40706912/9568 [====================>.........] - ETA: 1:11 - loss: 0.40606976/9568 [====================>.........] - ETA: 1:09 - loss: 0.40467040/9568 [=====================>........] - ETA: 1:07 - loss: 0.40327104/9568 [=====================>........] - ETA: 1:04 - loss: 0.40177168/9568 [=====================>........] - ETA: 1:02 - loss: 0.40047232/9568 [=====================>........] - ETA: 1:00 - loss: 0.39907296/9568 [=====================>........] - ETA: 58s - loss: 0.3978 7360/9568 [======================>.......] - ETA: 56s - loss: 0.39657424/9568 [======================>.......] - ETA: 54s - loss: 0.39537488/9568 [======================>.......] - ETA: 52s - loss: 0.39397552/9568 [======================>.......] - ETA: 50s - loss: 0.39267616/9568 [======================>.......] - ETA: 48s - loss: 0.39157680/9568 [=======================>......] - ETA: 47s - loss: 0.39097744/9568 [=======================>......] - ETA: 45s - loss: 0.38987808/9568 [=======================>......] - ETA: 43s - loss: 0.38857872/9568 [=======================>......] - ETA: 41s - loss: 0.38797936/9568 [=======================>......] - ETA: 39s - loss: 0.38708000/9568 [========================>.....] - ETA: 37s - loss: 0.38608064/9568 [========================>.....] - ETA: 36s - loss: 0.38518128/9568 [========================>.....] - ETA: 34s - loss: 0.38428192/9568 [========================>.....] - ETA: 32s - loss: 0.38338256/9568 [========================>.....] - ETA: 31s - loss: 0.38248320/9568 [=========================>....] - ETA: 29s - loss: 0.38178384/9568 [=========================>....] - ETA: 27s - loss: 0.38078448/9568 [=========================>....] - ETA: 26s - loss: 0.37958512/9568 [=========================>....] - ETA: 24s - loss: 0.37828576/9568 [=========================>....] - ETA: 22s - loss: 0.37748640/9568 [==========================>...] - ETA: 21s - loss: 0.37648704/9568 [==========================>...] - ETA: 19s - loss: 0.37538768/9568 [==========================>...] - ETA: 18s - loss: 0.37458832/9568 [==========================>...] - ETA: 16s - loss: 0.37398896/9568 [==========================>...] - ETA: 15s - loss: 0.37288960/9568 [===========================>..] - ETA: 13s - loss: 0.37189024/9568 [===========================>..] - ETA: 12s - loss: 0.37059088/9568 [===========================>..] - ETA: 10s - loss: 0.36979152/9568 [===========================>..] - ETA: 9s - loss: 0.3689 9216/9568 [===========================>..] - ETA: 7s - loss: 0.36819280/9568 [============================>.] - ETA: 6s - loss: 0.36719344/9568 [============================>.] - ETA: 4s - loss: 0.36639408/9568 [============================>.] - ETA: 3s - loss: 0.36569472/9568 [============================>.] - ETA: 2s - loss: 0.36479536/9568 [============================>.] - ETA: 0s - loss: 0.3643
Epoch 00001: val_loss improved from inf to 0.21007, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 261s 27ms/sample - loss: 0.3638 - val_loss: 0.2101
Epoch 2/100
  64/9568 [..............................] - ETA: 1:41 - loss: 0.2361 128/9568 [..............................] - ETA: 1:31 - loss: 0.2419 192/9568 [..............................] - ETA: 1:17 - loss: 0.2485 256/9568 [..............................] - ETA: 1:12 - loss: 0.2509 320/9568 [>.............................] - ETA: 1:06 - loss: 0.2476 384/9568 [>.............................] - ETA: 1:04 - loss: 0.2441 448/9568 [>.............................] - ETA: 1:04 - loss: 0.2398 512/9568 [>.............................] - ETA: 1:08 - loss: 0.2397 576/9568 [>.............................] - ETA: 1:06 - loss: 0.2402 640/9568 [=>............................] - ETA: 1:08 - loss: 0.2427 704/9568 [=>............................] - ETA: 1:07 - loss: 0.2416 768/9568 [=>............................] - ETA: 1:06 - loss: 0.2423 832/9568 [=>............................] - ETA: 1:04 - loss: 0.2401 896/9568 [=>............................] - ETA: 1:03 - loss: 0.2429 960/9568 [==>...........................] - ETA: 1:03 - loss: 0.24221024/9568 [==>...........................] - ETA: 1:02 - loss: 0.24161088/9568 [==>...........................] - ETA: 1:02 - loss: 0.24041152/9568 [==>...........................] - ETA: 1:02 - loss: 0.24101216/9568 [==>...........................] - ETA: 1:01 - loss: 0.23981280/9568 [===>..........................] - ETA: 1:02 - loss: 0.23951344/9568 [===>..........................] - ETA: 1:03 - loss: 0.23811408/9568 [===>..........................] - ETA: 1:03 - loss: 0.23951472/9568 [===>..........................] - ETA: 1:01 - loss: 0.23811536/9568 [===>..........................] - ETA: 59s - loss: 0.2368 1600/9568 [====>.........................] - ETA: 58s - loss: 0.23561664/9568 [====>.........................] - ETA: 57s - loss: 0.23681728/9568 [====>.........................] - ETA: 55s - loss: 0.23601792/9568 [====>.........................] - ETA: 54s - loss: 0.23581856/9568 [====>.........................] - ETA: 53s - loss: 0.23481920/9568 [=====>........................] - ETA: 52s - loss: 0.23441984/9568 [=====>........................] - ETA: 51s - loss: 0.23322048/9568 [=====>........................] - ETA: 50s - loss: 0.23262112/9568 [=====>........................] - ETA: 50s - loss: 0.23232176/9568 [=====>........................] - ETA: 49s - loss: 0.23202240/9568 [======>.......................] - ETA: 49s - loss: 0.23162304/9568 [======>.......................] - ETA: 49s - loss: 0.23192368/9568 [======>.......................] - ETA: 49s - loss: 0.23162432/9568 [======>.......................] - ETA: 49s - loss: 0.23172496/9568 [======>.......................] - ETA: 48s - loss: 0.23152560/9568 [=======>......................] - ETA: 48s - loss: 0.23122624/9568 [=======>......................] - ETA: 47s - loss: 0.23262688/9568 [=======>......................] - ETA: 47s - loss: 0.23282752/9568 [=======>......................] - ETA: 46s - loss: 0.23242816/9568 [=======>......................] - ETA: 46s - loss: 0.23212880/9568 [========>.....................] - ETA: 45s - loss: 0.23142944/9568 [========>.....................] - ETA: 44s - loss: 0.23083008/9568 [========>.....................] - ETA: 43s - loss: 0.23043072/9568 [========>.....................] - ETA: 43s - loss: 0.22913136/9568 [========>.....................] - ETA: 42s - loss: 0.23063200/9568 [=========>....................] - ETA: 41s - loss: 0.23173264/9568 [=========>....................] - ETA: 41s - loss: 0.23193328/9568 [=========>....................] - ETA: 40s - loss: 0.23183392/9568 [=========>....................] - ETA: 40s - loss: 0.23163456/9568 [=========>....................] - ETA: 39s - loss: 0.23123520/9568 [==========>...................] - ETA: 39s - loss: 0.23073584/9568 [==========>...................] - ETA: 39s - loss: 0.22983648/9568 [==========>...................] - ETA: 38s - loss: 0.22943712/9568 [==========>...................] - ETA: 37s - loss: 0.22903776/9568 [==========>...................] - ETA: 37s - loss: 0.22853840/9568 [===========>..................] - ETA: 36s - loss: 0.22823904/9568 [===========>..................] - ETA: 36s - loss: 0.22813968/9568 [===========>..................] - ETA: 35s - loss: 0.22714032/9568 [===========>..................] - ETA: 35s - loss: 0.22694096/9568 [===========>..................] - ETA: 35s - loss: 0.22774160/9568 [============>.................] - ETA: 34s - loss: 0.22754224/9568 [============>.................] - ETA: 34s - loss: 0.22724288/9568 [============>.................] - ETA: 33s - loss: 0.22814352/9568 [============>.................] - ETA: 33s - loss: 0.22844416/9568 [============>.................] - ETA: 33s - loss: 0.22914480/9568 [=============>................] - ETA: 32s - loss: 0.22944544/9568 [=============>................] - ETA: 32s - loss: 0.22974608/9568 [=============>................] - ETA: 32s - loss: 0.22944672/9568 [=============>................] - ETA: 31s - loss: 0.22974736/9568 [=============>................] - ETA: 31s - loss: 0.22994800/9568 [==============>...............] - ETA: 30s - loss: 0.22974864/9568 [==============>...............] - ETA: 30s - loss: 0.22934928/9568 [==============>...............] - ETA: 30s - loss: 0.22904992/9568 [==============>...............] - ETA: 29s - loss: 0.22865056/9568 [==============>...............] - ETA: 29s - loss: 0.22865120/9568 [===============>..............] - ETA: 29s - loss: 0.22925184/9568 [===============>..............] - ETA: 28s - loss: 0.22985248/9568 [===============>..............] - ETA: 28s - loss: 0.23005312/9568 [===============>..............] - ETA: 27s - loss: 0.23095376/9568 [===============>..............] - ETA: 27s - loss: 0.23065440/9568 [================>.............] - ETA: 27s - loss: 0.23065504/9568 [================>.............] - ETA: 27s - loss: 0.23045568/9568 [================>.............] - ETA: 26s - loss: 0.22995632/9568 [================>.............] - ETA: 26s - loss: 0.23005696/9568 [================>.............] - ETA: 26s - loss: 0.23005760/9568 [=================>............] - ETA: 25s - loss: 0.23035824/9568 [=================>............] - ETA: 25s - loss: 0.23075888/9568 [=================>............] - ETA: 24s - loss: 0.23045952/9568 [=================>............] - ETA: 24s - loss: 0.23006016/9568 [=================>............] - ETA: 24s - loss: 0.22996080/9568 [==================>...........] - ETA: 23s - loss: 0.22966144/9568 [==================>...........] - ETA: 23s - loss: 0.22956208/9568 [==================>...........] - ETA: 22s - loss: 0.22926272/9568 [==================>...........] - ETA: 22s - loss: 0.22906336/9568 [==================>...........] - ETA: 21s - loss: 0.22946400/9568 [===================>..........] - ETA: 21s - loss: 0.22936464/9568 [===================>..........] - ETA: 21s - loss: 0.22966528/9568 [===================>..........] - ETA: 20s - loss: 0.22946592/9568 [===================>..........] - ETA: 20s - loss: 0.22966656/9568 [===================>..........] - ETA: 19s - loss: 0.22946720/9568 [====================>.........] - ETA: 19s - loss: 0.22946784/9568 [====================>.........] - ETA: 18s - loss: 0.22946848/9568 [====================>.........] - ETA: 18s - loss: 0.22946912/9568 [====================>.........] - ETA: 18s - loss: 0.22976976/9568 [====================>.........] - ETA: 17s - loss: 0.22947040/9568 [=====================>........] - ETA: 17s - loss: 0.22927104/9568 [=====================>........] - ETA: 16s - loss: 0.22897168/9568 [=====================>........] - ETA: 16s - loss: 0.22877232/9568 [=====================>........] - ETA: 16s - loss: 0.22857296/9568 [=====================>........] - ETA: 15s - loss: 0.22817360/9568 [======================>.......] - ETA: 15s - loss: 0.22787424/9568 [======================>.......] - ETA: 14s - loss: 0.22807488/9568 [======================>.......] - ETA: 14s - loss: 0.22787552/9568 [======================>.......] - ETA: 13s - loss: 0.22797616/9568 [======================>.......] - ETA: 13s - loss: 0.22797680/9568 [=======================>......] - ETA: 13s - loss: 0.22757744/9568 [=======================>......] - ETA: 12s - loss: 0.22727808/9568 [=======================>......] - ETA: 12s - loss: 0.22717872/9568 [=======================>......] - ETA: 11s - loss: 0.22697936/9568 [=======================>......] - ETA: 11s - loss: 0.22688000/9568 [========================>.....] - ETA: 10s - loss: 0.22648064/9568 [========================>.....] - ETA: 10s - loss: 0.22668128/9568 [========================>.....] - ETA: 9s - loss: 0.2263 8192/9568 [========================>.....] - ETA: 9s - loss: 0.22608256/9568 [========================>.....] - ETA: 9s - loss: 0.22608320/9568 [=========================>....] - ETA: 8s - loss: 0.22588384/9568 [=========================>....] - ETA: 8s - loss: 0.22588448/9568 [=========================>....] - ETA: 7s - loss: 0.22558512/9568 [=========================>....] - ETA: 7s - loss: 0.22568576/9568 [=========================>....] - ETA: 6s - loss: 0.22568640/9568 [==========================>...] - ETA: 6s - loss: 0.22538704/9568 [==========================>...] - ETA: 5s - loss: 0.22508768/9568 [==========================>...] - ETA: 5s - loss: 0.22488832/9568 [==========================>...] - ETA: 5s - loss: 0.22438896/9568 [==========================>...] - ETA: 4s - loss: 0.22408960/9568 [===========================>..] - ETA: 4s - loss: 0.22389024/9568 [===========================>..] - ETA: 3s - loss: 0.22359088/9568 [===========================>..] - ETA: 3s - loss: 0.22359152/9568 [===========================>..] - ETA: 2s - loss: 0.22349216/9568 [===========================>..] - ETA: 2s - loss: 0.22389280/9568 [============================>.] - ETA: 1s - loss: 0.22399344/9568 [============================>.] - ETA: 1s - loss: 0.22369408/9568 [============================>.] - ETA: 1s - loss: 0.22329472/9568 [============================>.] - ETA: 0s - loss: 0.22309536/9568 [============================>.] - ETA: 0s - loss: 0.2230
Epoch 00002: val_loss improved from 0.21007 to 0.18475, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 70s 7ms/sample - loss: 0.2228 - val_loss: 0.1848
Epoch 3/100
  64/9568 [..............................] - ETA: 1:56 - loss: 0.1828 128/9568 [..............................] - ETA: 1:18 - loss: 0.1837 192/9568 [..............................] - ETA: 1:07 - loss: 0.1961 256/9568 [..............................] - ETA: 1:04 - loss: 0.1959 320/9568 [>.............................] - ETA: 1:00 - loss: 0.1993 384/9568 [>.............................] - ETA: 1:09 - loss: 0.2001 448/9568 [>.............................] - ETA: 1:12 - loss: 0.1966 512/9568 [>.............................] - ETA: 1:09 - loss: 0.1992 576/9568 [>.............................] - ETA: 1:09 - loss: 0.2019 640/9568 [=>............................] - ETA: 1:11 - loss: 0.2032 704/9568 [=>............................] - ETA: 1:11 - loss: 0.2039 768/9568 [=>............................] - ETA: 1:11 - loss: 0.2042 832/9568 [=>............................] - ETA: 1:11 - loss: 0.2031 896/9568 [=>............................] - ETA: 1:13 - loss: 0.2026 960/9568 [==>...........................] - ETA: 1:12 - loss: 0.20191024/9568 [==>...........................] - ETA: 1:11 - loss: 0.20101088/9568 [==>...........................] - ETA: 1:11 - loss: 0.20351152/9568 [==>...........................] - ETA: 1:12 - loss: 0.20401216/9568 [==>...........................] - ETA: 1:12 - loss: 0.20541280/9568 [===>..........................] - ETA: 1:13 - loss: 0.20431344/9568 [===>..........................] - ETA: 1:15 - loss: 0.20461408/9568 [===>..........................] - ETA: 1:13 - loss: 0.20401472/9568 [===>..........................] - ETA: 1:12 - loss: 0.20241536/9568 [===>..........................] - ETA: 1:09 - loss: 0.20281600/9568 [====>.........................] - ETA: 1:07 - loss: 0.20261664/9568 [====>.........................] - ETA: 1:05 - loss: 0.20181728/9568 [====>.........................] - ETA: 1:04 - loss: 0.20141792/9568 [====>.........................] - ETA: 1:03 - loss: 0.20111856/9568 [====>.........................] - ETA: 1:02 - loss: 0.20071920/9568 [=====>........................] - ETA: 1:01 - loss: 0.20031984/9568 [=====>........................] - ETA: 1:00 - loss: 0.20272048/9568 [=====>........................] - ETA: 1:00 - loss: 0.20292112/9568 [=====>........................] - ETA: 1:01 - loss: 0.20312176/9568 [=====>........................] - ETA: 1:01 - loss: 0.20272240/9568 [======>.......................] - ETA: 59s - loss: 0.2050 2304/9568 [======>.......................] - ETA: 58s - loss: 0.20532368/9568 [======>.......................] - ETA: 57s - loss: 0.20572432/9568 [======>.......................] - ETA: 56s - loss: 0.20592496/9568 [======>.......................] - ETA: 55s - loss: 0.20642560/9568 [=======>......................] - ETA: 54s - loss: 0.20642624/9568 [=======>......................] - ETA: 54s - loss: 0.20732688/9568 [=======>......................] - ETA: 53s - loss: 0.20712752/9568 [=======>......................] - ETA: 52s - loss: 0.20672816/9568 [=======>......................] - ETA: 52s - loss: 0.20592880/9568 [========>.....................] - ETA: 52s - loss: 0.20602944/9568 [========>.....................] - ETA: 51s - loss: 0.20573008/9568 [========>.....................] - ETA: 51s - loss: 0.20583072/9568 [========>.....................] - ETA: 50s - loss: 0.20633136/9568 [========>.....................] - ETA: 49s - loss: 0.20623200/9568 [=========>....................] - ETA: 48s - loss: 0.20563264/9568 [=========>....................] - ETA: 48s - loss: 0.20553328/9568 [=========>....................] - ETA: 47s - loss: 0.20493392/9568 [=========>....................] - ETA: 46s - loss: 0.20463456/9568 [=========>....................] - ETA: 45s - loss: 0.20493520/9568 [==========>...................] - ETA: 45s - loss: 0.20553584/9568 [==========>...................] - ETA: 44s - loss: 0.20493648/9568 [==========>...................] - ETA: 44s - loss: 0.20473712/9568 [==========>...................] - ETA: 43s - loss: 0.20423776/9568 [==========>...................] - ETA: 43s - loss: 0.20353840/9568 [===========>..................] - ETA: 42s - loss: 0.20323904/9568 [===========>..................] - ETA: 41s - loss: 0.20363968/9568 [===========>..................] - ETA: 41s - loss: 0.20394032/9568 [===========>..................] - ETA: 40s - loss: 0.20394096/9568 [===========>..................] - ETA: 40s - loss: 0.20344160/9568 [============>.................] - ETA: 39s - loss: 0.20304224/9568 [============>.................] - ETA: 39s - loss: 0.20354288/9568 [============>.................] - ETA: 38s - loss: 0.20304352/9568 [============>.................] - ETA: 38s - loss: 0.20324416/9568 [============>.................] - ETA: 37s - loss: 0.20304480/9568 [=============>................] - ETA: 36s - loss: 0.20314544/9568 [=============>................] - ETA: 36s - loss: 0.20374608/9568 [=============>................] - ETA: 35s - loss: 0.20354672/9568 [=============>................] - ETA: 35s - loss: 0.20414736/9568 [=============>................] - ETA: 35s - loss: 0.20424800/9568 [==============>...............] - ETA: 34s - loss: 0.20394864/9568 [==============>...............] - ETA: 33s - loss: 0.20404928/9568 [==============>...............] - ETA: 33s - loss: 0.20394992/9568 [==============>...............] - ETA: 33s - loss: 0.20355056/9568 [==============>...............] - ETA: 32s - loss: 0.20325120/9568 [===============>..............] - ETA: 32s - loss: 0.20285184/9568 [===============>..............] - ETA: 32s - loss: 0.20285248/9568 [===============>..............] - ETA: 31s - loss: 0.20315312/9568 [===============>..............] - ETA: 31s - loss: 0.20285376/9568 [===============>..............] - ETA: 31s - loss: 0.20285440/9568 [================>.............] - ETA: 30s - loss: 0.20255504/9568 [================>.............] - ETA: 29s - loss: 0.20265568/9568 [================>.............] - ETA: 29s - loss: 0.20315632/9568 [================>.............] - ETA: 28s - loss: 0.20305696/9568 [================>.............] - ETA: 28s - loss: 0.20325760/9568 [=================>............] - ETA: 27s - loss: 0.20285824/9568 [=================>............] - ETA: 27s - loss: 0.20245888/9568 [=================>............] - ETA: 26s - loss: 0.20275952/9568 [=================>............] - ETA: 26s - loss: 0.20266016/9568 [=================>............] - ETA: 25s - loss: 0.20306080/9568 [==================>...........] - ETA: 25s - loss: 0.20316144/9568 [==================>...........] - ETA: 24s - loss: 0.20296208/9568 [==================>...........] - ETA: 24s - loss: 0.20266272/9568 [==================>...........] - ETA: 23s - loss: 0.20266336/9568 [==================>...........] - ETA: 23s - loss: 0.20266400/9568 [===================>..........] - ETA: 22s - loss: 0.20256464/9568 [===================>..........] - ETA: 22s - loss: 0.20266528/9568 [===================>..........] - ETA: 21s - loss: 0.20286592/9568 [===================>..........] - ETA: 21s - loss: 0.20256656/9568 [===================>..........] - ETA: 20s - loss: 0.20296720/9568 [====================>.........] - ETA: 20s - loss: 0.20266784/9568 [====================>.........] - ETA: 20s - loss: 0.20226848/9568 [====================>.........] - ETA: 19s - loss: 0.20226912/9568 [====================>.........] - ETA: 19s - loss: 0.20186976/9568 [====================>.........] - ETA: 18s - loss: 0.20187040/9568 [=====================>........] - ETA: 18s - loss: 0.20197104/9568 [=====================>........] - ETA: 17s - loss: 0.20187168/9568 [=====================>........] - ETA: 17s - loss: 0.20237232/9568 [=====================>........] - ETA: 16s - loss: 0.20257296/9568 [=====================>........] - ETA: 16s - loss: 0.20247360/9568 [======================>.......] - ETA: 15s - loss: 0.20237424/9568 [======================>.......] - ETA: 15s - loss: 0.20207488/9568 [======================>.......] - ETA: 15s - loss: 0.20207552/9568 [======================>.......] - ETA: 14s - loss: 0.20207616/9568 [======================>.......] - ETA: 14s - loss: 0.20237680/9568 [=======================>......] - ETA: 13s - loss: 0.20197744/9568 [=======================>......] - ETA: 13s - loss: 0.20197808/9568 [=======================>......] - ETA: 12s - loss: 0.20177872/9568 [=======================>......] - ETA: 12s - loss: 0.20197936/9568 [=======================>......] - ETA: 11s - loss: 0.20218000/9568 [========================>.....] - ETA: 11s - loss: 0.20208064/9568 [========================>.....] - ETA: 10s - loss: 0.20208128/9568 [========================>.....] - ETA: 10s - loss: 0.20208192/9568 [========================>.....] - ETA: 10s - loss: 0.20208256/9568 [========================>.....] - ETA: 9s - loss: 0.2019 8320/9568 [=========================>....] - ETA: 9s - loss: 0.20198384/9568 [=========================>....] - ETA: 8s - loss: 0.20188448/9568 [=========================>....] - ETA: 8s - loss: 0.20188512/9568 [=========================>....] - ETA: 7s - loss: 0.20178576/9568 [=========================>....] - ETA: 7s - loss: 0.20168640/9568 [==========================>...] - ETA: 6s - loss: 0.20148704/9568 [==========================>...] - ETA: 6s - loss: 0.20138768/9568 [==========================>...] - ETA: 5s - loss: 0.20128832/9568 [==========================>...] - ETA: 5s - loss: 0.20108896/9568 [==========================>...] - ETA: 4s - loss: 0.20088960/9568 [===========================>..] - ETA: 4s - loss: 0.20099024/9568 [===========================>..] - ETA: 3s - loss: 0.20079088/9568 [===========================>..] - ETA: 3s - loss: 0.20069152/9568 [===========================>..] - ETA: 2s - loss: 0.20039216/9568 [===========================>..] - ETA: 2s - loss: 0.20029280/9568 [============================>.] - ETA: 2s - loss: 0.20009344/9568 [============================>.] - ETA: 1s - loss: 0.19979408/9568 [============================>.] - ETA: 1s - loss: 0.19979472/9568 [============================>.] - ETA: 0s - loss: 0.19999536/9568 [============================>.] - ETA: 0s - loss: 0.2001
Epoch 00003: val_loss improved from 0.18475 to 0.18045, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 72s 8ms/sample - loss: 0.2000 - val_loss: 0.1805
Epoch 4/100
  64/9568 [..............................] - ETA: 1:48 - loss: 0.1884 128/9568 [..............................] - ETA: 1:46 - loss: 0.1812 192/9568 [..............................] - ETA: 1:39 - loss: 0.1824 256/9568 [..............................] - ETA: 1:27 - loss: 0.1877 320/9568 [>.............................] - ETA: 1:19 - loss: 0.1899 384/9568 [>.............................] - ETA: 1:13 - loss: 0.1918 448/9568 [>.............................] - ETA: 1:10 - loss: 0.1894 512/9568 [>.............................] - ETA: 1:08 - loss: 0.1861 576/9568 [>.............................] - ETA: 1:08 - loss: 0.1900 640/9568 [=>............................] - ETA: 1:06 - loss: 0.1889 704/9568 [=>............................] - ETA: 1:08 - loss: 0.1893 768/9568 [=>............................] - ETA: 1:10 - loss: 0.1879 832/9568 [=>............................] - ETA: 1:12 - loss: 0.1865 896/9568 [=>............................] - ETA: 1:09 - loss: 0.1859 960/9568 [==>...........................] - ETA: 1:08 - loss: 0.18491024/9568 [==>...........................] - ETA: 1:08 - loss: 0.18321088/9568 [==>...........................] - ETA: 1:09 - loss: 0.18211152/9568 [==>...........................] - ETA: 1:07 - loss: 0.18181216/9568 [==>...........................] - ETA: 1:06 - loss: 0.18161280/9568 [===>..........................] - ETA: 1:04 - loss: 0.18251344/9568 [===>..........................] - ETA: 1:04 - loss: 0.18301408/9568 [===>..........................] - ETA: 1:04 - loss: 0.18211472/9568 [===>..........................] - ETA: 1:05 - loss: 0.18171536/9568 [===>..........................] - ETA: 1:05 - loss: 0.18131600/9568 [====>.........................] - ETA: 1:04 - loss: 0.18151664/9568 [====>.........................] - ETA: 1:03 - loss: 0.18121728/9568 [====>.........................] - ETA: 1:03 - loss: 0.18231792/9568 [====>.........................] - ETA: 1:02 - loss: 0.18251856/9568 [====>.........................] - ETA: 1:01 - loss: 0.18271920/9568 [=====>........................] - ETA: 1:01 - loss: 0.18221984/9568 [=====>........................] - ETA: 1:00 - loss: 0.18172048/9568 [=====>........................] - ETA: 59s - loss: 0.1812 2112/9568 [=====>........................] - ETA: 59s - loss: 0.18112176/9568 [=====>........................] - ETA: 58s - loss: 0.18072240/9568 [======>.......................] - ETA: 57s - loss: 0.18072304/9568 [======>.......................] - ETA: 56s - loss: 0.18142368/9568 [======>.......................] - ETA: 55s - loss: 0.18202432/9568 [======>.......................] - ETA: 54s - loss: 0.18152496/9568 [======>.......................] - ETA: 53s - loss: 0.18192560/9568 [=======>......................] - ETA: 52s - loss: 0.18242624/9568 [=======>......................] - ETA: 52s - loss: 0.18332688/9568 [=======>......................] - ETA: 51s - loss: 0.18412752/9568 [=======>......................] - ETA: 50s - loss: 0.18532816/9568 [=======>......................] - ETA: 50s - loss: 0.18602880/9568 [========>.....................] - ETA: 49s - loss: 0.18592944/9568 [========>.....................] - ETA: 49s - loss: 0.18663008/9568 [========>.....................] - ETA: 49s - loss: 0.18843072/9568 [========>.....................] - ETA: 48s - loss: 0.18883136/9568 [========>.....................] - ETA: 48s - loss: 0.18833200/9568 [=========>....................] - ETA: 47s - loss: 0.18823264/9568 [=========>....................] - ETA: 46s - loss: 0.18843328/9568 [=========>....................] - ETA: 45s - loss: 0.18793392/9568 [=========>....................] - ETA: 45s - loss: 0.18833456/9568 [=========>....................] - ETA: 44s - loss: 0.18803520/9568 [==========>...................] - ETA: 43s - loss: 0.18763584/9568 [==========>...................] - ETA: 43s - loss: 0.18763648/9568 [==========>...................] - ETA: 42s - loss: 0.18703712/9568 [==========>...................] - ETA: 42s - loss: 0.18663776/9568 [==========>...................] - ETA: 41s - loss: 0.18653840/9568 [===========>..................] - ETA: 41s - loss: 0.18653904/9568 [===========>..................] - ETA: 41s - loss: 0.18653968/9568 [===========>..................] - ETA: 40s - loss: 0.18724032/9568 [===========>..................] - ETA: 40s - loss: 0.18704096/9568 [===========>..................] - ETA: 39s - loss: 0.18674160/9568 [============>.................] - ETA: 39s - loss: 0.18664224/9568 [============>.................] - ETA: 38s - loss: 0.18674288/9568 [============>.................] - ETA: 38s - loss: 0.18634352/9568 [============>.................] - ETA: 37s - loss: 0.18624416/9568 [============>.................] - ETA: 36s - loss: 0.18664480/9568 [=============>................] - ETA: 36s - loss: 0.18704544/9568 [=============>................] - ETA: 36s - loss: 0.18704608/9568 [=============>................] - ETA: 35s - loss: 0.18674672/9568 [=============>................] - ETA: 35s - loss: 0.18674736/9568 [=============>................] - ETA: 34s - loss: 0.18644800/9568 [==============>...............] - ETA: 34s - loss: 0.18644864/9568 [==============>...............] - ETA: 33s - loss: 0.18624928/9568 [==============>...............] - ETA: 33s - loss: 0.18594992/9568 [==============>...............] - ETA: 32s - loss: 0.18605056/9568 [==============>...............] - ETA: 31s - loss: 0.18625120/9568 [===============>..............] - ETA: 31s - loss: 0.18615184/9568 [===============>..............] - ETA: 30s - loss: 0.18615248/9568 [===============>..............] - ETA: 30s - loss: 0.18675312/9568 [===============>..............] - ETA: 29s - loss: 0.18715376/9568 [===============>..............] - ETA: 29s - loss: 0.18705440/9568 [================>.............] - ETA: 28s - loss: 0.18745504/9568 [================>.............] - ETA: 28s - loss: 0.18725568/9568 [================>.............] - ETA: 27s - loss: 0.18795632/9568 [================>.............] - ETA: 27s - loss: 0.18845696/9568 [================>.............] - ETA: 26s - loss: 0.18835760/9568 [=================>............] - ETA: 26s - loss: 0.18815824/9568 [=================>............] - ETA: 25s - loss: 0.18815888/9568 [=================>............] - ETA: 25s - loss: 0.18825952/9568 [=================>............] - ETA: 25s - loss: 0.18866016/9568 [=================>............] - ETA: 24s - loss: 0.18866080/9568 [==================>...........] - ETA: 24s - loss: 0.18866144/9568 [==================>...........] - ETA: 23s - loss: 0.18856208/9568 [==================>...........] - ETA: 23s - loss: 0.18836272/9568 [==================>...........] - ETA: 22s - loss: 0.18866336/9568 [==================>...........] - ETA: 22s - loss: 0.18866400/9568 [===================>..........] - ETA: 21s - loss: 0.18856464/9568 [===================>..........] - ETA: 21s - loss: 0.18876528/9568 [===================>..........] - ETA: 20s - loss: 0.18856592/9568 [===================>..........] - ETA: 20s - loss: 0.18846656/9568 [===================>..........] - ETA: 19s - loss: 0.18896720/9568 [====================>.........] - ETA: 19s - loss: 0.18876784/9568 [====================>.........] - ETA: 19s - loss: 0.18876848/9568 [====================>.........] - ETA: 18s - loss: 0.18846912/9568 [====================>.........] - ETA: 18s - loss: 0.18806976/9568 [====================>.........] - ETA: 17s - loss: 0.18847040/9568 [=====================>........] - ETA: 17s - loss: 0.18847104/9568 [=====================>........] - ETA: 16s - loss: 0.18807168/9568 [=====================>........] - ETA: 16s - loss: 0.18777232/9568 [=====================>........] - ETA: 15s - loss: 0.18787296/9568 [=====================>........] - ETA: 15s - loss: 0.18767360/9568 [======================>.......] - ETA: 15s - loss: 0.18777424/9568 [======================>.......] - ETA: 14s - loss: 0.18777488/9568 [======================>.......] - ETA: 14s - loss: 0.18787552/9568 [======================>.......] - ETA: 14s - loss: 0.18787616/9568 [======================>.......] - ETA: 13s - loss: 0.18797680/9568 [=======================>......] - ETA: 13s - loss: 0.18767744/9568 [=======================>......] - ETA: 12s - loss: 0.18767808/9568 [=======================>......] - ETA: 12s - loss: 0.18747872/9568 [=======================>......] - ETA: 11s - loss: 0.18727936/9568 [=======================>......] - ETA: 11s - loss: 0.18708000/9568 [========================>.....] - ETA: 11s - loss: 0.18728064/9568 [========================>.....] - ETA: 10s - loss: 0.18728128/9568 [========================>.....] - ETA: 10s - loss: 0.18738192/9568 [========================>.....] - ETA: 9s - loss: 0.1872 8256/9568 [========================>.....] - ETA: 9s - loss: 0.18698320/9568 [=========================>....] - ETA: 8s - loss: 0.18698384/9568 [=========================>....] - ETA: 8s - loss: 0.18678448/9568 [=========================>....] - ETA: 7s - loss: 0.18678512/9568 [=========================>....] - ETA: 7s - loss: 0.18678576/9568 [=========================>....] - ETA: 6s - loss: 0.18658640/9568 [==========================>...] - ETA: 6s - loss: 0.18648704/9568 [==========================>...] - ETA: 6s - loss: 0.18658768/9568 [==========================>...] - ETA: 5s - loss: 0.18698832/9568 [==========================>...] - ETA: 5s - loss: 0.18708896/9568 [==========================>...] - ETA: 4s - loss: 0.18688960/9568 [===========================>..] - ETA: 4s - loss: 0.18679024/9568 [===========================>..] - ETA: 3s - loss: 0.18669088/9568 [===========================>..] - ETA: 3s - loss: 0.18649152/9568 [===========================>..] - ETA: 2s - loss: 0.18639216/9568 [===========================>..] - ETA: 2s - loss: 0.18639280/9568 [============================>.] - ETA: 2s - loss: 0.18629344/9568 [============================>.] - ETA: 1s - loss: 0.18629408/9568 [============================>.] - ETA: 1s - loss: 0.18629472/9568 [============================>.] - ETA: 0s - loss: 0.18619536/9568 [============================>.] - ETA: 0s - loss: 0.1861
Epoch 00004: val_loss did not improve from 0.18045
9568/9568 [==============================] - 71s 7ms/sample - loss: 0.1861 - val_loss: 0.1936
Epoch 5/100
  64/9568 [..............................] - ETA: 1:00 - loss: 0.1731 128/9568 [..............................] - ETA: 58s - loss: 0.1740  192/9568 [..............................] - ETA: 1:01 - loss: 0.1719 256/9568 [..............................] - ETA: 1:02 - loss: 0.1757 320/9568 [>.............................] - ETA: 1:02 - loss: 0.1812 384/9568 [>.............................] - ETA: 1:01 - loss: 0.1883 448/9568 [>.............................] - ETA: 57s - loss: 0.1865  512/9568 [>.............................] - ETA: 58s - loss: 0.1887 576/9568 [>.............................] - ETA: 58s - loss: 0.1880 640/9568 [=>............................] - ETA: 1:01 - loss: 0.1843 704/9568 [=>............................] - ETA: 58s - loss: 0.1844  768/9568 [=>............................] - ETA: 57s - loss: 0.1821 832/9568 [=>............................] - ETA: 57s - loss: 0.1813 896/9568 [=>............................] - ETA: 58s - loss: 0.1794 960/9568 [==>...........................] - ETA: 57s - loss: 0.17951024/9568 [==>...........................] - ETA: 56s - loss: 0.17861088/9568 [==>...........................] - ETA: 56s - loss: 0.18051152/9568 [==>...........................] - ETA: 59s - loss: 0.18241216/9568 [==>...........................] - ETA: 59s - loss: 0.18071280/9568 [===>..........................] - ETA: 58s - loss: 0.18021344/9568 [===>..........................] - ETA: 58s - loss: 0.18131408/9568 [===>..........................] - ETA: 58s - loss: 0.18071472/9568 [===>..........................] - ETA: 59s - loss: 0.17981536/9568 [===>..........................] - ETA: 57s - loss: 0.18101600/9568 [====>.........................] - ETA: 57s - loss: 0.18161664/9568 [====>.........................] - ETA: 57s - loss: 0.18201728/9568 [====>.........................] - ETA: 56s - loss: 0.18101792/9568 [====>.........................] - ETA: 57s - loss: 0.18151856/9568 [====>.........................] - ETA: 57s - loss: 0.18521920/9568 [=====>........................] - ETA: 57s - loss: 0.18391984/9568 [=====>........................] - ETA: 57s - loss: 0.18322048/9568 [=====>........................] - ETA: 57s - loss: 0.18432112/9568 [=====>........................] - ETA: 57s - loss: 0.18492176/9568 [=====>........................] - ETA: 57s - loss: 0.18452240/9568 [======>.......................] - ETA: 56s - loss: 0.18542304/9568 [======>.......................] - ETA: 55s - loss: 0.18482368/9568 [======>.......................] - ETA: 55s - loss: 0.18492432/9568 [======>.......................] - ETA: 54s - loss: 0.18422496/9568 [======>.......................] - ETA: 53s - loss: 0.18562560/9568 [=======>......................] - ETA: 52s - loss: 0.18542624/9568 [=======>......................] - ETA: 51s - loss: 0.18442688/9568 [=======>......................] - ETA: 51s - loss: 0.18472752/9568 [=======>......................] - ETA: 50s - loss: 0.18402816/9568 [=======>......................] - ETA: 49s - loss: 0.18412880/9568 [========>.....................] - ETA: 48s - loss: 0.18342944/9568 [========>.....................] - ETA: 48s - loss: 0.18403008/9568 [========>.....................] - ETA: 47s - loss: 0.18423072/9568 [========>.....................] - ETA: 47s - loss: 0.18353136/9568 [========>.....................] - ETA: 46s - loss: 0.18323200/9568 [=========>....................] - ETA: 46s - loss: 0.18333264/9568 [=========>....................] - ETA: 45s - loss: 0.18303328/9568 [=========>....................] - ETA: 44s - loss: 0.18293392/9568 [=========>....................] - ETA: 43s - loss: 0.18353456/9568 [=========>....................] - ETA: 42s - loss: 0.18303520/9568 [==========>...................] - ETA: 42s - loss: 0.18333584/9568 [==========>...................] - ETA: 41s - loss: 0.18273648/9568 [==========>...................] - ETA: 40s - loss: 0.18213712/9568 [==========>...................] - ETA: 39s - loss: 0.18173776/9568 [==========>...................] - ETA: 39s - loss: 0.18133840/9568 [===========>..................] - ETA: 38s - loss: 0.18113904/9568 [===========>..................] - ETA: 38s - loss: 0.18083968/9568 [===========>..................] - ETA: 38s - loss: 0.18044032/9568 [===========>..................] - ETA: 37s - loss: 0.18054096/9568 [===========>..................] - ETA: 37s - loss: 0.18034160/9568 [============>.................] - ETA: 36s - loss: 0.18044224/9568 [============>.................] - ETA: 36s - loss: 0.18034288/9568 [============>.................] - ETA: 35s - loss: 0.18054352/9568 [============>.................] - ETA: 35s - loss: 0.18054416/9568 [============>.................] - ETA: 34s - loss: 0.18044480/9568 [=============>................] - ETA: 34s - loss: 0.18004544/9568 [=============>................] - ETA: 34s - loss: 0.18014608/9568 [=============>................] - ETA: 33s - loss: 0.18024672/9568 [=============>................] - ETA: 33s - loss: 0.17984736/9568 [=============>................] - ETA: 33s - loss: 0.18024800/9568 [==============>...............] - ETA: 33s - loss: 0.17974864/9568 [==============>...............] - ETA: 32s - loss: 0.17974928/9568 [==============>...............] - ETA: 31s - loss: 0.17964992/9568 [==============>...............] - ETA: 31s - loss: 0.17935056/9568 [==============>...............] - ETA: 30s - loss: 0.17925120/9568 [===============>..............] - ETA: 30s - loss: 0.17885184/9568 [===============>..............] - ETA: 30s - loss: 0.17865248/9568 [===============>..............] - ETA: 29s - loss: 0.17855312/9568 [===============>..............] - ETA: 29s - loss: 0.17865376/9568 [===============>..............] - ETA: 28s - loss: 0.17845440/9568 [================>.............] - ETA: 28s - loss: 0.17865504/9568 [================>.............] - ETA: 27s - loss: 0.17855568/9568 [================>.............] - ETA: 27s - loss: 0.17845632/9568 [================>.............] - ETA: 26s - loss: 0.17855696/9568 [================>.............] - ETA: 26s - loss: 0.17835760/9568 [=================>............] - ETA: 25s - loss: 0.17875824/9568 [=================>............] - ETA: 25s - loss: 0.17855888/9568 [=================>............] - ETA: 25s - loss: 0.17855952/9568 [=================>............] - ETA: 24s - loss: 0.17856016/9568 [=================>............] - ETA: 24s - loss: 0.17876080/9568 [==================>...........] - ETA: 23s - loss: 0.17886144/9568 [==================>...........] - ETA: 23s - loss: 0.17896208/9568 [==================>...........] - ETA: 22s - loss: 0.17876272/9568 [==================>...........] - ETA: 22s - loss: 0.17896336/9568 [==================>...........] - ETA: 21s - loss: 0.17886400/9568 [===================>..........] - ETA: 21s - loss: 0.17886464/9568 [===================>..........] - ETA: 20s - loss: 0.17846528/9568 [===================>..........] - ETA: 20s - loss: 0.17836592/9568 [===================>..........] - ETA: 20s - loss: 0.17816656/9568 [===================>..........] - ETA: 19s - loss: 0.17816720/9568 [====================>.........] - ETA: 19s - loss: 0.17836784/9568 [====================>.........] - ETA: 18s - loss: 0.17816848/9568 [====================>.........] - ETA: 18s - loss: 0.17806912/9568 [====================>.........] - ETA: 17s - loss: 0.17846976/9568 [====================>.........] - ETA: 17s - loss: 0.17857040/9568 [=====================>........] - ETA: 16s - loss: 0.17847104/9568 [=====================>........] - ETA: 16s - loss: 0.17837168/9568 [=====================>........] - ETA: 15s - loss: 0.17837232/9568 [=====================>........] - ETA: 15s - loss: 0.17847296/9568 [=====================>........] - ETA: 15s - loss: 0.17847360/9568 [======================>.......] - ETA: 14s - loss: 0.17887424/9568 [======================>.......] - ETA: 14s - loss: 0.17877488/9568 [======================>.......] - ETA: 13s - loss: 0.17867552/9568 [======================>.......] - ETA: 13s - loss: 0.17847616/9568 [======================>.......] - ETA: 12s - loss: 0.17857680/9568 [=======================>......] - ETA: 12s - loss: 0.17837744/9568 [=======================>......] - ETA: 11s - loss: 0.17837808/9568 [=======================>......] - ETA: 11s - loss: 0.17827872/9568 [=======================>......] - ETA: 11s - loss: 0.17817936/9568 [=======================>......] - ETA: 10s - loss: 0.17798000/9568 [========================>.....] - ETA: 10s - loss: 0.17818064/9568 [========================>.....] - ETA: 9s - loss: 0.1780 8128/9568 [========================>.....] - ETA: 9s - loss: 0.17788192/9568 [========================>.....] - ETA: 9s - loss: 0.17838256/9568 [========================>.....] - ETA: 8s - loss: 0.17818320/9568 [=========================>....] - ETA: 8s - loss: 0.17808384/9568 [=========================>....] - ETA: 7s - loss: 0.17808448/9568 [=========================>....] - ETA: 7s - loss: 0.17818512/9568 [=========================>....] - ETA: 7s - loss: 0.17828576/9568 [=========================>....] - ETA: 6s - loss: 0.17848640/9568 [==========================>...] - ETA: 6s - loss: 0.17858704/9568 [==========================>...] - ETA: 5s - loss: 0.17858768/9568 [==========================>...] - ETA: 5s - loss: 0.17848832/9568 [==========================>...] - ETA: 5s - loss: 0.17858896/9568 [==========================>...] - ETA: 4s - loss: 0.17858960/9568 [===========================>..] - ETA: 4s - loss: 0.17849024/9568 [===========================>..] - ETA: 3s - loss: 0.17849088/9568 [===========================>..] - ETA: 3s - loss: 0.17829152/9568 [===========================>..] - ETA: 2s - loss: 0.17839216/9568 [===========================>..] - ETA: 2s - loss: 0.17829280/9568 [============================>.] - ETA: 1s - loss: 0.17849344/9568 [============================>.] - ETA: 1s - loss: 0.17869408/9568 [============================>.] - ETA: 1s - loss: 0.17849472/9568 [============================>.] - ETA: 0s - loss: 0.17879536/9568 [============================>.] - ETA: 0s - loss: 0.1787
Epoch 00005: val_loss did not improve from 0.18045
9568/9568 [==============================] - 69s 7ms/sample - loss: 0.1787 - val_loss: 0.1833
Epoch 6/100
  64/9568 [..............................] - ETA: 33s - loss: 0.1647 128/9568 [..............................] - ETA: 40s - loss: 0.1677 192/9568 [..............................] - ETA: 36s - loss: 0.1692 256/9568 [..............................] - ETA: 42s - loss: 0.1665 320/9568 [>.............................] - ETA: 44s - loss: 0.1629 384/9568 [>.............................] - ETA: 42s - loss: 0.1638 448/9568 [>.............................] - ETA: 43s - loss: 0.1625 512/9568 [>.............................] - ETA: 43s - loss: 0.1665 576/9568 [>.............................] - ETA: 45s - loss: 0.1692 640/9568 [=>............................] - ETA: 44s - loss: 0.1676 704/9568 [=>............................] - ETA: 44s - loss: 0.1705 768/9568 [=>............................] - ETA: 44s - loss: 0.1735 832/9568 [=>............................] - ETA: 42s - loss: 0.1716 896/9568 [=>............................] - ETA: 41s - loss: 0.1699 960/9568 [==>...........................] - ETA: 40s - loss: 0.16941024/9568 [==>...........................] - ETA: 39s - loss: 0.16961088/9568 [==>...........................] - ETA: 38s - loss: 0.17021152/9568 [==>...........................] - ETA: 38s - loss: 0.16991216/9568 [==>...........................] - ETA: 39s - loss: 0.17051280/9568 [===>..........................] - ETA: 38s - loss: 0.17071344/9568 [===>..........................] - ETA: 38s - loss: 0.17111408/9568 [===>..........................] - ETA: 38s - loss: 0.17001472/9568 [===>..........................] - ETA: 40s - loss: 0.16921536/9568 [===>..........................] - ETA: 39s - loss: 0.17001600/9568 [====>.........................] - ETA: 39s - loss: 0.17141664/9568 [====>.........................] - ETA: 39s - loss: 0.17231728/9568 [====>.........................] - ETA: 39s - loss: 0.17131792/9568 [====>.........................] - ETA: 39s - loss: 0.17031856/9568 [====>.........................] - ETA: 38s - loss: 0.16981920/9568 [=====>........................] - ETA: 39s - loss: 0.16941984/9568 [=====>........................] - ETA: 38s - loss: 0.16932048/9568 [=====>........................] - ETA: 38s - loss: 0.16892112/9568 [=====>........................] - ETA: 38s - loss: 0.16862176/9568 [=====>........................] - ETA: 37s - loss: 0.16822240/9568 [======>.......................] - ETA: 36s - loss: 0.16922304/9568 [======>.......................] - ETA: 36s - loss: 0.16962368/9568 [======>.......................] - ETA: 36s - loss: 0.16932432/9568 [======>.......................] - ETA: 36s - loss: 0.16892496/9568 [======>.......................] - ETA: 35s - loss: 0.16802560/9568 [=======>......................] - ETA: 35s - loss: 0.16722624/9568 [=======>......................] - ETA: 35s - loss: 0.16732688/9568 [=======>......................] - ETA: 36s - loss: 0.16702752/9568 [=======>......................] - ETA: 35s - loss: 0.16682816/9568 [=======>......................] - ETA: 36s - loss: 0.16652880/9568 [========>.....................] - ETA: 36s - loss: 0.16692944/9568 [========>.....................] - ETA: 36s - loss: 0.16673008/9568 [========>.....................] - ETA: 36s - loss: 0.16653072/9568 [========>.....................] - ETA: 36s - loss: 0.16653136/9568 [========>.....................] - ETA: 36s - loss: 0.16633200/9568 [=========>....................] - ETA: 36s - loss: 0.16613264/9568 [=========>....................] - ETA: 36s - loss: 0.16603328/9568 [=========>....................] - ETA: 35s - loss: 0.16563392/9568 [=========>....................] - ETA: 35s - loss: 0.16583456/9568 [=========>....................] - ETA: 34s - loss: 0.16563520/9568 [==========>...................] - ETA: 34s - loss: 0.16573584/9568 [==========>...................] - ETA: 33s - loss: 0.16603648/9568 [==========>...................] - ETA: 33s - loss: 0.16623712/9568 [==========>...................] - ETA: 33s - loss: 0.16613776/9568 [==========>...................] - ETA: 33s - loss: 0.16713840/9568 [===========>..................] - ETA: 33s - loss: 0.16813904/9568 [===========>..................] - ETA: 32s - loss: 0.16833968/9568 [===========>..................] - ETA: 32s - loss: 0.16834032/9568 [===========>..................] - ETA: 31s - loss: 0.16814096/9568 [===========>..................] - ETA: 31s - loss: 0.16784160/9568 [============>.................] - ETA: 30s - loss: 0.16824224/9568 [============>.................] - ETA: 30s - loss: 0.16804288/9568 [============>.................] - ETA: 30s - loss: 0.16784352/9568 [============>.................] - ETA: 29s - loss: 0.16784416/9568 [============>.................] - ETA: 29s - loss: 0.16794480/9568 [=============>................] - ETA: 29s - loss: 0.16774544/9568 [=============>................] - ETA: 28s - loss: 0.16754608/9568 [=============>................] - ETA: 28s - loss: 0.16744672/9568 [=============>................] - ETA: 27s - loss: 0.16764736/9568 [=============>................] - ETA: 27s - loss: 0.16744800/9568 [==============>...............] - ETA: 26s - loss: 0.16704864/9568 [==============>...............] - ETA: 26s - loss: 0.16684928/9568 [==============>...............] - ETA: 26s - loss: 0.16664992/9568 [==============>...............] - ETA: 26s - loss: 0.16675056/9568 [==============>...............] - ETA: 25s - loss: 0.16655120/9568 [===============>..............] - ETA: 25s - loss: 0.16645184/9568 [===============>..............] - ETA: 24s - loss: 0.16625248/9568 [===============>..............] - ETA: 24s - loss: 0.16665312/9568 [===============>..............] - ETA: 24s - loss: 0.16635376/9568 [===============>..............] - ETA: 23s - loss: 0.16635440/9568 [================>.............] - ETA: 23s - loss: 0.16655504/9568 [================>.............] - ETA: 23s - loss: 0.16695568/9568 [================>.............] - ETA: 23s - loss: 0.16695632/9568 [================>.............] - ETA: 22s - loss: 0.16705696/9568 [================>.............] - ETA: 22s - loss: 0.16715760/9568 [=================>............] - ETA: 22s - loss: 0.16725824/9568 [=================>............] - ETA: 21s - loss: 0.16715888/9568 [=================>............] - ETA: 21s - loss: 0.16725952/9568 [=================>............] - ETA: 21s - loss: 0.16706016/9568 [=================>............] - ETA: 20s - loss: 0.16696080/9568 [==================>...........] - ETA: 20s - loss: 0.16706144/9568 [==================>...........] - ETA: 20s - loss: 0.16716208/9568 [==================>...........] - ETA: 19s - loss: 0.16706272/9568 [==================>...........] - ETA: 19s - loss: 0.16706336/9568 [==================>...........] - ETA: 18s - loss: 0.16696400/9568 [===================>..........] - ETA: 18s - loss: 0.16696464/9568 [===================>..........] - ETA: 17s - loss: 0.16726528/9568 [===================>..........] - ETA: 17s - loss: 0.16706592/9568 [===================>..........] - ETA: 17s - loss: 0.16696656/9568 [===================>..........] - ETA: 16s - loss: 0.16696720/9568 [====================>.........] - ETA: 16s - loss: 0.16706784/9568 [====================>.........] - ETA: 16s - loss: 0.16706848/9568 [====================>.........] - ETA: 15s - loss: 0.16696912/9568 [====================>.........] - ETA: 15s - loss: 0.16716976/9568 [====================>.........] - ETA: 14s - loss: 0.16697040/9568 [=====================>........] - ETA: 14s - loss: 0.16687104/9568 [=====================>........] - ETA: 14s - loss: 0.16717168/9568 [=====================>........] - ETA: 13s - loss: 0.16697232/9568 [=====================>........] - ETA: 13s - loss: 0.16687296/9568 [=====================>........] - ETA: 13s - loss: 0.16687360/9568 [======================>.......] - ETA: 12s - loss: 0.16677424/9568 [======================>.......] - ETA: 12s - loss: 0.16677488/9568 [======================>.......] - ETA: 12s - loss: 0.16717552/9568 [======================>.......] - ETA: 11s - loss: 0.16777616/9568 [======================>.......] - ETA: 11s - loss: 0.16767680/9568 [=======================>......] - ETA: 10s - loss: 0.16787744/9568 [=======================>......] - ETA: 10s - loss: 0.16777808/9568 [=======================>......] - ETA: 10s - loss: 0.16757872/9568 [=======================>......] - ETA: 9s - loss: 0.1677 7936/9568 [=======================>......] - ETA: 9s - loss: 0.16778000/9568 [========================>.....] - ETA: 9s - loss: 0.16768064/9568 [========================>.....] - ETA: 8s - loss: 0.16758128/9568 [========================>.....] - ETA: 8s - loss: 0.16758192/9568 [========================>.....] - ETA: 7s - loss: 0.16758256/9568 [========================>.....] - ETA: 7s - loss: 0.16758320/9568 [=========================>....] - ETA: 7s - loss: 0.16778384/9568 [=========================>....] - ETA: 6s - loss: 0.16798448/9568 [=========================>....] - ETA: 6s - loss: 0.16798512/9568 [=========================>....] - ETA: 6s - loss: 0.16808576/9568 [=========================>....] - ETA: 5s - loss: 0.16818640/9568 [==========================>...] - ETA: 5s - loss: 0.16838704/9568 [==========================>...] - ETA: 4s - loss: 0.16838768/9568 [==========================>...] - ETA: 4s - loss: 0.16828832/9568 [==========================>...] - ETA: 4s - loss: 0.16838896/9568 [==========================>...] - ETA: 3s - loss: 0.16858960/9568 [===========================>..] - ETA: 3s - loss: 0.16869024/9568 [===========================>..] - ETA: 3s - loss: 0.16869088/9568 [===========================>..] - ETA: 2s - loss: 0.16879152/9568 [===========================>..] - ETA: 2s - loss: 0.16869216/9568 [===========================>..] - ETA: 2s - loss: 0.16869280/9568 [============================>.] - ETA: 1s - loss: 0.16859344/9568 [============================>.] - ETA: 1s - loss: 0.16859408/9568 [============================>.] - ETA: 0s - loss: 0.16879472/9568 [============================>.] - ETA: 0s - loss: 0.16879536/9568 [============================>.] - ETA: 0s - loss: 0.1686
Epoch 00006: val_loss improved from 0.18045 to 0.17300, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 64s 7ms/sample - loss: 0.1685 - val_loss: 0.1730
Epoch 7/100
  64/9568 [..............................] - ETA: 1:21 - loss: 0.1544 128/9568 [..............................] - ETA: 1:20 - loss: 0.1844 192/9568 [..............................] - ETA: 1:33 - loss: 0.1761 256/9568 [..............................] - ETA: 1:22 - loss: 0.1717 320/9568 [>.............................] - ETA: 1:15 - loss: 0.1658 384/9568 [>.............................] - ETA: 1:10 - loss: 0.1665 448/9568 [>.............................] - ETA: 1:05 - loss: 0.1683 512/9568 [>.............................] - ETA: 1:01 - loss: 0.1673 576/9568 [>.............................] - ETA: 58s - loss: 0.1682  640/9568 [=>............................] - ETA: 57s - loss: 0.1671 704/9568 [=>............................] - ETA: 58s - loss: 0.1688 768/9568 [=>............................] - ETA: 59s - loss: 0.1659 832/9568 [=>............................] - ETA: 57s - loss: 0.1650 896/9568 [=>............................] - ETA: 58s - loss: 0.1653 960/9568 [==>...........................] - ETA: 59s - loss: 0.16431024/9568 [==>...........................] - ETA: 59s - loss: 0.16441088/9568 [==>...........................] - ETA: 59s - loss: 0.16481152/9568 [==>...........................] - ETA: 58s - loss: 0.16561216/9568 [==>...........................] - ETA: 57s - loss: 0.16611280/9568 [===>..........................] - ETA: 55s - loss: 0.16531344/9568 [===>..........................] - ETA: 53s - loss: 0.16811408/9568 [===>..........................] - ETA: 53s - loss: 0.16811472/9568 [===>..........................] - ETA: 52s - loss: 0.16791536/9568 [===>..........................] - ETA: 51s - loss: 0.16691600/9568 [====>.........................] - ETA: 50s - loss: 0.16671664/9568 [====>.........................] - ETA: 48s - loss: 0.16641728/9568 [====>.........................] - ETA: 48s - loss: 0.16621792/9568 [====>.........................] - ETA: 46s - loss: 0.16651856/9568 [====>.........................] - ETA: 46s - loss: 0.16661920/9568 [=====>........................] - ETA: 46s - loss: 0.16781984/9568 [=====>........................] - ETA: 45s - loss: 0.16832048/9568 [=====>........................] - ETA: 44s - loss: 0.16782112/9568 [=====>........................] - ETA: 44s - loss: 0.16732176/9568 [=====>........................] - ETA: 44s - loss: 0.16812240/9568 [======>.......................] - ETA: 43s - loss: 0.16782304/9568 [======>.......................] - ETA: 43s - loss: 0.16722368/9568 [======>.......................] - ETA: 42s - loss: 0.16732432/9568 [======>.......................] - ETA: 42s - loss: 0.16702496/9568 [======>.......................] - ETA: 41s - loss: 0.16652560/9568 [=======>......................] - ETA: 40s - loss: 0.16662624/9568 [=======>......................] - ETA: 39s - loss: 0.16592688/9568 [=======>......................] - ETA: 39s - loss: 0.16522752/9568 [=======>......................] - ETA: 38s - loss: 0.16512816/9568 [=======>......................] - ETA: 37s - loss: 0.16502880/9568 [========>.....................] - ETA: 37s - loss: 0.16522944/9568 [========>.....................] - ETA: 36s - loss: 0.16543008/9568 [========>.....................] - ETA: 36s - loss: 0.16513072/9568 [========>.....................] - ETA: 35s - loss: 0.16563136/9568 [========>.....................] - ETA: 35s - loss: 0.16593200/9568 [=========>....................] - ETA: 34s - loss: 0.16543264/9568 [=========>....................] - ETA: 34s - loss: 0.16543328/9568 [=========>....................] - ETA: 33s - loss: 0.16493392/9568 [=========>....................] - ETA: 33s - loss: 0.16443456/9568 [=========>....................] - ETA: 33s - loss: 0.16393520/9568 [==========>...................] - ETA: 33s - loss: 0.16383584/9568 [==========>...................] - ETA: 33s - loss: 0.16413648/9568 [==========>...................] - ETA: 32s - loss: 0.16403712/9568 [==========>...................] - ETA: 32s - loss: 0.16363776/9568 [==========>...................] - ETA: 32s - loss: 0.16323840/9568 [===========>..................] - ETA: 32s - loss: 0.16303904/9568 [===========>..................] - ETA: 32s - loss: 0.16263968/9568 [===========>..................] - ETA: 31s - loss: 0.16294032/9568 [===========>..................] - ETA: 31s - loss: 0.16284096/9568 [===========>..................] - ETA: 30s - loss: 0.16304160/9568 [============>.................] - ETA: 30s - loss: 0.16364224/9568 [============>.................] - ETA: 29s - loss: 0.16364288/9568 [============>.................] - ETA: 29s - loss: 0.16384352/9568 [============>.................] - ETA: 28s - loss: 0.16364416/9568 [============>.................] - ETA: 28s - loss: 0.16354480/9568 [=============>................] - ETA: 28s - loss: 0.16354544/9568 [=============>................] - ETA: 27s - loss: 0.16324608/9568 [=============>................] - ETA: 27s - loss: 0.16314672/9568 [=============>................] - ETA: 27s - loss: 0.16304736/9568 [=============>................] - ETA: 27s - loss: 0.16284800/9568 [==============>...............] - ETA: 26s - loss: 0.16284864/9568 [==============>...............] - ETA: 26s - loss: 0.16254928/9568 [==============>...............] - ETA: 26s - loss: 0.16274992/9568 [==============>...............] - ETA: 26s - loss: 0.16265056/9568 [==============>...............] - ETA: 25s - loss: 0.16285120/9568 [===============>..............] - ETA: 25s - loss: 0.16285184/9568 [===============>..............] - ETA: 24s - loss: 0.16265248/9568 [===============>..............] - ETA: 24s - loss: 0.16265312/9568 [===============>..............] - ETA: 24s - loss: 0.16245376/9568 [===============>..............] - ETA: 23s - loss: 0.16235440/9568 [================>.............] - ETA: 23s - loss: 0.16235504/9568 [================>.............] - ETA: 23s - loss: 0.16245568/9568 [================>.............] - ETA: 22s - loss: 0.16255632/9568 [================>.............] - ETA: 22s - loss: 0.16245696/9568 [================>.............] - ETA: 22s - loss: 0.16235760/9568 [=================>............] - ETA: 21s - loss: 0.16215824/9568 [=================>............] - ETA: 21s - loss: 0.16205888/9568 [=================>............] - ETA: 21s - loss: 0.16215952/9568 [=================>............] - ETA: 20s - loss: 0.16236016/9568 [=================>............] - ETA: 20s - loss: 0.16246080/9568 [==================>...........] - ETA: 20s - loss: 0.16256144/9568 [==================>...........] - ETA: 19s - loss: 0.16356208/9568 [==================>...........] - ETA: 19s - loss: 0.16346272/9568 [==================>...........] - ETA: 19s - loss: 0.16326336/9568 [==================>...........] - ETA: 18s - loss: 0.16346400/9568 [===================>..........] - ETA: 18s - loss: 0.16356464/9568 [===================>..........] - ETA: 18s - loss: 0.16346528/9568 [===================>..........] - ETA: 17s - loss: 0.16336592/9568 [===================>..........] - ETA: 17s - loss: 0.16326656/9568 [===================>..........] - ETA: 17s - loss: 0.16326720/9568 [====================>.........] - ETA: 16s - loss: 0.16316784/9568 [====================>.........] - ETA: 16s - loss: 0.16376848/9568 [====================>.........] - ETA: 16s - loss: 0.16376912/9568 [====================>.........] - ETA: 15s - loss: 0.16376976/9568 [====================>.........] - ETA: 15s - loss: 0.16387040/9568 [=====================>........] - ETA: 14s - loss: 0.16427104/9568 [=====================>........] - ETA: 14s - loss: 0.16407168/9568 [=====================>........] - ETA: 14s - loss: 0.16387232/9568 [=====================>........] - ETA: 13s - loss: 0.16367296/9568 [=====================>........] - ETA: 13s - loss: 0.16367360/9568 [======================>.......] - ETA: 13s - loss: 0.16357424/9568 [======================>.......] - ETA: 12s - loss: 0.16357488/9568 [======================>.......] - ETA: 12s - loss: 0.16347552/9568 [======================>.......] - ETA: 11s - loss: 0.16337616/9568 [======================>.......] - ETA: 11s - loss: 0.16377680/9568 [=======================>......] - ETA: 11s - loss: 0.16347744/9568 [=======================>......] - ETA: 10s - loss: 0.16347808/9568 [=======================>......] - ETA: 10s - loss: 0.16317872/9568 [=======================>......] - ETA: 9s - loss: 0.1631 7936/9568 [=======================>......] - ETA: 9s - loss: 0.16318000/9568 [========================>.....] - ETA: 9s - loss: 0.16328064/9568 [========================>.....] - ETA: 8s - loss: 0.16328128/9568 [========================>.....] - ETA: 8s - loss: 0.16308192/9568 [========================>.....] - ETA: 8s - loss: 0.16298256/9568 [========================>.....] - ETA: 7s - loss: 0.16288320/9568 [=========================>....] - ETA: 7s - loss: 0.16298384/9568 [=========================>....] - ETA: 6s - loss: 0.16338448/9568 [=========================>....] - ETA: 6s - loss: 0.16308512/9568 [=========================>....] - ETA: 6s - loss: 0.16298576/9568 [=========================>....] - ETA: 5s - loss: 0.16298640/9568 [==========================>...] - ETA: 5s - loss: 0.16288704/9568 [==========================>...] - ETA: 5s - loss: 0.16278768/9568 [==========================>...] - ETA: 4s - loss: 0.16278832/9568 [==========================>...] - ETA: 4s - loss: 0.16258896/9568 [==========================>...] - ETA: 3s - loss: 0.16248960/9568 [===========================>..] - ETA: 3s - loss: 0.16239024/9568 [===========================>..] - ETA: 3s - loss: 0.16229088/9568 [===========================>..] - ETA: 2s - loss: 0.16259152/9568 [===========================>..] - ETA: 2s - loss: 0.16269216/9568 [===========================>..] - ETA: 2s - loss: 0.16269280/9568 [============================>.] - ETA: 1s - loss: 0.16249344/9568 [============================>.] - ETA: 1s - loss: 0.16239408/9568 [============================>.] - ETA: 0s - loss: 0.16229472/9568 [============================>.] - ETA: 0s - loss: 0.16219536/9568 [============================>.] - ETA: 0s - loss: 0.1623
Epoch 00007: val_loss did not improve from 0.17300
9568/9568 [==============================] - 58s 6ms/sample - loss: 0.1623 - val_loss: 0.1743
Epoch 8/100
  64/9568 [..............................] - ETA: 25s - loss: 0.1722 128/9568 [..............................] - ETA: 44s - loss: 0.1615 192/9568 [..............................] - ETA: 43s - loss: 0.1713 256/9568 [..............................] - ETA: 43s - loss: 0.1659 320/9568 [>.............................] - ETA: 50s - loss: 0.1633 384/9568 [>.............................] - ETA: 51s - loss: 0.1609 448/9568 [>.............................] - ETA: 54s - loss: 0.1577 512/9568 [>.............................] - ETA: 52s - loss: 0.1567 576/9568 [>.............................] - ETA: 51s - loss: 0.1562 640/9568 [=>............................] - ETA: 49s - loss: 0.1619 704/9568 [=>............................] - ETA: 47s - loss: 0.1608 768/9568 [=>............................] - ETA: 46s - loss: 0.1580 832/9568 [=>............................] - ETA: 45s - loss: 0.1568 896/9568 [=>............................] - ETA: 47s - loss: 0.1573 960/9568 [==>...........................] - ETA: 47s - loss: 0.15901024/9568 [==>...........................] - ETA: 46s - loss: 0.15851088/9568 [==>...........................] - ETA: 48s - loss: 0.16041152/9568 [==>...........................] - ETA: 51s - loss: 0.16151216/9568 [==>...........................] - ETA: 50s - loss: 0.16231280/9568 [===>..........................] - ETA: 51s - loss: 0.16371344/9568 [===>..........................] - ETA: 51s - loss: 0.16281408/9568 [===>..........................] - ETA: 49s - loss: 0.16181472/9568 [===>..........................] - ETA: 50s - loss: 0.16211536/9568 [===>..........................] - ETA: 51s - loss: 0.16071600/9568 [====>.........................] - ETA: 51s - loss: 0.16181664/9568 [====>.........................] - ETA: 50s - loss: 0.16121728/9568 [====>.........................] - ETA: 49s - loss: 0.16211792/9568 [====>.........................] - ETA: 49s - loss: 0.16151856/9568 [====>.........................] - ETA: 50s - loss: 0.16081920/9568 [=====>........................] - ETA: 50s - loss: 0.16051984/9568 [=====>........................] - ETA: 49s - loss: 0.16142048/9568 [=====>........................] - ETA: 49s - loss: 0.16052112/9568 [=====>........................] - ETA: 48s - loss: 0.16062176/9568 [=====>........................] - ETA: 47s - loss: 0.16002240/9568 [======>.......................] - ETA: 46s - loss: 0.15932304/9568 [======>.......................] - ETA: 46s - loss: 0.15902368/9568 [======>.......................] - ETA: 46s - loss: 0.15822432/9568 [======>.......................] - ETA: 45s - loss: 0.15812496/9568 [======>.......................] - ETA: 45s - loss: 0.15762560/9568 [=======>......................] - ETA: 44s - loss: 0.15692624/9568 [=======>......................] - ETA: 43s - loss: 0.15662688/9568 [=======>......................] - ETA: 42s - loss: 0.15762752/9568 [=======>......................] - ETA: 42s - loss: 0.15802816/9568 [=======>......................] - ETA: 42s - loss: 0.15782880/9568 [========>.....................] - ETA: 41s - loss: 0.15752944/9568 [========>.....................] - ETA: 41s - loss: 0.15843008/9568 [========>.....................] - ETA: 40s - loss: 0.15823072/9568 [========>.....................] - ETA: 40s - loss: 0.15823136/9568 [========>.....................] - ETA: 39s - loss: 0.15783200/9568 [=========>....................] - ETA: 39s - loss: 0.15783264/9568 [=========>....................] - ETA: 39s - loss: 0.15733328/9568 [=========>....................] - ETA: 38s - loss: 0.15693392/9568 [=========>....................] - ETA: 37s - loss: 0.15673456/9568 [=========>....................] - ETA: 37s - loss: 0.15653520/9568 [==========>...................] - ETA: 36s - loss: 0.15643584/9568 [==========>...................] - ETA: 36s - loss: 0.15623648/9568 [==========>...................] - ETA: 35s - loss: 0.15583712/9568 [==========>...................] - ETA: 35s - loss: 0.15633776/9568 [==========>...................] - ETA: 34s - loss: 0.15653840/9568 [===========>..................] - ETA: 34s - loss: 0.15633904/9568 [===========>..................] - ETA: 33s - loss: 0.15613968/9568 [===========>..................] - ETA: 33s - loss: 0.15584032/9568 [===========>..................] - ETA: 33s - loss: 0.15624096/9568 [===========>..................] - ETA: 33s - loss: 0.15624160/9568 [============>.................] - ETA: 33s - loss: 0.15594224/9568 [============>.................] - ETA: 32s - loss: 0.15584288/9568 [============>.................] - ETA: 31s - loss: 0.15574352/9568 [============>.................] - ETA: 31s - loss: 0.15564416/9568 [============>.................] - ETA: 31s - loss: 0.15564480/9568 [=============>................] - ETA: 30s - loss: 0.15584544/9568 [=============>................] - ETA: 29s - loss: 0.15564608/9568 [=============>................] - ETA: 29s - loss: 0.15584672/9568 [=============>................] - ETA: 29s - loss: 0.15594736/9568 [=============>................] - ETA: 28s - loss: 0.15634800/9568 [==============>...............] - ETA: 28s - loss: 0.15644864/9568 [==============>...............] - ETA: 27s - loss: 0.15604928/9568 [==============>...............] - ETA: 27s - loss: 0.15594992/9568 [==============>...............] - ETA: 27s - loss: 0.15605056/9568 [==============>...............] - ETA: 26s - loss: 0.15615120/9568 [===============>..............] - ETA: 26s - loss: 0.15615184/9568 [===============>..............] - ETA: 25s - loss: 0.15615248/9568 [===============>..............] - ETA: 25s - loss: 0.15605312/9568 [===============>..............] - ETA: 25s - loss: 0.15605376/9568 [===============>..............] - ETA: 24s - loss: 0.15585440/9568 [================>.............] - ETA: 24s - loss: 0.15585504/9568 [================>.............] - ETA: 23s - loss: 0.15595568/9568 [================>.............] - ETA: 23s - loss: 0.15565632/9568 [================>.............] - ETA: 23s - loss: 0.15575696/9568 [================>.............] - ETA: 22s - loss: 0.15595760/9568 [=================>............] - ETA: 22s - loss: 0.15585824/9568 [=================>............] - ETA: 21s - loss: 0.15575888/9568 [=================>............] - ETA: 21s - loss: 0.15565952/9568 [=================>............] - ETA: 20s - loss: 0.15576016/9568 [=================>............] - ETA: 20s - loss: 0.15576080/9568 [==================>...........] - ETA: 20s - loss: 0.15626144/9568 [==================>...........] - ETA: 19s - loss: 0.15616208/9568 [==================>...........] - ETA: 19s - loss: 0.15616272/9568 [==================>...........] - ETA: 18s - loss: 0.15646336/9568 [==================>...........] - ETA: 18s - loss: 0.15646400/9568 [===================>..........] - ETA: 18s - loss: 0.15616464/9568 [===================>..........] - ETA: 17s - loss: 0.15636528/9568 [===================>..........] - ETA: 17s - loss: 0.15616592/9568 [===================>..........] - ETA: 16s - loss: 0.15626656/9568 [===================>..........] - ETA: 16s - loss: 0.15616720/9568 [====================>.........] - ETA: 16s - loss: 0.15646784/9568 [====================>.........] - ETA: 15s - loss: 0.15686848/9568 [====================>.........] - ETA: 15s - loss: 0.15746912/9568 [====================>.........] - ETA: 14s - loss: 0.15756976/9568 [====================>.........] - ETA: 14s - loss: 0.15787040/9568 [=====================>........] - ETA: 14s - loss: 0.15777104/9568 [=====================>........] - ETA: 13s - loss: 0.15767168/9568 [=====================>........] - ETA: 13s - loss: 0.15767232/9568 [=====================>........] - ETA: 12s - loss: 0.15747296/9568 [=====================>........] - ETA: 12s - loss: 0.15737360/9568 [======================>.......] - ETA: 12s - loss: 0.15747424/9568 [======================>.......] - ETA: 11s - loss: 0.15737488/9568 [======================>.......] - ETA: 11s - loss: 0.15737552/9568 [======================>.......] - ETA: 11s - loss: 0.15747616/9568 [======================>.......] - ETA: 10s - loss: 0.15787680/9568 [=======================>......] - ETA: 10s - loss: 0.15767744/9568 [=======================>......] - ETA: 10s - loss: 0.15747808/9568 [=======================>......] - ETA: 9s - loss: 0.1574 7872/9568 [=======================>......] - ETA: 9s - loss: 0.15737936/9568 [=======================>......] - ETA: 9s - loss: 0.15748000/9568 [========================>.....] - ETA: 8s - loss: 0.15748064/9568 [========================>.....] - ETA: 8s - loss: 0.15768128/9568 [========================>.....] - ETA: 7s - loss: 0.15778192/9568 [========================>.....] - ETA: 7s - loss: 0.15758256/9568 [========================>.....] - ETA: 7s - loss: 0.15748320/9568 [=========================>....] - ETA: 6s - loss: 0.15768384/9568 [=========================>....] - ETA: 6s - loss: 0.15778448/9568 [=========================>....] - ETA: 6s - loss: 0.15778512/9568 [=========================>....] - ETA: 5s - loss: 0.15768576/9568 [=========================>....] - ETA: 5s - loss: 0.15758640/9568 [==========================>...] - ETA: 5s - loss: 0.15748704/9568 [==========================>...] - ETA: 4s - loss: 0.15768768/9568 [==========================>...] - ETA: 4s - loss: 0.15798832/9568 [==========================>...] - ETA: 4s - loss: 0.15788896/9568 [==========================>...] - ETA: 3s - loss: 0.15798960/9568 [===========================>..] - ETA: 3s - loss: 0.15809024/9568 [===========================>..] - ETA: 3s - loss: 0.15799088/9568 [===========================>..] - ETA: 2s - loss: 0.15789152/9568 [===========================>..] - ETA: 2s - loss: 0.15779216/9568 [===========================>..] - ETA: 2s - loss: 0.15779280/9568 [============================>.] - ETA: 1s - loss: 0.15759344/9568 [============================>.] - ETA: 1s - loss: 0.15739408/9568 [============================>.] - ETA: 0s - loss: 0.15739472/9568 [============================>.] - ETA: 0s - loss: 0.15749536/9568 [============================>.] - ETA: 0s - loss: 0.1575
Epoch 00008: val_loss did not improve from 0.17300
9568/9568 [==============================] - 58s 6ms/sample - loss: 0.1575 - val_loss: 0.1853
Epoch 9/100
  64/9568 [..............................] - ETA: 54s - loss: 0.1717 128/9568 [..............................] - ETA: 57s - loss: 0.1609 192/9568 [..............................] - ETA: 48s - loss: 0.1543 256/9568 [..............................] - ETA: 46s - loss: 0.1505 320/9568 [>.............................] - ETA: 45s - loss: 0.1499 384/9568 [>.............................] - ETA: 43s - loss: 0.1552 448/9568 [>.............................] - ETA: 47s - loss: 0.1525 512/9568 [>.............................] - ETA: 48s - loss: 0.1502 576/9568 [>.............................] - ETA: 47s - loss: 0.1561 640/9568 [=>............................] - ETA: 48s - loss: 0.1553 704/9568 [=>............................] - ETA: 49s - loss: 0.1562 768/9568 [=>............................] - ETA: 49s - loss: 0.1558 832/9568 [=>............................] - ETA: 47s - loss: 0.1561 896/9568 [=>............................] - ETA: 45s - loss: 0.1587 960/9568 [==>...........................] - ETA: 43s - loss: 0.15801024/9568 [==>...........................] - ETA: 43s - loss: 0.15671088/9568 [==>...........................] - ETA: 42s - loss: 0.15811152/9568 [==>...........................] - ETA: 41s - loss: 0.15761216/9568 [==>...........................] - ETA: 41s - loss: 0.15731280/9568 [===>..........................] - ETA: 42s - loss: 0.15821344/9568 [===>..........................] - ETA: 43s - loss: 0.15671408/9568 [===>..........................] - ETA: 42s - loss: 0.15581472/9568 [===>..........................] - ETA: 42s - loss: 0.15831536/9568 [===>..........................] - ETA: 41s - loss: 0.15841600/9568 [====>.........................] - ETA: 40s - loss: 0.15821664/9568 [====>.........................] - ETA: 39s - loss: 0.15811728/9568 [====>.........................] - ETA: 40s - loss: 0.15701792/9568 [====>.........................] - ETA: 39s - loss: 0.15631856/9568 [====>.........................] - ETA: 39s - loss: 0.15631920/9568 [=====>........................] - ETA: 38s - loss: 0.15581984/9568 [=====>........................] - ETA: 38s - loss: 0.15552048/9568 [=====>........................] - ETA: 38s - loss: 0.15452112/9568 [=====>........................] - ETA: 38s - loss: 0.15462176/9568 [=====>........................] - ETA: 37s - loss: 0.15512240/9568 [======>.......................] - ETA: 37s - loss: 0.15452304/9568 [======>.......................] - ETA: 36s - loss: 0.15552368/9568 [======>.......................] - ETA: 37s - loss: 0.15562432/9568 [======>.......................] - ETA: 37s - loss: 0.15502496/9568 [======>.......................] - ETA: 36s - loss: 0.15472560/9568 [=======>......................] - ETA: 36s - loss: 0.15432624/9568 [=======>......................] - ETA: 36s - loss: 0.15402688/9568 [=======>......................] - ETA: 35s - loss: 0.15392752/9568 [=======>......................] - ETA: 35s - loss: 0.15462816/9568 [=======>......................] - ETA: 35s - loss: 0.15432880/9568 [========>.....................] - ETA: 34s - loss: 0.15482944/9568 [========>.....................] - ETA: 34s - loss: 0.15473008/9568 [========>.....................] - ETA: 34s - loss: 0.15473072/9568 [========>.....................] - ETA: 33s - loss: 0.15533136/9568 [========>.....................] - ETA: 33s - loss: 0.15513200/9568 [=========>....................] - ETA: 32s - loss: 0.15543264/9568 [=========>....................] - ETA: 33s - loss: 0.15573328/9568 [=========>....................] - ETA: 32s - loss: 0.15563392/9568 [=========>....................] - ETA: 32s - loss: 0.15603456/9568 [=========>....................] - ETA: 32s - loss: 0.15573520/9568 [==========>...................] - ETA: 32s - loss: 0.15533584/9568 [==========>...................] - ETA: 31s - loss: 0.15533648/9568 [==========>...................] - ETA: 31s - loss: 0.15583712/9568 [==========>...................] - ETA: 30s - loss: 0.15563776/9568 [==========>...................] - ETA: 30s - loss: 0.15583840/9568 [===========>..................] - ETA: 29s - loss: 0.15553904/9568 [===========>..................] - ETA: 30s - loss: 0.15583968/9568 [===========>..................] - ETA: 29s - loss: 0.15584032/9568 [===========>..................] - ETA: 29s - loss: 0.15574096/9568 [===========>..................] - ETA: 29s - loss: 0.15584160/9568 [============>.................] - ETA: 30s - loss: 0.15554224/9568 [============>.................] - ETA: 29s - loss: 0.15564288/9568 [============>.................] - ETA: 29s - loss: 0.15614352/9568 [============>.................] - ETA: 28s - loss: 0.15674416/9568 [============>.................] - ETA: 28s - loss: 0.15644480/9568 [=============>................] - ETA: 27s - loss: 0.15644544/9568 [=============>................] - ETA: 27s - loss: 0.15624608/9568 [=============>................] - ETA: 27s - loss: 0.15614672/9568 [=============>................] - ETA: 27s - loss: 0.15594736/9568 [=============>................] - ETA: 26s - loss: 0.15584800/9568 [==============>...............] - ETA: 26s - loss: 0.15544864/9568 [==============>...............] - ETA: 26s - loss: 0.15514928/9568 [==============>...............] - ETA: 26s - loss: 0.15514992/9568 [==============>...............] - ETA: 25s - loss: 0.15495056/9568 [==============>...............] - ETA: 25s - loss: 0.15475120/9568 [===============>..............] - ETA: 24s - loss: 0.15445184/9568 [===============>..............] - ETA: 24s - loss: 0.15465248/9568 [===============>..............] - ETA: 24s - loss: 0.15435312/9568 [===============>..............] - ETA: 23s - loss: 0.15455376/9568 [===============>..............] - ETA: 23s - loss: 0.15425440/9568 [================>.............] - ETA: 23s - loss: 0.15435504/9568 [================>.............] - ETA: 22s - loss: 0.15455568/9568 [================>.............] - ETA: 22s - loss: 0.15415632/9568 [================>.............] - ETA: 21s - loss: 0.15405696/9568 [================>.............] - ETA: 21s - loss: 0.15395760/9568 [=================>............] - ETA: 21s - loss: 0.15365824/9568 [=================>............] - ETA: 20s - loss: 0.15345888/9568 [=================>............] - ETA: 20s - loss: 0.15335952/9568 [=================>............] - ETA: 20s - loss: 0.15316016/9568 [=================>............] - ETA: 20s - loss: 0.15296080/9568 [==================>...........] - ETA: 19s - loss: 0.15316144/9568 [==================>...........] - ETA: 19s - loss: 0.15286208/9568 [==================>...........] - ETA: 18s - loss: 0.15276272/9568 [==================>...........] - ETA: 18s - loss: 0.15256336/9568 [==================>...........] - ETA: 18s - loss: 0.15286400/9568 [===================>..........] - ETA: 17s - loss: 0.15266464/9568 [===================>..........] - ETA: 17s - loss: 0.15236528/9568 [===================>..........] - ETA: 17s - loss: 0.15216592/9568 [===================>..........] - ETA: 16s - loss: 0.15226656/9568 [===================>..........] - ETA: 16s - loss: 0.15226720/9568 [====================>.........] - ETA: 15s - loss: 0.15216784/9568 [====================>.........] - ETA: 15s - loss: 0.15206848/9568 [====================>.........] - ETA: 15s - loss: 0.15196912/9568 [====================>.........] - ETA: 15s - loss: 0.15176976/9568 [====================>.........] - ETA: 14s - loss: 0.15207040/9568 [=====================>........] - ETA: 14s - loss: 0.15207104/9568 [=====================>........] - ETA: 14s - loss: 0.15217168/9568 [=====================>........] - ETA: 13s - loss: 0.15217232/9568 [=====================>........] - ETA: 13s - loss: 0.15227296/9568 [=====================>........] - ETA: 12s - loss: 0.15247360/9568 [======================>.......] - ETA: 12s - loss: 0.15257424/9568 [======================>.......] - ETA: 12s - loss: 0.15257488/9568 [======================>.......] - ETA: 11s - loss: 0.15257552/9568 [======================>.......] - ETA: 11s - loss: 0.15287616/9568 [======================>.......] - ETA: 11s - loss: 0.15277680/9568 [=======================>......] - ETA: 10s - loss: 0.15277744/9568 [=======================>......] - ETA: 10s - loss: 0.15267808/9568 [=======================>......] - ETA: 10s - loss: 0.15247872/9568 [=======================>......] - ETA: 9s - loss: 0.1526 7936/9568 [=======================>......] - ETA: 9s - loss: 0.15268000/9568 [========================>.....] - ETA: 9s - loss: 0.15268064/9568 [========================>.....] - ETA: 8s - loss: 0.15258128/9568 [========================>.....] - ETA: 8s - loss: 0.15268192/9568 [========================>.....] - ETA: 7s - loss: 0.15278256/9568 [========================>.....] - ETA: 7s - loss: 0.15278320/9568 [=========================>....] - ETA: 7s - loss: 0.15298384/9568 [=========================>....] - ETA: 6s - loss: 0.15288448/9568 [=========================>....] - ETA: 6s - loss: 0.15308512/9568 [=========================>....] - ETA: 6s - loss: 0.15288576/9568 [=========================>....] - ETA: 5s - loss: 0.15288640/9568 [==========================>...] - ETA: 5s - loss: 0.15258704/9568 [==========================>...] - ETA: 4s - loss: 0.15248768/9568 [==========================>...] - ETA: 4s - loss: 0.15248832/9568 [==========================>...] - ETA: 4s - loss: 0.15258896/9568 [==========================>...] - ETA: 3s - loss: 0.15248960/9568 [===========================>..] - ETA: 3s - loss: 0.15259024/9568 [===========================>..] - ETA: 3s - loss: 0.15239088/9568 [===========================>..] - ETA: 2s - loss: 0.15259152/9568 [===========================>..] - ETA: 2s - loss: 0.15249216/9568 [===========================>..] - ETA: 1s - loss: 0.15259280/9568 [============================>.] - ETA: 1s - loss: 0.15249344/9568 [============================>.] - ETA: 1s - loss: 0.15259408/9568 [============================>.] - ETA: 0s - loss: 0.15249472/9568 [============================>.] - ETA: 0s - loss: 0.15259536/9568 [============================>.] - ETA: 0s - loss: 0.1524
Epoch 00009: val_loss improved from 0.17300 to 0.16788, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 58s 6ms/sample - loss: 0.1523 - val_loss: 0.1679
Epoch 10/100
  64/9568 [..............................] - ETA: 47s - loss: 0.1529 128/9568 [..............................] - ETA: 54s - loss: 0.1575 192/9568 [..............................] - ETA: 1:05 - loss: 0.1657 256/9568 [..............................] - ETA: 56s - loss: 0.1585  320/9568 [>.............................] - ETA: 59s - loss: 0.1632 384/9568 [>.............................] - ETA: 55s - loss: 0.1577 448/9568 [>.............................] - ETA: 57s - loss: 0.1551 512/9568 [>.............................] - ETA: 59s - loss: 0.1572 576/9568 [>.............................] - ETA: 1:01 - loss: 0.1560 640/9568 [=>............................] - ETA: 58s - loss: 0.1553  704/9568 [=>............................] - ETA: 59s - loss: 0.1550 768/9568 [=>............................] - ETA: 58s - loss: 0.1530 832/9568 [=>............................] - ETA: 58s - loss: 0.1536 896/9568 [=>............................] - ETA: 1:02 - loss: 0.1544 960/9568 [==>...........................] - ETA: 1:00 - loss: 0.15341024/9568 [==>...........................] - ETA: 59s - loss: 0.1570 1088/9568 [==>...........................] - ETA: 57s - loss: 0.15681152/9568 [==>...........................] - ETA: 56s - loss: 0.15561216/9568 [==>...........................] - ETA: 56s - loss: 0.15701280/9568 [===>..........................] - ETA: 56s - loss: 0.15631344/9568 [===>..........................] - ETA: 58s - loss: 0.15541408/9568 [===>..........................] - ETA: 58s - loss: 0.15421472/9568 [===>..........................] - ETA: 58s - loss: 0.15431536/9568 [===>..........................] - ETA: 57s - loss: 0.15501600/9568 [====>.........................] - ETA: 57s - loss: 0.15571664/9568 [====>.........................] - ETA: 56s - loss: 0.15561728/9568 [====>.........................] - ETA: 55s - loss: 0.15541792/9568 [====>.........................] - ETA: 55s - loss: 0.15581856/9568 [====>.........................] - ETA: 54s - loss: 0.15591920/9568 [=====>........................] - ETA: 54s - loss: 0.15501984/9568 [=====>........................] - ETA: 53s - loss: 0.15442048/9568 [=====>........................] - ETA: 52s - loss: 0.15432112/9568 [=====>........................] - ETA: 52s - loss: 0.15562176/9568 [=====>........................] - ETA: 51s - loss: 0.15562240/9568 [======>.......................] - ETA: 50s - loss: 0.15462304/9568 [======>.......................] - ETA: 49s - loss: 0.15432368/9568 [======>.......................] - ETA: 48s - loss: 0.15392432/9568 [======>.......................] - ETA: 47s - loss: 0.15332496/9568 [======>.......................] - ETA: 46s - loss: 0.15312560/9568 [=======>......................] - ETA: 46s - loss: 0.15282624/9568 [=======>......................] - ETA: 45s - loss: 0.15242688/9568 [=======>......................] - ETA: 46s - loss: 0.15192752/9568 [=======>......................] - ETA: 45s - loss: 0.15152816/9568 [=======>......................] - ETA: 45s - loss: 0.15132880/9568 [========>.....................] - ETA: 44s - loss: 0.15092944/9568 [========>.....................] - ETA: 44s - loss: 0.15093008/9568 [========>.....................] - ETA: 43s - loss: 0.15093072/9568 [========>.....................] - ETA: 42s - loss: 0.15053136/9568 [========>.....................] - ETA: 42s - loss: 0.15013200/9568 [=========>....................] - ETA: 41s - loss: 0.15013264/9568 [=========>....................] - ETA: 40s - loss: 0.15033328/9568 [=========>....................] - ETA: 40s - loss: 0.15023392/9568 [=========>....................] - ETA: 39s - loss: 0.15013456/9568 [=========>....................] - ETA: 38s - loss: 0.14993520/9568 [==========>...................] - ETA: 38s - loss: 0.14983584/9568 [==========>...................] - ETA: 37s - loss: 0.14953648/9568 [==========>...................] - ETA: 37s - loss: 0.14953712/9568 [==========>...................] - ETA: 37s - loss: 0.14973776/9568 [==========>...................] - ETA: 36s - loss: 0.14993840/9568 [===========>..................] - ETA: 36s - loss: 0.14973904/9568 [===========>..................] - ETA: 35s - loss: 0.14993968/9568 [===========>..................] - ETA: 35s - loss: 0.14964032/9568 [===========>..................] - ETA: 35s - loss: 0.14944096/9568 [===========>..................] - ETA: 34s - loss: 0.14924160/9568 [============>.................] - ETA: 34s - loss: 0.14934224/9568 [============>.................] - ETA: 33s - loss: 0.14914288/9568 [============>.................] - ETA: 32s - loss: 0.14934352/9568 [============>.................] - ETA: 32s - loss: 0.14924416/9568 [============>.................] - ETA: 31s - loss: 0.14954480/9568 [=============>................] - ETA: 31s - loss: 0.14924544/9568 [=============>................] - ETA: 31s - loss: 0.14914608/9568 [=============>................] - ETA: 30s - loss: 0.14914672/9568 [=============>................] - ETA: 30s - loss: 0.14914736/9568 [=============>................] - ETA: 29s - loss: 0.14954800/9568 [==============>...............] - ETA: 29s - loss: 0.14924864/9568 [==============>...............] - ETA: 28s - loss: 0.14914928/9568 [==============>...............] - ETA: 28s - loss: 0.14884992/9568 [==============>...............] - ETA: 28s - loss: 0.14855056/9568 [==============>...............] - ETA: 27s - loss: 0.14865120/9568 [===============>..............] - ETA: 27s - loss: 0.14845184/9568 [===============>..............] - ETA: 26s - loss: 0.14855248/9568 [===============>..............] - ETA: 26s - loss: 0.14855312/9568 [===============>..............] - ETA: 25s - loss: 0.14875376/9568 [===============>..............] - ETA: 25s - loss: 0.14885440/9568 [================>.............] - ETA: 24s - loss: 0.14885504/9568 [================>.............] - ETA: 24s - loss: 0.14865568/9568 [================>.............] - ETA: 23s - loss: 0.14875632/9568 [================>.............] - ETA: 23s - loss: 0.14945696/9568 [================>.............] - ETA: 22s - loss: 0.14945760/9568 [=================>............] - ETA: 22s - loss: 0.14935824/9568 [=================>............] - ETA: 21s - loss: 0.14925888/9568 [=================>............] - ETA: 21s - loss: 0.14925952/9568 [=================>............] - ETA: 21s - loss: 0.14906016/9568 [=================>............] - ETA: 20s - loss: 0.14906080/9568 [==================>...........] - ETA: 20s - loss: 0.14946144/9568 [==================>...........] - ETA: 19s - loss: 0.14936208/9568 [==================>...........] - ETA: 19s - loss: 0.14916272/9568 [==================>...........] - ETA: 19s - loss: 0.14896336/9568 [==================>...........] - ETA: 19s - loss: 0.14906400/9568 [===================>..........] - ETA: 18s - loss: 0.14896464/9568 [===================>..........] - ETA: 18s - loss: 0.14956528/9568 [===================>..........] - ETA: 17s - loss: 0.14966592/9568 [===================>..........] - ETA: 17s - loss: 0.14936656/9568 [===================>..........] - ETA: 17s - loss: 0.14926720/9568 [====================>.........] - ETA: 17s - loss: 0.14926784/9568 [====================>.........] - ETA: 16s - loss: 0.14906848/9568 [====================>.........] - ETA: 16s - loss: 0.14906912/9568 [====================>.........] - ETA: 16s - loss: 0.14896976/9568 [====================>.........] - ETA: 15s - loss: 0.14897040/9568 [=====================>........] - ETA: 15s - loss: 0.14897104/9568 [=====================>........] - ETA: 15s - loss: 0.14887168/9568 [=====================>........] - ETA: 14s - loss: 0.14897232/9568 [=====================>........] - ETA: 14s - loss: 0.14897296/9568 [=====================>........] - ETA: 14s - loss: 0.14897360/9568 [======================>.......] - ETA: 13s - loss: 0.14877424/9568 [======================>.......] - ETA: 13s - loss: 0.14877488/9568 [======================>.......] - ETA: 12s - loss: 0.14877552/9568 [======================>.......] - ETA: 12s - loss: 0.14877616/9568 [======================>.......] - ETA: 12s - loss: 0.14867680/9568 [=======================>......] - ETA: 11s - loss: 0.14867744/9568 [=======================>......] - ETA: 11s - loss: 0.14877808/9568 [=======================>......] - ETA: 10s - loss: 0.14867872/9568 [=======================>......] - ETA: 10s - loss: 0.14857936/9568 [=======================>......] - ETA: 10s - loss: 0.14858000/9568 [========================>.....] - ETA: 9s - loss: 0.1486 8064/9568 [========================>.....] - ETA: 9s - loss: 0.14868128/9568 [========================>.....] - ETA: 8s - loss: 0.14858192/9568 [========================>.....] - ETA: 8s - loss: 0.14838256/9568 [========================>.....] - ETA: 8s - loss: 0.14828320/9568 [=========================>....] - ETA: 7s - loss: 0.14818384/9568 [=========================>....] - ETA: 7s - loss: 0.14818448/9568 [=========================>....] - ETA: 7s - loss: 0.14808512/9568 [=========================>....] - ETA: 6s - loss: 0.14788576/9568 [=========================>....] - ETA: 6s - loss: 0.14788640/9568 [==========================>...] - ETA: 5s - loss: 0.14778704/9568 [==========================>...] - ETA: 5s - loss: 0.14768768/9568 [==========================>...] - ETA: 4s - loss: 0.14758832/9568 [==========================>...] - ETA: 4s - loss: 0.14758896/9568 [==========================>...] - ETA: 4s - loss: 0.14748960/9568 [===========================>..] - ETA: 3s - loss: 0.14759024/9568 [===========================>..] - ETA: 3s - loss: 0.14749088/9568 [===========================>..] - ETA: 2s - loss: 0.14739152/9568 [===========================>..] - ETA: 2s - loss: 0.14739216/9568 [===========================>..] - ETA: 2s - loss: 0.14729280/9568 [============================>.] - ETA: 1s - loss: 0.14729344/9568 [============================>.] - ETA: 1s - loss: 0.14719408/9568 [============================>.] - ETA: 0s - loss: 0.14729472/9568 [============================>.] - ETA: 0s - loss: 0.14719536/9568 [============================>.] - ETA: 0s - loss: 0.1471
Epoch 00010: val_loss did not improve from 0.16788
9568/9568 [==============================] - 63s 7ms/sample - loss: 0.1471 - val_loss: 0.1785
Epoch 11/100
  64/9568 [..............................] - ETA: 28s - loss: 0.1437 128/9568 [..............................] - ETA: 28s - loss: 0.1418 192/9568 [..............................] - ETA: 34s - loss: 0.1367 256/9568 [..............................] - ETA: 33s - loss: 0.1402 320/9568 [>.............................] - ETA: 32s - loss: 0.1373 384/9568 [>.............................] - ETA: 32s - loss: 0.1402 448/9568 [>.............................] - ETA: 33s - loss: 0.1443 512/9568 [>.............................] - ETA: 37s - loss: 0.1436 576/9568 [>.............................] - ETA: 37s - loss: 0.1481 640/9568 [=>............................] - ETA: 38s - loss: 0.1473 704/9568 [=>............................] - ETA: 40s - loss: 0.1486 768/9568 [=>............................] - ETA: 40s - loss: 0.1474 832/9568 [=>............................] - ETA: 39s - loss: 0.1475 896/9568 [=>............................] - ETA: 38s - loss: 0.1470 960/9568 [==>...........................] - ETA: 37s - loss: 0.14711024/9568 [==>...........................] - ETA: 36s - loss: 0.14871088/9568 [==>...........................] - ETA: 37s - loss: 0.14741152/9568 [==>...........................] - ETA: 38s - loss: 0.14651216/9568 [==>...........................] - ETA: 38s - loss: 0.14581280/9568 [===>..........................] - ETA: 37s - loss: 0.14641344/9568 [===>..........................] - ETA: 37s - loss: 0.14901408/9568 [===>..........................] - ETA: 37s - loss: 0.14881472/9568 [===>..........................] - ETA: 36s - loss: 0.14821536/9568 [===>..........................] - ETA: 37s - loss: 0.14821600/9568 [====>.........................] - ETA: 36s - loss: 0.14801664/9568 [====>.........................] - ETA: 35s - loss: 0.14831728/9568 [====>.........................] - ETA: 35s - loss: 0.14821792/9568 [====>.........................] - ETA: 34s - loss: 0.14811856/9568 [====>.........................] - ETA: 34s - loss: 0.14721920/9568 [=====>........................] - ETA: 34s - loss: 0.14711984/9568 [=====>........................] - ETA: 34s - loss: 0.14862048/9568 [=====>........................] - ETA: 35s - loss: 0.14802112/9568 [=====>........................] - ETA: 35s - loss: 0.14792176/9568 [=====>........................] - ETA: 36s - loss: 0.14752240/9568 [======>.......................] - ETA: 36s - loss: 0.14772304/9568 [======>.......................] - ETA: 36s - loss: 0.14802368/9568 [======>.......................] - ETA: 36s - loss: 0.14832432/9568 [======>.......................] - ETA: 36s - loss: 0.14792496/9568 [======>.......................] - ETA: 36s - loss: 0.14722560/9568 [=======>......................] - ETA: 36s - loss: 0.14682624/9568 [=======>......................] - ETA: 36s - loss: 0.14662688/9568 [=======>......................] - ETA: 36s - loss: 0.14662752/9568 [=======>......................] - ETA: 36s - loss: 0.14692816/9568 [=======>......................] - ETA: 35s - loss: 0.14662880/9568 [========>.....................] - ETA: 35s - loss: 0.14742944/9568 [========>.....................] - ETA: 35s - loss: 0.14753008/9568 [========>.....................] - ETA: 35s - loss: 0.14723072/9568 [========>.....................] - ETA: 35s - loss: 0.14743136/9568 [========>.....................] - ETA: 35s - loss: 0.14713200/9568 [=========>....................] - ETA: 35s - loss: 0.14693264/9568 [=========>....................] - ETA: 35s - loss: 0.14713328/9568 [=========>....................] - ETA: 35s - loss: 0.14693392/9568 [=========>....................] - ETA: 35s - loss: 0.14673456/9568 [=========>....................] - ETA: 34s - loss: 0.14663520/9568 [==========>...................] - ETA: 34s - loss: 0.14653584/9568 [==========>...................] - ETA: 34s - loss: 0.14613648/9568 [==========>...................] - ETA: 34s - loss: 0.14603712/9568 [==========>...................] - ETA: 33s - loss: 0.14583776/9568 [==========>...................] - ETA: 32s - loss: 0.14573840/9568 [===========>..................] - ETA: 32s - loss: 0.14543904/9568 [===========>..................] - ETA: 31s - loss: 0.14543968/9568 [===========>..................] - ETA: 31s - loss: 0.14524032/9568 [===========>..................] - ETA: 31s - loss: 0.14484096/9568 [===========>..................] - ETA: 31s - loss: 0.14524160/9568 [============>.................] - ETA: 30s - loss: 0.14524224/9568 [============>.................] - ETA: 30s - loss: 0.14534288/9568 [============>.................] - ETA: 30s - loss: 0.14534352/9568 [============>.................] - ETA: 29s - loss: 0.14504416/9568 [============>.................] - ETA: 29s - loss: 0.14484480/9568 [=============>................] - ETA: 29s - loss: 0.14474544/9568 [=============>................] - ETA: 28s - loss: 0.14474608/9568 [=============>................] - ETA: 28s - loss: 0.14464672/9568 [=============>................] - ETA: 28s - loss: 0.14464736/9568 [=============>................] - ETA: 27s - loss: 0.14464800/9568 [==============>...............] - ETA: 27s - loss: 0.14454864/9568 [==============>...............] - ETA: 27s - loss: 0.14434928/9568 [==============>...............] - ETA: 26s - loss: 0.14414992/9568 [==============>...............] - ETA: 26s - loss: 0.14415056/9568 [==============>...............] - ETA: 25s - loss: 0.14405120/9568 [===============>..............] - ETA: 25s - loss: 0.14415184/9568 [===============>..............] - ETA: 24s - loss: 0.14385248/9568 [===============>..............] - ETA: 24s - loss: 0.14375312/9568 [===============>..............] - ETA: 24s - loss: 0.14385376/9568 [===============>..............] - ETA: 23s - loss: 0.14355440/9568 [================>.............] - ETA: 23s - loss: 0.14385504/9568 [================>.............] - ETA: 22s - loss: 0.14385568/9568 [================>.............] - ETA: 22s - loss: 0.14365632/9568 [================>.............] - ETA: 21s - loss: 0.14345696/9568 [================>.............] - ETA: 21s - loss: 0.14335760/9568 [=================>............] - ETA: 21s - loss: 0.14375824/9568 [=================>............] - ETA: 20s - loss: 0.14385888/9568 [=================>............] - ETA: 20s - loss: 0.14385952/9568 [=================>............] - ETA: 19s - loss: 0.14366016/9568 [=================>............] - ETA: 19s - loss: 0.14336080/9568 [==================>...........] - ETA: 19s - loss: 0.14326144/9568 [==================>...........] - ETA: 18s - loss: 0.14366208/9568 [==================>...........] - ETA: 18s - loss: 0.14356272/9568 [==================>...........] - ETA: 17s - loss: 0.14356336/9568 [==================>...........] - ETA: 17s - loss: 0.14346400/9568 [===================>..........] - ETA: 17s - loss: 0.14336464/9568 [===================>..........] - ETA: 16s - loss: 0.14336528/9568 [===================>..........] - ETA: 16s - loss: 0.14316592/9568 [===================>..........] - ETA: 16s - loss: 0.14306656/9568 [===================>..........] - ETA: 15s - loss: 0.14286720/9568 [====================>.........] - ETA: 15s - loss: 0.14286784/9568 [====================>.........] - ETA: 14s - loss: 0.14256848/9568 [====================>.........] - ETA: 14s - loss: 0.14276912/9568 [====================>.........] - ETA: 14s - loss: 0.14266976/9568 [====================>.........] - ETA: 13s - loss: 0.14247040/9568 [=====================>........] - ETA: 13s - loss: 0.14237104/9568 [=====================>........] - ETA: 12s - loss: 0.14237168/9568 [=====================>........] - ETA: 12s - loss: 0.14247232/9568 [=====================>........] - ETA: 12s - loss: 0.14237296/9568 [=====================>........] - ETA: 11s - loss: 0.14237360/9568 [======================>.......] - ETA: 11s - loss: 0.14227424/9568 [======================>.......] - ETA: 11s - loss: 0.14207488/9568 [======================>.......] - ETA: 10s - loss: 0.14247552/9568 [======================>.......] - ETA: 10s - loss: 0.14257616/9568 [======================>.......] - ETA: 10s - loss: 0.14267680/9568 [=======================>......] - ETA: 9s - loss: 0.1424 7744/9568 [=======================>......] - ETA: 9s - loss: 0.14247808/9568 [=======================>......] - ETA: 9s - loss: 0.14267872/9568 [=======================>......] - ETA: 8s - loss: 0.14257936/9568 [=======================>......] - ETA: 8s - loss: 0.14258000/9568 [========================>.....] - ETA: 8s - loss: 0.14238064/9568 [========================>.....] - ETA: 7s - loss: 0.14238128/9568 [========================>.....] - ETA: 7s - loss: 0.14228192/9568 [========================>.....] - ETA: 7s - loss: 0.14208256/9568 [========================>.....] - ETA: 6s - loss: 0.14198320/9568 [=========================>....] - ETA: 6s - loss: 0.14198384/9568 [=========================>....] - ETA: 6s - loss: 0.14198448/9568 [=========================>....] - ETA: 5s - loss: 0.14248512/9568 [=========================>....] - ETA: 5s - loss: 0.14238576/9568 [=========================>....] - ETA: 5s - loss: 0.14228640/9568 [==========================>...] - ETA: 4s - loss: 0.14218704/9568 [==========================>...] - ETA: 4s - loss: 0.14218768/9568 [==========================>...] - ETA: 4s - loss: 0.14198832/9568 [==========================>...] - ETA: 3s - loss: 0.14198896/9568 [==========================>...] - ETA: 3s - loss: 0.14188960/9568 [===========================>..] - ETA: 3s - loss: 0.14179024/9568 [===========================>..] - ETA: 2s - loss: 0.14179088/9568 [===========================>..] - ETA: 2s - loss: 0.14169152/9568 [===========================>..] - ETA: 2s - loss: 0.14169216/9568 [===========================>..] - ETA: 1s - loss: 0.14159280/9568 [============================>.] - ETA: 1s - loss: 0.14169344/9568 [============================>.] - ETA: 1s - loss: 0.14169408/9568 [============================>.] - ETA: 0s - loss: 0.14159472/9568 [============================>.] - ETA: 0s - loss: 0.14179536/9568 [============================>.] - ETA: 0s - loss: 0.1416
Epoch 00011: val_loss did not improve from 0.16788
9568/9568 [==============================] - 53s 6ms/sample - loss: 0.1415 - val_loss: 0.1773
Epoch 12/100
  64/9568 [..............................] - ETA: 41s - loss: 0.1178 128/9568 [..............................] - ETA: 40s - loss: 0.1235 192/9568 [..............................] - ETA: 59s - loss: 0.1289 256/9568 [..............................] - ETA: 54s - loss: 0.1267 320/9568 [>.............................] - ETA: 53s - loss: 0.1308 384/9568 [>.............................] - ETA: 56s - loss: 0.1331 448/9568 [>.............................] - ETA: 59s - loss: 0.1347 512/9568 [>.............................] - ETA: 57s - loss: 0.1366 576/9568 [>.............................] - ETA: 54s - loss: 0.1364 640/9568 [=>............................] - ETA: 51s - loss: 0.1365 704/9568 [=>............................] - ETA: 51s - loss: 0.1392 768/9568 [=>............................] - ETA: 53s - loss: 0.1383 832/9568 [=>............................] - ETA: 52s - loss: 0.1371 896/9568 [=>............................] - ETA: 50s - loss: 0.1383 960/9568 [==>...........................] - ETA: 48s - loss: 0.13681024/9568 [==>...........................] - ETA: 48s - loss: 0.13671088/9568 [==>...........................] - ETA: 47s - loss: 0.13821152/9568 [==>...........................] - ETA: 45s - loss: 0.13751216/9568 [==>...........................] - ETA: 44s - loss: 0.13701280/9568 [===>..........................] - ETA: 43s - loss: 0.13721344/9568 [===>..........................] - ETA: 42s - loss: 0.13791408/9568 [===>..........................] - ETA: 41s - loss: 0.13871472/9568 [===>..........................] - ETA: 40s - loss: 0.13821536/9568 [===>..........................] - ETA: 40s - loss: 0.13811600/9568 [====>.........................] - ETA: 39s - loss: 0.13921664/9568 [====>.........................] - ETA: 40s - loss: 0.13931728/9568 [====>.........................] - ETA: 40s - loss: 0.13861792/9568 [====>.........................] - ETA: 39s - loss: 0.13821856/9568 [====>.........................] - ETA: 39s - loss: 0.13851920/9568 [=====>........................] - ETA: 39s - loss: 0.13841984/9568 [=====>........................] - ETA: 38s - loss: 0.13832048/9568 [=====>........................] - ETA: 38s - loss: 0.13822112/9568 [=====>........................] - ETA: 37s - loss: 0.13862176/9568 [=====>........................] - ETA: 37s - loss: 0.13842240/9568 [======>.......................] - ETA: 36s - loss: 0.13932304/9568 [======>.......................] - ETA: 36s - loss: 0.13922368/9568 [======>.......................] - ETA: 35s - loss: 0.13962432/9568 [======>.......................] - ETA: 34s - loss: 0.13982496/9568 [======>.......................] - ETA: 34s - loss: 0.14012560/9568 [=======>......................] - ETA: 33s - loss: 0.13992624/9568 [=======>......................] - ETA: 32s - loss: 0.14002688/9568 [=======>......................] - ETA: 32s - loss: 0.14002752/9568 [=======>......................] - ETA: 31s - loss: 0.14012816/9568 [=======>......................] - ETA: 31s - loss: 0.13982880/9568 [========>.....................] - ETA: 31s - loss: 0.14032944/9568 [========>.....................] - ETA: 31s - loss: 0.14073008/9568 [========>.....................] - ETA: 30s - loss: 0.14053072/9568 [========>.....................] - ETA: 30s - loss: 0.14033136/9568 [========>.....................] - ETA: 30s - loss: 0.14013200/9568 [=========>....................] - ETA: 30s - loss: 0.14003264/9568 [=========>....................] - ETA: 30s - loss: 0.14003328/9568 [=========>....................] - ETA: 29s - loss: 0.13983392/9568 [=========>....................] - ETA: 29s - loss: 0.13973456/9568 [=========>....................] - ETA: 29s - loss: 0.13983520/9568 [==========>...................] - ETA: 28s - loss: 0.13973584/9568 [==========>...................] - ETA: 28s - loss: 0.13953648/9568 [==========>...................] - ETA: 27s - loss: 0.13943712/9568 [==========>...................] - ETA: 27s - loss: 0.13923776/9568 [==========>...................] - ETA: 27s - loss: 0.13883840/9568 [===========>..................] - ETA: 27s - loss: 0.13863904/9568 [===========>..................] - ETA: 26s - loss: 0.13823968/9568 [===========>..................] - ETA: 26s - loss: 0.13804032/9568 [===========>..................] - ETA: 26s - loss: 0.13804096/9568 [===========>..................] - ETA: 27s - loss: 0.13804160/9568 [============>.................] - ETA: 26s - loss: 0.13794224/9568 [============>.................] - ETA: 26s - loss: 0.13764288/9568 [============>.................] - ETA: 26s - loss: 0.13754352/9568 [============>.................] - ETA: 26s - loss: 0.13764416/9568 [============>.................] - ETA: 25s - loss: 0.13774480/9568 [=============>................] - ETA: 25s - loss: 0.13774544/9568 [=============>................] - ETA: 24s - loss: 0.13784608/9568 [=============>................] - ETA: 24s - loss: 0.13774672/9568 [=============>................] - ETA: 24s - loss: 0.13764736/9568 [=============>................] - ETA: 23s - loss: 0.13764800/9568 [==============>...............] - ETA: 23s - loss: 0.13794864/9568 [==============>...............] - ETA: 23s - loss: 0.13804928/9568 [==============>...............] - ETA: 22s - loss: 0.13814992/9568 [==============>...............] - ETA: 22s - loss: 0.13865056/9568 [==============>...............] - ETA: 22s - loss: 0.13855120/9568 [===============>..............] - ETA: 21s - loss: 0.13855184/9568 [===============>..............] - ETA: 21s - loss: 0.13835248/9568 [===============>..............] - ETA: 21s - loss: 0.13855312/9568 [===============>..............] - ETA: 21s - loss: 0.13835376/9568 [===============>..............] - ETA: 20s - loss: 0.13825440/9568 [================>.............] - ETA: 20s - loss: 0.13815504/9568 [================>.............] - ETA: 20s - loss: 0.13795568/9568 [================>.............] - ETA: 19s - loss: 0.13795632/9568 [================>.............] - ETA: 19s - loss: 0.13785696/9568 [================>.............] - ETA: 19s - loss: 0.13795760/9568 [=================>............] - ETA: 18s - loss: 0.13785824/9568 [=================>............] - ETA: 18s - loss: 0.13775888/9568 [=================>............] - ETA: 17s - loss: 0.13745952/9568 [=================>............] - ETA: 17s - loss: 0.13726016/9568 [=================>............] - ETA: 17s - loss: 0.13696080/9568 [==================>...........] - ETA: 16s - loss: 0.13696144/9568 [==================>...........] - ETA: 16s - loss: 0.13676208/9568 [==================>...........] - ETA: 16s - loss: 0.13676272/9568 [==================>...........] - ETA: 15s - loss: 0.13676336/9568 [==================>...........] - ETA: 15s - loss: 0.13676400/9568 [===================>..........] - ETA: 15s - loss: 0.13676464/9568 [===================>..........] - ETA: 15s - loss: 0.13666528/9568 [===================>..........] - ETA: 14s - loss: 0.13666592/9568 [===================>..........] - ETA: 14s - loss: 0.13666656/9568 [===================>..........] - ETA: 14s - loss: 0.13656720/9568 [====================>.........] - ETA: 14s - loss: 0.13656784/9568 [====================>.........] - ETA: 13s - loss: 0.13656848/9568 [====================>.........] - ETA: 13s - loss: 0.13646912/9568 [====================>.........] - ETA: 13s - loss: 0.13636976/9568 [====================>.........] - ETA: 12s - loss: 0.13627040/9568 [=====================>........] - ETA: 12s - loss: 0.13627104/9568 [=====================>........] - ETA: 12s - loss: 0.13637168/9568 [=====================>........] - ETA: 11s - loss: 0.13617232/9568 [=====================>........] - ETA: 11s - loss: 0.13607296/9568 [=====================>........] - ETA: 11s - loss: 0.13597360/9568 [======================>.......] - ETA: 10s - loss: 0.13587424/9568 [======================>.......] - ETA: 10s - loss: 0.13597488/9568 [======================>.......] - ETA: 10s - loss: 0.13617552/9568 [======================>.......] - ETA: 9s - loss: 0.1360 7616/9568 [======================>.......] - ETA: 9s - loss: 0.13597680/9568 [=======================>......] - ETA: 9s - loss: 0.13587744/9568 [=======================>......] - ETA: 8s - loss: 0.13587808/9568 [=======================>......] - ETA: 8s - loss: 0.13597872/9568 [=======================>......] - ETA: 8s - loss: 0.13607936/9568 [=======================>......] - ETA: 7s - loss: 0.13608000/9568 [========================>.....] - ETA: 7s - loss: 0.13608064/9568 [========================>.....] - ETA: 7s - loss: 0.13608128/9568 [========================>.....] - ETA: 6s - loss: 0.13588192/9568 [========================>.....] - ETA: 6s - loss: 0.13578256/9568 [========================>.....] - ETA: 6s - loss: 0.13568320/9568 [=========================>....] - ETA: 5s - loss: 0.13578384/9568 [=========================>....] - ETA: 5s - loss: 0.13588448/9568 [=========================>....] - ETA: 5s - loss: 0.13578512/9568 [=========================>....] - ETA: 5s - loss: 0.13578576/9568 [=========================>....] - ETA: 4s - loss: 0.13588640/9568 [==========================>...] - ETA: 4s - loss: 0.13588704/9568 [==========================>...] - ETA: 4s - loss: 0.13598768/9568 [==========================>...] - ETA: 3s - loss: 0.13648832/9568 [==========================>...] - ETA: 3s - loss: 0.13638896/9568 [==========================>...] - ETA: 3s - loss: 0.13658960/9568 [===========================>..] - ETA: 2s - loss: 0.13649024/9568 [===========================>..] - ETA: 2s - loss: 0.13659088/9568 [===========================>..] - ETA: 2s - loss: 0.13689152/9568 [===========================>..] - ETA: 1s - loss: 0.13679216/9568 [===========================>..] - ETA: 1s - loss: 0.13669280/9568 [============================>.] - ETA: 1s - loss: 0.13669344/9568 [============================>.] - ETA: 1s - loss: 0.13669408/9568 [============================>.] - ETA: 0s - loss: 0.13659472/9568 [============================>.] - ETA: 0s - loss: 0.13659536/9568 [============================>.] - ETA: 0s - loss: 0.1365
Epoch 00012: val_loss improved from 0.16788 to 0.16660, saving model to /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min/saved_models/visitors/fixed/tmp/TemporalFusionTransformer.check
9568/9568 [==============================] - 50s 5ms/sample - loss: 0.1365 - val_loss: 0.1666
Epoch 13/100
  64/9568 [..............................] - ETA: 1:16 - loss: 0.1350 128/9568 [..............................] - ETA: 1:04 - loss: 0.1402 192/9568 [..............................] - ETA: 58s - loss: 0.1354  256/9568 [..............................] - ETA: 1:00 - loss: 0.1363 320/9568 [>.............................] - ETA: 1:02 - loss: 0.1399 384/9568 [>.............................] - ETA: 59s - loss: 0.1401  448/9568 [>.............................] - ETA: 1:00 - loss: 0.1406 512/9568 [>.............................] - ETA: 58s - loss: 0.1398  576/9568 [>.............................] - ETA: 55s - loss: 0.1370 640/9568 [=>............................] - ETA: 51s - loss: 0.1353 704/9568 [=>............................] - ETA: 50s - loss: 0.1354 768/9568 [=>............................] - ETA: 48s - loss: 0.1367 832/9568 [=>............................] - ETA: 47s - loss: 0.1359 896/9568 [=>............................] - ETA: 49s - loss: 0.1350 960/9568 [==>...........................] - ETA: 49s - loss: 0.13441024/9568 [==>...........................] - ETA: 49s - loss: 0.13401088/9568 [==>...........................] - ETA: 48s - loss: 0.13401152/9568 [==>...........................] - ETA: 47s - loss: 0.13551216/9568 [==>...........................] - ETA: 46s - loss: 0.13511280/9568 [===>..........................] - ETA: 45s - loss: 0.13671344/9568 [===>..........................] - ETA: 44s - loss: 0.13771408/9568 [===>..........................] - ETA: 45s - loss: 0.13701472/9568 [===>..........................] - ETA: 44s - loss: 0.13631536/9568 [===>..........................] - ETA: 43s - loss: 0.13581600/9568 [====>.........................] - ETA: 43s - loss: 0.13581664/9568 [====>.........................] - ETA: 42s - loss: 0.13511728/9568 [====>.........................] - ETA: 42s - loss: 0.13451792/9568 [====>.........................] - ETA: 41s - loss: 0.13441856/9568 [====>.........................] - ETA: 41s - loss: 0.13551920/9568 [=====>........................] - ETA: 40s - loss: 0.13491984/9568 [=====>........................] - ETA: 42s - loss: 0.13522048/9568 [=====>........................] - ETA: 42s - loss: 0.13532112/9568 [=====>........................] - ETA: 41s - loss: 0.13512176/9568 [=====>........................] - ETA: 40s - loss: 0.13472240/9568 [======>.......................] - ETA: 39s - loss: 0.13442304/9568 [======>.......................] - ETA: 38s - loss: 0.13422368/9568 [======>.......................] - ETA: 37s - loss: 0.13462432/9568 [======>.......................] - ETA: 37s - loss: 0.13432496/9568 [======>.......................] - ETA: 36s - loss: 0.13412560/9568 [=======>......................] - ETA: 36s - loss: 0.13392624/9568 [=======>......................] - ETA: 35s - loss: 0.13362688/9568 [=======>......................] - ETA: 35s - loss: 0.13342752/9568 [=======>......................] - ETA: 34s - loss: 0.13402816/9568 [=======>......................] - ETA: 34s - loss: 0.13372880/9568 [========>.....................] - ETA: 33s - loss: 0.13412944/9568 [========>.....................] - ETA: 33s - loss: 0.13393008/9568 [========>.....................] - ETA: 33s - loss: 0.13403072/9568 [========>.....................] - ETA: 32s - loss: 0.13373136/9568 [========>.....................] - ETA: 32s - loss: 0.13363200/9568 [=========>....................] - ETA: 31s - loss: 0.13343264/9568 [=========>....................] - ETA: 30s - loss: 0.13313328/9568 [=========>....................] - ETA: 30s - loss: 0.13273392/9568 [=========>....................] - ETA: 30s - loss: 0.13313456/9568 [=========>....................] - ETA: 29s - loss: 0.13343520/9568 [==========>...................] - ETA: 29s - loss: 0.13323584/9568 [==========>...................] - ETA: 28s - loss: 0.13363648/9568 [==========>...................] - ETA: 28s - loss: 0.13373712/9568 [==========>...................] - ETA: 27s - loss: 0.13363776/9568 [==========>...................] - ETA: 27s - loss: 0.13463840/9568 [===========>..................] - ETA: 27s - loss: 0.13503904/9568 [===========>..................] - ETA: 27s - loss: 0.13513968/9568 [===========>..................] - ETA: 27s - loss: 0.13514032/9568 [===========>..................] - ETA: 27s - loss: 0.13524096/9568 [===========>..................] - ETA: 26s - loss: 0.13524160/9568 [============>.................] - ETA: 26s - loss: 0.13534224/9568 [============>.................] - ETA: 25s - loss: 0.13554288/9568 [============>.................] - ETA: 25s - loss: 0.13544352/9568 [============>.................] - ETA: 25s - loss: 0.13544416/9568 [============>.................] - ETA: 24s - loss: 0.13524480/9568 [=============>................] - ETA: 24s - loss: 0.13534544/9568 [=============>................] - ETA: 24s - loss: 0.13524608/9568 [=============>................] - ETA: 23s - loss: 0.13524672/9568 [=============>................] - ETA: 23s - loss: 0.13534736/9568 [=============>................] - ETA: 22s - loss: 0.13524800/9568 [==============>...............] - ETA: 22s - loss: 0.13524864/9568 [==============>...............] - ETA: 22s - loss: 0.13504928/9568 [==============>...............] - ETA: 21s - loss: 0.13504992/9568 [==============>...............] - ETA: 21s - loss: 0.13495056/9568 [==============>...............] - ETA: 21s - loss: 0.13505120/9568 [===============>..............] - ETA: 20s - loss: 0.13525184/9568 [===============>..............] - ETA: 20s - loss: 0.13535248/9568 [===============>..............] - ETA: 19s - loss: 0.13515312/9568 [===============>..............] - ETA: 19s - loss: 0.13495376/9568 [===============>..............] - ETA: 19s - loss: 0.13515440/9568 [================>.............] - ETA: 18s - loss: 0.13505504/9568 [================>.............] - ETA: 18s - loss: 0.13495568/9568 [================>.............] - ETA: 18s - loss: 0.13485632/9568 [================>.............] - ETA: 18s - loss: 0.13475696/9568 [================>.............] - ETA: 17s - loss: 0.13475760/9568 [=================>............] - ETA: 17s - loss: 0.13485824/9568 [=================>............] - ETA: 17s - loss: 0.13525888/9568 [=================>............] - ETA: 16s - loss: 0.13525952/9568 [=================>............] - ETA: 16s - loss: 0.13516016/9568 [=================>............] - ETA: 16s - loss: 0.13506080/9568 [==================>...........] - ETA: 16s - loss: 0.13496144/9568 [==================>...........] - ETA: 15s - loss: 0.13486208/9568 [==================>...........] - ETA: 15s - loss: 0.13476272/9568 [==================>...........] - ETA: 15s - loss: 0.13456336/9568 [==================>...........] - ETA: 14s - loss: 0.13476400/9568 [===================>..........] - ETA: 14s - loss: 0.13476464/9568 [===================>..........] - ETA: 14s - loss: 0.13486528/9568 [===================>..........] - ETA: 13s - loss: 0.13516592/9568 [===================>..........] - ETA: 13s - loss: 0.13516656/9568 [===================>..........] - ETA: 13s - loss: 0.13516720/9568 [====================>.........] - ETA: 13s - loss: 0.13546784/9568 [====================>.........] - ETA: 13s - loss: 0.13536848/9568 [====================>.........] - ETA: 12s - loss: 0.13566912/9568 [====================>.........] - ETA: 12s - loss: 0.13596976/9568 [====================>.........] - ETA: 12s - loss: 0.13577040/9568 [=====================>........] - ETA: 12s - loss: 0.13567104/9568 [=====================>........] - ETA: 11s - loss: 0.13597168/9568 [=====================>........] - ETA: 11s - loss: 0.13577232/9568 [=====================>........] - ETA: 11s - loss: 0.13567296/9568 [=====================>........] - ETA: 10s - loss: 0.13567360/9568 [======================>.......] - ETA: 10s - loss: 0.13557424/9568 [======================>.......] - ETA: 10s - loss: 0.13547488/9568 [======================>.......] - ETA: 9s - loss: 0.1353 7552/9568 [======================>.......] - ETA: 9s - loss: 0.13527616/9568 [======================>.......] - ETA: 9s - loss: 0.13527680/9568 [=======================>......] - ETA: 9s - loss: 0.13527744/9568 [=======================>......] - ETA: 8s - loss: 0.13527808/9568 [=======================>......] - ETA: 8s - loss: 0.13537872/9568 [=======================>......] - ETA: 8s - loss: 0.13547936/9568 [=======================>......] - ETA: 7s - loss: 0.13538000/9568 [========================>.....] - ETA: 7s - loss: 0.13528064/9568 [========================>.....] - ETA: 7s - loss: 0.13518128/9568 [========================>.....] - ETA: 6s - loss: 0.13538192/9568 [========================>.....] - ETA: 6s - loss: 0.13548256/9568 [========================>.....] - ETA: 6s - loss: 0.13538320/9568 [=========================>....] - ETA: 5s - loss: 0.13538384/9568 [=========================>....] - ETA: 5s - loss: 0.13548448/9568 [=========================>....] - ETA: 5s - loss: 0.13538512/9568 [=========================>....] - ETA: 5s - loss: 0.13558576/9568 [=========================>....] - ETA: 4s - loss: 0.13548640/9568 [==========================>...] - ETA: 4s - loss: 0.13538704/9568 [==========================>...] - ETA: 4s - loss: 0.13528768/9568 [==========================>...] - ETA: 3s - loss: 0.13528832/9568 [==========================>...] - ETA: 3s - loss: 0.13528896/9568 [==========================>...] - ETA: 3s - loss: 0.13528960/9568 [===========================>..] - ETA: 2s - loss: 0.13529024/9568 [===========================>..] - ETA: 2s - loss: 0.13509088/9568 [===========================>..] - ETA: 2s - loss: 0.13509152/9568 [===========================>..] - ETA: 2s - loss: 0.13499216/9568 [===========================>..] - ETA: 1s - loss: 0.13499280/9568 [============================>.] - ETA: 1s - loss: 0.13509344/9568 [============================>.] - ETA: 1s - loss: 0.13509408/9568 [============================>.] - ETA: 0s - loss: 0.13499472/9568 [============================>.] - ETA: 0s - loss: 0.13499536/9568 [============================>.] - ETA: 0s - loss: 0.1349
Epoch 00013: val_loss did not improve from 0.16660
9568/9568 [==============================] - 50s 5ms/sample - loss: 0.1349 - val_loss: 0.1736
Epoch 14/100
  64/9568 [..............................] - ETA: 34s - loss: 0.1224 128/9568 [..............................] - ETA: 35s - loss: 0.1315 192/9568 [..............................] - ETA: 42s - loss: 0.1325 256/9568 [..............................] - ETA: 42s - loss: 0.1407 320/9568 [>.............................] - ETA: 44s - loss: 0.1409 384/9568 [>.............................] - ETA: 44s - loss: 0.1389 448/9568 [>.............................] - ETA: 41s - loss: 0.1348 512/9568 [>.............................] - ETA: 38s - loss: 0.1326 576/9568 [>.............................] - ETA: 37s - loss: 0.1321 640/9568 [=>............................] - ETA: 36s - loss: 0.1315 704/9568 [=>............................] - ETA: 35s - loss: 0.1330 768/9568 [=>............................] - ETA: 33s - loss: 0.1330 832/9568 [=>............................] - ETA: 35s - loss: 0.1328 896/9568 [=>............................] - ETA: 34s - loss: 0.1317 960/9568 [==>...........................] - ETA: 35s - loss: 0.13111024/9568 [==>...........................] - ETA: 34s - loss: 0.13021088/9568 [==>...........................] - ETA: 33s - loss: 0.13131152/9568 [==>...........................] - ETA: 32s - loss: 0.13121216/9568 [==>...........................] - ETA: 32s - loss: 0.13081280/9568 [===>..........................] - ETA: 32s - loss: 0.13241344/9568 [===>..........................] - ETA: 32s - loss: 0.13371408/9568 [===>..........................] - ETA: 31s - loss: 0.13361472/9568 [===>..........................] - ETA: 31s - loss: 0.13321536/9568 [===>..........................] - ETA: 32s - loss: 0.13321600/9568 [====>.........................] - ETA: 31s - loss: 0.13401664/9568 [====>.........................] - ETA: 31s - loss: 0.13401728/9568 [====>.........................] - ETA: 31s - loss: 0.13331792/9568 [====>.........................] - ETA: 31s - loss: 0.13291856/9568 [====>.........................] - ETA: 30s - loss: 0.13221920/9568 [=====>........................] - ETA: 31s - loss: 0.13201984/9568 [=====>........................] - ETA: 30s - loss: 0.13172048/9568 [=====>........................] - ETA: 30s - loss: 0.13132112/9568 [=====>........................] - ETA: 30s - loss: 0.13172176/9568 [=====>........................] - ETA: 30s - loss: 0.13182240/9568 [======>.......................] - ETA: 30s - loss: 0.13172304/9568 [======>.......................] - ETA: 30s - loss: 0.13152368/9568 [======>.......................] - ETA: 30s - loss: 0.13172432/9568 [======>.......................] - ETA: 30s - loss: 0.13202496/9568 [======>.......................] - ETA: 29s - loss: 0.13152560/9568 [=======>......................] - ETA: 29s - loss: 0.13132624/9568 [=======>......................] - ETA: 30s - loss: 0.13102688/9568 [=======>......................] - ETA: 30s - loss: 0.13072752/9568 [=======>......................] - ETA: 29s - loss: 0.13132816/9568 [=======>......................] - ETA: 30s - loss: 0.13112880/9568 [========>.....................] - ETA: 30s - loss: 0.13132944/9568 [========>.....................] - ETA: 30s - loss: 0.13103008/9568 [========>.....................] - ETA: 30s - loss: 0.13093072/9568 [========>.....................] - ETA: 29s - loss: 0.13043136/9568 [========>.....................] - ETA: 29s - loss: 0.13013200/9568 [=========>....................] - ETA: 29s - loss: 0.12983264/9568 [=========>....................] - ETA: 29s - loss: 0.12963328/9568 [=========>....................] - ETA: 28s - loss: 0.13083392/9568 [=========>....................] - ETA: 28s - loss: 0.13063456/9568 [=========>....................] - ETA: 28s - loss: 0.13073520/9568 [==========>...................] - ETA: 27s - loss: 0.13033584/9568 [==========>...................] - ETA: 27s - loss: 0.13033648/9568 [==========>...................] - ETA: 26s - loss: 0.13023712/9568 [==========>...................] - ETA: 26s - loss: 0.13003776/9568 [==========>...................] - ETA: 26s - loss: 0.12983840/9568 [===========>..................] - ETA: 25s - loss: 0.13003904/9568 [===========>..................] - ETA: 25s - loss: 0.12973968/9568 [===========>..................] - ETA: 25s - loss: 0.12984032/9568 [===========>..................] - ETA: 24s - loss: 0.13004096/9568 [===========>..................] - ETA: 24s - loss: 0.12984160/9568 [============>.................] - ETA: 24s - loss: 0.12974224/9568 [============>.................] - ETA: 23s - loss: 0.12964288/9568 [============>.................] - ETA: 23s - loss: 0.12964352/9568 [============>.................] - ETA: 23s - loss: 0.12984416/9568 [============>.................] - ETA: 22s - loss: 0.12984480/9568 [=============>................] - ETA: 22s - loss: 0.12974544/9568 [=============>................] - ETA: 22s - loss: 0.12984608/9568 [=============>................] - ETA: 22s - loss: 0.12964672/9568 [=============>................] - ETA: 21s - loss: 0.12964736/9568 [=============>................] - ETA: 21s - loss: 0.12934800/9568 [==============>...............] - ETA: 21s - loss: 0.12924864/9568 [==============>...............] - ETA: 20s - loss: 0.12934928/9568 [==============>...............] - ETA: 20s - loss: 0.12934992/9568 [==============>...............] - ETA: 20s - loss: 0.12905056/9568 [==============>...............] - ETA: 20s - loss: 0.12915120/9568 [===============>..............] - ETA: 20s - loss: 0.12925184/9568 [===============>..............] - ETA: 19s - loss: 0.12925248/9568 [===============>..............] - ETA: 19s - loss: 0.12915312/9568 [===============>..............] - ETA: 19s - loss: 0.12925376/9568 [===============>..............] - ETA: 19s - loss: 0.12925440/9568 [================>.............] - ETA: 18s - loss: 0.12905504/9568 [================>.............] - ETA: 18s - loss: 0.12895568/9568 [================>.............] - ETA: 18s - loss: 0.12855632/9568 [================>.............] - ETA: 17s - loss: 0.12845696/9568 [================>.............] - ETA: 17s - loss: 0.12885760/9568 [=================>............] - ETA: 17s - loss: 0.12885824/9568 [=================>............] - ETA: 17s - loss: 0.12865888/9568 [=================>............] - ETA: 16s - loss: 0.12845952/9568 [=================>............] - ETA: 16s - loss: 0.12846016/9568 [=================>............] - ETA: 16s - loss: 0.12836080/9568 [==================>...........] - ETA: 16s - loss: 0.12826144/9568 [==================>...........] - ETA: 15s - loss: 0.12836208/9568 [==================>...........] - ETA: 15s - loss: 0.12826272/9568 [==================>...........] - ETA: 15s - loss: 0.12816336/9568 [==================>...........] - ETA: 14s - loss: 0.12846400/9568 [===================>..........] - ETA: 14s - loss: 0.12846464/9568 [===================>..........] - ETA: 14s - loss: 0.12836528/9568 [===================>..........] - ETA: 14s - loss: 0.12816592/9568 [===================>..........] - ETA: 13s - loss: 0.12826656/9568 [===================>..........] - ETA: 13s - loss: 0.12836720/9568 [====================>.........] - ETA: 13s - loss: 0.12856784/9568 [====================>.........] - ETA: 12s - loss: 0.12856848/9568 [====================>.........] - ETA: 12s - loss: 0.12896912/9568 [====================>.........] - ETA: 12s - loss: 0.12876976/9568 [====================>.........] - ETA: 11s - loss: 0.12897040/9568 [=====================>........] - ETA: 11s - loss: 0.12887104/9568 [=====================>........] - ETA: 11s - loss: 0.12877168/9568 [=====================>........] - ETA: 10s - loss: 0.12867232/9568 [=====================>........] - ETA: 10s - loss: 0.12847296/9568 [=====================>........] - ETA: 10s - loss: 0.12837360/9568 [======================>.......] - ETA: 10s - loss: 0.12837424/9568 [======================>.......] - ETA: 9s - loss: 0.1282 7488/9568 [======================>.......] - ETA: 9s - loss: 0.12827552/9568 [======================>.......] - ETA: 9s - loss: 0.12817616/9568 [======================>.......] - ETA: 8s - loss: 0.12817680/9568 [=======================>......] - ETA: 8s - loss: 0.12857744/9568 [=======================>......] - ETA: 8s - loss: 0.12847808/9568 [=======================>......] - ETA: 7s - loss: 0.12867872/9568 [=======================>......] - ETA: 7s - loss: 0.12867936/9568 [=======================>......] - ETA: 7s - loss: 0.12878000/9568 [========================>.....] - ETA: 6s - loss: 0.12878064/9568 [========================>.....] - ETA: 6s - loss: 0.12868128/9568 [========================>.....] - ETA: 6s - loss: 0.12858192/9568 [========================>.....] - ETA: 6s - loss: 0.12858256/9568 [========================>.....] - ETA: 5s - loss: 0.12848320/9568 [=========================>....] - ETA: 5s - loss: 0.12858384/9568 [=========================>....] - ETA: 5s - loss: 0.12848448/9568 [=========================>....] - ETA: 4s - loss: 0.12838512/9568 [=========================>....] - ETA: 4s - loss: 0.12838576/9568 [=========================>....] - ETA: 4s - loss: 0.12838640/9568 [==========================>...] - ETA: 4s - loss: 0.12818704/9568 [==========================>...] - ETA: 3s - loss: 0.12818768/9568 [==========================>...] - ETA: 3s - loss: 0.12818832/9568 [==========================>...] - ETA: 3s - loss: 0.12818896/9568 [==========================>...] - ETA: 2s - loss: 0.12808960/9568 [===========================>..] - ETA: 2s - loss: 0.12829024/9568 [===========================>..] - ETA: 2s - loss: 0.12829088/9568 [===========================>..] - ETA: 2s - loss: 0.12819152/9568 [===========================>..] - ETA: 1s - loss: 0.12819216/9568 [===========================>..] - ETA: 1s - loss: 0.12819280/9568 [============================>.] - ETA: 1s - loss: 0.12819344/9568 [============================>.] - ETA: 1s - loss: 0.12819408/9568 [============================>.] - ETA: 0s - loss: 0.12809472/9568 [============================>.] - ETA: 0s - loss: 0.12809536/9568 [============================>.] - ETA: 0s - loss: 0.1278
Epoch 00014: val_loss did not improve from 0.16660
9568/9568 [==============================] - 47s 5ms/sample - loss: 0.1280 - val_loss: 0.1735
Epoch 15/100
  64/9568 [..............................] - ETA: 45s - loss: 0.1273 128/9568 [..............................] - ETA: 49s - loss: 0.1312 192/9568 [..............................] - ETA: 55s - loss: 0.1310 256/9568 [..............................] - ETA: 48s - loss: 0.1290 320/9568 [>.............................] - ETA: 45s - loss: 0.1295 384/9568 [>.............................] - ETA: 41s - loss: 0.1267 448/9568 [>.............................] - ETA: 40s - loss: 0.1271 512/9568 [>.............................] - ETA: 40s - loss: 0.1265 576/9568 [>.............................] - ETA: 43s - loss: 0.1256 640/9568 [=>............................] - ETA: 44s - loss: 0.1251 704/9568 [=>............................] - ETA: 44s - loss: 0.1248 768/9568 [=>............................] - ETA: 43s - loss: 0.1258 832/9568 [=>............................] - ETA: 43s - loss: 0.1246 896/9568 [=>............................] - ETA: 43s - loss: 0.1252 960/9568 [==>...........................] - ETA: 42s - loss: 0.12511024/9568 [==>...........................] - ETA: 42s - loss: 0.12491088/9568 [==>...........................] - ETA: 41s - loss: 0.12531152/9568 [==>...........................] - ETA: 40s - loss: 0.12471216/9568 [==>...........................] - ETA: 39s - loss: 0.12451280/9568 [===>..........................] - ETA: 38s - loss: 0.12431344/9568 [===>..........................] - ETA: 38s - loss: 0.12441408/9568 [===>..........................] - ETA: 38s - loss: 0.12451472/9568 [===>..........................] - ETA: 38s - loss: 0.12441536/9568 [===>..........................] - ETA: 38s - loss: 0.12341600/9568 [====>.........................] - ETA: 37s - loss: 0.12441664/9568 [====>.........................] - ETA: 37s - loss: 0.12461728/9568 [====>.........................] - ETA: 36s - loss: 0.12461792/9568 [====>.........................] - ETA: 36s - loss: 0.12451856/9568 [====>.........................] - ETA: 36s - loss: 0.12471920/9568 [=====>........................] - ETA: 35s - loss: 0.12481984/9568 [=====>........................] - ETA: 35s - loss: 0.12472048/9568 [=====>........................] - ETA: 35s - loss: 0.12462112/9568 [=====>........................] - ETA: 34s - loss: 0.12462176/9568 [=====>........................] - ETA: 35s - loss: 0.12512240/9568 [======>.......................] - ETA: 35s - loss: 0.12512304/9568 [======>.......................] - ETA: 34s - loss: 0.12482368/9568 [======>.......................] - ETA: 34s - loss: 0.12442432/9568 [======>.......................] - ETA: 33s - loss: 0.12472496/9568 [======>.......................] - ETA: 33s - loss: 0.12492560/9568 [=======>......................] - ETA: 32s - loss: 0.12502624/9568 [=======>......................] - ETA: 32s - loss: 0.12512688/9568 [=======>......................] - ETA: 31s - loss: 0.12502752/9568 [=======>......................] - ETA: 31s - loss: 0.12462816/9568 [=======>......................] - ETA: 31s - loss: 0.12452880/9568 [========>.....................] - ETA: 30s - loss: 0.12462944/9568 [========>.....................] - ETA: 30s - loss: 0.12433008/9568 [========>.....................] - ETA: 30s - loss: 0.12403072/9568 [========>.....................] - ETA: 30s - loss: 0.12433136/9568 [========>.....................] - ETA: 30s - loss: 0.12513200/9568 [=========>....................] - ETA: 29s - loss: 0.12523264/9568 [=========>....................] - ETA: 29s - loss: 0.12523328/9568 [=========>....................] - ETA: 29s - loss: 0.12533392/9568 [=========>....................] - ETA: 28s - loss: 0.12503456/9568 [=========>....................] - ETA: 28s - loss: 0.12503520/9568 [==========>...................] - ETA: 27s - loss: 0.12483584/9568 [==========>...................] - ETA: 27s - loss: 0.12473648/9568 [==========>...................] - ETA: 27s - loss: 0.12473712/9568 [==========>...................] - ETA: 26s - loss: 0.12473776/9568 [==========>...................] - ETA: 26s - loss: 0.12483840/9568 [===========>..................] - ETA: 25s - loss: 0.12463904/9568 [===========>..................] - ETA: 25s - loss: 0.12453968/9568 [===========>..................] - ETA: 24s - loss: 0.12424032/9568 [===========>..................] - ETA: 24s - loss: 0.12424096/9568 [===========>..................] - ETA: 24s - loss: 0.12464160/9568 [============>.................] - ETA: 23s - loss: 0.12444224/9568 [============>.................] - ETA: 23s - loss: 0.12444288/9568 [============>.................] - ETA: 23s - loss: 0.12444352/9568 [============>.................] - ETA: 23s - loss: 0.12434416/9568 [============>.................] - ETA: 22s - loss: 0.12494480/9568 [=============>................] - ETA: 22s - loss: 0.12524544/9568 [=============>................] - ETA: 22s - loss: 0.12494608/9568 [=============>................] - ETA: 22s - loss: 0.12494672/9568 [=============>................] - ETA: 21s - loss: 0.12494736/9568 [=============>................] - ETA: 21s - loss: 0.12464800/9568 [==============>...............] - ETA: 21s - loss: 0.12454864/9568 [==============>...............] - ETA: 21s - loss: 0.12474928/9568 [==============>...............] - ETA: 21s - loss: 0.12464992/9568 [==============>...............] - ETA: 20s - loss: 0.12455056/9568 [==============>...............] - ETA: 20s - loss: 0.12435120/9568 [===============>..............] - ETA: 20s - loss: 0.12425184/9568 [===============>..............] - ETA: 19s - loss: 0.12425248/9568 [===============>..............] - ETA: 19s - loss: 0.12445312/9568 [===============>..............] - ETA: 19s - loss: 0.12435376/9568 [===============>..............] - ETA: 19s - loss: 0.12445440/9568 [================>.............] - ETA: 19s - loss: 0.12435504/9568 [================>.............] - ETA: 18s - loss: 0.12435568/9568 [================>.............] - ETA: 18s - loss: 0.12425632/9568 [================>.............] - ETA: 17s - loss: 0.12425696/9568 [================>.............] - ETA: 17s - loss: 0.12415760/9568 [=================>............] - ETA: 17s - loss: 0.12435824/9568 [=================>............] - ETA: 17s - loss: 0.12445888/9568 [=================>............] - ETA: 16s - loss: 0.12445952/9568 [=================>............] - ETA: 16s - loss: 0.12446016/9568 [=================>............] - ETA: 16s - loss: 0.12426080/9568 [==================>...........] - ETA: 16s - loss: 0.12426144/9568 [==================>...........] - ETA: 15s - loss: 0.12436208/9568 [==================>...........] - ETA: 15s - loss: 0.12446272/9568 [==================>...........] - ETA: 15s - loss: 0.12466336/9568 [==================>...........] - ETA: 15s - loss: 0.12486400/9568 [===================>..........] - ETA: 15s - loss: 0.12476464/9568 [===================>..........] - ETA: 14s - loss: 0.12476528/9568 [===================>..........] - ETA: 14s - loss: 0.12466592/9568 [===================>..........] - ETA: 14s - loss: 0.12466656/9568 [===================>..........] - ETA: 13s - loss: 0.12456720/9568 [====================>.........] - ETA: 13s - loss: 0.12446784/9568 [====================>.........] - ETA: 13s - loss: 0.12476848/9568 [====================>.........] - ETA: 13s - loss: 0.12476912/9568 [====================>.........] - ETA: 12s - loss: 0.12466976/9568 [====================>.........] - ETA: 12s - loss: 0.12467040/9568 [=====================>........] - ETA: 12s - loss: 0.12457104/9568 [=====================>........] - ETA: 11s - loss: 0.12447168/9568 [=====================>........] - ETA: 11s - loss: 0.12457232/9568 [=====================>........] - ETA: 11s - loss: 0.12447296/9568 [=====================>........] - ETA: 11s - loss: 0.12447360/9568 [======================>.......] - ETA: 10s - loss: 0.12457424/9568 [======================>.......] - ETA: 10s - loss: 0.12457488/9568 [======================>.......] - ETA: 10s - loss: 0.12457552/9568 [======================>.......] - ETA: 9s - loss: 0.1244 7616/9568 [======================>.......] - ETA: 9s - loss: 0.12437680/9568 [=======================>......] - ETA: 9s - loss: 0.12417744/9568 [=======================>......] - ETA: 8s - loss: 0.12417808/9568 [=======================>......] - ETA: 8s - loss: 0.12417872/9568 [=======================>......] - ETA: 8s - loss: 0.12397936/9568 [=======================>......] - ETA: 8s - loss: 0.12398000/9568 [========================>.....] - ETA: 7s - loss: 0.12408064/9568 [========================>.....] - ETA: 7s - loss: 0.12398128/9568 [========================>.....] - ETA: 7s - loss: 0.12428192/9568 [========================>.....] - ETA: 6s - loss: 0.12438256/9568 [========================>.....] - ETA: 6s - loss: 0.12448320/9568 [=========================>....] - ETA: 6s - loss: 0.12448384/9568 [=========================>....] - ETA: 5s - loss: 0.12448448/9568 [=========================>....] - ETA: 5s - loss: 0.12458512/9568 [=========================>....] - ETA: 5s - loss: 0.12458576/9568 [=========================>....] - ETA: 4s - loss: 0.12448640/9568 [==========================>...] - ETA: 4s - loss: 0.12448704/9568 [==========================>...] - ETA: 4s - loss: 0.12448768/9568 [==========================>...] - ETA: 3s - loss: 0.12448832/9568 [==========================>...] - ETA: 3s - loss: 0.12438896/9568 [==========================>...] - ETA: 3s - loss: 0.12468960/9568 [===========================>..] - ETA: 2s - loss: 0.12459024/9568 [===========================>..] - ETA: 2s - loss: 0.12469088/9568 [===========================>..] - ETA: 2s - loss: 0.12469152/9568 [===========================>..] - ETA: 2s - loss: 0.12479216/9568 [===========================>..] - ETA: 1s - loss: 0.12479280/9568 [============================>.] - ETA: 1s - loss: 0.12459344/9568 [============================>.] - ETA: 1s - loss: 0.12459408/9568 [============================>.] - ETA: 0s - loss: 0.12459472/9568 [============================>.] - ETA: 0s - loss: 0.12449536/9568 [============================>.] - ETA: 0s - loss: 0.1243
Epoch 00015: val_loss did not improve from 0.16660
9568/9568 [==============================] - 49s 5ms/sample - loss: 0.1243 - val_loss: 0.1728
Epoch 00015: early stopping
Cannot load from /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min/saved_models/visitors/fixed/tmp, skipping ...
Using cached validation data
  32/2711 [..............................] - ETA: 3s - loss: 0.2205  64/2711 [..............................] - ETA: 3s - loss: 0.1850 128/2711 [>.............................] - ETA: 3s - loss: 0.2354 192/2711 [=>............................] - ETA: 3s - loss: 0.2161 256/2711 [=>............................] - ETA: 3s - loss: 0.2104 288/2711 [==>...........................] - ETA: 3s - loss: 0.2034 320/2711 [==>...........................] - ETA: 3s - loss: 0.1997 384/2711 [===>..........................] - ETA: 3s - loss: 0.1935 448/2711 [===>..........................] - ETA: 3s - loss: 0.1846 512/2711 [====>.........................] - ETA: 3s - loss: 0.1732 544/2711 [=====>........................] - ETA: 3s - loss: 0.1709 576/2711 [=====>........................] - ETA: 3s - loss: 0.1753 608/2711 [=====>........................] - ETA: 3s - loss: 0.1722 640/2711 [======>.......................] - ETA: 3s - loss: 0.1694 672/2711 [======>.......................] - ETA: 3s - loss: 0.1675 736/2711 [=======>......................] - ETA: 3s - loss: 0.1693 768/2711 [=======>......................] - ETA: 3s - loss: 0.1685 832/2711 [========>.....................] - ETA: 3s - loss: 0.1707 896/2711 [========>.....................] - ETA: 2s - loss: 0.1711 960/2711 [=========>....................] - ETA: 2s - loss: 0.1667 992/2711 [=========>....................] - ETA: 2s - loss: 0.16801024/2711 [==========>...................] - ETA: 2s - loss: 0.16781088/2711 [===========>..................] - ETA: 2s - loss: 0.16721152/2711 [===========>..................] - ETA: 2s - loss: 0.16801216/2711 [============>.................] - ETA: 2s - loss: 0.16761280/2711 [=============>................] - ETA: 2s - loss: 0.16561344/2711 [=============>................] - ETA: 2s - loss: 0.16521408/2711 [==============>...............] - ETA: 2s - loss: 0.16581472/2711 [===============>..............] - ETA: 1s - loss: 0.16441536/2711 [===============>..............] - ETA: 1s - loss: 0.16291600/2711 [================>.............] - ETA: 1s - loss: 0.16221664/2711 [=================>............] - ETA: 1s - loss: 0.16191728/2711 [==================>...........] - ETA: 1s - loss: 0.16191760/2711 [==================>...........] - ETA: 1s - loss: 0.16171824/2711 [===================>..........] - ETA: 1s - loss: 0.16001888/2711 [===================>..........] - ETA: 1s - loss: 0.16221920/2711 [====================>.........] - ETA: 1s - loss: 0.16141952/2711 [====================>.........] - ETA: 1s - loss: 0.16202016/2711 [=====================>........] - ETA: 1s - loss: 0.16012048/2711 [=====================>........] - ETA: 1s - loss: 0.16042080/2711 [======================>.......] - ETA: 0s - loss: 0.16272112/2711 [======================>.......] - ETA: 0s - loss: 0.16202176/2711 [=======================>......] - ETA: 0s - loss: 0.16112208/2711 [=======================>......] - ETA: 0s - loss: 0.16062272/2711 [========================>.....] - ETA: 0s - loss: 0.16222304/2711 [========================>.....] - ETA: 0s - loss: 0.16192336/2711 [========================>.....] - ETA: 0s - loss: 0.16102368/2711 [=========================>....] - ETA: 0s - loss: 0.16122400/2711 [=========================>....] - ETA: 0s - loss: 0.16942432/2711 [=========================>....] - ETA: 0s - loss: 0.17542464/2711 [==========================>...] - ETA: 0s - loss: 0.17552496/2711 [==========================>...] - ETA: 0s - loss: 0.17442528/2711 [==========================>...] - ETA: 0s - loss: 0.17392560/2711 [===========================>..] - ETA: 0s - loss: 0.17492592/2711 [===========================>..] - ETA: 0s - loss: 0.17492624/2711 [============================>.] - ETA: 0s - loss: 0.17462656/2711 [============================>.] - ETA: 0s - loss: 0.17412688/2711 [============================>.] - ETA: 0s - loss: 0.17322711/2711 [==============================] - 5s 2ms/sample - loss: 0.1728
Optimal model found, updating
WARNING:tensorflow:From /opt/BAA/TFT/libs/utils.py:173: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /opt/BAA/TFT/libs/utils.py:173: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /opt/BAA/TFT/libs/utils.py:174: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

Model saved to: /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min/saved_models/visitors/fixed/TemporalFusionTransformer.ckpt
*** Running tests ***
2024-12-23 20:52:10.403078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla M10 major: 5 minor: 0 memoryClockRate(GHz): 1.0325
pciBusID: 0000:b3:00.0
2024-12-23 20:52:10.403789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-12-23 20:52:10.403910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-12-23 20:52:10.403970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-12-23 20:52:10.404025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-12-23 20:52:10.404054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-12-23 20:52:10.404079: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-12-23 20:52:10.404112: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-12-23 20:52:10.432517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-12-23 20:52:10.432798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-23 20:52:10.432844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-23 20:52:10.432865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-12-23 20:52:10.439965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7692 MB memory) -> physical GPU (device: 0, name: Tesla M10, pci bus id: 0000:b3:00.0, compute capability: 5.0)
Resetting temp folder...
*** TemporalFusionTransformer params ***
# dropout_rate = 0.3
# hidden_layer_size = 160
# learning_rate = 0.001
# max_gradient_norm = 0.01
# minibatch_size = 64
# model_folder = /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min/saved_models/visitors/fixed
# num_heads = 1
# stack_size = 1
# total_time_steps = 32
# num_encoder_steps = 24
# num_epochs = 100
# early_stopping_patience = 3
# multiprocessing_workers = 5
# column_definition = [('dummy_id', <DataTypes.REAL_VALUED: 0>, <InputTypes.ID: 4>), ('date', <DataTypes.DATE: 2>, <InputTypes.TIME: 5>), ('minute_of_hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('hour_of_day', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('week_of_year', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('month_of_year', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_month', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('Wind Speed', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('visitors', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('region', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>)]
# input_size = 9
# output_size = 1
# category_counts = [1]
# input_obs_loc = [7]
# static_input_loc = [8]
# known_regular_inputs = [0, 1, 2, 3, 4, 5, 6]
# known_categorical_inputs = [0]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 9)]      0                                            
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           input_1[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32)]         0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
sequential (Sequential)         (None, 32, 160)      160         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 160)]        0           sequential[1][0]                 
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
flatten (Flatten)               (None, 160)          0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 160)          25760       flatten[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
activation (Activation)         (None, 160)          0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 1, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 160)          25760       activation[0][0]                 
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 1, 160)       0           dense_13[0][0]                   
__________________________________________________________________________________________________
dropout (Dropout)               (None, 160)          0           dense_10[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 1, 160)       25760       activation_2[0][0]               
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 1)            161         dropout[0][0]                    
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 1)            161         dropout[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 1, 160)       0           dense_14[0][0]                   
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 1)            161         flatten[0][0]                    
__________________________________________________________________________________________________
multiply (Multiply)             (None, 1)            0           dense_11[0][0]                   
                                                                 dense_12[0][0]                   
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 1, 160)       25760       dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 1, 160)       25760       dropout_1[0][0]                  
__________________________________________________________________________________________________
add (Add)                       (None, 1)            0           dense_8[0][0]                    
                                                                 multiply[0][0]                   
__________________________________________________________________________________________________
multiply_1 (Multiply)           (None, 1, 160)       0           dense_15[0][0]                   
                                                                 dense_16[0][0]                   
__________________________________________________________________________________________________
layer_normalization (LayerNorma (None, 1)            2           add[0][0]                        
__________________________________________________________________________________________________
add_1 (Add)                     (None, 1, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_1[0][0]                 
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 1)            0           layer_normalization[0][0]        
__________________________________________________________________________________________________
layer_normalization_1 (LayerNor (None, 1, 160)       320         add_1[0][0]                      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 1)]       0           activation_1[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_1[0][0]      
__________________________________________________________________________________________________
multiply_2 (Multiply)           (None, 1, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 160)]        0           multiply_2[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 160)          0           dense_17[0][0]                   
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 8)]      0           input_1[0][0]                    
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 160)          25760       activation_3[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 1)]      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 160)          0           dense_18[0][0]                   
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed (TimeDistribut (None, 32, 160)      320         tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 160)          25760       dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 160)          25760       dropout_2[0][0]                  
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160, 7)] 0           time_distributed_1[0][0]         
                                                                 time_distributed_2[0][0]         
                                                                 time_distributed_3[0][0]         
                                                                 time_distributed_4[0][0]         
                                                                 time_distributed_5[0][0]         
                                                                 time_distributed_6[0][0]         
                                                                 time_distributed_7[0][0]         
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160, 1)] 0           time_distributed[0][0]           
__________________________________________________________________________________________________
multiply_3 (Multiply)           (None, 160)          0           dense_19[0][0]                   
                                                                 dense_20[0][0]                   
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 7)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 1)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_2 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_3[0][0]                 
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 8)] 0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
layer_normalization_2 (LayerNor (None, 160)          320         add_2[0][0]                      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 1280)]   0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_2[0][0]      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160, 7)]  0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, 24, 160)      204960      tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, 1, 160)       25600       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 1120)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_2[0][0]      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           time_distributed_9[0][0]         
                                                                 time_distributed_10[0][0]        
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_47 (TimeDistri (None, 8, 160)       179360      tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_48 (TimeDistri (None, 1, 160)       25600       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_14 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_18 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_22 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_26 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_30 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_34 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_38 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_42 (TimeDistri (None, 24, 160)      25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           time_distributed_47[0][0]        
                                                                 time_distributed_48[0][0]        
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, 24, 160)      25760       activation_7[0][0]               
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 24, 160)      0           time_distributed_14[0][0]        
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 24, 160)      0           time_distributed_18[0][0]        
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 24, 160)      0           time_distributed_22[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 160)      0           time_distributed_26[0][0]        
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 24, 160)      0           time_distributed_30[0][0]        
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 24, 160)      0           time_distributed_34[0][0]        
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 24, 160)      0           time_distributed_38[0][0]        
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 24, 160)      0           time_distributed_42[0][0]        
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_52 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_56 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_60 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_64 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_68 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_72 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_76 (TimeDistri (None, 8, 160)       25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 160)      0           time_distributed_11[0][0]        
__________________________________________________________________________________________________
time_distributed_15 (TimeDistri (None, 24, 160)      25760       activation_9[0][0]               
__________________________________________________________________________________________________
time_distributed_19 (TimeDistri (None, 24, 160)      25760       activation_10[0][0]              
__________________________________________________________________________________________________
time_distributed_23 (TimeDistri (None, 24, 160)      25760       activation_11[0][0]              
__________________________________________________________________________________________________
time_distributed_27 (TimeDistri (None, 24, 160)      25760       activation_12[0][0]              
__________________________________________________________________________________________________
time_distributed_31 (TimeDistri (None, 24, 160)      25760       activation_13[0][0]              
__________________________________________________________________________________________________
time_distributed_35 (TimeDistri (None, 24, 160)      25760       activation_14[0][0]              
__________________________________________________________________________________________________
time_distributed_39 (TimeDistri (None, 24, 160)      25760       activation_15[0][0]              
__________________________________________________________________________________________________
time_distributed_43 (TimeDistri (None, 24, 160)      25760       activation_16[0][0]              
__________________________________________________________________________________________________
time_distributed_49 (TimeDistri (None, 8, 160)       25760       activation_17[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 160)       0           time_distributed_52[0][0]        
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 160)       0           time_distributed_56[0][0]        
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 160)       0           time_distributed_60[0][0]        
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 160)       0           time_distributed_64[0][0]        
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 160)       0           time_distributed_68[0][0]        
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 160)       0           time_distributed_72[0][0]        
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 160)       0           time_distributed_76[0][0]        
__________________________________________________________________________________________________
time_distributed_12 (TimeDistri (None, 24, 8)        1288        dropout_6[0][0]                  
__________________________________________________________________________________________________
time_distributed_13 (TimeDistri (None, 24, 8)        1288        dropout_6[0][0]                  
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 160)      0           time_distributed_15[0][0]        
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 160)      0           time_distributed_19[0][0]        
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 160)      0           time_distributed_23[0][0]        
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 160)      0           time_distributed_27[0][0]        
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 160)      0           time_distributed_31[0][0]        
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 160)      0           time_distributed_35[0][0]        
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 24, 160)      0           time_distributed_39[0][0]        
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 24, 160)      0           time_distributed_43[0][0]        
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 8, 160)       0           time_distributed_49[0][0]        
__________________________________________________________________________________________________
time_distributed_53 (TimeDistri (None, 8, 160)       25760       activation_19[0][0]              
__________________________________________________________________________________________________
time_distributed_57 (TimeDistri (None, 8, 160)       25760       activation_20[0][0]              
__________________________________________________________________________________________________
time_distributed_61 (TimeDistri (None, 8, 160)       25760       activation_21[0][0]              
__________________________________________________________________________________________________
time_distributed_65 (TimeDistri (None, 8, 160)       25760       activation_22[0][0]              
__________________________________________________________________________________________________
time_distributed_69 (TimeDistri (None, 8, 160)       25760       activation_23[0][0]              
__________________________________________________________________________________________________
time_distributed_73 (TimeDistri (None, 8, 160)       25760       activation_24[0][0]              
__________________________________________________________________________________________________
time_distributed_77 (TimeDistri (None, 8, 160)       25760       activation_25[0][0]              
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, 24, 8)        10248       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
multiply_7 (Multiply)           (None, 24, 8)        0           time_distributed_12[0][0]        
                                                                 time_distributed_13[0][0]        
__________________________________________________________________________________________________
time_distributed_16 (TimeDistri (None, 24, 160)      25760       dropout_7[0][0]                  
__________________________________________________________________________________________________
time_distributed_17 (TimeDistri (None, 24, 160)      25760       dropout_7[0][0]                  
__________________________________________________________________________________________________
time_distributed_20 (TimeDistri (None, 24, 160)      25760       dropout_8[0][0]                  
__________________________________________________________________________________________________
time_distributed_21 (TimeDistri (None, 24, 160)      25760       dropout_8[0][0]                  
__________________________________________________________________________________________________
time_distributed_24 (TimeDistri (None, 24, 160)      25760       dropout_9[0][0]                  
__________________________________________________________________________________________________
time_distributed_25 (TimeDistri (None, 24, 160)      25760       dropout_9[0][0]                  
__________________________________________________________________________________________________
time_distributed_28 (TimeDistri (None, 24, 160)      25760       dropout_10[0][0]                 
__________________________________________________________________________________________________
time_distributed_29 (TimeDistri (None, 24, 160)      25760       dropout_10[0][0]                 
__________________________________________________________________________________________________
time_distributed_32 (TimeDistri (None, 24, 160)      25760       dropout_11[0][0]                 
__________________________________________________________________________________________________
time_distributed_33 (TimeDistri (None, 24, 160)      25760       dropout_11[0][0]                 
__________________________________________________________________________________________________
time_distributed_36 (TimeDistri (None, 24, 160)      25760       dropout_12[0][0]                 
__________________________________________________________________________________________________
time_distributed_37 (TimeDistri (None, 24, 160)      25760       dropout_12[0][0]                 
__________________________________________________________________________________________________
time_distributed_40 (TimeDistri (None, 24, 160)      25760       dropout_13[0][0]                 
__________________________________________________________________________________________________
time_distributed_41 (TimeDistri (None, 24, 160)      25760       dropout_13[0][0]                 
__________________________________________________________________________________________________
time_distributed_44 (TimeDistri (None, 24, 160)      25760       dropout_14[0][0]                 
__________________________________________________________________________________________________
time_distributed_45 (TimeDistri (None, 24, 160)      25760       dropout_14[0][0]                 
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 160)          0           dense_25[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 160)          0           dense_29[0][0]                   
__________________________________________________________________________________________________
time_distributed_50 (TimeDistri (None, 8, 7)         1127        dropout_15[0][0]                 
__________________________________________________________________________________________________
time_distributed_51 (TimeDistri (None, 8, 7)         1127        dropout_15[0][0]                 
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 8, 160)       0           time_distributed_53[0][0]        
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 8, 160)       0           time_distributed_57[0][0]        
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 8, 160)       0           time_distributed_61[0][0]        
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 8, 160)       0           time_distributed_65[0][0]        
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, 8, 160)       0           time_distributed_69[0][0]        
__________________________________________________________________________________________________
dropout_21 (Dropout)            (None, 8, 160)       0           time_distributed_73[0][0]        
__________________________________________________________________________________________________
dropout_22 (Dropout)            (None, 8, 160)       0           time_distributed_77[0][0]        
__________________________________________________________________________________________________
add_6 (Add)                     (None, 24, 8)        0           time_distributed_8[0][0]         
                                                                 multiply_7[0][0]                 
__________________________________________________________________________________________________
multiply_8 (Multiply)           (None, 24, 160)      0           time_distributed_16[0][0]        
                                                                 time_distributed_17[0][0]        
__________________________________________________________________________________________________
multiply_9 (Multiply)           (None, 24, 160)      0           time_distributed_20[0][0]        
                                                                 time_distributed_21[0][0]        
__________________________________________________________________________________________________
multiply_10 (Multiply)          (None, 24, 160)      0           time_distributed_24[0][0]        
                                                                 time_distributed_25[0][0]        
__________________________________________________________________________________________________
multiply_11 (Multiply)          (None, 24, 160)      0           time_distributed_28[0][0]        
                                                                 time_distributed_29[0][0]        
__________________________________________________________________________________________________
multiply_12 (Multiply)          (None, 24, 160)      0           time_distributed_32[0][0]        
                                                                 time_distributed_33[0][0]        
__________________________________________________________________________________________________
multiply_13 (Multiply)          (None, 24, 160)      0           time_distributed_36[0][0]        
                                                                 time_distributed_37[0][0]        
__________________________________________________________________________________________________
multiply_14 (Multiply)          (None, 24, 160)      0           time_distributed_40[0][0]        
                                                                 time_distributed_41[0][0]        
__________________________________________________________________________________________________
multiply_15 (Multiply)          (None, 24, 160)      0           time_distributed_44[0][0]        
                                                                 time_distributed_45[0][0]        
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 160)          25760       activation_5[0][0]               
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 160)          25760       activation_6[0][0]               
__________________________________________________________________________________________________
time_distributed_46 (TimeDistri (None, 8, 7)         7847        tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
multiply_17 (Multiply)          (None, 8, 7)         0           time_distributed_50[0][0]        
                                                                 time_distributed_51[0][0]        
__________________________________________________________________________________________________
time_distributed_54 (TimeDistri (None, 8, 160)       25760       dropout_16[0][0]                 
__________________________________________________________________________________________________
time_distributed_55 (TimeDistri (None, 8, 160)       25760       dropout_16[0][0]                 
__________________________________________________________________________________________________
time_distributed_58 (TimeDistri (None, 8, 160)       25760       dropout_17[0][0]                 
__________________________________________________________________________________________________
time_distributed_59 (TimeDistri (None, 8, 160)       25760       dropout_17[0][0]                 
__________________________________________________________________________________________________
time_distributed_62 (TimeDistri (None, 8, 160)       25760       dropout_18[0][0]                 
__________________________________________________________________________________________________
time_distributed_63 (TimeDistri (None, 8, 160)       25760       dropout_18[0][0]                 
__________________________________________________________________________________________________
time_distributed_66 (TimeDistri (None, 8, 160)       25760       dropout_19[0][0]                 
__________________________________________________________________________________________________
time_distributed_67 (TimeDistri (None, 8, 160)       25760       dropout_19[0][0]                 
__________________________________________________________________________________________________
time_distributed_70 (TimeDistri (None, 8, 160)       25760       dropout_20[0][0]                 
__________________________________________________________________________________________________
time_distributed_71 (TimeDistri (None, 8, 160)       25760       dropout_20[0][0]                 
__________________________________________________________________________________________________
time_distributed_74 (TimeDistri (None, 8, 160)       25760       dropout_21[0][0]                 
__________________________________________________________________________________________________
time_distributed_75 (TimeDistri (None, 8, 160)       25760       dropout_21[0][0]                 
__________________________________________________________________________________________________
time_distributed_78 (TimeDistri (None, 8, 160)       25760       dropout_22[0][0]                 
__________________________________________________________________________________________________
time_distributed_79 (TimeDistri (None, 8, 160)       25760       dropout_22[0][0]                 
__________________________________________________________________________________________________
layer_normalization_6 (LayerNor (None, 24, 8)        16          add_6[0][0]                      
__________________________________________________________________________________________________
add_7 (Add)                     (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_8[0][0]                 
__________________________________________________________________________________________________
add_8 (Add)                     (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_9[0][0]                 
__________________________________________________________________________________________________
add_9 (Add)                     (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_10[0][0]                
__________________________________________________________________________________________________
add_10 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_11[0][0]                
__________________________________________________________________________________________________
add_11 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_12[0][0]                
__________________________________________________________________________________________________
add_12 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_13[0][0]                
__________________________________________________________________________________________________
add_13 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_14[0][0]                
__________________________________________________________________________________________________
add_14 (Add)                    (None, 24, 160)      0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_15[0][0]                
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 160)          0           dense_26[0][0]                   
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 160)          0           dense_30[0][0]                   
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 7)         0           time_distributed_46[0][0]        
                                                                 multiply_17[0][0]                
__________________________________________________________________________________________________
multiply_18 (Multiply)          (None, 8, 160)       0           time_distributed_54[0][0]        
                                                                 time_distributed_55[0][0]        
__________________________________________________________________________________________________
multiply_19 (Multiply)          (None, 8, 160)       0           time_distributed_58[0][0]        
                                                                 time_distributed_59[0][0]        
__________________________________________________________________________________________________
multiply_20 (Multiply)          (None, 8, 160)       0           time_distributed_62[0][0]        
                                                                 time_distributed_63[0][0]        
__________________________________________________________________________________________________
multiply_21 (Multiply)          (None, 8, 160)       0           time_distributed_66[0][0]        
                                                                 time_distributed_67[0][0]        
__________________________________________________________________________________________________
multiply_22 (Multiply)          (None, 8, 160)       0           time_distributed_70[0][0]        
                                                                 time_distributed_71[0][0]        
__________________________________________________________________________________________________
multiply_23 (Multiply)          (None, 8, 160)       0           time_distributed_74[0][0]        
                                                                 time_distributed_75[0][0]        
__________________________________________________________________________________________________
multiply_24 (Multiply)          (None, 8, 160)       0           time_distributed_78[0][0]        
                                                                 time_distributed_79[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 8)        0           layer_normalization_6[0][0]      
__________________________________________________________________________________________________
layer_normalization_7 (LayerNor (None, 24, 160)      320         add_7[0][0]                      
__________________________________________________________________________________________________
layer_normalization_8 (LayerNor (None, 24, 160)      320         add_8[0][0]                      
__________________________________________________________________________________________________
layer_normalization_9 (LayerNor (None, 24, 160)      320         add_9[0][0]                      
__________________________________________________________________________________________________
layer_normalization_10 (LayerNo (None, 24, 160)      320         add_10[0][0]                     
__________________________________________________________________________________________________
layer_normalization_11 (LayerNo (None, 24, 160)      320         add_11[0][0]                     
__________________________________________________________________________________________________
layer_normalization_12 (LayerNo (None, 24, 160)      320         add_12[0][0]                     
__________________________________________________________________________________________________
layer_normalization_13 (LayerNo (None, 24, 160)      320         add_13[0][0]                     
__________________________________________________________________________________________________
layer_normalization_14 (LayerNo (None, 24, 160)      320         add_14[0][0]                     
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 160)          25760       dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 160)          25760       dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 160)          25760       dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 160)          25760       dropout_5[0][0]                  
__________________________________________________________________________________________________
layer_normalization_15 (LayerNo (None, 8, 7)         14          add_15[0][0]                     
__________________________________________________________________________________________________
add_16 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_18[0][0]                
__________________________________________________________________________________________________
add_17 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_19[0][0]                
__________________________________________________________________________________________________
add_18 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_20[0][0]                
__________________________________________________________________________________________________
add_19 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_21[0][0]                
__________________________________________________________________________________________________
add_20 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_22[0][0]                
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_23[0][0]                
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 160)       0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_24[0][0]                
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 1, 8)]   0           activation_8[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160, 8)] 0           layer_normalization_7[0][0]      
                                                                 layer_normalization_8[0][0]      
                                                                 layer_normalization_9[0][0]      
                                                                 layer_normalization_10[0][0]     
                                                                 layer_normalization_11[0][0]     
                                                                 layer_normalization_12[0][0]     
                                                                 layer_normalization_13[0][0]     
                                                                 layer_normalization_14[0][0]     
__________________________________________________________________________________________________
multiply_5 (Multiply)           (None, 160)          0           dense_27[0][0]                   
                                                                 dense_28[0][0]                   
__________________________________________________________________________________________________
multiply_6 (Multiply)           (None, 160)          0           dense_31[0][0]                   
                                                                 dense_32[0][0]                   
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 7)         0           layer_normalization_15[0][0]     
__________________________________________________________________________________________________
layer_normalization_16 (LayerNo (None, 8, 160)       320         add_16[0][0]                     
__________________________________________________________________________________________________
layer_normalization_17 (LayerNo (None, 8, 160)       320         add_17[0][0]                     
__________________________________________________________________________________________________
layer_normalization_18 (LayerNo (None, 8, 160)       320         add_18[0][0]                     
__________________________________________________________________________________________________
layer_normalization_19 (LayerNo (None, 8, 160)       320         add_19[0][0]                     
__________________________________________________________________________________________________
layer_normalization_20 (LayerNo (None, 8, 160)       320         add_20[0][0]                     
__________________________________________________________________________________________________
layer_normalization_21 (LayerNo (None, 8, 160)       320         add_21[0][0]                     
__________________________________________________________________________________________________
layer_normalization_22 (LayerNo (None, 8, 160)       320         add_22[0][0]                     
__________________________________________________________________________________________________
multiply_16 (Multiply)          (None, 24, 160, 8)   0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_4 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_5[0][0]                 
__________________________________________________________________________________________________
add_5 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_6[0][0]                 
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 1, 7)]    0           activation_18[0][0]              
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160, 7)]  0           layer_normalization_16[0][0]     
                                                                 layer_normalization_17[0][0]     
                                                                 layer_normalization_18[0][0]     
                                                                 layer_normalization_19[0][0]     
                                                                 layer_normalization_20[0][0]     
                                                                 layer_normalization_21[0][0]     
                                                                 layer_normalization_22[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 24, 160)]    0           multiply_16[0][0]                
__________________________________________________________________________________________________
layer_normalization_4 (LayerNor (None, 160)          320         add_4[0][0]                      
__________________________________________________________________________________________________
layer_normalization_5 (LayerNor (None, 160)          320         add_5[0][0]                      
__________________________________________________________________________________________________
multiply_25 (Multiply)          (None, 8, 160, 7)    0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 160)          25760       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
cu_dnnlstm (CuDNNLSTM)          [(None, 24, 160), (N 206080      tf_op_layer_TemporalFusionTransfo
                                                                 layer_normalization_4[0][0]      
                                                                 layer_normalization_5[0][0]      
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           multiply_25[0][0]                
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 160)          0           dense_21[0][0]                   
__________________________________________________________________________________________________
cu_dnnlstm_1 (CuDNNLSTM)        (None, 8, 160)       206080      tf_op_layer_TemporalFusionTransfo
                                                                 cu_dnnlstm[0][1]                 
                                                                 cu_dnnlstm[0][2]                 
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 160)          25760       activation_4[0][0]               
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160)]    0           cu_dnnlstm[0][0]                 
                                                                 cu_dnnlstm_1[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 160)          0           dense_22[0][0]                   
__________________________________________________________________________________________________
dropout_23 (Dropout)            (None, 32, 160)      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 160)          25760       dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 160)          25760       dropout_3[0][0]                  
__________________________________________________________________________________________________
time_distributed_80 (TimeDistri (None, 32, 160)      25760       dropout_23[0][0]                 
__________________________________________________________________________________________________
time_distributed_81 (TimeDistri (None, 32, 160)      25760       dropout_23[0][0]                 
__________________________________________________________________________________________________
multiply_4 (Multiply)           (None, 160)          0           dense_23[0][0]                   
                                                                 dense_24[0][0]                   
__________________________________________________________________________________________________
multiply_26 (Multiply)          (None, 32, 160)      0           time_distributed_80[0][0]        
                                                                 time_distributed_81[0][0]        
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160)]    0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_3 (Add)                     (None, 160)          0           tf_op_layer_TemporalFusionTransfo
                                                                 multiply_4[0][0]                 
__________________________________________________________________________________________________
add_23 (Add)                    (None, 32, 160)      0           multiply_26[0][0]                
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
layer_normalization_3 (LayerNor (None, 160)          320         add_3[0][0]                      
__________________________________________________________________________________________________
layer_normalization_23 (LayerNo (None, 32, 160)      320         add_23[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 1, 160)]     0           layer_normalization_3[0][0]      
__________________________________________________________________________________________________
time_distributed_82 (TimeDistri (None, 32, 160)      25760       layer_normalization_23[0][0]     
__________________________________________________________________________________________________
time_distributed_83 (TimeDistri (None, 1, 160)       25600       tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 32, 160)]    0           time_distributed_82[0][0]        
                                                                 time_distributed_83[0][0]        
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 32, 160)      0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
time_distributed_84 (TimeDistri (None, 32, 160)      25760       activation_26[0][0]              
__________________________________________________________________________________________________
dropout_24 (Dropout)            (None, 32, 160)      0           time_distributed_84[0][0]        
__________________________________________________________________________________________________
time_distributed_85 (TimeDistri (None, 32, 160)      25760       dropout_24[0][0]                 
__________________________________________________________________________________________________
time_distributed_86 (TimeDistri (None, 32, 160)      25760       dropout_24[0][0]                 
__________________________________________________________________________________________________
multiply_27 (Multiply)          (None, 32, 160)      0           time_distributed_85[0][0]        
                                                                 time_distributed_86[0][0]        
__________________________________________________________________________________________________
add_24 (Add)                    (None, 32, 160)      0           layer_normalization_23[0][0]     
                                                                 multiply_27[0][0]                
__________________________________________________________________________________________________
layer_normalization_24 (LayerNo (None, 32, 160)      320         add_24[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(3,)]               0           layer_normalization_24[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [()]                 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(3,)]               0           layer_normalization_24[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [()]                 0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(1,)]               0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(1,)]               0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(2,)]               0           tf_op_layer_TemporalFusionTransfo
                                                                 tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, None)]       0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, None, None)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 32, 160)      25600       layer_normalization_24[0][0]     
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 32, 160)      25600       layer_normalization_24[0][0]     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, None, None)] 0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 32, 32)       0           dense_113[0][0]                  
                                                                 dense_114[0][0]                  
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, None, None)   0           tf_op_layer_TemporalFusionTransfo
__________________________________________________________________________________________________
add_25 (Add)                    (None, 32, 32)       0           lambda[0][0]                     
                                                                 lambda_1[0][0]                   
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 32, 32)       0           add_25[0][0]                     
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 32, 32)       0           activation_27[0][0]              
__________________________________________________________________________________________________
dense_112 (Dense)               (None, 32, 160)      25600       layer_normalization_24[0][0]     
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 32, 160)      0           dropout_25[0][0]                 
                                                                 dense_112[0][0]                  
__________________________________________________________________________________________________
dropout_26 (Dropout)            (None, 32, 160)      0           lambda_2[0][0]                   
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 32, 160)      25600       dropout_26[0][0]                 
__________________________________________________________________________________________________
dropout_27 (Dropout)            (None, 32, 160)      0           dense_115[0][0]                  
__________________________________________________________________________________________________
dropout_28 (Dropout)            (None, 32, 160)      0           dropout_27[0][0]                 
__________________________________________________________________________________________________
time_distributed_87 (TimeDistri (None, 32, 160)      25760       dropout_28[0][0]                 
__________________________________________________________________________________________________
time_distributed_88 (TimeDistri (None, 32, 160)      25760       dropout_28[0][0]                 
__________________________________________________________________________________________________
multiply_28 (Multiply)          (None, 32, 160)      0           time_distributed_87[0][0]        
                                                                 time_distributed_88[0][0]        
__________________________________________________________________________________________________
add_26 (Add)                    (None, 32, 160)      0           multiply_28[0][0]                
                                                                 layer_normalization_24[0][0]     
__________________________________________________________________________________________________
layer_normalization_25 (LayerNo (None, 32, 160)      320         add_26[0][0]                     
__________________________________________________________________________________________________
time_distributed_89 (TimeDistri (None, 32, 160)      25760       layer_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 32, 160)      0           time_distributed_89[0][0]        
__________________________________________________________________________________________________
time_distributed_90 (TimeDistri (None, 32, 160)      25760       activation_28[0][0]              
__________________________________________________________________________________________________
dropout_29 (Dropout)            (None, 32, 160)      0           time_distributed_90[0][0]        
__________________________________________________________________________________________________
time_distributed_91 (TimeDistri (None, 32, 160)      25760       dropout_29[0][0]                 
__________________________________________________________________________________________________
time_distributed_92 (TimeDistri (None, 32, 160)      25760       dropout_29[0][0]                 
__________________________________________________________________________________________________
multiply_29 (Multiply)          (None, 32, 160)      0           time_distributed_91[0][0]        
                                                                 time_distributed_92[0][0]        
__________________________________________________________________________________________________
add_27 (Add)                    (None, 32, 160)      0           layer_normalization_25[0][0]     
                                                                 multiply_29[0][0]                
__________________________________________________________________________________________________
layer_normalization_26 (LayerNo (None, 32, 160)      320         add_27[0][0]                     
__________________________________________________________________________________________________
time_distributed_93 (TimeDistri (None, 32, 160)      25760       layer_normalization_26[0][0]     
__________________________________________________________________________________________________
time_distributed_94 (TimeDistri (None, 32, 160)      25760       layer_normalization_26[0][0]     
__________________________________________________________________________________________________
multiply_30 (Multiply)          (None, 32, 160)      0           time_distributed_93[0][0]        
                                                                 time_distributed_94[0][0]        
__________________________________________________________________________________________________
add_28 (Add)                    (None, 32, 160)      0           multiply_30[0][0]                
                                                                 layer_normalization_23[0][0]     
__________________________________________________________________________________________________
layer_normalization_27 (LayerNo (None, 32, 160)      320         add_28[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_TemporalFusionTrans [(None, 8, 160)]     0           layer_normalization_27[0][0]     
__________________________________________________________________________________________________
time_distributed_95 (TimeDistri (None, 8, 3)         483         tf_op_layer_TemporalFusionTransfo
==================================================================================================
Total params: 3,534,803
Trainable params: 3,534,803
Non-trainable params: 0
__________________________________________________________________________________________________
None
Loading model from /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min/saved_models/visitors/fixed/TemporalFusionTransformer.ckpt
tensor_name:  TemporalFusionTransformer/cu_dnnlstm/bias
[ 0.0049752  -0.01643778 -0.00209472 ...  0.07088844  0.01149169
 -0.0295977 ]
tensor_name:  TemporalFusionTransformer/cu_dnnlstm/kernel
[[ 0.11599316 -0.05337153 -0.13536319 ... -0.05782831 -0.0302281
   0.06074468]
 [-0.14407554  0.07199793  0.13628839 ...  0.13785724 -0.0852531
   0.01857963]
 [ 0.05549618  0.08376224  0.05140566 ...  0.10065831 -0.09451071
   0.02627488]
 ...
 [-0.06355723  0.11727801 -0.02066676 ... -0.03724499  0.02486874
   0.09389751]
 [-0.1020877  -0.05189322  0.01255756 ... -0.03803406  0.02160612
   0.00731839]
 [ 0.05994329  0.04442402  0.00514651 ...  0.0264558   0.07207286
  -0.04752708]]
tensor_name:  TemporalFusionTransformer/cu_dnnlstm/recurrent_kernel
[[-0.01565346  0.0716804   0.06716232 ... -0.08212918  0.03477367
   0.08430368]
 [-0.00348405  0.05343835  0.09049713 ...  0.01961045  0.05076921
  -0.00242858]
 [-0.04016029 -0.05578289 -0.05379019 ...  0.05208325  0.13239603
   0.05274989]
 ...
 [ 0.06441449 -0.01803273  0.03107736 ... -0.1114811   0.02683162
  -0.06284635]
 [-0.05928162 -0.0396817   0.03435392 ... -0.10818998  0.09932629
  -0.00153441]
 [-0.05033684 -0.18731767 -0.00677007 ... -0.06498916 -0.02099926
   0.07226448]]
tensor_name:  TemporalFusionTransformer/cu_dnnlstm_1/bias
[-0.02644667 -0.02688974 -0.02286516 ...  0.02561647  0.00675468
 -0.02242208]
tensor_name:  TemporalFusionTransformer/cu_dnnlstm_1/kernel
[[-0.07818868 -0.07701469  0.0023497  ... -0.08184066  0.0332508
   0.03157422]
 [ 0.01639131  0.08724933  0.00998696 ...  0.02970573  0.0099667
   0.04604201]
 [-0.00473123  0.05527691 -0.04794874 ...  0.02603081  0.05556605
  -0.09907459]
 ...
 [-0.01997878 -0.03920672 -0.07428642 ... -0.01318578  0.0139208
  -0.12779556]
 [ 0.10556146 -0.02815683  0.08154438 ... -0.02044059 -0.11294641
   0.0471283 ]
 [ 0.01443128 -0.00181992  0.12840627 ...  0.11945885  0.05461032
   0.0109483 ]]
tensor_name:  TemporalFusionTransformer/cu_dnnlstm_1/recurrent_kernel
[[ 0.01315279 -0.06934312 -0.03116082 ...  0.11518073 -0.03541429
  -0.00437794]
 [-0.15069002 -0.05220241  0.06064321 ...  0.03181585 -0.20713565
  -0.04042042]
 [-0.02969913 -0.18178803 -0.11679538 ... -0.0571398  -0.02440217
  -0.03525671]
 ...
 [ 0.05399798  0.00054002  0.0519568  ...  0.06230005 -0.05230554
   0.00908577]
 [ 0.05142331  0.02706666  0.02851485 ... -0.03321632 -0.11337173
  -0.14961271]
 [-0.06929448 -0.013641   -0.10398975 ...  0.13361146  0.01655342
  -0.02386313]]
tensor_name:  TemporalFusionTransformer/dense_10/bias
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
tensor_name:  TemporalFusionTransformer/dense_10/kernel
[[ 0.09120882 -0.08460343 -0.00576057 ... -0.00075604  0.03838703
  -0.08876073]
 [ 0.04492188 -0.09731992 -0.1358565  ...  0.11230953 -0.06198891
  -0.06926334]
 [ 0.0845187   0.08361226 -0.1254228  ... -0.12946653 -0.02196702
  -0.07473756]
 ...
 [ 0.04681791 -0.12911747 -0.02879873 ... -0.1117944  -0.13515198
  -0.08542462]
 [ 0.02543634  0.09604244  0.08297862 ... -0.08308675  0.06125224
   0.10255985]
 [-0.11675256 -0.00472233  0.12218085 ...  0.08686592  0.08292244
   0.05694008]]
tensor_name:  TemporalFusionTransformer/dense_11/bias
[0.]
tensor_name:  TemporalFusionTransformer/dense_11/kernel
[[-0.18391405]
 [-0.09177861]
 [-0.06008624]
 [-0.13107897]
 [ 0.15274572]
 [-0.17011735]
 [ 0.1366198 ]
 [-0.12022743]
 [ 0.06410906]
 [ 0.15737608]
 [ 0.09291318]
 [-0.1409601 ]
 [ 0.03269748]
 [-0.12813538]
 [ 0.02976139]
 [ 0.17065373]
 [-0.11351845]
 [-0.0802277 ]
 [-0.15543324]
 [ 0.13339716]
 [ 0.10292107]
 [ 0.17398828]
 [ 0.11087868]
 [-0.02059698]
 [ 0.0730046 ]
 [-0.08751738]
 [-0.02189058]
 [-0.03878975]
 [ 0.09640825]
 [ 0.11461791]
 [-0.17855386]
 [ 0.13837805]
 [ 0.1434015 ]
 [-0.14281614]
 [-0.02741784]
 [-0.00350483]
 [-0.024637  ]
 [ 0.12344044]
 [-0.02505615]
 [ 0.02316496]
 [-0.09203359]
 [ 0.00385891]
 [-0.03185612]
 [ 0.07594585]
 [ 0.02350596]
 [-0.02152178]
 [ 0.15858352]
 [ 0.01111412]
 [-0.08419159]
 [-0.17092837]
 [ 0.18142608]
 [-0.06625049]
 [ 0.05394371]
 [ 0.14822194]
 [-0.08713325]
 [-0.12063412]
 [-0.15099895]
 [-0.02228558]
 [-0.0936399 ]
 [ 0.1396262 ]
 [ 0.05152149]
 [ 0.01102354]
 [ 0.16491836]
 [-0.16208518]
 [ 0.14522418]
 [ 0.17637756]
 [ 0.09560221]
 [ 0.12098962]
 [-0.1084822 ]
 [-0.05269879]
 [ 0.17154452]
 [ 0.07237461]
 [ 0.0875048 ]
 [ 0.12632176]
 [-0.13709608]
 [-0.01843026]
 [ 0.02057433]
 [-0.12294108]
 [-0.17844552]
 [ 0.0140368 ]
 [-0.02759947]
 [ 0.00624217]
 [ 0.18166116]
 [ 0.04291663]
 [-0.03906637]
 [-0.1389181 ]
 [-0.07292568]
 [-0.18754633]
 [ 0.07990962]
 [ 0.04573189]
 [-0.07768703]
 [ 0.04472995]
 [ 0.18175507]
 [ 0.0044995 ]
 [ 0.04499525]
 [-0.10172306]
 [ 0.15219638]
 [-0.10020287]
 [-0.14784184]
 [-0.17346464]
 [-0.09319335]
 [ 0.05734301]
 [-0.13118666]
 [ 0.13890219]
 [-0.02373107]
 [-0.05676919]
 [ 0.075486  ]
 [ 0.02589807]
 [-0.12470571]
 [-0.01377971]
 [-0.07204981]
 [ 0.17362434]
 [-0.11363394]
 [-0.13478811]
 [-0.1443159 ]
 [ 0.19048807]
 [-0.07987339]
 [ 0.08864662]
 [-0.04424383]
 [ 0.14034313]
 [-0.13523501]
 [ 0.10476461]
 [-0.03354381]
 [ 0.05244091]
 [ 0.00798891]
 [ 0.18304437]
 [-0.15710849]
 [ 0.06389287]
 [-0.05645369]
 [-0.11559308]
 [-0.18431304]
 [-0.03272422]
 [ 0.091499  ]
 [-0.00089276]
 [-0.08364403]
 [ 0.05272512]
 [ 0.09416252]
 [ 0.04913118]
 [-0.1341923 ]
 [-0.0149495 ]
 [ 0.09871647]
 [-0.16395292]
 [ 0.0288875 ]
 [-0.02270354]
 [ 0.06521395]
 [ 0.08661646]
 [ 0.18726295]
 [ 0.12884253]
 [-0.04798947]
 [-0.11239289]
 [-0.138689  ]
 [ 0.08987123]
 [-0.02059782]
 [ 0.12993586]
 [ 0.02495785]
 [ 0.0116912 ]
 [-0.14719096]
 [ 0.03043714]
 [-0.00577465]
 [ 0.08281606]]
tensor_name:  TemporalFusionTransformer/dense_112/kernel
[[-0.01779717 -0.09146607  0.01289832 ... -0.13210845  0.01116025
   0.09177314]
 [-0.05310141  0.16279867 -0.11843594 ... -0.07877737 -0.12523393
   0.02728873]
 [-0.04122246  0.02596961 -0.05475671 ... -0.00457028  0.02377112
   0.10546404]
 ...
 [-0.07750025 -0.03394489  0.12422512 ...  0.11754775  0.12026788
  -0.01310947]
 [-0.06551996 -0.07547995  0.00913675 ... -0.03921739  0.08907393
  -0.02901278]
 [ 0.06489526 -0.01861348 -0.02032467 ... -0.07116724 -0.04022666
   0.00781621]]
tensor_name:  TemporalFusionTransformer/dense_113/kernel
[[ 0.01375245  0.05334575 -0.12924567 ... -0.11684038 -0.10305215
  -0.15447403]
 [ 0.05920275  0.04246505 -0.13240221 ...  0.01063828  0.05611022
   0.06998902]
 [ 0.08046275 -0.09987365 -0.04916464 ... -0.08521367  0.07224181
   0.03363936]
 ...
 [ 0.10731197 -0.02467308  0.01485583 ...  0.02738565  0.0867962
   0.13145857]
 [-0.08577337 -0.0205931  -0.10712387 ... -0.06423651  0.11384098
   0.08925891]
 [-0.02215627 -0.1252961   0.1302632  ... -0.10403225 -0.08232963
  -0.10409865]]
tensor_name:  TemporalFusionTransformer/dense_114/kernel
[[ 0.08607653  0.09919216 -0.10557176 ...  0.15617932 -0.02302196
   0.11604605]
 [ 0.0225543  -0.10056964 -0.09305514 ...  0.10475582  0.06613287
   0.00555408]
 [ 0.06245023 -0.00252746 -0.08263469 ... -0.11390971  0.01577945
   0.15938559]
 ...
 [ 0.11432207 -0.14819531  0.08638716 ...  0.02419167  0.01608068
   0.11465336]
 [ 0.092815    0.01864299  0.08964469 ... -0.02850413  0.06121961
   0.01610893]
 [ 0.2099291  -0.10245452 -0.04088681 ...  0.01373518 -0.07915288
  -0.06614491]]
tensor_name:  TemporalFusionTransformer/dense_115/kernel
[[-0.06535397 -0.0487131  -0.0220327  ...  0.0293775   0.05926363
  -0.07176682]
 [ 0.03030529  0.07210707  0.02164157 ...  0.07691903 -0.17692277
  -0.01421472]
 [-0.06469049 -0.13052697  0.06390122 ... -0.10883795  0.09030915
   0.05583323]
 ...
 [ 0.07780862 -0.00447646  0.14704977 ... -0.0922223  -0.08861449
   0.09250227]
 [ 0.04804182 -0.08615717  0.17318164 ...  0.04575338  0.0746273
  -0.12958664]
 [-0.13606632  0.09878585 -0.11689401 ... -0.11765695  0.09362628
   0.07823962]]
tensor_name:  TemporalFusionTransformer/dense_12/bias
[0.]
tensor_name:  TemporalFusionTransformer/dense_12/kernel
[[ 0.13289708]
 [ 0.06987035]
 [-0.01868516]
 [ 0.01038221]
 [ 0.11997613]
 [-0.04248996]
 [-0.11982609]
 [ 0.16721418]
 [-0.07178962]
 [-0.0545084 ]
 [ 0.01739818]
 [ 0.16671598]
 [-0.07510243]
 [-0.18463357]
 [-0.14402004]
 [ 0.11764175]
 [-0.02348363]
 [ 0.19119734]
 [-0.14066862]
 [ 0.14945   ]
 [ 0.19137678]
 [-0.0756316 ]
 [-0.01425226]
 [ 0.17283067]
 [-0.19202921]
 [ 0.1834014 ]
 [ 0.10498363]
 [ 0.14531034]
 [-0.15459874]
 [ 0.19193098]
 [-0.13037574]
 [ 0.06022054]
 [ 0.16041705]
 [ 0.14716613]
 [ 0.03988346]
 [-0.10482549]
 [ 0.10611936]
 [ 0.10435337]
 [ 0.08297798]
 [-0.17920569]
 [ 0.09943533]
 [ 0.11114162]
 [-0.09785371]
 [ 0.096194  ]
 [-0.03102103]
 [-0.02243586]
 [-0.09093292]
 [ 0.03126524]
 [ 0.06934473]
 [-0.14833972]
 [-0.18039563]
 [ 0.04311191]
 [-0.02190863]
 [ 0.14644423]
 [ 0.17753544]
 [ 0.12345326]
 [-0.12683919]
 [-0.08273055]
 [-0.11714429]
 [ 0.13585481]
 [-0.06029524]
 [-0.15459403]
 [ 0.16289243]
 [-0.12719828]
 [-0.10585412]
 [ 0.02272236]
 [ 0.00487176]
 [-0.15387194]
 [ 0.09434557]
 [-0.01671469]
 [-0.08309005]
 [ 0.13385195]
 [-0.09521996]
 [ 0.19007617]
 [ 0.11865753]
 [ 0.12052861]
 [-0.16325705]
 [-0.15702182]
 [ 0.06539768]
 [-0.04993415]
 [-0.06682684]
 [ 0.02627701]
 [-0.06307268]
 [ 0.03212371]
 [-0.01325028]
 [-0.05043201]
 [ 0.06161565]
 [-0.06944087]
 [-0.12787004]
 [ 0.11116716]
 [ 0.11907205]
 [-0.17872955]
 [ 0.180473  ]
 [ 0.01656778]
 [-0.14912836]
 [ 0.00986759]
 [ 0.00397365]
 [-0.06213798]
 [ 0.18687433]
 [ 0.01698837]
 [ 0.08758372]
 [ 0.02864131]
 [-0.11141171]
 [ 0.11442807]
 [-0.17160836]
 [ 0.0455564 ]
 [ 0.16343024]
 [-0.05210271]
 [ 0.15643778]
 [ 0.14629248]
 [ 0.15733668]
 [-0.06217563]
 [ 0.16543555]
 [ 0.09564701]
 [ 0.10956594]
 [ 0.16323099]
 [-0.125702  ]
 [-0.02316813]
 [ 0.11492974]
 [ 0.0193917 ]
 [ 0.12852237]
 [ 0.18874255]
 [ 0.03862281]
 [-0.17267695]
 [ 0.14472598]
 [-0.1732652 ]
 [ 0.18370426]
 [-0.05427045]
 [ 0.05882323]
 [ 0.0245803 ]
 [-0.15983763]
 [-0.09210419]
 [-0.15818825]
 [ 0.15948743]
 [ 0.02172214]
 [ 0.14861268]
 [-0.01668027]
 [ 0.18468645]
 [ 0.05404584]
 [-0.04823515]
 [ 0.1395101 ]
 [ 0.03048354]
 [ 0.00450566]
 [ 0.06339797]
 [-0.18520218]
 [ 0.0516987 ]
 [-0.07615795]
 [ 0.00305802]
 [-0.03346285]
 [-0.05622944]
 [-0.10930897]
 [ 0.14175755]
 [ 0.1567756 ]
 [ 0.00539185]
 [-0.10341949]
 [-0.14187154]
 [-0.00594011]
 [-0.09590501]
 [-0.0374456 ]
 [-0.05972318]]
tensor_name:  TemporalFusionTransformer/dense_13/bias
[ 1.3713062e-02 -3.8852911e-03 -2.1437290e-03 -4.7472090e-04
  1.5140072e-02  1.8880514e-02 -1.1661166e-02 -1.6793430e-02
 -5.1620156e-03 -3.8173816e-03  8.8477191e-03 -7.1614678e-03
 -5.6654331e-03 -1.4426106e-02  3.2594460e-03  2.3904829e-03
  1.4981254e-03 -2.4137719e-02  2.0622348e-02 -1.3479489e-02
  7.0621301e-03 -5.5640442e-03  1.1415113e-02  4.9338788e-03
  9.0585798e-03 -9.4107427e-03 -9.5441581e-05  1.4055432e-02
 -6.6796094e-03 -3.2283796e-03 -6.8125781e-03 -2.6505956e-02
 -7.0168246e-03 -1.3399367e-02  4.2828061e-03 -1.6270026e-03
 -2.1608355e-02  7.5131021e-03 -1.1909601e-02 -1.2085370e-02
  8.7012267e-03 -2.4258399e-02 -1.7976194e-03  1.1706280e-02
 -2.7304832e-03 -8.8681481e-05 -1.4357285e-02  1.6219671e-03
 -6.8798764e-03  7.7204960e-03 -1.0949736e-02  5.5563487e-03
  2.3953686e-03  6.9512813e-03 -4.2358558e-03 -1.6393637e-02
 -7.8028464e-03  7.6015792e-03 -1.0968627e-02  2.7535870e-03
 -2.3318266e-03  1.3135129e-02 -1.3024762e-02  3.2311867e-03
  4.1580432e-05  1.9285548e-03 -1.8647591e-02 -3.8316834e-03
  1.5905358e-02  2.4597904e-02 -8.4262937e-03 -8.7805428e-03
 -7.0421067e-03 -3.9068274e-03 -1.4519123e-03  6.4157657e-03
 -6.6508050e-03 -1.8923887e-03 -9.4156405e-03 -2.4545353e-04
 -2.0853572e-02  1.1139948e-02 -2.0310579e-02 -7.9026567e-03
 -9.7833117e-03  6.3876817e-03  3.6784839e-03 -1.4531918e-02
  3.9319028e-03 -3.5242580e-03  5.7655028e-03  6.5550325e-03
 -3.8831292e-03  2.9024042e-03  1.1454243e-02  5.0037117e-03
  1.6402781e-02  1.7524291e-02  5.7036416e-03  2.6372564e-03
 -2.8283657e-03  2.2115842e-03 -5.6049936e-03  4.2917844e-04
  9.0868277e-03  4.7556320e-03 -8.5704902e-04  3.9383369e-03
  2.7371747e-02  2.6451251e-03  8.8259596e-03  6.0726819e-03
 -2.5631493e-02 -5.9522036e-03 -5.3894958e-03  7.3778764e-03
 -8.2723694e-03 -7.5501497e-03  1.2824205e-03 -6.5800566e-03
  1.0656968e-02  7.8099743e-03 -4.3181451e-03 -4.4629364e-03
  6.4380665e-04  3.3851429e-03 -1.4126160e-02 -1.7754631e-02
  9.2463684e-04 -9.6035516e-03  1.1893452e-02 -7.7593951e-03
  1.0015313e-02  1.2448067e-02 -1.4608129e-03 -1.3023471e-02
 -4.4240938e-03 -1.1869814e-03  3.9554320e-04 -2.9600107e-03
 -2.2699613e-02  2.8756217e-04  9.6022151e-03  5.7276748e-03
  5.2767042e-03 -2.3496104e-02 -2.5400328e-03 -1.9071320e-02
 -1.0788217e-02 -3.1613093e-03 -1.8167001e-04 -1.0467833e-02
 -2.4383988e-03  8.6596422e-03 -9.4594155e-03  8.5023539e-03
  5.2719614e-03  5.4951878e-03 -1.2103686e-02 -1.6711045e-02]
tensor_name:  TemporalFusionTransformer/dense_13/kernel
[[ 0.13096763  0.12004022 -0.04936888 ... -0.00225111  0.11916706
  -0.12972824]
 [ 0.04892728  0.09817923  0.11225107 ...  0.06499747  0.00504013
   0.0053408 ]
 [ 0.0277658  -0.12006369  0.11060701 ... -0.10725692  0.07845583
  -0.05964405]
 ...
 [ 0.00024385 -0.09791188 -0.06861103 ...  0.06721535  0.06993591
  -0.00401923]
 [ 0.0975771   0.10433163  0.02859625 ... -0.01320877 -0.06083936
  -0.01980874]
 [ 0.14638016 -0.099681    0.00848834 ... -0.08633177 -0.04779506
  -0.06399261]]
tensor_name:  TemporalFusionTransformer/dense_14/bias
[-1.43537496e-03 -5.22566959e-03 -6.32689102e-04  5.02004114e-04
  4.68880124e-03 -9.00448114e-03 -5.80780115e-03  1.43079869e-02
 -5.25203999e-03  1.79439988e-02  6.49856869e-03 -2.64795329e-02
 -4.50446876e-03  3.79946688e-03  3.72613855e-02  6.89315982e-03
 -7.35926116e-03 -2.30420958e-02  1.92475058e-02  7.59475585e-03
 -1.81211031e-03 -1.32355688e-03  3.95165384e-03  9.46681574e-03
 -3.66449147e-03 -5.04259579e-03  9.29333561e-04 -1.43472962e-02
 -1.15165217e-02 -2.28554644e-02 -1.53134959e-02  1.25102308e-02
 -3.10538011e-03  2.54873256e-03 -5.83678391e-03 -1.59983849e-03
 -2.13110149e-02 -2.69449642e-03 -1.35321962e-02 -9.55457333e-03
  1.54082403e-02  2.05219112e-05  1.45303421e-02  1.66256838e-02
  2.03462541e-02 -6.25804393e-03 -6.40876498e-03 -1.50905615e-02
 -5.55785932e-03 -6.30741299e-04  1.05166649e-02 -3.48900096e-04
 -1.02597130e-02 -3.01466119e-02  7.30600487e-03 -1.53381901e-03
  1.85855217e-02  4.57126414e-03 -9.37590841e-03  3.63777997e-03
 -5.15377522e-03 -3.11008701e-03  1.57731362e-02 -1.08528975e-03
  9.09864996e-03  5.44335553e-03 -7.42846867e-03  3.63820978e-02
  1.07817240e-02 -2.98398710e-03 -3.25936708e-03 -5.43046044e-03
 -1.51330810e-02 -1.70621113e-03  3.38542974e-03  3.95906856e-03
  5.23538422e-03  1.31358625e-04 -1.81882121e-02  1.16407080e-02
 -7.52285880e-04 -1.01983044e-02  1.23475795e-03 -2.90258578e-03
 -3.21585569e-03  2.17842567e-03  6.76788716e-03 -2.07336377e-02
 -1.46322325e-02  1.06745940e-02  1.51010379e-02  6.91208802e-03
 -5.87465661e-03  9.70070995e-03 -2.83222925e-02  2.60675214e-02
 -1.32016623e-02  7.59888964e-04  1.87072605e-02  8.39943253e-03
  1.95386317e-02 -2.39618239e-03 -1.52593199e-02 -1.34766353e-02
  5.89819998e-03 -3.57178762e-03  1.76010113e-02  2.16481946e-02
 -6.04487676e-03  7.46887270e-03  1.31943487e-02 -1.24586029e-02
  7.29687791e-03 -3.54320812e-03 -1.14983250e-03 -1.76504496e-02
  1.58469740e-03  8.24333727e-03  1.47364307e-02  4.44389461e-03
 -5.39899059e-03  9.52622667e-03  1.98662118e-03  1.45523855e-02
  1.49954222e-02 -1.91271782e-03  1.50838727e-02 -1.81361362e-02
 -2.09686104e-02 -1.23572852e-02  1.90286636e-02  2.30558775e-02
  8.58543348e-03  4.35764715e-03 -1.88953243e-02  1.14003448e-02
 -1.07147323e-03  2.24951636e-02 -9.56952665e-03 -9.17630550e-03
 -2.18753312e-02  1.02852629e-02  5.97541267e-03  9.32202768e-03
  3.65703809e-03 -5.60254464e-03 -2.49835905e-02  8.01083352e-03
  2.05273516e-02 -1.55175813e-02  2.30111703e-02 -6.21748390e-03
  7.17088720e-03 -9.55466367e-03  1.79399282e-03 -2.37666443e-02
 -2.96765729e-03  4.25420731e-04  6.85463985e-03  8.51531979e-03]
tensor_name:  TemporalFusionTransformer/dense_14/kernel
[[-0.0733707  -0.07587203 -0.04689056 ... -0.07346191  0.14100386
   0.08412679]
 [ 0.06920622 -0.03658919  0.03237041 ... -0.00977007  0.10255383
   0.09710494]
 [ 0.09099904  0.06888683 -0.03991372 ... -0.00171011 -0.08590293
   0.07504904]
 ...
 [-0.0142924   0.07530753  0.09944006 ...  0.11554603 -0.12525794
  -0.11668548]
 [-0.02998503  0.08320158 -0.00722202 ... -0.06829239  0.03372461
  -0.00256378]
 [ 0.09505625  0.11365294  0.06403922 ... -0.0067817  -0.14829989
   0.00097647]]
tensor_name:  TemporalFusionTransformer/dense_15/bias
[-3.86804459e-03  4.48938236e-02 -7.71761872e-03 -1.37311155e-02
 -1.31083075e-02 -9.72692762e-03  4.68184473e-03 -7.26950774e-03
  6.33877190e-03  1.95575855e-03 -2.14969963e-02  1.91034693e-02
 -9.37838573e-03  5.31306723e-04  2.62497403e-02  1.18824875e-03
  2.02545850e-03 -3.90760135e-03  1.43698659e-02 -3.20333359e-03
 -1.51245121e-03  9.80031677e-04 -5.62293036e-03  7.54740508e-03
 -6.45923754e-03 -1.23439264e-02  2.55498546e-03 -1.25267599e-02
  3.41545744e-03  1.20511046e-03 -1.34172924e-02 -6.62547490e-03
 -7.11166766e-03 -7.54853385e-03 -1.08114434e-02  7.89772626e-03
  2.33486178e-03  8.31654947e-03 -1.32328933e-02 -1.59875990e-03
 -2.70370767e-02 -5.89542440e-04  1.00115994e-02  8.45345948e-03
 -3.54164490e-03 -4.87172417e-03 -7.41086807e-03 -4.44062147e-03
  1.88219652e-04 -7.74905668e-04  8.41962826e-03  2.57848632e-02
 -8.97951145e-03  5.38294204e-03 -1.24229665e-03 -6.39222004e-03
  1.35759562e-02  2.70032100e-02 -2.51953639e-02  3.73553345e-03
  3.08296317e-03 -1.05827609e-02 -2.37442157e-03  1.78199336e-02
 -3.57494392e-02  5.04283176e-04  5.84300328e-03  5.84362494e-03
  5.83068933e-03  1.35535980e-02 -1.21174892e-02 -2.32628565e-02
  4.43161093e-03 -2.91701430e-03 -8.00155848e-03 -4.92358289e-04
  6.90518226e-03  8.86675995e-03  4.98768582e-04 -6.19170209e-03
  5.33337239e-03 -2.55985954e-03 -5.66404965e-03  1.52073754e-03
 -1.14263697e-02  2.03067735e-02  1.60718113e-02  1.90579053e-02
  2.19744572e-04  5.44093270e-03 -6.82100328e-03  3.14866304e-02
  8.91019532e-04  3.60690150e-03 -1.72102917e-02  2.51780311e-03
 -6.38577575e-03  2.01527146e-03 -4.50608507e-02  1.79823469e-02
 -4.21495177e-03 -3.29847145e-03  4.59072820e-04 -8.67206883e-03
 -7.30842212e-03 -4.30388236e-03  1.41089607e-03 -8.24011490e-03
 -6.37544924e-03  2.62368117e-02 -5.31929312e-03 -7.09077925e-04
  2.33834540e-03  9.01728345e-05  1.68954693e-02 -1.10753067e-02
  2.78583057e-02  2.43287534e-03  3.30837257e-03 -2.34495616e-03
 -2.60436791e-03 -8.52376781e-03  1.63329411e-02 -8.05940293e-03
  4.84890444e-03  1.26998464e-03  2.07851012e-03  1.65921607e-04
 -4.28193109e-03  8.94049276e-03 -9.63599363e-04 -9.32874624e-03
  1.97302252e-02 -5.22071635e-03  7.62944482e-03 -8.86618905e-03
  1.09139355e-02 -1.46571337e-03 -1.85949507e-03 -2.96994066e-03
 -1.82112714e-03 -1.50176380e-02  2.14401986e-02 -4.66068182e-03
  5.53521095e-03  5.83519519e-04 -8.06983188e-03 -9.66653414e-03
 -3.07533015e-02 -7.55141396e-03 -3.31851305e-03  5.15000848e-03
 -8.33026425e-04  4.02019301e-04  3.44416266e-03 -1.19152078e-02
  7.89201178e-04  1.08876480e-02  1.88104361e-02  1.45554170e-02]
tensor_name:  TemporalFusionTransformer/dense_15/kernel
[[-0.07082091  0.03227438 -0.07713781 ... -0.09920051 -0.07602877
   0.0075689 ]
 [-0.07858215 -0.01684    -0.03494081 ... -0.06067798  0.05778072
  -0.13596599]
 [-0.08780837  0.08515282 -0.00125874 ...  0.115023   -0.1112458
  -0.01092712]
 ...
 [ 0.05521196  0.04325674  0.09554208 ...  0.03935548 -0.07885475
   0.00712331]
 [ 0.13765362  0.12573028  0.11507159 ... -0.01516003  0.05873377
  -0.061382  ]
 [ 0.08755545  0.09324723 -0.01918666 ... -0.11678682  0.02175727
  -0.0112017 ]]
tensor_name:  TemporalFusionTransformer/dense_16/bias
[-0.00709147  0.02033255 -0.01226668 -0.00264278 -0.00055896 -0.00986802
 -0.00587888 -0.00855203 -0.00186217 -0.01480109  0.01198905  0.00079279
 -0.00708537 -0.01424495  0.01273854 -0.01688157 -0.01471479 -0.01085933
  0.01142376 -0.017743   -0.00640573 -0.01255733 -0.00062501 -0.00884206
 -0.01410707 -0.00675456 -0.00614423  0.00252916 -0.00163452 -0.01141702
  0.0058067  -0.00510338 -0.00221053 -0.01231942  0.00016886 -0.02255952
 -0.00380779  0.00146532  0.00168535 -0.00603267  0.01055608 -0.00327755
  0.00211248 -0.00128141 -0.00531838 -0.00172879  0.00422706 -0.00614688
 -0.01450724 -0.01054288  0.00157572  0.01334975  0.00310018 -0.00864558
 -0.00104921  0.00235385  0.00030293  0.01357926 -0.00202655 -0.00518275
 -0.01601249 -0.01445754 -0.00628801 -0.00651519  0.0274555  -0.01495419
 -0.01609481 -0.007219    0.00077113 -0.00927174  0.00165386  0.01605956
 -0.01507638  0.0043821  -0.0097066  -0.01304368 -0.0032163  -0.01159392
 -0.0228907  -0.01473708 -0.01081796 -0.01281197 -0.00276165 -0.00242841
  0.00267596 -0.00272221  0.00998618  0.0196557  -0.01126547 -0.00337565
  0.01413     0.01867701 -0.00453608 -0.01080145  0.00912197 -0.01165619
 -0.00072459 -0.0023463   0.02930408  0.00198308  0.00082668 -0.00342369
 -0.00926455  0.00465    -0.00148437 -0.0023393  -0.00438598  0.00025214
 -0.01157848  0.01103483 -0.00410593 -0.00286158 -0.01200985 -0.00128585
 -0.00593413  0.00256899  0.02341896 -0.00593442 -0.01557779 -0.00725278
 -0.00730745 -0.00248171  0.00645528 -0.01891632 -0.00668284 -0.00614653
 -0.0103787  -0.00873672  0.00391298  0.00528921 -0.00408231  0.00197205
  0.00519003 -0.00455335 -0.02436097 -0.00977388 -0.02220981 -0.00273147
 -0.01403268 -0.01398664 -0.01630324  0.00877154  0.00855066 -0.02035413
 -0.00416688 -0.01245414 -0.012673   -0.00332616  0.02252222 -0.01207808
 -0.00874972 -0.00124182  0.00396683  0.00247581 -0.00650127  0.00471619
 -0.01733538 -0.00787701  0.00995363 -0.01218216]
tensor_name:  TemporalFusionTransformer/dense_16/kernel
[[ 0.01678269 -0.08532136  0.07851048 ...  0.11145249  0.04961013
   0.08635861]
 [ 0.11515354  0.00120925  0.11946593 ...  0.01871531  0.00158242
  -0.03841395]
 [ 0.1139056  -0.0490864  -0.12372523 ... -0.03623485 -0.04963769
  -0.10992523]
 ...
 [-0.00865943 -0.01848501  0.11096253 ...  0.1230584  -0.00688722
   0.13505855]
 [-0.02192805  0.07877398 -0.13896492 ...  0.02010598  0.10768507
   0.07310432]
 [ 0.07988849 -0.11969633  0.05701546 ... -0.07708447 -0.06198907
  -0.00770847]]
tensor_name:  TemporalFusionTransformer/dense_17/bias
[ 6.7045130e-03 -1.2956131e-02  5.0857393e-03 -1.5219814e-03
  4.4709803e-03 -5.6188260e-03  7.2452836e-03 -8.7135360e-03
 -3.7472905e-03 -6.4783231e-03  1.3970218e-03 -7.9023950e-03
 -6.3566030e-03 -1.2448876e-02  4.8331488e-03 -4.6023824e-03
 -6.4853302e-05  4.8284545e-03 -1.3516610e-03 -8.1494329e-03
  6.9350726e-04 -5.2869618e-03  9.3358604e-04 -3.9387825e-03
  9.2764193e-04 -1.2286928e-03  5.9558796e-03  1.0831282e-03
  2.6660960e-03  1.5934410e-03 -6.9267442e-04  3.6187263e-03
  2.6765063e-03 -6.4689205e-03 -7.1995734e-04  1.9698895e-03
  8.3521561e-05  1.3784519e-03 -5.3848200e-03 -4.0034824e-03
  5.4630218e-03  3.0199208e-03 -8.0034211e-03  4.6966749e-04
 -7.7514783e-03 -2.1136818e-03 -5.7810852e-03 -3.2707790e-03
 -3.0048697e-03  3.7810048e-03 -4.5310645e-03 -6.8573449e-03
 -9.4385520e-03  1.0266854e-02  3.7216749e-03  1.0474383e-02
 -7.4003516e-03  7.7190376e-03  3.5897777e-03  2.8151399e-05
 -4.2442936e-03 -1.0715895e-02 -4.3818345e-03 -4.3547009e-03
 -1.1399920e-02 -7.8439936e-03  3.6737199e-03 -1.3043273e-03
 -3.1538089e-03  2.7159811e-03 -9.5365169e-03 -3.4130707e-03
  1.2028194e-02  4.1101906e-03 -5.4735085e-03 -3.0411107e-03
 -3.8320944e-03  2.3201369e-03 -5.9914979e-04  9.9201151e-04
  8.6592194e-03  9.9827945e-03  2.0558182e-03 -3.4134530e-03
  2.5918344e-03 -2.6033602e-03  1.3623374e-02 -6.3623153e-03
  6.9504902e-03 -1.0561037e-02  7.9346299e-03 -3.8914250e-03
  4.5127096e-03 -6.7822146e-03  7.7845524e-03 -9.7645363e-03
 -6.2277666e-03 -3.8049931e-03 -3.2019338e-03  1.5133173e-02
 -4.5780395e-04  8.2033165e-03 -4.9806926e-03  8.2258284e-03
 -6.2979320e-03 -7.4721500e-03  1.5328696e-03 -9.4473558e-03
  1.0835017e-03  1.5501734e-03  3.7374864e-03 -7.4201394e-03
  8.9045772e-03  8.9993384e-03  7.5343868e-04  3.8897288e-03
 -2.6027514e-03 -1.7856547e-03 -8.0260652e-04  3.3891958e-03
 -4.8643434e-03 -2.7505455e-03 -4.3671909e-03 -7.7133453e-03
  1.5540920e-03 -5.9869802e-03  5.9385328e-03 -7.3368265e-03
 -5.8130883e-03 -4.5984243e-03 -1.5092341e-03  1.3830502e-02
 -3.7908712e-03 -1.7206054e-03  1.7995744e-03  9.7411081e-05
 -1.1031967e-02  2.7782142e-03 -3.9124861e-03  4.9347770e-03
  1.0636733e-04 -5.7803439e-03  3.2970242e-03  1.6130225e-03
 -1.4320093e-02 -6.6174776e-03 -7.4577914e-04  7.4084126e-03
  2.4777215e-03  1.8248842e-04 -7.3106857e-03 -1.1887843e-02
 -1.1483418e-02 -9.3501583e-03  1.3134411e-02 -8.5126963e-03
 -2.2440637e-03  7.9093445e-03  2.3788402e-03 -4.7256607e-03]
tensor_name:  TemporalFusionTransformer/dense_17/kernel
[[-0.02554534 -0.07493043 -0.11624781 ...  0.09903217  0.12666534
   0.04054962]
 [-0.14159577  0.04819326  0.00035829 ...  0.015255    0.12394715
   0.02836321]
 [-0.03653891  0.01056955 -0.01839331 ... -0.12961431  0.08351017
   0.13274111]
 ...
 [ 0.05597436  0.01461813 -0.08285484 ... -0.03996027  0.1284857
  -0.09795672]
 [-0.00615416 -0.12619744  0.04167339 ... -0.06468947 -0.0633438
   0.1064469 ]
 [-0.08128917 -0.05142453  0.12144445 ...  0.11248537  0.13298886
  -0.06943715]]
tensor_name:  TemporalFusionTransformer/dense_18/bias
[ 1.27744945e-02 -2.43189931e-03  2.78968690e-03  2.32363539e-03
 -1.02191260e-02  1.89265907e-02  9.48814861e-03 -2.86402705e-04
 -1.35158617e-02  9.21053719e-03 -2.40042130e-03  2.16710614e-03
  8.71898979e-03  8.79196730e-03  9.59391985e-03  6.05313573e-04
 -3.72658507e-03  1.44657325e-02 -1.22730508e-02 -1.30291041e-02
 -9.00059007e-03  8.71066097e-03 -2.86051407e-02 -1.13937743e-02
 -1.55958335e-03  5.31240413e-03  5.89981163e-03  4.81959432e-03
  8.53948109e-03 -7.30302045e-03 -2.80768680e-03  1.74627814e-03
 -1.69084815e-03 -6.96557947e-03 -8.54705868e-05  6.15567528e-03
 -3.50017310e-03 -1.71962176e-02  3.20619019e-03  4.12971806e-03
 -3.17005347e-03  2.25703865e-02  7.82267656e-03 -4.02433425e-03
 -1.13541866e-02  6.61645317e-03  3.27180000e-03  7.21583026e-04
 -2.18817918e-03 -3.09908693e-03  3.11643654e-03  5.27035445e-03
  1.40236982e-03 -7.55172037e-03 -8.88711866e-03  1.81014035e-02
  2.47967168e-04  7.37161003e-03 -5.87499654e-03  5.92655223e-03
 -3.23199527e-03  9.05972812e-03  7.13125756e-03 -1.15331006e-03
 -9.35835764e-03 -1.01928655e-02  3.42113920e-03  1.50506711e-03
 -2.60079606e-03 -4.54786699e-03  5.94063848e-03 -5.86542720e-03
  1.74017213e-02  1.24103914e-03  4.49615158e-03 -9.03492328e-03
 -7.02676037e-03  3.33535671e-03  1.41641721e-02  1.35370053e-03
 -7.02616246e-03  1.22671882e-02 -1.29625655e-03 -1.60704181e-02
 -4.19375999e-03 -6.88612973e-03  4.32352396e-03  4.93859639e-04
  4.49369196e-03  1.25027483e-03 -7.28032785e-04  1.68908178e-03
  1.19633498e-02 -6.36297651e-03 -1.22370655e-02  8.64259899e-03
 -2.40634242e-03 -1.21124426e-03 -8.69116839e-03  9.61311627e-03
  1.70062128e-02 -1.37704359e-02 -1.35943387e-03 -2.20679049e-03
  2.80918553e-03  1.05423424e-02  8.23224522e-03 -3.43946647e-03
  1.97896874e-03  1.63486658e-03 -3.82625638e-03  1.36947529e-02
 -4.93980478e-03  1.57204997e-02 -1.03414981e-02 -3.95150669e-03
 -1.59041828e-03  1.14184469e-02  1.35787297e-02  1.90384071e-02
 -1.31789139e-02 -4.14762506e-03  1.86215714e-02 -7.61305168e-03
 -8.21224414e-03  1.00597525e-02 -5.34431683e-03  1.56839189e-04
  9.41025931e-03 -8.92521068e-03 -2.15539220e-03 -2.88617401e-03
 -1.19207031e-03 -4.10865247e-03  4.24723607e-03  7.18666986e-03
  5.91249252e-03 -3.07641388e-03  4.83149244e-03  4.20950120e-03
 -9.37623344e-03 -8.74423422e-03 -6.87752478e-03 -1.59113687e-02
 -3.18316068e-03  8.87893955e-04  7.19088409e-03 -3.73300340e-04
  7.60504138e-03  9.83408373e-03 -6.68514241e-03 -1.65427162e-03
 -1.53221493e-03 -3.68490582e-03 -1.30991370e-03  8.42189230e-03
 -8.53199046e-03 -1.67120714e-02 -5.00936713e-03 -7.33368192e-03]
tensor_name:  TemporalFusionTransformer/dense_18/kernel
[[-0.09704302 -0.09538673 -0.12330429 ... -0.04857181 -0.04054746
  -0.03895519]
 [-0.10877471 -0.00588272 -0.01207215 ... -0.02587723  0.05331801
   0.03667704]
 [-0.05806745 -0.11358266 -0.11002713 ... -0.13006102 -0.1184527
  -0.12149472]
 ...
 [ 0.06093054 -0.02630218 -0.00349715 ... -0.09908178  0.11161986
  -0.00650031]
 [-0.09452215 -0.04931814  0.02370202 ... -0.11544006  0.12805738
   0.11826362]
 [-0.04837016 -0.05859702 -0.12405586 ... -0.11237045  0.02525562
  -0.00595606]]
tensor_name:  TemporalFusionTransformer/dense_19/bias
[ 0.00063039  0.00507398  0.00091312 -0.00196523 -0.00461974 -0.00338624
  0.00116217 -0.00382357  0.00057143  0.00245517 -0.00681492  0.01071149
  0.00291655 -0.00227347  0.00881326 -0.00270005  0.00881283 -0.00115556
  0.0114341   0.00048911  0.00663476  0.00130932 -0.00170441  0.00412613
 -0.0101377  -0.00233124  0.00696349 -0.00096734  0.00344993  0.0057144
 -0.00133962 -0.01322338 -0.00030767 -0.00596928  0.00620155  0.00308508
  0.00159674  0.00448318 -0.00128754 -0.00278257 -0.01061241  0.00054047
  0.01036907  0.01071092 -0.00081124 -0.00545042 -0.00435564 -0.00052873
  0.00350283  0.00461389  0.01270965  0.01663176 -0.0079342  -0.00683131
  0.0059537   0.00201923  0.00389655  0.00317275 -0.01028343  0.00196789
  0.00456093  0.00496431  0.00261819  0.02087655 -0.0172279   0.0041033
 -0.00908517  0.0077521   0.00374248  0.00758499 -0.00697395 -0.00632112
  0.00825363 -0.00569024 -0.00656216  0.00094495  0.00261139  0.00454539
  0.00946635 -0.00560939  0.01659843  0.00155831 -0.00111989 -0.00116058
 -0.00367045 -0.00242506  0.01411151  0.00665638 -0.00126566  0.00332785
 -0.00562396  0.00764729  0.0030398  -0.00359485 -0.00317738  0.0015098
  0.00208151  0.00450758 -0.05705547  0.00068159  0.00875513 -0.00212
 -0.00445603 -0.00418248 -0.01146894 -0.00242794 -0.00777302 -0.00952988
 -0.00521556  0.00436377  0.00616027 -0.00320669 -0.00202138 -0.01169619
  0.00751099 -0.01808508  0.03951051 -0.00234715 -0.00300471 -0.00694635
 -0.00768212 -0.00427649  0.01049481 -0.00410268 -0.00313866 -0.0054293
 -0.00631732  0.00098601 -0.00611339  0.00769378  0.00090312 -0.01281046
  0.00627387  0.0054113   0.00146123 -0.01447776 -0.00298111  0.00202572
  0.00440116  0.00633274  0.00266973 -0.01607986  0.02946834  0.00748145
 -0.00208363  0.00250672  0.00483509 -0.01119336 -0.01597513 -0.0085966
 -0.00563719  0.00613044  0.00629427  0.00064063 -0.00787308 -0.00832678
  0.00103006 -0.00235462  0.00183544  0.00484415]
tensor_name:  TemporalFusionTransformer/dense_19/kernel
[[-0.02784236 -0.07230921  0.0733596  ...  0.01714738  0.09806057
  -0.04083435]
 [ 0.07292043  0.02710869  0.1500971  ...  0.03105142 -0.02289078
  -0.10528262]
 [ 0.1355262  -0.1367261   0.07607685 ...  0.07446451 -0.0237297
   0.07656493]
 ...
 [-0.04767671  0.04718086  0.05970719 ...  0.07379923  0.10254791
   0.04653147]
 [ 0.02025041 -0.05011364  0.11891713 ...  0.03472545  0.05920888
  -0.14616445]
 [ 0.06022502  0.00483617  0.03461285 ... -0.09003878  0.09037875
   0.00888757]]
tensor_name:  TemporalFusionTransformer/dense_20/bias
[-4.30316757e-03 -9.13783442e-03 -8.79180431e-03 -1.41278254e-02
  8.56359862e-03 -1.29513945e-02 -4.00215574e-03 -2.21926626e-03
 -1.67015661e-02 -1.32738221e-02 -1.19960112e-02 -8.01863056e-03
 -1.26827706e-03  4.22674231e-03 -1.45113012e-02  5.22029540e-03
 -1.46352230e-02 -7.98871508e-04 -7.70476880e-03 -2.83504324e-03
 -7.08648982e-03 -6.98634936e-03 -5.65814227e-03 -5.14480611e-03
 -1.05945999e-02 -1.30046271e-02  7.10563967e-03  6.19371794e-03
 -1.17406584e-02  1.55474560e-03 -1.19200116e-02 -6.29144581e-03
 -1.72923822e-02 -4.96169785e-03 -1.33084394e-02 -4.74655861e-03
 -1.01847081e-02 -1.77190881e-02 -1.02736913e-02 -8.12313240e-03
  1.16855442e-03 -1.01036737e-02  2.91825109e-03  1.37836374e-02
 -9.68877226e-03 -3.58380820e-03 -5.78883709e-03 -9.46493354e-03
  2.98006902e-03 -6.52248506e-03  7.43208779e-03  1.46625256e-02
  8.80881958e-03 -1.45058101e-02 -1.35086477e-02  3.76030011e-03
 -1.28517291e-02  1.40898367e-02  1.09632853e-02 -2.79490417e-03
 -5.47882263e-03 -3.13061615e-03  3.38867470e-03  1.40879508e-02
  1.28702819e-02 -1.82248894e-02 -1.22382771e-02 -8.83037690e-03
 -7.55472621e-03  9.79912747e-03 -6.11630362e-03  6.46075746e-03
 -7.63145462e-03 -1.47854127e-02 -2.26133596e-03 -5.56559442e-03
 -4.79435455e-03 -6.98032277e-03 -1.03263566e-02 -7.80903921e-03
  2.74985284e-03  8.23177490e-03 -6.41746866e-03  2.80565349e-03
 -3.42367892e-03  1.59731612e-03 -1.78160786e-03  9.93098225e-03
 -3.32317804e-03 -6.82008918e-03  4.01461869e-03  7.57876551e-04
 -8.89956765e-03 -4.79242206e-03 -7.98639748e-03 -1.61394775e-02
 -8.32439214e-03 -6.56381249e-03  1.79129373e-02 -3.99391679e-03
 -3.00310878e-03  3.04900226e-03 -5.35737351e-03 -3.19212722e-03
  1.03709623e-02 -7.63804885e-04 -2.77959602e-03  9.23166890e-03
 -5.04620979e-03 -2.83272646e-04 -2.81912158e-03 -1.05772251e-02
  3.38808913e-03 -1.17266718e-02 -1.19188400e-02  1.80837475e-02
  1.76132843e-02 -1.75052541e-04 -9.44451522e-03  3.86563060e-03
 -8.60606227e-03 -1.64893251e-02 -7.62717752e-03 -6.78113289e-03
  6.53254509e-04  5.90087241e-03 -1.01786423e-02  6.53150899e-04
 -1.37496060e-02 -1.66845345e-03 -1.28236609e-02 -1.05924737e-02
  2.93692900e-03  1.07276451e-03 -9.27694235e-03  5.83235268e-03
  1.03068398e-02 -7.85536598e-03 -8.09806399e-04  1.76239829e-03
 -2.04344178e-04  4.26614238e-03  1.18735433e-02 -3.11741885e-03
 -7.17697991e-03 -1.10352058e-02  3.00953211e-03 -2.49139522e-03
 -5.88313490e-03 -1.82951230e-03  6.16705627e-04 -1.16696814e-02
 -9.60000418e-03 -1.02727478e-02  1.11185350e-02  1.01257654e-04
 -1.79823544e-02  9.24893175e-05 -1.69193149e-02 -6.75851433e-03]
tensor_name:  TemporalFusionTransformer/dense_20/kernel
[[ 0.07196052  0.04483908  0.0151724  ...  0.02420413 -0.11265343
   0.09570263]
 [ 0.00957234 -0.00915635  0.01311239 ... -0.09765635  0.05079379
  -0.1285718 ]
 [ 0.07377258 -0.08467581 -0.07895762 ...  0.04549357 -0.04705601
   0.08783676]
 ...
 [-0.05683907  0.08529753  0.00940826 ... -0.04586374  0.00136282
   0.12763491]
 [ 0.05567421 -0.06431013 -0.06162404 ...  0.1095751   0.05018556
  -0.10905611]
 [-0.00262966 -0.02014858  0.03279863 ... -0.08112571 -0.01094261
   0.12869698]]
tensor_name:  TemporalFusionTransformer/dense_21/bias
[ 7.5674644e-03 -3.3609010e-03  9.2771426e-03 -6.3188495e-03
  1.5745509e-03  1.1722639e-02  9.6819649e-04 -1.3944822e-03
  5.9412647e-04 -4.7605387e-03  6.4813984e-03 -8.3274012e-03
 -8.8971136e-03  5.7713692e-03  3.3803864e-03 -5.4453323e-03
 -4.6235514e-03 -6.0378169e-03  2.0728668e-03  1.8498783e-04
 -3.5774901e-03 -1.0042385e-02  5.5274169e-05 -8.3245672e-03
  5.5744534e-04 -4.7070594e-03 -6.6810022e-03  1.0230986e-02
 -5.1117730e-03  1.2194199e-02  5.9525558e-04  6.3500386e-03
 -6.6602444e-03  2.6267399e-03 -3.3943993e-03  5.2611060e-03
 -1.4543346e-03  2.4308937e-03  1.2864001e-02 -1.6862097e-03
 -4.2913365e-03  3.2095762e-03  5.3388784e-03  5.2004764e-03
 -2.2864274e-03  2.8015675e-03  3.0849082e-03  2.1925946e-03
 -1.0745605e-02 -2.9022226e-03 -1.3564249e-03 -1.0845794e-02
  9.4184605e-04  8.4600532e-03  1.1611359e-02  4.3189968e-03
 -1.0942701e-02  1.9644042e-03 -1.6309601e-03  7.7139819e-03
  8.0099851e-03  1.0187276e-02  7.2288741e-03 -2.8047713e-03
 -4.8296307e-03  3.4598068e-03  1.1135672e-02  1.2593581e-03
  1.0147441e-02  1.0343220e-02 -4.6673403e-03  4.8649241e-03
 -2.0131348e-03  5.4387408e-03  4.9448838e-03  8.3788345e-04
 -3.1058025e-03 -3.1494519e-03  2.6929928e-03 -8.2326168e-03
  4.0817470e-03  8.2372613e-03 -2.9403039e-03 -1.1443387e-02
 -9.4150510e-03  7.6331776e-03 -2.5711630e-03 -1.8324376e-03
 -5.8393879e-03  4.4225506e-03 -1.5253971e-03  4.9029221e-03
 -1.0793609e-02 -2.2191072e-03  6.9104442e-03  5.3290551e-04
  7.9507669e-03  1.8430913e-03  6.3404855e-03 -9.2723448e-04
  3.5854005e-03 -8.5291969e-05 -6.5892300e-04 -5.0688693e-03
 -4.9803620e-03  7.2732050e-04 -3.9130668e-04  9.8463697e-03
 -1.1805835e-02  4.4907453e-03 -4.8655397e-03 -7.7218167e-03
  7.3802168e-04  9.8156088e-05 -6.9739856e-04 -6.9453423e-03
  1.3574146e-04 -1.0032252e-02 -1.0901470e-02 -4.7305780e-03
  1.1765079e-02 -9.4638467e-03  3.1211617e-04  7.8846999e-03
 -2.1278511e-03  6.1333887e-03 -1.5236168e-03 -5.3321566e-03
  2.1464814e-04 -5.3346404e-03 -5.4200399e-03 -6.6296109e-03
 -3.3014803e-03  2.7676055e-03  1.1058275e-02 -3.5526368e-03
  8.7121241e-03 -5.9839827e-03  1.9064752e-03 -8.3099771e-03
  2.5095569e-03 -4.8065376e-03 -4.9362085e-03 -1.4780853e-03
 -1.3638227e-02 -5.1196776e-03 -3.8729049e-03 -1.9761929e-04
  1.1757064e-02 -3.2914476e-03  4.4759857e-03  3.5272210e-03
  2.7915542e-03  8.7397033e-03  1.0047477e-03  1.4198817e-03
 -7.3568104e-03  4.6031064e-04 -3.4344122e-03 -1.1395048e-02]
tensor_name:  TemporalFusionTransformer/dense_21/kernel
[[-0.08343041  0.03770839 -0.00102212 ... -0.04123907 -0.06276153
   0.12845935]
 [ 0.0574946   0.11879747 -0.10092051 ... -0.02133312 -0.09550288
  -0.07247843]
 [ 0.00965257 -0.09688888 -0.11734734 ...  0.13153009 -0.04125302
   0.05893404]
 ...
 [ 0.06584422  0.09365845  0.01826158 ...  0.09848005 -0.04504267
   0.05283673]
 [-0.07895307  0.09777135 -0.02757588 ... -0.04888043 -0.08398786
   0.02427545]
 [ 0.10249513  0.0730324   0.01131131 ... -0.06952107  0.12208066
  -0.11105175]]
tensor_name:  TemporalFusionTransformer/dense_22/bias
[-0.00019516  0.01299584 -0.00612523 -0.00527484 -0.0076219  -0.01138548
 -0.00304907  0.00228425  0.00367458 -0.00519973  0.00638973 -0.00853981
  0.00053091 -0.00489098 -0.00252355 -0.00915306  0.00319545 -0.00462756
  0.00727571  0.00566371 -0.0031241  -0.00012445  0.00602776 -0.01282139
  0.00784606 -0.00512988  0.00816844 -0.01050586 -0.0159988  -0.00278943
 -0.00315942 -0.00295688  0.0086397  -0.0073662  -0.01790949 -0.00590395
  0.00570332  0.00206091 -0.00045339 -0.00219184 -0.00050469 -0.00350789
 -0.00280022 -0.01325097  0.00575754 -0.00658521  0.00282865 -0.0054781
 -0.0034807   0.00400714  0.00553309 -0.00825638 -0.00826065 -0.00652618
  0.0076849   0.00952494 -0.00526361 -0.00760343  0.00769984  0.00038732
 -0.00527863 -0.00087189  0.01622829 -0.00396602 -0.00337883  0.00388531
 -0.00488984 -0.0037409  -0.01913789  0.00552365 -0.00292866 -0.00740764
  0.0201765  -0.00697239 -0.00356739 -0.00086212  0.0065751   0.00355703
  0.01360924  0.00106071  0.00227786  0.00090495  0.00488452  0.01095144
  0.01486336  0.00886456  0.00620582  0.00650206 -0.00185537  0.01072314
  0.01222969  0.0035912   0.00310996  0.01289667 -0.00493718 -0.00382996
 -0.00161763  0.01151771  0.00050732  0.00181419 -0.00014132 -0.00554924
  0.01231473  0.00647093 -0.00287254  0.0032722  -0.00664229 -0.00869173
 -0.0077558   0.00397206 -0.00498988 -0.00502259 -0.00747298 -0.00977452
  0.01291331 -0.00535439  0.01496383  0.00600653 -0.00871361  0.01248825
  0.00802542  0.00212626 -0.00265049 -0.001961   -0.01281363 -0.00663358
 -0.00093756 -0.00207715  0.00286412  0.01261121 -0.013921    0.01004697
  0.00733684 -0.01017042  0.00973    -0.00223915  0.006669   -0.00245037
  0.00069212  0.01213129 -0.01334364 -0.00046716 -0.0024157  -0.00411327
 -0.00547834 -0.00989424 -0.01122246  0.00856537  0.00795404  0.00858913
  0.00475051  0.00152479 -0.00422936  0.00152535  0.00352471  0.00108178
 -0.00033956 -0.00704934  0.00185631 -0.0033858 ]
tensor_name:  TemporalFusionTransformer/dense_22/kernel
[[-0.01481139  0.03487825  0.0244706  ...  0.10394903 -0.04367488
  -0.07993071]
 [ 0.04392318 -0.07735043 -0.1509707  ... -0.03888004 -0.07866745
   0.04392935]
 [ 0.09157424  0.10835917 -0.06774823 ...  0.10555342  0.03884828
  -0.05952279]
 ...
 [ 0.08999299  0.05676737 -0.022795   ...  0.01268076 -0.07080363
   0.1407429 ]
 [-0.07176363 -0.14909087 -0.00024627 ... -0.11444391  0.09505531
  -0.07914148]
 [ 0.01755847  0.0708725  -0.01329465 ... -0.00854075 -0.05542962
   0.02257673]]
tensor_name:  TemporalFusionTransformer/dense_23/bias
[-2.44985777e-03  5.73467370e-03  4.61853435e-03 -3.70728783e-03
 -8.65011755e-03  3.29593103e-03 -6.59274729e-03  1.52346131e-03
 -4.53914702e-03  3.48110264e-03  9.19896923e-03  2.53097806e-03
 -1.13340244e-02 -1.92944554e-03  1.24470815e-02  4.30735387e-03
  8.29687249e-03  6.65834593e-03  7.11906748e-03  6.63906289e-03
 -8.54464620e-03  7.67026609e-03  9.90686379e-03  4.18459484e-03
 -2.64860271e-03 -1.24020770e-03 -5.75609459e-03 -6.02700841e-03
  6.37273013e-04 -1.83860853e-03  3.34149692e-04  3.45820887e-03
  1.02552411e-03 -1.12136016e-02 -1.34324667e-03 -1.85423787e-03
 -2.33251485e-03  6.50465162e-03 -5.05664805e-03  6.36406941e-03
 -4.67597274e-03 -2.87696789e-03 -2.16774293e-03  2.59324396e-03
 -1.04333200e-02  4.77134623e-03  4.96012717e-03  1.70229410e-03
 -8.36675987e-03  3.13483574e-03  1.70688878e-03 -8.50636570e-04
 -1.10284751e-02 -4.76536341e-03  9.41123755e-04 -8.99440795e-03
  3.56555963e-03  1.15514407e-02 -1.53865367e-02 -5.82887838e-03
  3.08808056e-03 -1.44047281e-02 -7.43071176e-03 -2.12521129e-03
 -2.08309498e-02 -6.03318331e-04 -4.28887224e-03  3.39238031e-04
  1.27586175e-03  2.56664027e-03  2.06587231e-03 -9.89805534e-03
  1.10186916e-03 -8.42609443e-03 -5.07411920e-03  2.65040621e-03
  2.13227700e-03 -1.50699634e-03 -3.26744420e-03 -5.21662785e-03
 -6.54039555e-04  3.67327943e-03  2.27502733e-03  2.69501656e-03
  2.92630168e-03  1.23823686e-02 -4.57255263e-03  6.19090069e-03
  2.45275232e-03 -5.65089103e-05 -1.55500639e-02  8.16076528e-03
 -3.25034745e-03  7.07292743e-03 -7.54629122e-03  5.46318479e-03
  9.11347102e-03  5.50286472e-03 -1.48456367e-02  2.08063563e-03
 -1.62655965e-03  1.09548438e-02  2.94362823e-03 -8.43402557e-03
  8.04477558e-03  5.58799948e-04  7.67540769e-04  7.54966540e-03
  4.27089864e-03  6.05394738e-03 -6.20356412e-04  9.80973616e-03
 -8.45956989e-03  8.05846881e-03  2.44838651e-03  3.15746828e-03
 -9.58744250e-03  2.81926547e-03  8.57841410e-03 -3.80641059e-03
  6.51501026e-03 -8.43972433e-03  7.35837780e-03 -2.10667285e-03
 -5.53240860e-03  1.43267438e-02  3.14139551e-03 -6.08687988e-03
  6.81859732e-04 -5.47509594e-03  7.50821456e-03  1.50506699e-03
  6.15984391e-05 -1.09545887e-02  2.35173595e-03  3.18352925e-03
  4.51144343e-03  4.69600520e-04 -5.63632697e-03 -9.98147065e-04
  4.89687809e-05 -8.04792345e-03  3.61131621e-03 -6.69363094e-03
  4.46758699e-03 -1.31203444e-03 -7.57718040e-03 -1.72626949e-03
 -2.78073526e-03  1.30425824e-03  4.99344605e-04  1.93705980e-03
  5.33695158e-04  1.26310242e-02  3.70583916e-03 -9.27544079e-06
 -1.07678361e-02 -1.87227281e-03  1.26505522e-02 -6.97267056e-03]
tensor_name:  TemporalFusionTransformer/dense_23/kernel
[[-0.01645856  0.01110307  0.05849087 ...  0.03595448 -0.01010264
  -0.07188282]
 [ 0.1386584   0.13718452  0.10525061 ...  0.12494071  0.09745792
  -0.03240379]
 [-0.11021011 -0.06940056  0.09029868 ...  0.05465704 -0.05969417
   0.09643999]
 ...
 [-0.08673131  0.06209467  0.05399944 ... -0.04727386 -0.08207516
  -0.08709261]
 [ 0.01587148  0.03237192 -0.03281543 ...  0.10845128  0.10467128
   0.07402509]
 [ 0.13355373 -0.06434532 -0.12769304 ... -0.03869356 -0.08034337
   0.05944334]]
tensor_name:  TemporalFusionTransformer/dense_24/bias
[-4.64608893e-03 -1.04227755e-03 -7.04173045e-03 -3.41328653e-03
 -1.10354275e-02  8.64063259e-05 -7.65594002e-03  7.40746094e-04
 -1.46662060e-03  1.52548710e-02 -1.45585602e-03 -4.56435699e-03
  7.58415612e-04  6.22597709e-03  1.20450035e-02 -4.61124670e-04
 -1.39585985e-02 -1.34715680e-02 -3.00930138e-03 -1.13036139e-02
  1.90002297e-03  1.96959684e-03  5.85773680e-03  1.52107095e-04
 -8.13599210e-03 -7.30664283e-03 -1.20495372e-02  7.51653267e-03
 -5.85109880e-03 -3.18945502e-04  5.53598022e-03  3.16667417e-03
 -7.18654925e-03  4.09552595e-03 -5.69396513e-03 -8.36626627e-04
 -1.43746706e-03 -4.74217022e-03  3.86602455e-03  4.69660433e-03
 -1.70362019e-03 -7.38932472e-03 -7.14806723e-04  2.16702279e-03
 -7.20843067e-03 -9.82983969e-03 -7.29723647e-03 -2.29193829e-03
 -8.64398759e-03  6.89597288e-03 -9.04086605e-03 -3.05293314e-03
  5.36863785e-03  1.03650009e-03 -8.37916974e-03  4.96738032e-03
 -3.09774815e-03  4.28918703e-03 -4.22444381e-03  5.00765489e-03
 -1.40898582e-02  8.03409331e-03 -1.70639250e-03 -1.29074533e-03
  1.29895704e-02 -3.44594801e-03 -1.07168630e-02 -2.88990000e-03
 -1.13920169e-02 -1.11573155e-03  2.55653838e-04  1.15936054e-02
 -2.38958420e-03 -9.89985466e-03 -1.66418927e-03 -1.75021618e-04
 -6.22389419e-03 -6.35357713e-03 -2.51724385e-04  4.04346781e-03
 -1.79180168e-02  4.06618565e-05 -1.43077355e-02 -6.68212632e-03
 -1.21200578e-02  8.74429848e-03  3.76594369e-03  4.14837245e-03
  3.62631888e-03 -1.20464284e-02  7.51465047e-03  7.35831494e-03
 -3.12178489e-03 -1.68169977e-03  1.20032495e-02 -7.91809708e-03
  3.84643045e-03  5.46516571e-03 -9.98814590e-03 -6.81368283e-06
 -1.13348402e-02 -1.36586383e-03 -4.90766484e-03  3.11616855e-03
  8.36538151e-03 -2.16992060e-03 -8.21351819e-03 -1.57757308e-02
  2.26359745e-03 -6.78777462e-03 -4.49339813e-03  1.18877096e-02
 -2.12797453e-03 -1.24627491e-02 -4.33788286e-04 -5.09377057e-03
  9.96085722e-03 -9.45800357e-03 -9.21831280e-03  5.75535705e-05
  2.07651732e-03  9.29755042e-04 -1.24072619e-02 -1.88041222e-03
 -1.54447998e-03  1.04451748e-02 -3.88040906e-03  2.92853802e-03
 -6.74437825e-03  1.99483708e-03 -4.48607607e-03 -4.24378319e-04
  8.82260210e-04  8.57981574e-03 -5.40630566e-03  7.32728885e-03
 -3.82407592e-03 -3.21201817e-03 -6.95782294e-03 -4.25473088e-03
 -4.32033412e-04  8.17024149e-03  5.04649058e-03 -2.21289680e-04
 -9.56710055e-03 -1.30680203e-03  5.65286493e-03 -1.15753571e-02
 -2.19663465e-03 -5.40917087e-03 -1.97626487e-03  1.68041897e-03
 -4.52564622e-04  1.23930275e-02 -1.58712931e-03 -2.56524049e-03
 -6.51538372e-04 -8.40424560e-03  2.00552470e-03  4.73914295e-03]
tensor_name:  TemporalFusionTransformer/dense_24/kernel
[[ 0.07771658  0.07732616  0.00577918 ...  0.08344973  0.04360733
   0.09267735]
 [ 0.07901219  0.00989602 -0.00054869 ... -0.00676402 -0.05878693
  -0.05993916]
 [-0.01010545 -0.08517568 -0.11009695 ...  0.00645665  0.03267713
  -0.07996693]
 ...
 [ 0.14505428 -0.01532042  0.08459173 ... -0.00306544 -0.03906339
  -0.08198424]
 [-0.07756098  0.10287704 -0.07197024 ... -0.0724804  -0.1414249
  -0.11744145]
 [-0.08276559  0.09721642 -0.09912536 ...  0.07102381  0.10839389
  -0.01767342]]
tensor_name:  TemporalFusionTransformer/dense_25/bias
[ 1.61703061e-02 -1.31846219e-02 -1.09893046e-02  7.25781359e-03
  9.20925010e-03  1.30106078e-03  2.25155838e-02  2.04369444e-02
 -1.27664059e-02 -1.57513469e-02  1.95972528e-03 -6.28851680e-03
  1.22152483e-02  1.32953364e-03 -8.17963667e-03 -9.34220012e-03
 -9.13297385e-03 -1.27221760e-03 -8.04789457e-03  4.05171281e-03
 -2.95006810e-03 -7.53724528e-03  1.81039516e-02 -2.08798796e-02
 -1.05824722e-02 -7.49068335e-03  5.80146946e-02  1.15976892e-02
 -1.16576273e-02 -2.20278185e-02 -1.58484280e-02 -1.32289911e-02
  3.41704674e-02  2.03528628e-02 -9.92229115e-03 -2.24506967e-02
 -1.17101455e-02 -2.21473742e-02  4.49392432e-03  7.14412006e-03
 -8.10565613e-03 -1.10178264e-02 -1.87870152e-02  3.23047233e-03
 -7.26149371e-03  1.61507428e-02  1.30891474e-03 -1.49362721e-02
 -7.57653406e-03  1.18327076e-02 -1.14953471e-02 -1.23222647e-02
 -6.84540486e-03  1.10616656e-02  1.48874810e-02 -9.87793691e-03
 -1.11377100e-02 -9.37789399e-03 -2.48549003e-02 -9.32924915e-03
  7.84990750e-03  1.85715575e-02 -7.58978445e-03 -1.30624771e-02
  8.78828391e-03 -1.79758500e-02  1.06320130e-02  1.35288071e-02
 -2.50464329e-03 -6.93500857e-04 -4.73396794e-04 -1.22617465e-02
  1.91411637e-02  5.96338976e-03 -1.93912890e-02  2.38902271e-02
  2.31674057e-03 -1.96813443e-03  1.31425937e-03 -4.79380274e-03
  1.80562213e-02 -4.31192480e-03  1.13409925e-02 -2.36170534e-02
  8.04193504e-03 -5.66211669e-03 -1.70127731e-02  5.82115725e-03
 -1.41447773e-02 -1.12198526e-02  2.04345621e-02  2.32107304e-02
  5.61100524e-03 -1.38307773e-02  1.16830310e-02  2.52017705e-03
 -1.65386070e-02  1.25715081e-02  3.47466245e-02  2.47656666e-02
  7.04090809e-03 -8.52754340e-03 -4.39509330e-03 -4.42327140e-03
  4.11184989e-02 -1.84263592e-03 -6.38788624e-05  3.86228710e-02
  4.28789072e-02  8.73974804e-03  2.03115959e-02 -2.76591489e-03
 -2.16898452e-02 -2.05466151e-02 -1.63193494e-02  5.15948283e-03
  1.94118060e-02  1.52828647e-02  1.21615045e-02 -2.30563413e-02
 -4.35564294e-03 -8.09486210e-03 -6.11647638e-03  1.67698544e-02
  2.56030187e-02  5.75244485e-04 -5.92801906e-03 -8.71126913e-03
 -1.64207239e-02 -2.07301788e-02 -1.17738964e-05 -1.02182124e-02
 -8.34692642e-03 -4.35996009e-03  1.41081400e-02  3.32373451e-03
  2.20948383e-02 -1.08550154e-02 -8.62249359e-03 -2.10677623e-03
  2.83559244e-02  2.20384561e-02  4.64810198e-03 -1.39107360e-02
 -5.20355767e-04  1.48628894e-02 -5.70594741e-04  4.52725915e-03
  1.93762761e-02 -1.84644368e-02 -4.42277547e-03 -5.48034720e-03
 -1.77112184e-02  3.34143937e-02 -8.51806626e-03  2.37969216e-03
 -5.41919799e-05  1.89524086e-03  4.22731228e-03 -4.78149252e-03]
tensor_name:  TemporalFusionTransformer/dense_25/kernel
[[ 0.02034487  0.11416131 -0.11520687 ... -0.06749478 -0.0633777
   0.1106182 ]
 [ 0.05967019 -0.06476744  0.02266853 ...  0.04299727  0.11212355
   0.0388676 ]
 [ 0.00906259 -0.07148644  0.10866112 ... -0.0349473  -0.08815717
   0.08605824]
 ...
 [ 0.09537131  0.0437034   0.02832282 ... -0.01811925 -0.05741889
   0.09703013]
 [ 0.13722011  0.07035416 -0.03234243 ... -0.05739029 -0.02148985
  -0.10397159]
 [ 0.13661367 -0.14778122 -0.03369197 ...  0.06587224 -0.12287751
   0.03466937]]
tensor_name:  TemporalFusionTransformer/dense_26/bias
[-1.14282323e-02 -2.80710980e-02 -3.83465551e-04 -1.41153494e-02
  1.00805899e-02  2.21293550e-02 -1.12971906e-02  2.64115777e-04
  2.44084988e-02  3.06918155e-02 -3.71896713e-05 -8.34821537e-03
  7.94292241e-03  1.48568461e-02 -2.63474081e-02 -7.80308712e-03
  6.31723106e-02  6.30550506e-03  1.21013829e-02 -1.83064807e-02
 -2.85206717e-02 -1.22003062e-02  5.51743200e-03  1.79560818e-02
  1.26059176e-02 -8.13327078e-03 -2.64038816e-02 -1.33774262e-02
  2.05796398e-03  1.31109497e-02  1.12181697e-02 -7.58118648e-03
  4.77888584e-02 -2.47302521e-02  2.93677486e-03  1.90705378e-02
 -3.66151631e-02  1.62029639e-02  1.64233204e-02  1.75773595e-02
 -1.09345876e-02  6.78249309e-03  1.77573655e-02 -1.52279753e-02
 -4.31905827e-03  1.21857841e-02  1.84081439e-02  1.24250341e-03
 -9.42812487e-03 -8.36464204e-03  6.01594243e-03 -5.14894770e-03
  1.07818674e-02  6.87250635e-03 -1.09024793e-02  1.04059814e-03
 -2.23606918e-02  3.57910548e-03  3.40076946e-02 -1.41595360e-02
  3.08631826e-03 -2.26583201e-02  9.76577215e-03  1.23158498e-02
 -5.02284011e-03  2.99326442e-02 -8.87243357e-03  8.13795812e-03
  2.09664367e-02 -3.22754891e-03 -6.33247662e-03  6.83344901e-03
 -1.91839784e-02 -3.76549177e-02  4.50383872e-03  5.16500324e-03
 -2.08201148e-02  3.06168646e-02 -1.90614872e-02 -7.50754401e-03
 -2.16163881e-02  6.89948862e-03 -2.40224879e-02 -1.02260895e-02
  3.60642336e-02 -4.33707098e-03 -5.32580912e-03  1.11074164e-03
 -1.61102563e-02 -1.43129507e-03 -1.37264552e-02 -2.22325958e-02
 -1.14405481e-02  6.93201274e-03 -2.84995995e-02  8.27290211e-03
  4.33636684e-04  4.03694436e-03  1.59898133e-03  1.74097586e-02
  3.97621276e-04 -2.65289266e-02 -9.23022686e-04  1.58858877e-02
  2.12446507e-03 -1.76545028e-02  2.48203776e-03 -1.73231196e-02
  2.89460924e-03 -8.67368933e-03  4.44256812e-02  3.45410034e-02
  9.11849830e-03 -2.26907209e-02  4.41061100e-03  7.82165863e-03
  4.49067773e-03  1.79568250e-02 -1.58432443e-02 -3.12349591e-02
  4.00677472e-02  9.40449815e-03 -1.39876176e-02  1.73795652e-02
  3.21229035e-03 -1.68285407e-02 -1.60656311e-02 -1.12908352e-02
  1.09358812e-02 -1.02448799e-02  1.07320063e-02  3.67879793e-02
  9.19346604e-03  8.53017718e-03  1.22563401e-02  2.81990529e-03
 -5.16558019e-03 -2.29173321e-02  3.28158103e-02 -3.21431980e-02
 -8.83179368e-04 -4.45052097e-03  3.33635160e-03  9.78002697e-03
  8.01098906e-03 -1.64193828e-02 -7.91438203e-03 -4.59816214e-03
 -3.65805975e-03 -9.23241675e-03  3.12139839e-02 -2.08704583e-02
  3.84113081e-02  3.48442011e-02 -1.53263351e-02  1.72528550e-02
 -3.42618488e-02 -1.04345288e-03  2.52058078e-02 -7.48968730e-03]
tensor_name:  TemporalFusionTransformer/dense_26/kernel
[[ 0.10322168 -0.07791216 -0.00877063 ... -0.11413473  0.05837008
   0.08446527]
 [-0.08252797 -0.03070192  0.11935215 ... -0.07924695 -0.155478
  -0.0511407 ]
 [ 0.13293195  0.1045202   0.07101648 ...  0.0095498  -0.08044825
   0.07648853]
 ...
 [ 0.09469977 -0.0382592   0.05894493 ... -0.1302478   0.10134468
  -0.081141  ]
 [ 0.13587284  0.03729409 -0.01799858 ...  0.06830479 -0.0083949
  -0.04589776]
 [ 0.08993023  0.03508876  0.12957002 ... -0.06403181  0.03541055
  -0.00181931]]
tensor_name:  TemporalFusionTransformer/dense_27/bias
[-0.00563131 -0.0016496  -0.02119934 -0.01527463 -0.01607627  0.00459608
 -0.00337429  0.00214497 -0.00657392 -0.00848152 -0.02756484  0.00973444
  0.00288976  0.0062802  -0.00234487 -0.00698866  0.0083625  -0.04057368
  0.0028967   0.00728431  0.05080944  0.00154679  0.00348735  0.02097377
  0.00286031  0.00462754 -0.00655443 -0.01740212  0.01442704 -0.00715341
 -0.00501792 -0.00101922 -0.00448292  0.05722348 -0.01209505 -0.00956399
  0.00028928 -0.00316142  0.00578054 -0.00307951  0.02024651  0.00421956
  0.00160047  0.01638278  0.01658476 -0.00165053  0.0206897  -0.0051857
 -0.00961439 -0.00651965  0.01736171  0.00615005 -0.00989087  0.02129476
 -0.00270314 -0.00072198  0.0090004  -0.00161344  0.01760641  0.00101534
 -0.00817836 -0.00115274 -0.00520079  0.00657257  0.01526441 -0.02732748
  0.00113852 -0.00481501  0.00378631  0.00078413  0.00286196 -0.01440937
 -0.00548039  0.01665957  0.01029478  0.00482945 -0.01535563 -0.0049288
 -0.00920018 -0.00015505 -0.00393851 -0.00385264 -0.0145774   0.01415305
  0.00763327  0.01695483 -0.00389882  0.03722267 -0.0076412  -0.00083965
  0.00574993 -0.00120478  0.0048722   0.00052868 -0.01242599 -0.00068741
  0.00426451 -0.00124831  0.00468476 -0.00285534  0.03492315 -0.02831274
  0.00088142  0.02774816  0.01292546 -0.00522399  0.0051006  -0.0004456
 -0.00695445  0.00101874 -0.00660128 -0.00642812  0.00643366  0.01856197
  0.06835768 -0.00199423  0.0021307  -0.05545988  0.03412795  0.00134443
  0.00985321 -0.00203951  0.04626665  0.01439781  0.01035746 -0.00779438
  0.00577989 -0.00147756 -0.00232432  0.01033876 -0.00191731 -0.00010157
 -0.01923849  0.01045051  0.0019831  -0.00861264 -0.02309952  0.00463728
  0.00597346 -0.03500603 -0.00718121 -0.00109924 -0.003189    0.00760917
  0.00533205 -0.00861793  0.00634568 -0.01420027 -0.00516667  0.02337334
 -0.00803617 -0.01776204  0.0003316  -0.00413438  0.0051531  -0.00265734
 -0.00384889 -0.00374434 -0.00255398 -0.00329886]
tensor_name:  TemporalFusionTransformer/dense_27/kernel
[[-0.01335542 -0.0325125   0.14477296 ... -0.08308888  0.07615794
  -0.01356752]
 [-0.08086239 -0.11888093  0.15593114 ... -0.0291165   0.09323096
   0.08194377]
 [ 0.00479501  0.10907372  0.10929857 ...  0.134696   -0.04081354
  -0.08584768]
 ...
 [-0.08585902  0.11593414 -0.10606207 ...  0.07188947 -0.0119218
   0.11714958]
 [-0.01781531 -0.09330888 -0.09729368 ... -0.05173401  0.11079139
   0.04883388]
 [ 0.00634361 -0.09830223 -0.14184974 ... -0.05503779 -0.09641366
  -0.07717726]]
tensor_name:  TemporalFusionTransformer/dense_28/bias
[ 0.00347787 -0.02624571  0.01206819  0.01099455  0.01132553  0.00670186
  0.0127036   0.01381451 -0.01085273 -0.01266635  0.01911993  0.01980661
 -0.00889497 -0.01641803 -0.00628272 -0.01140182 -0.00672156  0.0132797
  0.02449294  0.00788137  0.02032891 -0.01324889  0.00886028 -0.0352417
 -0.01489145 -0.00572186 -0.00562565  0.01295258 -0.0025667  -0.02614065
 -0.01485749 -0.01883045 -0.00944092  0.02377948 -0.0137269   0.02443301
  0.0043075  -0.01278392 -0.01037982 -0.01741491  0.03153678 -0.01367618
 -0.01287758  0.02182961  0.01107128 -0.00961865  0.00536397  0.01354323
 -0.01458845 -0.01491548  0.01789874 -0.01322055  0.0068884   0.00772875
 -0.00158687 -0.01150774 -0.02170731  0.00890449  0.03093572  0.00545179
  0.01871345 -0.01938476  0.01037302  0.00092566  0.01141291  0.0127771
 -0.01793244 -0.01521435 -0.01344588 -0.02477729 -0.01246352  0.00222721
 -0.01998777  0.01526949 -0.01090148 -0.0235089   0.00178639 -0.01289789
  0.00165504 -0.01256166  0.01614549 -0.01520216 -0.01662233 -0.00566286
 -0.01394883  0.01422661 -0.01047192  0.02390507  0.02494019 -0.0289439
 -0.01393358 -0.00495861 -0.01907922 -0.00821968  0.01772409 -0.0152951
 -0.00948776 -0.01195436 -0.00706677 -0.03016075  0.00959541  0.01817245
 -0.01394433  0.01987397  0.02538962 -0.01035422 -0.0090302   0.0068403
 -0.01716153 -0.000916   -0.01014424 -0.01518728  0.00723306  0.02345911
  0.03113148 -0.01380577 -0.0102558   0.02829608  0.01678544 -0.01693734
  0.0204934  -0.01098119  0.02631673  0.01353949 -0.01541168 -0.00822964
 -0.01434504 -0.01317468 -0.01019802 -0.01088634 -0.01102175 -0.00951301
  0.02161496  0.02318708 -0.01442172 -0.03510305  0.01309432 -0.0319471
 -0.00398593 -0.00860774  0.01837565  0.00702936 -0.00757021 -0.0116581
 -0.01453998  0.00186808 -0.00941598  0.00568384 -0.02378031  0.01622357
 -0.02564443  0.01431517 -0.02218892 -0.0048736  -0.01500467 -0.01646566
 -0.01261147 -0.0085709  -0.01503761 -0.02360506]
tensor_name:  TemporalFusionTransformer/dense_28/kernel
[[-0.1479587   0.05266783 -0.08450598 ...  0.14156921  0.11667982
  -0.10395411]
 [-0.09992109  0.06639491  0.08254573 ... -0.10913018  0.12061489
   0.01753119]
 [ 0.12272291  0.13642058  0.11477691 ...  0.01623786  0.03805606
   0.06042949]
 ...
 [-0.02379221 -0.04362682 -0.10183652 ...  0.03813151  0.08184424
  -0.08105547]
 [-0.03332808  0.0301895  -0.0700269  ... -0.14476684 -0.03106676
   0.11993339]
 [ 0.00754636  0.08662777  0.09637938 ... -0.0121786  -0.11570431
   0.07039378]]
tensor_name:  TemporalFusionTransformer/dense_29/bias
[-0.00584731  0.00817339  0.03050272  0.00455556  0.00103187 -0.01837452
 -0.00456074 -0.00834117  0.0024894   0.01404397  0.00138123  0.00580191
  0.00543748 -0.01718104  0.01246842 -0.01343472 -0.0089108   0.0097355
  0.01481316 -0.01323346 -0.00845143  0.01507011 -0.01392489  0.01411865
 -0.02189596 -0.00941044 -0.00487486 -0.00155152 -0.00952147 -0.00290204
 -0.00481466  0.00464841 -0.00565188 -0.00665591 -0.01670524 -0.00171046
 -0.00187773 -0.0033107  -0.01667463 -0.01887831 -0.00533398  0.02635352
  0.00399906 -0.00985476 -0.01128289  0.00932001  0.02097973 -0.00394009
 -0.02232076 -0.00617375  0.01563694 -0.00143538 -0.0147727   0.00512058
 -0.00179268 -0.0079014   0.00198688 -0.00583777 -0.00695214  0.00022444
 -0.01403797 -0.00011409 -0.00657055 -0.00501012 -0.00482261 -0.00695721
 -0.0130725   0.00490007 -0.01199637 -0.01651245  0.01847201 -0.02005806
 -0.0104345  -0.00631903 -0.00011665 -0.00896499 -0.01003528 -0.00648299
 -0.00445111  0.00233807  0.02695115 -0.00520971  0.01292887  0.00990012
 -0.00020446 -0.0028687  -0.01754175 -0.01002863  0.03679914 -0.01673843
 -0.01449899 -0.02392335 -0.00838502 -0.00807563  0.00043105  0.01650368
  0.00097104  0.01473561 -0.00921529  0.01887956  0.00129712 -0.01268973
  0.0090717   0.00398688  0.01484915 -0.00950073  0.00909108 -0.00621314
 -0.00081556 -0.00868017 -0.00672132 -0.00920059 -0.00848696 -0.00459471
 -0.00365201  0.00792356  0.00505595 -0.0122573   0.01644778  0.0021396
 -0.00015934 -0.00365039  0.02826198  0.00690226  0.01100014  0.00231597
 -0.01229289 -0.00260804  0.00304246 -0.02309413 -0.00515036 -0.01004092
  0.0031877  -0.00976258  0.01192291 -0.00307009 -0.01682499 -0.00148648
 -0.00484042 -0.00532769 -0.00074148  0.00817227 -0.01748926 -0.01732974
 -0.01451048  0.00371251  0.0023518   0.01076673 -0.00835598  0.00915604
  0.00567515  0.00259787  0.00511881 -0.00641912  0.00523952  0.00538955
 -0.00939912  0.00418865  0.03155119 -0.0078602 ]
tensor_name:  TemporalFusionTransformer/dense_29/kernel
[[-0.0474745   0.06213781  0.03721324 ...  0.07766549  0.12252469
   0.04572912]
 [-0.12560324  0.07746898  0.0439895  ... -0.06532844 -0.04239982
   0.02822441]
 [ 0.12653963 -0.05282725  0.06908552 ... -0.08339123  0.07664432
  -0.01345293]
 ...
 [-0.06090273  0.08354737 -0.00976754 ...  0.01213218 -0.06187038
  -0.14505294]
 [-0.08995304 -0.12052019  0.01996728 ...  0.0674201   0.01232815
   0.05559851]
 [ 0.06698547  0.03758487 -0.04689518 ...  0.00900792 -0.00640403
   0.10342257]]
tensor_name:  TemporalFusionTransformer/dense_30/bias
[-1.61246192e-02  7.76028167e-03 -4.50955145e-03  2.63161734e-02
  1.84538728e-03 -3.01976898e-03  4.21703607e-03  2.83553787e-02
 -2.82959994e-02 -8.84825643e-03  2.26236042e-02 -2.27259379e-02
 -9.32692923e-03 -3.41701647e-03 -4.05378863e-02  3.55937518e-05
 -9.85332113e-03 -2.78474670e-03 -1.65066402e-02 -6.39784383e-03
 -2.17700899e-02 -4.62293829e-04  2.33137072e-03 -2.16916371e-02
  4.21790453e-03  6.09281659e-03  9.44947731e-03 -2.42790370e-03
 -1.67999715e-02 -7.15121301e-03  1.78929679e-02 -1.49919381e-02
 -5.03901718e-03  8.61764606e-03 -2.25246027e-02 -2.15149373e-02
  3.16686509e-03  2.35942341e-02 -3.36427568e-03  2.18137354e-02
 -3.02961804e-02  2.17030104e-02 -1.47754550e-02  2.88126599e-02
 -7.58213829e-03  1.24801155e-02  5.54685853e-03 -2.65177153e-02
 -3.77720746e-04 -1.38445515e-02  2.11177338e-02 -6.65009674e-03
  1.26005651e-03  2.72897668e-02  2.18571536e-03 -9.98079870e-03
 -2.81469361e-03 -1.87461160e-03 -2.14192681e-02  1.03554949e-02
 -8.27470887e-03  4.22274135e-03  1.10949734e-02  1.11371488e-03
  2.92075193e-03  3.75548285e-03  2.45520356e-03 -1.14464723e-02
  1.79142648e-04  1.80911943e-02 -3.88669665e-03  2.34308857e-02
  9.04660393e-03  1.18987607e-02 -2.95993872e-03 -1.42759122e-02
 -3.18205804e-02  1.19238179e-02  1.38503490e-02 -7.39152124e-03
  2.63791140e-02  2.21797191e-02 -1.50984405e-02  4.19056159e-04
  1.35640437e-02  3.44372950e-02  4.35378887e-02  4.67471452e-03
  1.25797894e-02  6.08411618e-04  9.14748758e-03 -7.96889234e-03
 -2.15858761e-02 -1.53043149e-02  1.86096709e-02 -2.89925444e-03
  1.07782218e-03 -1.44449864e-02  1.92264207e-02  2.06038225e-02
 -2.01924127e-02  2.28099804e-03  1.28846094e-02 -4.93320404e-03
  1.49418358e-02  3.89819965e-02  1.17997930e-03  2.41696136e-03
  6.25982927e-03  1.76522024e-02  2.38045599e-04 -1.59005006e-03
  1.18557792e-02  1.15705319e-02 -1.28973005e-02  4.50368598e-03
 -3.63657065e-02  1.50432531e-02 -1.22483568e-02  1.49749555e-02
 -2.47654617e-02 -3.96671938e-03  5.46006113e-03 -1.66081414e-02
 -4.47688485e-03  7.77119910e-03  3.44792940e-02 -5.57979569e-03
 -1.96185820e-02  5.73124783e-03  2.85474071e-03 -2.64601894e-02
 -7.97916204e-03  3.02645061e-02 -7.06076436e-03  3.43172345e-03
 -1.50463674e-02  6.05108496e-03 -7.91842397e-03 -6.63314853e-03
 -2.03525331e-02 -9.25927330e-03  3.71668022e-03  4.27943096e-03
 -2.09440733e-03  1.60189122e-02 -9.30762477e-03  4.77011967e-03
  3.66170518e-03 -3.96871567e-03  1.21602407e-02  3.32746357e-02
  5.82905998e-03 -1.45954225e-04 -5.83572127e-03  6.29137037e-03
  1.07271606e-02 -2.49166954e-02 -1.67158945e-03 -3.90844001e-03]
tensor_name:  TemporalFusionTransformer/dense_30/kernel
[[-0.04355692  0.03820592  0.10896267 ... -0.05583801  0.05772452
  -0.09922189]
 [-0.05706233  0.01407533  0.03021082 ...  0.02470404  0.03518714
  -0.09457054]
 [-0.15448062  0.10395433 -0.04758957 ... -0.05698235 -0.01027465
  -0.06174466]
 ...
 [ 0.10838064  0.03300642 -0.00212011 ...  0.14797626 -0.1276891
  -0.09711473]
 [ 0.08337162  0.09855574  0.04392477 ... -0.12677957  0.13649577
  -0.01014222]
 [-0.01493112  0.0535104   0.1160199  ...  0.1122311   0.02440913
  -0.04911721]]
tensor_name:  TemporalFusionTransformer/dense_31/bias
[-0.01611656  0.05552015 -0.00118317  0.00299245 -0.00137467  0.01121056
 -0.00171716 -0.00943625  0.00741783  0.00532224  0.00108503  0.02283451
  0.0051404  -0.0051405   0.01875858  0.00447142 -0.00737221  0.0037596
 -0.00638379  0.00494187 -0.01661054  0.01103976 -0.01196975  0.01914088
 -0.00109823  0.00354759 -0.00688143 -0.01051673  0.01343625  0.00554468
 -0.04969309  0.01114274 -0.00064002 -0.0016973   0.00448507 -0.00938963
  0.00031349  0.00857173  0.00588366 -0.00562038  0.00247275 -0.00104746
 -0.00445453  0.02327357 -0.00654697  0.00023934  0.02528238 -0.00720969
 -0.00195528 -0.00653109  0.00813832  0.02916404  0.01163171  0.0070081
  0.04632723 -0.00392498  0.01008777 -0.00278813  0.01802636  0.02154534
 -0.00036402 -0.00936661  0.01059439 -0.00789938 -0.00348664 -0.0150909
  0.01598193 -0.01100436  0.01726379 -0.00656701 -0.00083492 -0.00150075
  0.00246657  0.00979936 -0.00561095  0.02249809 -0.01870889 -0.0014106
  0.00140871 -0.00229442 -0.0016137  -0.00598425  0.00301955 -0.00626909
  0.00023076  0.01367472  0.00719667 -0.00130606  0.00654527 -0.00072223
 -0.01173121 -0.0035372   0.01064271 -0.01125267 -0.02031526 -0.00097298
 -0.01324498  0.03689912 -0.01163651 -0.01489573 -0.00069424 -0.05150135
  0.00728653 -0.01722245 -0.04644363 -0.00295932  0.01521995 -0.00712926
 -0.01280929 -0.00303997 -0.0177293   0.00470261 -0.00815781  0.00249517
 -0.00336647  0.0109283  -0.00233807  0.00803599  0.02847805 -0.00619042
 -0.00014148 -0.00119829  0.02804423  0.000887    0.00317824  0.00913656
 -0.016689   -0.00025244 -0.00034415 -0.00435027 -0.0020467   0.005307
  0.00267907  0.0040662   0.01256715 -0.00680073  0.00847216  0.00051863
  0.00424377 -0.03828178 -0.00501074  0.01357903  0.01640866 -0.02477174
  0.00366129 -0.00292135 -0.0076674  -0.01054418 -0.03065315  0.02161543
 -0.01326755  0.00590096  0.00606401  0.00947369 -0.01224148  0.00699089
  0.00464669  0.01818785 -0.00487185 -0.02482982]
tensor_name:  TemporalFusionTransformer/dense_31/kernel
[[ 0.01651215  0.00301443  0.06725039 ...  0.09455952 -0.14293411
  -0.01647603]
 [-0.08836903  0.02767432 -0.090215   ... -0.02327601 -0.17066614
  -0.0056553 ]
 [ 0.13177732 -0.06010596  0.0994837  ... -0.00982104 -0.129664
   0.01704053]
 ...
 [ 0.06045403 -0.0855203  -0.04476552 ... -0.0890485  -0.0640205
   0.08088651]
 [ 0.04444144  0.04889443 -0.11532917 ... -0.03443986  0.06442741
  -0.0045173 ]
 [-0.09474117 -0.00662127  0.11421947 ... -0.12108611 -0.09319643
   0.0682248 ]]
tensor_name:  TemporalFusionTransformer/dense_32/bias
[ 0.01510758  0.01976155 -0.00221102 -0.00454282 -0.01742001 -0.02287616
 -0.01780472  0.01707831  0.01320768 -0.00479701 -0.00756364  0.01456137
  0.0022961  -0.02260558  0.01835923  0.00199122 -0.01484547  0.01030601
 -0.02101472 -0.01438749  0.00385656 -0.02767785  0.01376913  0.02889412
 -0.01165274  0.00462334 -0.02178431 -0.01646357 -0.00552413 -0.01535648
  0.0260873  -0.00779702 -0.00428132 -0.01185361  0.01051755 -0.0076948
 -0.00821568 -0.00623451 -0.00494976 -0.01247285 -0.01617692  0.01351575
 -0.00397467  0.01368375 -0.01413287  0.01480666  0.02273005 -0.01062597
 -0.00829931  0.0143154  -0.01458895  0.02046897  0.01158623  0.01009215
  0.01325135 -0.00213013 -0.02036768 -0.01308477  0.01687213  0.01798945
 -0.01146654 -0.01430608 -0.0084686  -0.00322558 -0.0087337   0.01640547
  0.01004968 -0.00078683  0.01465744  0.00347611 -0.0220281  -0.00972844
 -0.00619497 -0.02478471  0.01647971  0.01107885  0.02387907 -0.01625804
 -0.00836588 -0.01083065  0.00668412 -0.01968801 -0.00122649  0.00526587
  0.00527136  0.00902457  0.00715959 -0.00956853 -0.01353132  0.00547969
  0.02509257 -0.00621926 -0.01217267 -0.01589969  0.0009176  -0.02446885
  0.02299066  0.02827112 -0.01561032  0.01156506  0.00605847  0.02418703
 -0.00455714  0.01366277  0.02757737 -0.00957566 -0.0070817  -0.01092718
  0.01751567 -0.01247036  0.01847282 -0.00837276 -0.00121547  0.0051193
 -0.00851011 -0.00551734  0.0024755  -0.02294808  0.01924883 -0.01774335
 -0.01215781 -0.00561937  0.02747061  0.00591173 -0.00033235 -0.01263738
  0.00602173 -0.01822343 -0.00974231  0.00369825  0.02378155 -0.01758512
 -0.00196241 -0.01566482 -0.01024008 -0.0150878  -0.03017794 -0.00864151
 -0.01520489  0.02180029  0.01307031  0.0147569   0.01781336 -0.02701349
 -0.0146916  -0.00965797 -0.00986571 -0.00126637  0.0065208   0.02115463
 -0.01883275  0.01278109 -0.02854517 -0.00997113 -0.02677632 -0.00012645
  0.01836286  0.0020272  -0.00115962  0.0079133 ]
tensor_name:  TemporalFusionTransformer/dense_32/kernel
[[ 0.03884426  0.01491504  0.02518267 ...  0.06806546  0.03669238
   0.038826  ]
 [ 0.00756602 -0.00671045 -0.09495007 ...  0.05135347  0.11051051
   0.11620257]
 [-0.06727505 -0.08696364  0.03639089 ...  0.05193439  0.09126431
   0.09228197]
 ...
 [ 0.07744944 -0.11413331 -0.05797932 ... -0.1221901  -0.05586459
  -0.06225294]
 [-0.12655292  0.09193163 -0.08227924 ... -0.06331351  0.05272715
   0.00639663]
 [ 0.14879073 -0.02914541  0.08652693 ...  0.01393984 -0.02159628
   0.00645468]]
tensor_name:  TemporalFusionTransformer/dense_8/bias
[0.]
tensor_name:  TemporalFusionTransformer/dense_8/kernel
[[ 0.03901081]
 [ 0.00565775]
 [ 0.12191856]
 [ 0.18653035]
 [ 0.06798899]
 [ 0.12836182]
 [ 0.03345723]
 [-0.15236528]
 [ 0.01333423]
 [ 0.1215122 ]
 [-0.06305519]
 [-0.02706979]
 [-0.15044563]
 [-0.08019272]
 [ 0.15888998]
 [ 0.13907152]
 [-0.0731548 ]
 [-0.06944442]
 [-0.1446476 ]
 [-0.08087745]
 [-0.10006236]
 [-0.1826116 ]
 [-0.14386907]
 [-0.12223066]
 [-0.10268211]
 [ 0.04354456]
 [-0.16630535]
 [-0.15472296]
 [ 0.09978721]
 [ 0.04904935]
 [-0.0129783 ]
 [ 0.1895769 ]
 [ 0.1454033 ]
 [ 0.13340273]
 [-0.10732231]
 [-0.1841184 ]
 [ 0.04904102]
 [ 0.10040963]
 [ 0.17058599]
 [-0.16428457]
 [ 0.07370913]
 [ 0.1208311 ]
 [ 0.08074412]
 [ 0.08135593]
 [-0.03543608]
 [ 0.07783848]
 [-0.02048817]
 [ 0.12970775]
 [ 0.17261109]
 [ 0.18579978]
 [-0.13739893]
 [ 0.10679659]
 [ 0.12992722]
 [-0.15476535]
 [-0.0678459 ]
 [ 0.12663043]
 [ 0.00074957]
 [-0.11184841]
 [-0.18012284]
 [ 0.16144294]
 [-0.10379552]
 [ 0.02590354]
 [-0.19031994]
 [ 0.16265562]
 [-0.0810049 ]
 [ 0.1002818 ]
 [-0.15037079]
 [-0.13735594]
 [-0.0269203 ]
 [ 0.05924851]
 [-0.08831547]
 [-0.17303397]
 [-0.01497592]
 [ 0.01854344]
 [ 0.0169694 ]
 [ 0.12023801]
 [ 0.11185023]
 [-0.02698773]
 [-0.08783919]
 [ 0.19241199]
 [ 0.02928439]
 [ 0.04973601]
 [-0.1450379 ]
 [ 0.06168914]
 [ 0.13123977]
 [-0.06667224]
 [-0.03372064]
 [ 0.09891567]
 [-0.00755452]
 [-0.02864757]
 [-0.08562208]
 [ 0.1738219 ]
 [-0.06960394]
 [ 0.07706764]
 [ 0.0923515 ]
 [ 0.0725562 ]
 [ 0.07492077]
 [ 0.02093117]
 [ 0.12790602]
 [ 0.12742367]
 [ 0.03707638]
 [-0.160501  ]
 [-0.13076788]
 [ 0.03116785]
 [-0.16234817]
 [-0.05205737]
 [-0.14289986]
 [ 0.05646299]
 [ 0.12617394]
 [-0.18495566]
 [ 0.1893054 ]
 [-0.0670298 ]
 [ 0.01319034]
 [ 0.17135751]
 [-0.07280082]
 [ 0.11386347]
 [-0.01321281]
 [-0.18606576]
 [ 0.07650334]
 [ 0.1690253 ]
 [ 0.1771394 ]
 [ 0.12981358]
 [ 0.17158994]
 [-0.00433399]
 [ 0.13214338]
 [-0.17554998]
 [-0.07947066]
 [ 0.07837644]
 [ 0.01032482]
 [-0.0906668 ]
 [ 0.08994713]
 [-0.04286991]
 [ 0.07675195]
 [ 0.06673685]
 [ 0.16512504]
 [-0.08804931]
 [-0.09779337]
 [-0.13886927]
 [ 0.08581024]
 [ 0.17471954]
 [-0.02158079]
 [-0.16354729]
 [ 0.10664475]
 [ 0.07140052]
 [ 0.12962258]
 [ 0.07780582]
 [ 0.05234554]
 [-0.10322613]
 [-0.12748522]
 [-0.15670213]
 [ 0.08254939]
 [-0.09050806]
 [ 0.0719409 ]
 [-0.14644676]
 [-0.11442029]
 [ 0.07992932]
 [ 0.06747556]
 [-0.16714628]
 [-0.13606265]
 [ 0.09405044]]
tensor_name:  TemporalFusionTransformer/dense_9/bias
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
tensor_name:  TemporalFusionTransformer/dense_9/kernel
[[-0.04224677 -0.05119376 -0.12281828 ... -0.02793904  0.03883626
   0.04814392]
 [-0.03754795 -0.02010704 -0.02716035 ...  0.05843347 -0.09002067
   0.0063215 ]
 [ 0.08635385  0.04176438 -0.12231496 ...  0.11108407 -0.07886735
  -0.08499711]
 ...
 [ 0.04508273  0.09893763  0.01608998 ... -0.10590135 -0.00715654
   0.00898942]
 [-0.01730908 -0.0695853  -0.12684728 ...  0.05375081 -0.11351554
   0.02450198]
 [-0.06283493 -0.02786148 -0.05017397 ...  0.02431682 -0.09569038
  -0.04878749]]
tensor_name:  TemporalFusionTransformer/embedding/embeddings
[[-0.0020895   0.06313452  0.02369896 -0.0321002  -0.05392817  0.03331418
   0.03696483 -0.03211962 -0.04145298 -0.00300575 -0.0544328   0.02861832
  -0.02976905  0.03597542  0.06317141  0.00154418 -0.00386655  0.03140198
   0.04351263 -0.01040323 -0.04118214 -0.02433664 -0.03031448  0.02510569
  -0.02296428 -0.0372247  -0.03161049  0.01492119  0.00145949 -0.03523356
  -0.04901204  0.01782946 -0.05726238  0.02257529  0.03391    -0.00787327
  -0.00358855  0.02568739 -0.03997631 -0.04402843  0.00876193 -0.04618476
  -0.01437998 -0.01935699 -0.03375569 -0.02988281 -0.05630855  0.04923613
  -0.01734323  0.04285251  0.06535794  0.0576906  -0.006121    0.02362398
  -0.03781657 -0.03732295  0.06204071  0.03020849 -0.04215751  0.01059404
  -0.00587977 -0.05241689 -0.02306596  0.00702989 -0.07687922 -0.02871158
   0.00990298  0.01954322 -0.04005583  0.04108555 -0.0334266  -0.06068194
   0.03986526 -0.01212542 -0.04019447  0.00418754 -0.01318436 -0.02452911
   0.0010255  -0.00929804  0.04151431 -0.02216655  0.01062249 -0.0435383
  -0.00397809  0.05131261  0.04470739  0.02860013 -0.03853847 -0.03917529
  -0.03381268  0.01439378  0.05455031 -0.01613882 -0.04019405 -0.0243039
  -0.00852158 -0.01285027 -0.0549963   0.06467063  0.03826385 -0.04727706
   0.01568157  0.04657084  0.03979192  0.00066544 -0.05158272  0.03852952
  -0.05240754 -0.01450179 -0.05362625  0.03869382 -0.01685319 -0.01118378
   0.02053985 -0.03262663  0.02241348  0.03230263  0.05354063  0.01830476
  -0.01224551 -0.06334074 -0.03615088 -0.04252072 -0.02330491  0.03906733
   0.00522788 -0.02961941  0.01901445  0.05433144  0.00498254  0.0528725
   0.05020002  0.0072277   0.0494349  -0.00820446 -0.03083444 -0.01252785
  -0.01098249 -0.00505274  0.01471431 -0.04684413  0.00065583 -0.0318441
   0.02951729  0.00532436  0.01291051 -0.02738993 -0.07597062 -0.02999269
  -0.01192823  0.0316909   0.00843509 -0.00657144 -0.00313983  0.0094351
   0.00684938  0.04963687  0.07643773  0.02886118]]
tensor_name:  TemporalFusionTransformer/layer_normalization/beta
[0.]
tensor_name:  TemporalFusionTransformer/layer_normalization/gamma
[1.]
tensor_name:  TemporalFusionTransformer/layer_normalization_1/beta
[-2.96920980e-03  2.51880214e-02 -2.25228490e-03 -6.53686794e-03
 -1.77513305e-02 -3.75519018e-03  8.43452581e-04 -4.31105401e-03
  3.58439237e-03  6.05980214e-03 -1.35477288e-02  1.61967948e-02
 -4.16465243e-03  2.92465091e-03  1.68542545e-02  4.31551645e-03
  4.82369401e-03  3.27524118e-04  1.47486515e-02  1.18087884e-03
  9.44112835e-04  5.98697690e-03 -4.63390141e-04  8.27724021e-03
 -5.08139795e-03 -7.07889348e-03  1.88120862e-03 -5.18084737e-03
  1.04572764e-03  3.55505734e-03 -7.54946098e-03 -3.97299463e-03
 -3.64053203e-03 -5.76133560e-03 -6.32173382e-03  5.36016887e-03
 -2.71565019e-04  7.03872042e-03 -9.35687590e-03  1.69196422e-03
 -1.35763390e-02 -2.96079903e-03  4.35350509e-03  5.71292359e-03
 -2.42161332e-03 -7.78126623e-03 -6.69498835e-03 -3.48441885e-03
 -1.43996289e-03 -8.83407309e-04  6.01801090e-03  1.84171647e-02
 -9.49700177e-03  3.40044266e-03  2.92308000e-03  8.07666947e-05
  5.43119200e-03  1.92908291e-02 -1.83251873e-02  5.00269001e-03
  3.00452230e-03 -6.46348298e-03 -4.89695696e-03  1.42334262e-02
 -2.66987570e-02  1.49126304e-03  5.31239109e-03  1.22114539e-03
  3.31612281e-03  9.58410650e-03 -1.07491128e-02 -2.26375293e-02
  3.62848723e-03 -4.53005545e-03 -6.83321338e-03 -3.21879750e-03
  6.35483116e-03 -1.91501982e-04  3.45058949e-03 -6.02028286e-03
  7.91202858e-03  5.18624671e-04 -1.47914712e-03  4.09564655e-03
 -5.32014063e-03  1.11068347e-02  1.36324586e-02  1.67726818e-02
  3.31244199e-04  4.27178014e-03 -8.50518234e-03  2.15202961e-02
 -3.03888554e-03  4.26379452e-03 -1.29480259e-02  5.35820657e-03
  1.88874488e-03  2.18745880e-03 -2.91072819e-02  1.05305417e-02
 -3.04514682e-03 -2.49335449e-03  2.33224928e-05 -4.52514971e-03
 -2.37338338e-03 -6.68325648e-03  2.42188410e-03 -5.18796127e-03
 -5.43259643e-03  1.54188443e-02 -5.94775099e-03 -4.11198504e-04
 -1.07610707e-04  1.97442505e-03  1.28899841e-02 -1.28026875e-02
  2.42593437e-02  3.08771525e-03  1.60247670e-03  4.02833073e-04
 -1.62374310e-03 -1.01464409e-02  1.54248280e-02 -7.55237881e-03
  3.44942231e-03  2.52657174e-03 -3.18081514e-03 -2.49771448e-03
 -3.86914611e-03  8.84602778e-03  2.83089723e-03 -7.48912664e-03
  1.27751222e-02 -3.99155961e-03  5.40525327e-03 -7.73763377e-03
  1.16696144e-02  4.88373172e-03 -3.74684157e-03 -3.60887521e-03
  2.81807128e-03 -1.71218701e-02  1.46254431e-02 -2.56958255e-03
  2.28551240e-03 -2.91583478e-03 -8.17143172e-03 -7.41337752e-03
 -2.45467033e-02 -2.75267567e-03 -3.60402069e-03  9.58918314e-03
  3.86773213e-03  2.11671903e-03  5.63845551e-03 -1.35879740e-02
  9.91673325e-04  4.01035789e-03  1.93701927e-02  4.27692151e-03]
tensor_name:  TemporalFusionTransformer/layer_normalization_1/gamma
[0.98708767 1.0297471  0.9818111  1.0003566  1.0116007  0.9879088
 0.9769868  0.99512744 0.9871066  0.98580223 1.0119802  1.0112866
 0.9926262  0.99121267 1.0150864  0.97949725 0.9820191  0.9872295
 1.0123142  0.98024476 0.9938995  0.98659843 0.9889072  0.99897015
 0.992219   0.9990012  0.99337405 0.9852682  0.99779403 0.9906397
 1.0037438  0.9897728  0.9914562  0.9834608  0.99626184 0.9805481
 0.99010456 1.0038595  1.0049037  0.99273735 1.0136341  0.9930478
 1.0117012  0.98545927 0.99276567 0.9905186  1.0027409  0.99355036
 0.9898675  1.0008775  1.0016739  1.0138888  1.0018     0.9946621
 0.98450905 0.9970362  0.99825585 1.0204159  1.0133104  0.98177385
 0.98586756 0.99714756 0.97169673 0.990629   1.0263082  0.98941356
 0.9791895  0.9920671  0.97563404 1.004465   1.0048677  1.0188551
 0.9965754  1.001003   0.996544   0.9833539  0.9952604  0.9758102
 0.9712305  0.97540915 0.9980543  0.9794083  0.99624294 0.9850167
 0.99833614 1.0043393  1.0108255  1.0198332  0.9958349  0.9775189
 1.0097662  1.0230948  0.9910128  0.99059135 1.0100086  0.9845646
 1.0004728  0.98789126 1.037569   1.0053099  0.98749214 0.98311317
 0.9884699  0.98864657 0.9871501  0.98941    0.99666435 0.9859928
 0.9930239  0.99812734 0.98700386 0.9943627  0.99017686 0.99763244
 0.9998884  1.0070056  1.0308965  0.9948683  0.99578804 0.9930858
 0.98987806 1.0075788  0.9894148  0.9968385  0.99046123 0.98647887
 0.98912084 0.9962127  0.9989647  1.0067112  0.99821144 0.98649234
 1.0081667  0.9949358  0.99711245 0.98331505 0.98252684 0.9935984
 0.9761185  0.97608435 0.99571097 1.0123595  1.0061439  0.983812
 0.9907559  0.98476475 0.9760475  0.999408   1.0245073  0.9837782
 0.9926026  0.997343   1.0020517  1.0003753  0.9887393  1.0021174
 0.98108846 0.99696946 1.0164169  0.99654794]
tensor_name:  TemporalFusionTransformer/layer_normalization_10/beta
[-1.20477770e-02  1.42395943e-02  2.65258737e-02 -2.38567498e-02
  1.45212663e-02  1.07993826e-03 -1.16139315e-02  7.67728873e-03
  1.03384666e-02 -7.06903031e-03  1.08470740e-02  4.11285907e-02
 -3.68817821e-02 -1.14872819e-02 -5.55163191e-04 -9.26356670e-03
  1.46553991e-02 -8.77823122e-03  7.15849572e-04  7.65801826e-03
 -1.76842064e-02  6.70773350e-03  1.88905261e-02  3.13981213e-02
  4.03723819e-03 -1.07331676e-02 -1.26312836e-03 -6.38344232e-03
 -2.37036794e-02  1.69232357e-02 -8.93835258e-03 -2.13669892e-02
 -2.09781975e-02  2.33576093e-02  2.79088132e-02  1.25853494e-02
 -2.24340777e-03 -5.70797082e-03  1.72217581e-02  7.04550138e-03
 -2.40460187e-02 -9.14506987e-03  4.58209589e-03  2.01206710e-02
 -8.77030380e-03 -1.28054712e-03  7.74106616e-03 -1.27433240e-02
  3.28227552e-03  9.06818174e-03  1.32168401e-02  9.51993372e-03
 -2.01709978e-02  1.20988060e-02  4.22403961e-03  1.87201183e-02
  2.76326854e-02  2.52041984e-02  1.48204360e-02 -1.55268004e-02
 -2.14634128e-02  1.11192958e-02 -1.54608656e-02 -5.74593060e-03
  1.40335709e-02  1.03657963e-02 -3.59519571e-02  1.41609572e-02
  1.29914396e-02  5.05228154e-03 -5.71844913e-03 -9.28810146e-03
  6.78884145e-03 -4.48017265e-04  1.66868363e-02  1.65844206e-02
  3.96641204e-03  2.11817566e-02 -1.32123167e-02 -9.49803274e-03
 -1.76865477e-02 -3.30269849e-03 -4.88028536e-03  1.38303526e-02
  2.19549164e-02  2.48256233e-03  7.92742055e-03  3.81026417e-02
 -4.90647228e-03  1.35462061e-02  1.37316510e-02  1.45996572e-04
 -1.41007686e-02  2.24058796e-02  1.97860971e-02 -1.28060114e-02
 -9.82763129e-04 -1.55459275e-04 -7.72119267e-03 -3.34625598e-03
  6.04109420e-03 -1.93581060e-02 -2.97908019e-02 -2.47241445e-02
 -2.46163383e-02 -2.03582756e-02  1.54807102e-02  2.49382085e-03
  3.81797040e-03 -1.25767617e-02 -5.36399661e-04  1.04070930e-02
  1.06543349e-02  1.33603429e-02 -1.51100308e-02 -2.61893719e-02
 -1.35779781e-02  1.37833878e-02 -5.26850447e-02 -5.51173538e-02
 -8.22191220e-03 -7.81885628e-03  1.95723698e-02  9.15333070e-03
 -1.79203898e-02  6.66911574e-03 -1.52211329e-02  1.10699804e-02
 -6.85055833e-03  1.01875914e-02 -2.20256690e-02  9.76935308e-03
 -1.60484314e-02  8.86255782e-03  1.37156732e-02 -1.62962191e-02
  1.93534084e-02  1.30950036e-02  1.03950512e-03 -1.40058333e-02
  1.11883609e-02 -6.08446635e-03  1.57544855e-02  9.27800220e-03
  7.55839143e-03 -3.14735016e-03  4.86227311e-03  7.85555784e-03
 -2.17310712e-02 -2.20492613e-02  6.90384395e-03  3.87683511e-02
  2.69033737e-03  2.63303909e-02  1.18846577e-02 -2.37289499e-02
  1.46559644e-02  1.99473910e-02 -1.30818160e-02 -9.67701490e-05]
tensor_name:  TemporalFusionTransformer/layer_normalization_10/gamma
[0.9862459  0.92286694 1.093758   1.0315711  0.9742864  0.9677398
 1.1178961  0.9844438  0.9591767  0.9741562  0.9425001  1.0019125
 0.98030496 0.9419677  1.0474517  1.079791   1.0397487  0.9562587
 1.0225708  1.0191743  1.012127   1.0118068  0.9990676  0.9413586
 0.96980876 0.9349075  0.9657508  0.9764969  0.98656094 1.0199156
 0.9626362  1.0034455  0.95219064 0.9211782  0.992045   0.9616821
 0.9529507  1.0758574  1.126668   1.0559806  0.9534129  1.0463673
 0.9638608  0.97040635 1.0095605  1.0523735  0.93993175 0.9427656
 0.9530543  0.9378161  0.96395904 0.8909348  1.0260118  0.99805355
 0.9606859  1.0130314  1.0532299  0.99107224 1.0033889  0.9416635
 0.91115373 0.8514576  0.9362926  0.9881004  0.9571475  1.013054
 1.1781403  1.102268   1.011604   1.0217638  0.9755698  1.0021648
 0.92579365 1.0196558  0.9276294  1.2126632  1.1274515  0.9232822
 1.1006385  0.96300113 1.0414155  0.94120675 0.9199098  0.912406
 0.92053336 1.0106856  1.2126883  0.9691012  0.9279852  0.9337783
 0.994375   0.97257465 1.0302737  0.9683917  0.94990706 1.0029384
 0.97674984 1.0617219  1.017991   1.0239699  0.96397555 0.991108
 0.97511846 1.0009558  0.94612485 0.92125386 0.96973604 1.0058908
 0.9676749  0.9575575  1.0554954  1.0244194  0.9532824  1.0053036
 1.0144897  0.96221095 0.95346254 0.95877665 1.0467426  0.9588652
 0.9731653  0.9380058  0.9815094  1.0065304  0.97123957 0.9952455
 1.0275015  1.0233648  1.0036097  0.9210869  1.0423231  0.94193774
 0.9487508  0.99596024 1.0368549  0.9669573  0.96120185 0.9166999
 0.99049807 0.94809175 0.96851414 0.9340475  1.0373113  0.94659823
 0.95855916 0.9846944  1.0576755  0.9917289  0.9257648  0.92557716
 0.96143335 1.007516   0.9833602  0.9923843  0.9696629  0.9090035
 0.9966498  0.92156935 1.0522305  0.94633895]
tensor_name:  TemporalFusionTransformer/layer_normalization_11/beta
[-0.00790762  0.00302972  0.01847855 -0.02299823  0.01324531  0.00799041
 -0.00948997  0.01165312  0.01802522 -0.00460766 -0.00014051  0.03834266
 -0.04066864 -0.01115297 -0.00489279 -0.01109381  0.01204472 -0.0079486
 -0.00438201  0.00440889 -0.0244085   0.00106897  0.01351977  0.03561427
  0.00133914 -0.01152281  0.00672354 -0.00772286 -0.02456113  0.01494915
 -0.00486934 -0.02052145 -0.0223605   0.02375559  0.02376659  0.007051
 -0.00352957 -0.00786101  0.02046551  0.00381347 -0.03002497 -0.00461292
  0.0064825   0.01695857 -0.0062128  -0.00252993  0.01355201 -0.00704258
 -0.00327751  0.01786815  0.00817401  0.01045713 -0.02428875  0.0094307
  0.0011517   0.02151852  0.02740976  0.02426996  0.01076248 -0.01170494
 -0.02127387  0.01232496 -0.01576907  0.00035146  0.01370556  0.00681172
 -0.03804333  0.01826239  0.01715806  0.00471585 -0.00524272 -0.00800309
  0.00994698  0.00178284  0.01538271  0.0179489  -0.00518546  0.0206812
 -0.01646126 -0.01095736 -0.01700219  0.00264561 -0.00734081  0.01430013
  0.01754643  0.00141389  0.01013274  0.03363642 -0.00169025  0.01520105
  0.01715894 -0.00367033 -0.01649924  0.02516635  0.02228882 -0.01704757
 -0.00501427  0.00139494 -0.00774332  0.00148915  0.00093992 -0.01380269
 -0.02829016 -0.02248272 -0.02534906 -0.0147878   0.0106018  -0.00188614
  0.00972464 -0.0134711  -0.0034291   0.00754288  0.0078363   0.01413999
 -0.01058009 -0.02852451 -0.01073333  0.0079341  -0.04955001 -0.04861994
 -0.00449966 -0.01468711  0.01823391  0.00411557 -0.01492037  0.0106988
 -0.02002644  0.01192154 -0.00212054  0.01138362 -0.02333073  0.01041048
 -0.00662231  0.00863936  0.01615699 -0.00815818  0.01420625  0.00926746
  0.00409971 -0.01814035  0.01947887 -0.00259726  0.01233051  0.00977484
  0.01211072 -0.00566746  0.0104174   0.01123454 -0.02143429 -0.02167393
  0.00678901  0.03589852  0.00093029  0.02689774  0.01327919 -0.01934602
  0.01030386  0.01887445 -0.01238913 -0.00762487]
tensor_name:  TemporalFusionTransformer/layer_normalization_11/gamma
[0.9516603  0.93794346 1.0692137  1.0311446  0.9588253  1.052717
 1.1168889  0.9992458  0.9938494  0.94248307 0.96259046 1.0155803
 0.9608481  0.91104907 0.9936544  1.0812742  0.9534301  0.9737387
 1.0072354  1.0223787  1.0268946  0.9839884  1.0060928  0.96839046
 0.9452783  0.9179264  0.96189374 0.9643944  0.99499035 1.0739555
 0.9763871  0.99501824 0.9776023  0.9182874  0.98638535 0.96161526
 0.9342091  1.038422   1.053949   0.971752   0.97653663 1.0185266
 0.987447   0.96055067 0.97583    0.99171704 0.9047735  0.96909344
 0.9433348  0.95556635 0.96393156 0.9687852  1.0396303  0.9856325
 0.99373007 0.99661976 1.0301005  0.9502739  0.9561887  0.9343684
 0.95805156 0.8703924  0.9650775  0.9638554  0.9172649  0.9942055
 1.0634034  1.0464184  1.0023866  1.0444537  0.9807027  0.9764914
 0.95059365 0.9935148  0.96941185 1.1252176  0.94466484 0.9434308
 1.0750074  0.9165891  1.0111787  0.9545997  0.9804937  0.94228286
 0.9726704  0.95862377 1.154158   0.9790638  0.9400519  0.9126151
 1.0026617  1.0011561  1.0281398  0.99357766 0.9612097  0.9704737
 0.9450621  1.0187739  1.0500418  0.9141766  1.0110779  0.9740488
 0.97313005 0.92001414 0.9829755  0.94895124 0.94050705 0.9741948
 0.9396623  0.9636517  1.0623868  0.98562634 0.9540924  0.9826716
 0.99675214 0.9556398  0.9461779  0.9188436  1.066719   0.9377754
 0.9395345  0.96820617 0.9721668  0.9974159  0.9755481  1.0089607
 0.98777056 1.0151045  0.9925182  0.95043445 1.032888   1.0377905
 0.95817333 1.0082707  0.9535844  0.9530501  0.92370486 0.9283607
 0.98739374 0.8938125  0.9187785  0.9799695  0.96331227 0.9516102
 0.9568785  0.98180574 1.0744638  0.926998   0.9040118  0.9596144
 0.9804698  1.0293142  0.9840909  0.90495145 0.95526916 0.9508933
 1.0206772  0.9411775  1.0700175  0.90375775]
tensor_name:  TemporalFusionTransformer/layer_normalization_12/beta
[-0.00937621  0.00404595  0.01227879 -0.02949435  0.01696147 -0.01076208
 -0.02116404  0.01914134  0.01485027 -0.00580293  0.00464414  0.04371594
 -0.04419044  0.00054046  0.00132345 -0.02248205  0.01705192 -0.00993826
 -0.01201103  0.02515537 -0.01951758  0.00059724 -0.00487245  0.03099437
  0.0151918  -0.0275147   0.00806143 -0.01141442 -0.01606467  0.0278512
 -0.01004474 -0.02780729 -0.02082526  0.03625353  0.01858385  0.0055481
  0.0053231  -0.00681551  0.00151798  0.01808912 -0.03588855 -0.01345149
  0.01708444  0.02028473 -0.02739182  0.02300837  0.01171095 -0.008659
  0.01780899  0.02006708  0.0024312   0.01923407 -0.01277713  0.02703966
 -0.00884339  0.01561548  0.03968775  0.03006972  0.01642385 -0.02366899
 -0.02769422  0.01835967 -0.01329721 -0.00782023  0.00908011  0.01607948
 -0.03164475  0.01140992  0.00744179  0.01521962  0.00752668 -0.00755417
  0.02240956 -0.01029124  0.02393229  0.00712739  0.00420356  0.0233759
 -0.01255855 -0.02046652  0.00301952 -0.01066161  0.00697266  0.01378673
  0.01948633 -0.01060758  0.00073013  0.02838859  0.00015174  0.00644669
  0.02199415 -0.00242801 -0.02781717  0.03351507  0.01762642 -0.00881407
 -0.00642373  0.00796563 -0.0241357   0.00718241  0.00730949  0.00846374
  0.00728594 -0.04791231 -0.02753441 -0.01495925  0.00909529 -0.01079015
  0.0143728  -0.01872346  0.00499141  0.00969095  0.03178252 -0.00823738
 -0.00040618 -0.02535119 -0.0238402   0.00535937 -0.03394818 -0.05363175
 -0.01097906 -0.01097231  0.00179177 -0.00054099 -0.02617303  0.00302921
 -0.02001149  0.01065937 -0.00370841  0.01919957 -0.02617519  0.01364338
 -0.00579729  0.00338922  0.01138739 -0.00899308  0.00146755  0.02240231
  0.00575085 -0.02011169  0.01212912 -0.00875254  0.02086945  0.00794975
  0.00065743  0.00311685 -0.00989532 -0.01255489 -0.02225752 -0.02638515
  0.00634295  0.03640874  0.00284897  0.03581383  0.01801299 -0.0298431
  0.01017509  0.00580029 -0.01317864 -0.00872368]
tensor_name:  TemporalFusionTransformer/layer_normalization_12/gamma
[0.97233856 0.9347933  1.0285419  1.2917717  1.0091372  1.1127766
 0.9503579  1.095514   1.0922358  0.9234358  0.9337468  0.9747153
 0.8571247  1.033985   0.9069954  1.0979213  0.9884877  1.0723878
 0.98896205 0.97542506 0.92097473 1.1633358  0.9245048  1.0812612
 0.97326094 0.9065876  0.9759781  1.0184352  1.00714    1.2050942
 0.96891624 0.99872303 0.96678    0.8390792  0.97121763 0.941474
 0.90510094 0.93818843 0.99709916 1.0845752  1.0846953  0.9310054
 1.0933869  0.93061167 1.031392   1.049457   1.0175103  1.0963732
 1.0012865  1.2127863  1.0914767  1.0424579  1.0755825  0.868288
 0.94174206 0.9826116  0.9144969  0.9717952  1.0483474  0.9624477
 0.95975935 1.03095    0.9734625  1.103531   1.0041616  1.1846954
 0.8896599  1.0160528  0.96300215 0.9126144  1.1436893  0.91411906
 0.86904156 0.8826972  0.9475729  1.0000072  1.0288794  0.9901068
 1.107496   1.2354162  1.1661171  1.0518035  1.1725532  0.95017314
 0.94017136 0.98738855 1.0067166  1.0743785  0.981843   1.2372189
 0.92497826 0.9721872  1.2095358  0.90294516 0.97322464 0.97693133
 1.0168977  0.97559524 1.1908896  0.98979527 1.0540049  1.0381409
 1.0086492  0.9571579  1.0613492  1.0571533  0.85667855 1.1320101
 0.98061985 1.1597177  1.038538   1.1130886  0.9394736  1.1021048
 0.9325454  1.1760452  1.0208669  1.1730039  1.0337245  0.9365454
 1.1123536  1.104483   1.0122142  0.93463355 0.93469626 0.9584932
 0.90931004 1.014801   1.0012082  0.88927364 0.8925216  0.9363556
 1.1167389  1.0306911  0.8792678  0.99861413 1.0655059  1.058037
 0.95760113 0.9291556  1.0297394  0.96824914 1.0742213  0.9876992
 1.0966793  0.8785016  1.0197097  1.011765   1.1482022  0.9970514
 0.98683876 0.94219553 0.94943947 0.99002033 0.92234105 1.0464402
 1.0017369  1.0145197  1.0162735  1.020048  ]
tensor_name:  TemporalFusionTransformer/layer_normalization_13/beta
[-0.0112131   0.00347106  0.02295566 -0.02579941  0.01568771  0.00132376
 -0.01784468  0.01369705  0.01706843 -0.00860332  0.01015537  0.04013867
 -0.038567   -0.00561512 -0.00212412 -0.00403255  0.01271586 -0.01553259
 -0.00391474  0.00756172 -0.02353464  0.00640552  0.01103835  0.03733206
  0.0025499  -0.01295672  0.00527608 -0.00899106 -0.01703511  0.01817472
 -0.00602712 -0.01970731 -0.0197688   0.02610928  0.02996281  0.01101044
  0.0004136  -0.00265532  0.01247453  0.00685444 -0.02667349 -0.00837488
  0.0055109   0.01874384 -0.01176469  0.00163054  0.01396196 -0.00331995
 -0.00522811  0.01940457  0.0048643   0.00848125 -0.03049101  0.01018401
  0.00152263  0.01683753  0.02749014  0.02266981  0.01713059 -0.01529183
 -0.02681952  0.01465585 -0.01601993 -0.00622785  0.01504461  0.01141455
 -0.03344929  0.01141328  0.0101147   0.0047229  -0.00408507 -0.00449434
  0.01663348 -0.00445002  0.00978653  0.00963107  0.00169261  0.02231789
 -0.01784375 -0.00738298 -0.01593265 -0.00039807 -0.01528689  0.01563958
  0.01513667  0.00346569  0.00184417  0.02969366 -0.00212322  0.01856702
  0.01553876 -0.00225996 -0.01808251  0.02493306  0.01840264 -0.01258674
 -0.00101888  0.00098925 -0.01101428  0.00393262  0.0079256  -0.01062937
 -0.01679539 -0.0292854  -0.02799981 -0.01324012  0.01009956 -0.00023023
  0.00187386 -0.02101043  0.00253616  0.00725925  0.00415858  0.01208828
 -0.00332611 -0.02584721 -0.01477872  0.01193135 -0.04581084 -0.05382319
 -0.00022133 -0.01037878  0.01935991  0.00536171 -0.02069102  0.00679973
 -0.01456641  0.0105176  -0.00332261  0.01380573 -0.020344    0.01474402
 -0.01282003  0.00210259  0.01724908 -0.01151878  0.01525662  0.01540339
  0.00891101 -0.01769931  0.0202441   0.00236793  0.01084681  0.01030262
  0.00627176 -0.00446869  0.00220348  0.01176057 -0.01209633 -0.02062466
  0.00895744  0.03432922  0.00065598  0.02573279  0.0158632  -0.02199013
  0.00862706  0.01726188 -0.00958704 -0.00444252]
tensor_name:  TemporalFusionTransformer/layer_normalization_13/gamma
[0.9042197  0.97268003 1.0883431  1.3016795  0.9288688  1.1795087
 0.947396   0.9399126  0.97852135 0.9170478  1.0772302  0.9534971
 0.95640856 0.8624177  0.9986349  0.94582117 0.9005382  0.978855
 0.9315066  0.93974936 1.0539527  1.0245773  1.0018183  1.0052587
 1.0583546  0.998943   0.9505564  0.94978577 1.0669346  1.0274525
 1.1085411  0.92026746 0.9637887  0.92746174 1.0311035  1.0923202
 1.0687401  0.94346136 1.0778357  0.969264   0.94102484 0.9515554
 1.0517213  1.0125589  0.910751   1.1244707  1.0256369  1.1807361
 1.2527822  1.149295   0.92773104 0.9704627  1.0456522  0.91901195
 1.0670662  1.014898   0.94500583 1.2447243  1.010407   1.0744724
 0.9560278  0.9962126  0.9193406  0.9481152  1.3978945  1.044718
 0.99014807 0.99989825 0.90449864 1.0620553  1.0216128  1.116041
 1.0967047  1.0394654  0.90744823 1.0063126  1.2344515  0.9965157
 1.1037035  0.9913069  0.931978   1.3825963  0.968027   0.9437847
 1.0503122  0.94367635 1.1309063  1.0144839  1.2821486  1.0866059
 1.0345453  1.0433176  1.072946   0.93576986 0.9602688  1.0409611
 0.95498085 1.3272188  1.0716931  0.9115087  0.9762941  1.0412152
 1.0494602  1.1424099  1.0243406  0.9365042  0.9049602  1.0158808
 0.9475524  1.0678809  0.9743049  1.0302976  1.0307838  1.1046662
 1.0099161  1.0382829  1.0160948  0.9712633  1.0610448  0.96444494
 1.181802   0.9950251  0.9879117  1.0282894  0.99019283 0.9731269
 0.97155386 0.9515634  1.0360223  0.9386859  1.0162742  0.98016286
 0.877268   0.9816653  1.0278561  0.9598031  0.90223414 0.9462871
 1.082737   0.9922352  0.9580572  1.0753112  0.9322315  0.9453625
 0.9702496  0.9569053  1.026086   1.0783877  1.1552428  0.9556912
 0.95150775 1.0048646  1.1394844  0.9811093  0.9942506  0.9825482
 0.9691935  0.9643287  0.98233944 0.926844  ]
tensor_name:  TemporalFusionTransformer/layer_normalization_14/beta
[-7.21543445e-04 -1.10520534e-02  9.01671778e-03 -2.43395604e-02
 -2.77793990e-03 -2.15453561e-04 -9.76386946e-03  1.95519608e-02
  2.16251109e-02 -9.92442481e-03 -1.02451700e-03  9.95552074e-03
 -1.39833819e-02  6.13140967e-03 -1.41256452e-02 -6.48234785e-03
 -4.69735404e-03 -1.05719604e-02 -2.05972902e-02 -5.01564378e-03
 -6.85752509e-03 -1.30570428e-02 -5.15561039e-03  8.05113930e-03
 -4.36146930e-03 -1.14748143e-02  1.26826614e-02 -1.26251932e-02
 -3.94584145e-03  4.85673605e-04  1.31077198e-02 -2.19867215e-05
 -9.75665729e-03  7.10143987e-03  1.63417887e-02 -1.60836370e-03
 -4.57618898e-03 -1.65040686e-03 -2.23109615e-03  2.57643987e-03
  1.33118569e-03  1.13510229e-02  2.18154863e-02 -5.86821930e-03
 -8.64832569e-03  6.43197214e-04  1.64467990e-02  8.04295857e-03
 -1.87950395e-03  1.24644879e-02 -1.74152032e-02  1.88502087e-03
 -1.43000372e-02 -4.45289444e-03 -4.39686747e-03  6.65377313e-03
  4.61846543e-03  2.27805153e-02 -1.65637583e-03  8.16009066e-04
 -1.66194700e-02  6.86049322e-03 -1.46987839e-02  3.04341293e-03
 -1.13250641e-02 -2.89945165e-03 -5.02873398e-03  9.54275951e-03
  2.10051797e-02  1.04460795e-03  3.97025328e-03  1.26277218e-02
  5.36364364e-03  4.10712697e-03 -1.73844397e-03 -1.65540678e-03
 -6.09129900e-03 -3.89199145e-03 -2.04054788e-02 -1.59888435e-02
  3.57353594e-03  8.73651297e-04 -7.04249879e-03  1.54277915e-02
 -2.28228560e-03 -1.59369074e-02  4.03770246e-03 -1.00033050e-02
  1.17775500e-02  7.09548825e-03  1.16615673e-04 -5.09944931e-03
 -1.98487788e-02  2.42005214e-02  1.44880731e-02 -2.30352934e-02
 -9.73207410e-04 -2.73743854e-03 -1.80945639e-02  1.12653747e-02
  1.30117051e-02  1.12929689e-02  1.20309005e-02 -8.81690159e-03
 -9.97048616e-03 -7.59312650e-03 -1.23755066e-02 -6.82071084e-03
  1.12975929e-02 -5.15155634e-03 -2.76402803e-03 -1.17811933e-03
 -3.40273674e-03 -1.13558080e-02  1.64105557e-02 -1.79915521e-02
  7.81449955e-03 -1.98770408e-02  4.88948962e-03 -1.24349631e-02
  1.35545190e-02 -4.38260054e-03  3.66991991e-03 -1.16284667e-02
 -1.21044545e-02  1.12722293e-02 -1.47706810e-02  2.86080856e-02
  1.96781866e-02  1.14069385e-02 -3.43595352e-03  1.63861865e-03
 -3.18564824e-03  1.25307534e-02  1.59309097e-02  8.47799052e-03
 -4.71097324e-03 -9.23480955e-04  1.26310280e-02 -2.16786005e-02
  1.18233962e-02  2.13801600e-02 -7.34416954e-03  1.62528493e-02
  1.49477301e-02  2.00020261e-02 -8.01962707e-03  5.09185484e-03
  9.62432101e-03 -3.56193492e-03  1.88567042e-02 -5.64054004e-04
 -6.08464237e-03  1.11957882e-02 -7.64485728e-03 -2.86415219e-03
 -4.60638851e-03  9.53909475e-03 -8.40610173e-03 -2.45776139e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_14/gamma
[1.0247878  1.0080497  0.97850835 0.93734497 1.0194191  0.91602886
 0.99583775 0.9810373  0.98662835 1.0163171  1.0120974  1.0151796
 0.9977913  1.039751   0.9918384  0.9437833  1.0311961  1.0131742
 0.9314118  1.0136472  0.9773302  0.98946893 0.95364606 1.0176146
 1.0563685  1.0138963  1.0290691  1.0107327  0.9139349  0.9528203
 0.99502367 1.0628815  1.0317917  1.050127   0.9801183  0.9651627
 1.0177734  0.99483424 0.93609256 0.95094204 1.0788708  0.96137905
 0.9928667  0.99374795 1.0417583  0.9886627  1.0267609  1.0339028
 0.94834584 0.9470499  0.86863697 1.0417033  0.8700568  1.0057077
 1.0074078  0.9875907  1.0001972  1.0168592  0.997668   1.0015515
 1.088479   1.0332807  1.0291861  0.9946822  0.92706907 1.0438159
 0.9821436  0.9188696  1.0227652  0.9958917  1.0095115  1.01607
 1.0417404  0.94571024 0.8543683  0.9594144  0.94423825 1.1137059
 0.9760564  0.89777863 0.91488165 0.9800654  1.0212115  1.0177388
 0.93256736 0.9988881  0.9041785  0.9592117  0.94962853 1.0093697
 1.0587388  0.9866434  0.9634311  1.0264359  1.0088431  1.0141437
 1.0148015  1.0053488  0.9711532  0.97701526 0.98020715 0.98827016
 0.9405269  0.98307127 1.0360051  1.0279557  0.99306524 0.9585945
 0.99102587 1.0064921  0.91664594 0.89668065 1.0119857  0.9345585
 0.91875213 0.97662467 1.0681827  0.985053   1.0077134  1.0639032
 0.96651673 0.9537297  1.0303525  0.94116193 1.0492761  0.9972335
 0.9210634  1.0395796  0.99375933 1.0763161  0.96250427 1.0326462
 0.96137685 1.0525103  0.9601208  0.9819556  0.9702148  1.0038031
 1.0215179  1.016195   1.020252   0.9359875  0.9596729  1.0116863
 0.93435323 0.9646509  0.9883556  1.0360322  0.97773004 1.0275671
 1.0405968  0.9661213  1.0189208  1.0469146  0.9996109  1.0221797
 0.97050256 1.0169713  1.0135905  0.9532236 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_15/beta
[-0.03644799 -0.05104758  0.09796216  0.01379506  0.05859251 -0.00302535
  0.06774104]
tensor_name:  TemporalFusionTransformer/layer_normalization_15/gamma
[1.0590574  0.96148986 1.0407797  1.0128437  0.9472946  1.0570917
 0.93335426]
tensor_name:  TemporalFusionTransformer/layer_normalization_16/beta
[ 2.72223298e-02  5.18352464e-02  2.04121880e-02 -6.07803836e-02
 -4.64720512e-03  5.75588644e-03 -2.66996175e-02 -2.85229068e-02
  3.05311475e-02 -2.33970080e-02 -4.35980447e-02 -3.41519415e-02
 -1.55542511e-02 -4.62036096e-02 -2.34868564e-02  3.16564888e-02
  2.40265168e-02 -8.54064431e-03 -5.17988279e-02  3.55693214e-02
  5.32043502e-02 -3.35155129e-02  4.21270318e-02  3.60739343e-02
  3.87657098e-02 -4.66344506e-02  2.83091757e-02 -3.48956063e-02
  1.31855784e-02 -1.57517311e-03  1.08067375e-02 -1.92390680e-02
  1.74759589e-02 -5.30194230e-02 -3.27069825e-03 -4.67448458e-02
  6.47681020e-03 -1.37192858e-02  2.00956799e-02  3.53326239e-02
 -4.11367193e-02  3.27803642e-02  4.79641706e-02  3.30819264e-02
 -1.25751114e-02  3.04943696e-02 -1.08563565e-02 -2.85913330e-02
 -3.11711598e-02  1.93653982e-02 -2.18033511e-02 -2.73302868e-02
 -9.85301659e-03 -1.66336466e-02 -1.79733913e-02  9.23182592e-02
 -9.71448515e-03  4.89395251e-03  9.08224564e-03 -1.07196225e-02
 -3.66735421e-02 -3.40102315e-02  4.36824448e-02  3.42549607e-02
  5.54868840e-02  3.48268524e-02 -8.77018087e-03  3.77266146e-02
  1.01710961e-03 -5.45613021e-02  5.38524948e-02  2.65392084e-02
 -3.20256986e-02  7.96948560e-03 -1.55583229e-02  1.11360184e-03
  3.32504474e-02 -1.55685311e-02 -5.59259206e-04 -5.58707543e-05
  2.12383401e-02 -5.03959358e-02 -4.87577952e-02  2.59374063e-02
 -2.62633041e-02 -1.10848062e-02 -1.65440682e-02 -1.08351391e-02
 -1.67030301e-02  4.39484278e-03  2.13988665e-02 -1.75361317e-02
  2.89725009e-02 -3.09239440e-02 -2.12419592e-02 -2.28823256e-02
  4.30825315e-02 -3.33907492e-02  2.38167495e-02 -2.02328749e-02
 -1.25476746e-02 -1.13124158e-02 -2.68463772e-02  2.91654263e-02
 -1.49059361e-02  4.58711535e-02  3.58965881e-02 -3.42921615e-02
  3.04537881e-02  1.36590637e-02 -4.87941201e-04 -8.54587089e-03
  2.62002721e-02 -3.40977386e-02 -7.51063647e-03  3.37630697e-02
  2.30628159e-02 -6.71563298e-02  1.65176997e-03  2.79213618e-02
  1.92402827e-03  1.64513220e-03  6.47512823e-02  3.34839411e-02
  1.67217571e-03  2.21745903e-03  1.19870956e-05  1.25494236e-02
 -1.40848672e-02 -3.10354121e-02  1.77705996e-02  1.98600646e-02
 -2.67795194e-02  3.89330834e-02 -2.73047183e-02 -7.73475831e-03
 -1.57463411e-03 -2.52428092e-02 -1.53816547e-02  5.77855892e-02
 -5.61443716e-03 -1.64369382e-02 -1.38698402e-03  8.54050275e-03
  2.03545298e-02 -2.65324526e-02 -1.69100575e-02 -1.84585862e-02
  1.43959243e-02 -6.29867613e-03  1.48378992e-02 -2.32532136e-02
 -2.10168380e-02 -1.03430390e-01 -4.73432709e-03  4.12870906e-02
  1.47953713e-02  2.43622772e-02  5.78785664e-04  2.02039946e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_16/gamma
[1.0015638  1.0730959  0.9605738  1.0753152  0.9813709  0.9774892
 0.9933673  0.97027093 1.0003376  0.95448774 0.98850924 1.0243152
 0.9956922  0.9832008  0.980945   0.9669752  0.9687777  0.9741672
 1.050071   1.0323763  1.0659865  1.0209256  0.9999778  1.0224358
 0.94728684 0.97544277 0.9750481  1.0309237  0.9795186  0.9664381
 0.9861459  1.0105318  1.0062652  1.0570865  0.99529344 1.0499879
 0.98817265 1.0053273  0.9542305  0.9633196  1.0402645  0.9984771
 1.0349218  1.0215074  0.9827215  0.9984489  0.9860503  0.99573433
 1.0070572  0.9922116  0.9936356  1.0134027  0.9684145  0.9830386
 1.0063939  1.1282777  0.9935953  0.9464565  0.9872081  0.9713505
 1.0035036  1.023562   1.0324394  1.0352362  1.0430121  1.0179986
 0.9642684  1.0226257  0.98387915 1.0363989  1.06687    1.0127933
 1.0150981  0.99765664 0.99040973 0.9489497  0.9983723  0.99845135
 0.97359407 0.97193426 1.007557   1.0513397  1.0471138  1.0097393
 0.9952501  0.99403995 0.99097496 0.96977115 1.0040876  0.9657727
 1.0050616  1.0056734  1.0026826  1.0045956  1.0118212  1.002383
 1.045263   1.0265871  0.99215037 0.9932444  0.988917   0.97979814
 0.974253   1.0244224  0.9809773  1.063668   1.0267164  0.9682511
 0.98011047 1.0001209  0.9773005  0.9826283  0.99068695 1.0306443
 0.99489284 1.0332125  0.9950965  1.0157192  0.9787876  0.9799899
 0.9864421  0.98130864 1.0958443  1.0319935  0.973464   0.9817546
 0.96492237 0.95541936 0.9727582  1.0208014  1.004954   1.0035415
 1.0224501  0.9604477  0.9888119  0.9757307  0.9812065  0.99960434
 0.9928108  1.0518345  0.9977316  1.0014654  0.9659839  0.95482945
 1.0017146  1.0031017  0.981246   0.96747583 0.98773205 0.964907
 1.001017   0.97013867 1.0040934  1.1538814  0.9912926  1.0216229
 0.98473877 0.9789428  0.9672624  0.95633155]
tensor_name:  TemporalFusionTransformer/layer_normalization_17/beta
[-1.45615393e-03  3.90557945e-02  7.51677761e-03  3.67752602e-03
  4.62154159e-03 -7.61275366e-03 -9.41683166e-03 -5.55978203e-03
 -1.82621263e-03 -3.29617187e-02  1.77385546e-02 -1.39559275e-02
 -6.04523299e-03  4.68128063e-02 -1.49937463e-03 -1.51113805e-03
 -5.19688334e-03 -2.43431330e-03  1.61885973e-02  7.55378604e-03
 -5.02497563e-03 -8.54712538e-03 -1.01146298e-02 -1.88098662e-02
  2.03975360e-03  9.73645225e-03 -1.04334215e-02  1.54767493e-02
  9.16645490e-03 -1.04712904e-03 -7.18331616e-03 -1.11321075e-04
  1.15693202e-02  1.53027624e-02 -5.12170792e-03  1.93706267e-02
  2.89843418e-03  8.52732360e-03  1.54111655e-02 -2.63422001e-02
  8.96648125e-05 -1.11441165e-02 -2.28956863e-02 -6.20467588e-03
 -8.36362317e-03  3.23135522e-03 -9.41718929e-03 -2.57025589e-03
  3.64519539e-03  1.11882286e-02 -1.37977023e-02 -8.83111730e-03
 -3.16525158e-03 -6.75101345e-03  2.47249752e-03  7.97561631e-02
 -9.39262193e-03 -3.06750694e-03  1.36512090e-02 -1.38377468e-03
  2.30977125e-02  6.59439294e-03  6.49826648e-03  4.24493942e-03
  1.48376171e-02 -2.84535401e-02 -4.66058124e-03 -1.80108398e-02
  1.14443116e-02 -1.83834117e-02  1.83710083e-02 -4.98002535e-03
 -2.22779214e-02  5.81220211e-03 -1.57127883e-02  7.03099137e-03
 -9.33745410e-03 -3.40669649e-03  1.06598986e-02  9.00223327e-04
  1.78180002e-02 -5.17948577e-03  5.08125406e-03 -1.75883365e-03
 -7.35695334e-03 -1.14289373e-02 -9.43742599e-03  1.39582960e-03
 -3.87148769e-03  1.32212136e-02 -1.65816734e-03 -4.12758673e-03
 -3.86934145e-03 -8.37486703e-03 -1.53287146e-02 -5.88512688e-04
 -7.81526789e-03 -1.47573266e-03 -6.78142626e-03 -3.96918226e-03
  4.61996114e-03 -6.92674145e-03  4.94485628e-03 -5.37134754e-03
  2.40658727e-02  4.74766828e-02 -6.17218949e-03 -9.82790487e-04
 -5.23307500e-03 -9.83781414e-04  9.77475755e-03  1.13880690e-02
  3.42058926e-03 -1.78997386e-02 -2.18951819e-03  4.78833448e-03
  4.86761564e-03 -1.51440850e-03  1.41753275e-02  1.83858220e-02
  8.07589293e-03 -6.45248964e-03  1.85597986e-02 -2.42417539e-03
 -1.81152089e-03 -6.67813281e-03  1.11174257e-03  1.33441538e-02
 -1.96203217e-02 -1.30881751e-02  7.03632552e-03  6.16237056e-03
 -1.91317033e-02 -1.93443932e-02  3.26998010e-02 -6.69570058e-04
 -5.36276028e-03 -1.53798505e-03  4.03303746e-03  6.15899358e-03
 -2.54633892e-02 -1.27003966e-02  1.37863355e-02 -2.49828072e-03
 -1.36081420e-03 -1.07981386e-02 -1.71112381e-02  9.54475906e-03
  6.49830885e-03  8.25327076e-03 -1.49357168e-03 -1.79433785e-02
 -7.69465184e-03 -9.89494249e-02  4.86343587e-03 -1.29438853e-02
  2.65071960e-03  1.39254620e-02  3.24120093e-03  1.29064145e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_17/gamma
[1.0044167  1.049985   0.9455353  0.9642692  0.9343034  0.9771708
 0.9878185  0.9827332  0.99835896 0.8502449  0.9428619  0.9827336
 0.9397342  0.89114416 0.9384819  0.99841535 0.8923233  0.95024425
 0.9782665  0.9402475  0.99121535 0.9836688  0.9631319  0.9462398
 0.96463865 0.99855477 0.96448207 0.92419493 0.9974948  0.85846037
 0.97511613 0.9630379  0.9805363  0.9059638  0.9548805  0.9439451
 0.9569499  0.8336262  0.9741347  0.9319876  0.95894355 0.9319933
 0.9622426  0.9704177  0.9588402  0.96194845 0.9803219  0.94475764
 0.9789759  0.98799765 0.9845798  0.97815317 0.92351466 0.9516513
 0.8604962  1.1229242  0.8916993  1.0040144  0.97061217 0.9895608
 0.9332835  0.96560323 1.0088812  0.9692473  0.9765369  0.9243866
 0.9617431  0.9164586  0.9348454  0.99922204 0.9941313  0.97434986
 0.9722595  0.9782131  0.9328483  0.96946484 0.855142   0.98227245
 0.9657007  0.925638   0.976806   0.9706049  0.9909125  0.9352209
 0.82394564 0.97607595 0.98147446 0.9259162  0.983154   0.96095246
 0.8445029  0.9006391  0.9798823  0.9557867  1.0017987  1.0021932
 0.95687354 0.9850633  0.8651827  0.93447536 0.9992911  0.9703651
 0.9828952  0.9236169  0.8095013  1.0054382  0.92898786 0.9834974
 0.96915454 0.9628942  0.97599995 0.9814252  0.90062785 0.9791267
 0.9679099  1.007729   0.8648479  0.9926238  1.0083463  1.017622
 1.0040215  0.90701234 0.9702669  0.9609622  0.92720836 0.96755844
 0.9651843  0.97601545 0.96009696 0.98558515 0.973492   0.9583571
 0.99854887 0.99781775 0.8942673  0.97290176 0.95260805 0.9608726
 0.95467216 0.9786134  1.0045066  0.95475245 1.0042615  0.9790941
 0.9741052  0.9747915  1.0081842  0.984541   0.8610603  0.87586147
 0.9792299  1.0071915  0.94922704 1.0858543  0.9354202  0.9441166
 0.986646   0.99030286 0.9846059  0.94508857]
tensor_name:  TemporalFusionTransformer/layer_normalization_18/beta
[ 0.01515321  0.03401746  0.02462813 -0.04451116  0.00616691 -0.00203746
 -0.0146587  -0.03607771  0.02266875 -0.02351913 -0.03378439 -0.03931104
 -0.02624977 -0.02040916 -0.02844146  0.04231277  0.02980896  0.00377147
 -0.05293917  0.03820308  0.02345328 -0.04338452  0.02667593  0.01721114
  0.04331675 -0.02903204  0.03066009 -0.02577244  0.02022625 -0.01543488
  0.00306133 -0.02562475  0.0208968  -0.03858472  0.00515038 -0.02722384
  0.00895401 -0.00637669  0.03074185  0.01398946 -0.0340892   0.04815956
  0.03104463  0.01752471 -0.01502649  0.01045705 -0.02347202 -0.0096006
 -0.01721784  0.00870106 -0.03457271 -0.04386273 -0.01683766 -0.02399594
 -0.02398383  0.13557065 -0.00032719  0.00226569 -0.00863132  0.00112342
 -0.03297273 -0.00840023  0.03666602  0.03175949  0.05067082  0.02520975
 -0.02060454  0.02514829  0.00940245 -0.03507691  0.07446657  0.00863288
 -0.04045573  0.01463593 -0.02856434  0.00815883  0.03686554  0.0013786
 -0.00828039  0.00688061 -0.00052227 -0.03153177 -0.03704604  0.03549169
  0.00056513 -0.01558737 -0.02618136  0.00212262 -0.00200698  0.00631187
  0.00955823 -0.02862248  0.01593029 -0.01415945 -0.02611233 -0.01185262
  0.03379427 -0.02480686  0.00980554 -0.04045674 -0.02021081 -0.01526599
 -0.00520949  0.03965101  0.01109647  0.04959193  0.01883693 -0.02660678
  0.01935755  0.0182261   0.01005298 -0.01803462 -0.00588476 -0.03644126
 -0.01654482  0.021166    0.0257728  -0.05844963  0.01358793  0.02906001
  0.00580562 -0.02878634  0.05982205  0.03071219  0.00948369  0.01773287
  0.00019364  0.02451357 -0.02482858 -0.02996965  0.02554465  0.00948869
 -0.03242311  0.04177581 -0.00864489 -0.00118714 -0.0137752  -0.0085233
 -0.00541113  0.03336462 -0.02330914 -0.02379409  0.00874551 -0.0031324
  0.00626467 -0.01444359 -0.01940233 -0.0041103   0.06054827  0.00838344
  0.00501387 -0.01932344 -0.00904153 -0.14816916 -0.02094068  0.02156066
 -0.00215213  0.03359615 -0.006822    0.00428782]
tensor_name:  TemporalFusionTransformer/layer_normalization_18/gamma
[0.9913014  1.0604979  1.0072854  1.0055574  0.9741564  0.973142
 0.97434    0.94692856 0.99275625 1.1802194  1.0025856  0.9625655
 0.96114963 1.1048551  0.9917693  1.0295147  0.9714955  0.9863979
 0.99921954 0.9921295  0.9809715  1.0473961  1.0305244  0.99328995
 1.0118238  0.9993908  1.0329072  1.0054759  1.0608748  1.0922093
 0.98038936 1.0019187  0.99608344 1.0391665  0.9912756  0.9893041
 0.9417377  1.4162484  0.9796986  1.0311677  1.0085629  1.0249411
 0.97350144 0.97656363 0.95753855 0.942947   1.0176034  0.9947451
 1.0088695  0.9834042  0.99888855 0.9883273  0.97766167 1.0061238
 0.97451794 1.1255282  1.0405465  0.97415286 1.0243299  0.9854909
 1.0266409  0.9919633  0.993476   1.0102504  0.9979848  1.0207218
 0.9784764  0.9754405  0.9627917  1.0440495  1.1231928  1.0074626
 0.9803227  0.97985995 1.0761782  0.98811823 0.9707862  0.99525213
 0.9896325  0.9978954  1.1564444  1.0200115  0.99085736 0.9913342
 1.0706306  0.9473528  1.0311275  0.9854865  0.9888499  1.0135177
 1.072831   1.0495735  1.0004579  0.97287893 0.999743   1.0027503
 1.027359   0.9677414  1.0059047  1.0515189  0.93836486 1.0056701
 0.99394786 1.046522   1.0367293  1.0166883  0.9828304  0.971332
 1.0115788  0.9636279  0.98271203 1.0192795  1.1961725  0.9469409
 1.007683   1.0575117  1.1209491  0.99870723 1.002116   0.9783295
 1.0014297  1.2470236  1.0614568  0.9921562  1.0223953  1.0059161
 0.9836327  1.0017081  1.0265963  0.95413536 1.0095099  0.9450789
 1.0365136  0.9341531  1.1561357  0.9460861  1.0143576  1.0154109
 0.9582029  1.0022523  0.9828707  0.999812   0.9963868  0.9808369
 0.98994064 0.9890522  0.9729602  1.0047256  1.3556252  0.9773804
 0.9769309  1.0087292  1.0007548  1.077815   1.0500202  1.0037462
 0.98812264 1.0707335  0.9907988  1.0852855 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_19/beta
[ 2.0334607e-02  4.3025680e-02  2.3196202e-02 -4.9828019e-02
 -1.0781025e-03  1.3269186e-03 -2.1996049e-02 -2.4898192e-02
  2.1624897e-02 -1.6040141e-02 -3.2978639e-02 -3.2784928e-02
 -1.5042635e-02 -3.0234246e-02 -2.3529546e-02  3.1154003e-02
  2.2538200e-02 -5.1664817e-03 -3.9075952e-02  3.2255027e-02
  4.3999802e-02 -3.0425979e-02  3.1246498e-02  3.4206145e-02
  3.5633892e-02 -4.4022199e-02  2.4638079e-02 -3.0023228e-02
  1.9353652e-02 -9.3898559e-03  8.6432928e-03 -1.7868290e-02
  1.7471114e-02 -4.4816166e-02 -2.1801807e-03 -4.2082954e-02
  1.4392823e-03 -1.5546906e-02  1.9953160e-02  2.2223342e-02
 -3.3955161e-02  2.3114700e-02  3.5679370e-02  2.8331855e-02
 -1.2100447e-02  2.6426436e-02 -1.1253701e-02 -2.5345910e-02
 -2.3262730e-02  1.9013109e-02 -1.9504478e-02 -2.4034312e-02
 -8.7515302e-03 -1.8176343e-02 -1.4428946e-02  8.2469396e-02
 -1.0851692e-02  2.5401786e-03  9.8874718e-03 -6.2809875e-03
 -3.6128949e-02 -2.9468307e-02  3.6958851e-02  3.0423312e-02
  5.1817279e-02  2.9222386e-02 -1.0283141e-02  3.0386550e-02
  3.5894308e-03 -4.4847038e-02  4.4185400e-02  2.3511210e-02
 -2.9951058e-02  8.1498008e-03 -1.6975503e-02  2.2495235e-03
  2.8865468e-02 -1.6359236e-02 -4.1115738e-04  4.6636765e-03
  1.1165690e-02 -4.6512131e-02 -3.8830291e-02  2.5978403e-02
 -1.9696509e-02 -1.1044358e-02 -1.7764326e-02 -8.9362357e-03
 -1.4212649e-02  2.5494809e-03  2.6017886e-02 -1.9888226e-02
  2.2665264e-02 -2.7419794e-02 -2.1841075e-02 -1.8202011e-02
  3.3339046e-02 -3.2389406e-02  2.0286214e-02 -1.7474653e-02
 -1.0196079e-02 -1.2291176e-02 -2.3058565e-02  2.8894721e-02
 -7.1289856e-03  3.9151896e-02  2.9606540e-02 -2.7924631e-02
  2.4197664e-02  1.2467886e-02  1.6851173e-03 -1.0735354e-02
  2.0344790e-02 -3.4143824e-02 -7.3703420e-03  2.8333141e-02
  2.8328776e-02 -5.8584634e-02  5.8504795e-03  3.0327335e-02
  2.9531890e-03 -6.3973235e-04  6.2342893e-02  3.1713922e-02
  5.0246730e-03  3.8068416e-03  6.3312953e-05  1.3304751e-02
 -1.6335241e-02 -3.1141028e-02  1.8596476e-02  2.0241026e-02
 -3.0210156e-02  3.2416321e-02 -1.6281577e-02 -9.2846630e-03
 -2.0556808e-03 -1.9757198e-02 -1.5184973e-02  5.3434696e-02
 -7.2341752e-03 -1.9064069e-02  4.7153193e-03  6.7317626e-03
  1.6003432e-02 -2.4330691e-02 -2.1319838e-02 -1.4373516e-02
  2.0617418e-02 -4.0496476e-03  1.2177958e-02 -2.7097352e-02
 -1.9482650e-02 -1.0585373e-01 -6.6596307e-03  3.4902304e-02
  1.2592906e-02  2.4676731e-02  3.8302809e-03  1.1744816e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_19/gamma
[0.9908619  1.0425785  1.02539    1.045753   0.9954501  0.9883447
 1.0485586  1.0257086  0.9824033  1.05658    1.1039356  1.0180119
 0.97000647 0.98320305 1.0303109  0.9933497  0.9843487  0.96624386
 0.9910184  1.0103716  1.0482014  1.0319554  1.0001925  1.0472677
 0.99002594 0.9805487  0.976132   0.9727905  0.9868275  0.98160434
 0.9768736  1.0040225  1.0184773  1.0353917  0.97357315 1.021125
 0.99679214 0.9863492  0.97261584 1.0069993  1.0657218  1.0049994
 1.0155679  1.0143251  0.9762494  0.9951467  0.97964823 0.98870087
 0.99606705 0.998786   0.9910759  1.0281442  1.0098417  1.0141847
 1.0203199  1.069363   0.9895363  1.0218781  0.96114796 0.98381805
 1.0567515  0.96166265 1.0168012  1.0022049  1.0034242  1.119018
 1.0087395  1.0045763  1.001982   1.0684099  1.0039768  0.98481256
 0.9996066  0.9836306  0.99541783 0.996719   1.0031731  0.9859718
 1.0031393  1.0257132  1.0047767  1.0157846  1.0199865  0.9701181
 0.9589753  0.964773   1.0061078  0.98835236 0.97551644 0.96957105
 1.0081176  0.9794205  0.9896451  0.97619766 1.025299   0.98197407
 1.0411882  0.9988545  0.98817486 1.0065113  0.98631734 1.012289
 0.9899812  1.0052532  1.0214422  1.0583259  1.0168033  0.9804171
 1.0648088  0.9792885  1.0096747  0.9952218  1.0518154  1.0036707
 1.0112988  0.97781765 0.99134785 1.0379469  1.0063285  0.9994375
 1.0027629  0.9971681  1.0443599  1.0124267  1.0008404  0.98873115
 0.9836342  1.0157614  0.9739474  1.0305086  0.9956645  1.0053451
 1.0066321  1.0087957  0.9599169  0.99808455 0.9853677  0.97569686
 0.9834661  1.0592707  0.979832   0.98680943 1.0035572  0.9629944
 0.9841956  0.9940162  1.015149   0.98060393 1.0287833  1.0270984
 0.9785822  1.0216414  0.9759385  1.3106484  0.97227633 0.98633295
 0.9701128  0.9798423  0.9365866  0.9683965 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_2/beta
[-1.88009217e-02  1.06709879e-02  6.53587654e-03  2.27600094e-02
  6.84464956e-03 -2.00874619e-02 -2.17923522e-02 -1.13005862e-02
 -8.11436796e-04 -1.34017142e-02 -2.15553096e-03  3.14735174e-02
  5.17470250e-03 -2.35088598e-02 -2.01633312e-02 -7.84826523e-04
  8.79705139e-03 -2.06564041e-03  7.43661309e-03  9.28258756e-04
 -1.13604008e-03  1.71027295e-02 -3.95426154e-02 -2.57615261e-02
 -2.75126677e-02 -1.26278233e-02 -1.02901645e-02 -8.82543158e-03
 -2.47220229e-02  1.11907814e-02 -1.85760634e-03 -1.92221592e-03
  1.15303532e-03 -1.55565911e-04 -3.83601412e-02  2.11748108e-02
 -7.51384359e-04 -1.65444780e-02  8.50936305e-03 -6.36439724e-03
 -1.09686190e-02  2.84468308e-02 -3.94636241e-04  7.51624117e-04
  1.30959451e-02 -4.03633974e-02  5.87463565e-03  2.00119503e-02
  1.29545778e-02 -2.84201857e-02  1.27070118e-02 -4.04824875e-03
 -1.99907627e-02  2.07467750e-02 -3.11609842e-02  9.73721128e-03
  1.63736064e-02 -4.48745955e-03  3.64218303e-03  2.29413155e-03
  2.97336858e-02  1.41127110e-02  1.22567313e-02  1.67650487e-02
 -1.34965265e-02  2.95739691e-03  1.89623963e-02  1.18424771e-02
 -1.96950361e-02  2.36424676e-05  2.28452403e-02  2.54369667e-03
 -7.59037724e-03 -7.81175448e-03 -6.90247724e-03 -2.52839811e-02
  4.66010794e-02  2.83442046e-02  5.26814312e-02 -2.22032275e-02
  5.20507945e-03 -1.09104859e-02 -2.09000316e-02  2.59375270e-03
 -2.29354072e-02 -3.83821279e-02  9.29591432e-03 -3.50701041e-03
  1.87345631e-02 -2.01662313e-02  2.31809728e-02 -4.00859490e-03
  8.73149186e-03 -3.82285044e-02  4.12111729e-03 -7.19838869e-03
 -3.71229649e-02 -1.93248261e-02 -2.58538872e-02  4.18130383e-02
  1.25923194e-02 -3.51442344e-04  7.34474510e-04  1.36709586e-03
 -9.10435151e-03  8.84277187e-03 -1.02490671e-02 -7.55206589e-03
 -1.18565150e-02  4.85714488e-02  1.92146990e-02  9.63838480e-04
  2.32644621e-02 -2.51428429e-02  4.06540893e-02 -2.76427418e-02
  2.96935719e-02 -4.64962609e-02 -3.57284620e-02  7.12655578e-03
 -1.42321959e-02  1.91921054e-03  2.84934770e-02 -2.49626283e-02
 -9.59538389e-03 -5.26591251e-03  1.03836479e-02 -1.59703486e-03
  3.58716659e-02  1.68546091e-03 -4.57159951e-02 -1.44560505e-02
  2.07402576e-02  7.29554985e-03  3.81548479e-02 -3.50577943e-03
  1.23340962e-02  2.70751826e-02  1.60823576e-02 -6.02640212e-03
 -8.00910313e-03 -4.76307375e-03  3.18903439e-02  2.27417573e-02
 -2.39266399e-02 -2.60904361e-03 -1.91150811e-02 -1.10994643e-02
 -2.33127605e-02 -2.64938135e-04  7.03951716e-03  2.77201477e-02
 -2.48877518e-02 -3.66607420e-02  4.00043605e-03 -3.25693041e-02
  4.62843552e-02 -4.25192900e-02  1.97279528e-02  3.41276750e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_2/gamma
[0.9874915  1.0009704  0.99184114 0.99428093 0.99218506 0.98906493
 0.97527117 0.9671422  0.9741574  0.9767666  0.99897    1.0013717
 0.98378485 0.984794   0.9970318  0.96468955 0.9827142  0.979025
 0.9901847  0.97837514 0.9946874  0.99123144 0.986715   0.94083583
 0.959728   0.9609034  0.98245966 0.9977425  0.98749185 0.9568991
 0.9954934  0.97476244 0.98957396 0.9895329  1.0005131  0.9917534
 0.98542976 0.9998622  0.9951456  0.93247354 0.99778855 1.0038992
 0.9918322  0.95320535 0.9843996  0.9817796  1.0031351  0.99363756
 0.97850347 0.9945706  0.9907838  0.99429464 0.94695514 0.9920444
 0.9780461  0.9745122  0.99842596 0.97605413 0.9922106  0.98595417
 0.9934996  0.9806448  0.9670887  0.9845692  1.0034752  0.9772307
 0.9860422  0.9935397  0.97223955 0.96706915 0.99832606 0.9776642
 0.98992574 0.99513936 0.9886654  0.9693169  0.98729986 1.0027846
 1.0086416  0.9735321  0.98818445 0.9415173  0.9916347  0.9793284
 0.9931214  0.97408897 0.96702987 0.983684   0.99523795 0.979778
 0.9860446  0.98352504 0.9916266  0.98982275 1.0003728  0.984949
 0.99371743 0.9860792  1.0224378  1.0098915  0.9898844  0.94898236
 0.9896257  0.98583204 0.98306996 0.96609795 0.9826509  0.9669096
 0.9955488  1.0116723  0.96508193 0.99302375 0.9928232  0.97254324
 1.0073438  0.9790389  1.0280995  0.983404   0.98588187 0.97780305
 0.9938453  0.9942495  0.9908278  0.9999742  0.97182935 0.94563055
 0.9756298  0.93811196 0.9943944  0.98529184 0.98917276 0.9636863
 1.0030143  0.9743499  0.9918348  0.98053116 0.9767448  0.99413013
 0.9912174  0.98851675 0.99665534 0.9872613  1.0293838  0.9861068
 0.97573197 0.98606807 0.9880815  1.0065877  1.0180428  0.94589776
 0.9834782  0.99491644 0.9925575  0.9799589  0.9730381  0.9926679
 0.9821443  0.979651   0.9979567  1.0082117 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_20/beta
[ 2.36162990e-02  6.15366772e-02  1.99227799e-02 -4.91851792e-02
 -3.79890087e-04  2.76090298e-03 -1.85536370e-02 -2.93787867e-02
  2.40799431e-02 -1.63110122e-02 -4.48096953e-02 -3.41735110e-02
 -1.51348356e-02 -2.06627958e-02 -2.72344258e-02  3.71916704e-02
  2.02747639e-02 -6.12550369e-03 -3.99837494e-02  3.19246575e-02
  4.27523367e-02 -3.79545502e-02  2.67174579e-02  2.02842448e-02
  4.63008694e-02 -4.73881401e-02  2.59007122e-02 -2.43070014e-02
  1.90522652e-02 -5.91862621e-03  7.61048030e-03 -2.12629866e-02
  1.45779951e-02 -1.94814615e-02 -6.19461713e-03 -2.48135887e-02
  5.36062988e-03 -1.86053161e-02  2.57958937e-02  2.59659700e-02
 -3.39464135e-02  2.94845738e-02  5.04529104e-02  2.53699757e-02
 -1.32897077e-02  2.61975154e-02 -1.38857188e-02 -3.18435766e-02
 -2.88552009e-02  2.71223132e-02 -2.52468772e-02 -2.24644281e-02
 -1.78047456e-02 -1.76411960e-02 -2.87855454e-02  1.17299564e-01
  2.32350794e-05  1.42257027e-02  7.27469241e-03 -5.59128122e-03
 -2.67157163e-02 -2.41772979e-02  3.43437679e-02  3.80132273e-02
  5.87213710e-02  4.79004495e-02 -5.77946473e-03  2.36943457e-02
  3.56119615e-03 -5.20854406e-02  3.55468020e-02  2.05756668e-02
 -3.65506075e-02  1.04887094e-02 -1.12135541e-02  4.14345460e-03
  3.34583297e-02 -1.13361822e-02 -5.43571310e-03 -6.63798489e-03
  8.29374697e-03 -4.27613519e-02 -3.63821201e-02  3.30928974e-02
 -1.07869888e-02 -1.20209195e-02 -1.68977808e-02 -3.50829517e-03
 -8.25036876e-03  8.34233314e-03  1.36934599e-04 -2.01458335e-02
  2.19011083e-02 -3.58253308e-02 -2.11713072e-02 -1.47122527e-02
  3.90405282e-02 -4.02297974e-02  2.18259171e-02 -5.40942186e-03
 -1.26579907e-02 -1.23234522e-02 -1.92055237e-02  3.09185684e-02
 -2.67343652e-02  3.33619975e-02  2.60884166e-02 -3.48439440e-02
  2.33137850e-02  1.37266619e-02  7.86149641e-04 -1.44714992e-02
  1.48957046e-02 -3.39700766e-02  1.51138345e-04  3.43916267e-02
  5.47611970e-04 -5.95416687e-02  6.66068215e-03  2.21132711e-02
  7.98441656e-03 -1.01348506e-02  5.67992032e-02  4.25736755e-02
  3.71333933e-03  3.20925587e-03  4.13479470e-03  1.01444088e-02
 -2.41391957e-02 -2.79596169e-02  1.82952024e-02  1.19986953e-02
 -3.36594991e-02  4.25885729e-02  8.21724907e-03 -8.33948050e-03
 -4.35636239e-03 -2.14634649e-02 -7.76385004e-03  5.67635037e-02
 -5.17514581e-03 -2.54581459e-02  3.16617102e-03  6.71818806e-03
  1.28100542e-02 -2.28967294e-02 -2.71240454e-02 -7.90923648e-03
  2.47496925e-03 -1.16153155e-02  1.25241186e-02 -2.67594270e-02
 -1.85376387e-02 -1.30316168e-01 -8.15191772e-03  2.30630916e-02
  9.31025390e-03  3.79476808e-02  2.92021083e-04  1.46323452e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_20/gamma
[1.0170919  1.2174149  0.9686296  1.0462852  0.9799572  0.99181104
 0.9992276  0.9976332  0.94242513 1.0524983  1.0740201  0.9412614
 0.98965603 0.9387515  1.0226392  0.9879344  0.9928471  0.9581627
 1.0430657  0.96338284 0.9985019  0.9945931  0.98331237 1.028941
 1.0039498  1.1633322  1.0117612  0.984285   0.9643937  0.9772272
 0.9949039  0.9804972  0.9695019  0.99668056 0.96788263 1.0290822
 0.9672426  1.0134921  0.9933969  1.0010934  1.0853895  1.0485266
 0.9985819  0.9996799  0.93390846 0.9918497  0.95259297 1.0210321
 1.0245578  1.0116309  0.9705406  0.98886627 0.9851199  0.9651876
 1.0036212  1.1870487  1.0540963  1.0535753  1.0386982  0.9701738
 0.8983036  0.9559914  1.0057902  1.015283   1.0237836  1.0596684
 0.9203486  0.9689278  0.94884837 1.1470796  1.0001683  0.9960003
 1.0110191  0.9441634  0.99154574 0.9706972  0.9822311  1.0335715
 0.9946313  1.0076402  1.0494168  1.0643725  0.9768004  1.041052
 1.0184774  0.9740685  0.9942386  0.99510705 0.9770603  1.0319033
 0.9724578  1.0005127  0.950534   1.0220406  0.98820615 0.999816
 1.021506   1.0038782  1.0080134  0.9934109  0.96944433 0.98349714
 0.9766684  1.026825   1.0248559  1.0806416  1.0048103  1.0150656
 1.0123209  0.9860984  0.9767989  0.992556   1.2048588  0.9736133
 0.9941797  1.0412538  1.2063595  1.0107423  0.9205735  1.0133675
 0.9187483  1.0007296  1.0545338  1.0340375  0.98579115 0.96748865
 0.96402514 0.9711798  0.987642   0.9714166  0.97756994 1.0110545
 0.9997218  0.96636236 0.9987593  0.96938795 0.96643436 1.0119494
 0.99236256 1.0688509  0.9644596  1.0149561  0.9999517  1.0033947
 0.98669446 0.99713993 0.9977867  0.99059427 1.1007314  1.034825
 0.98465985 0.9807176  0.9811518  1.192093   1.0016618  1.0094541
 0.97614515 0.96925706 0.96017545 0.9939906 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_21/beta
[ 0.02803669  0.06703978  0.01686484 -0.05492742 -0.00386735  0.0065454
 -0.01508479 -0.02727785  0.02566405 -0.02005249 -0.0528698  -0.03070124
 -0.01168654 -0.02741462 -0.02430385  0.03257276  0.0198619  -0.01033605
 -0.0431902   0.02896731  0.03889786 -0.03654656  0.03161144  0.02369988
  0.04355596 -0.04860202  0.02942553 -0.03028454  0.0128687  -0.00211908
  0.01202128 -0.01547955  0.00998603 -0.02111927 -0.00719724 -0.02928277
  0.00520495 -0.01765921  0.02125076  0.02965371 -0.04291137  0.03174955
  0.06067865  0.02386684 -0.01352025  0.02817162 -0.01048765 -0.03334861
 -0.03450928  0.02323855 -0.02251298 -0.01883682 -0.01299989 -0.01594836
 -0.02846497  0.1163315   0.00184023  0.01890942  0.00954295 -0.01019554
 -0.03126266 -0.02554676  0.03778309  0.03552391  0.05363579  0.05393074
 -0.00307663  0.02990361  0.00034941 -0.05712026  0.03861261  0.02294924
 -0.03306652  0.00861176 -0.01338651 -0.00032162  0.03450276 -0.01170059
 -0.004481   -0.01179644  0.01280606 -0.04308738 -0.0414554   0.03188454
 -0.00834507 -0.00968343 -0.0121441  -0.00587555 -0.01247093  0.00663884
  0.00356548 -0.01914754  0.02697154 -0.03987392 -0.01650248 -0.02072299
  0.04447334 -0.03616423  0.02542708 -0.00654016 -0.01412803 -0.007266
 -0.01772715  0.03123155 -0.03264805  0.03466948  0.02847456 -0.0368983
  0.02856982  0.01230094 -0.00232262 -0.00965429  0.01562251 -0.02919133
  0.00268058  0.03899917  0.00677958 -0.05837208  0.00042092  0.01833081
  0.00401676 -0.00669541  0.05236902  0.03909399  0.00086442  0.0017777
  0.00312497  0.00609821 -0.02011296 -0.0236316   0.01562749  0.00634921
 -0.02711556  0.04139639  0.00156883 -0.00922653 -0.00133689 -0.02644081
 -0.01040245  0.05291836 -0.00212157 -0.01859135 -0.0022833   0.00944396
  0.01790815 -0.02314079 -0.01902626 -0.01310313  0.00573541 -0.0173423
  0.01736266 -0.02193841 -0.0212323  -0.12769145 -0.00434527  0.0250863
  0.01240819  0.03247036  0.00242453  0.01676943]
tensor_name:  TemporalFusionTransformer/layer_normalization_21/gamma
[0.98764044 1.0235018  0.9624938  1.0284605  0.9935916  0.9490501
 0.9922709  0.9743935  0.9860448  1.2912518  0.9989865  1.0342274
 0.9786733  1.035706   1.0270152  0.98734283 0.9791632  0.9875147
 1.0162706  1.0118792  1.004726   1.0297638  0.97705054 0.9873035
 1.0339608  0.951143   1.0481635  1.0272973  0.94031686 0.97307837
 0.9785924  1.0013869  0.99526745 1.0177953  0.9996003  0.99080706
 0.9891987  1.0450171  0.98305845 1.1306043  1.0214487  0.9874129
 1.0376363  0.9792552  0.97589535 1.0090911  0.96568185 1.0061976
 1.0270133  0.98957944 0.9928325  0.98582786 1.0479754  0.99089104
 1.0072646  1.1388996  1.0426717  0.9993462  1.0017599  0.99059635
 1.0050216  0.9776537  1.0143479  0.99744886 0.98169196 1.1245815
 0.9833248  0.959789   0.9846285  1.0220742  1.0453544  0.9922634
 1.0184534  0.98581743 0.9605486  0.9845178  1.0091566  0.9708466
 0.9948967  0.9816405  1.0252804  1.003209   1.0131935  1.0214049
 1.0220656  0.9798778  0.9949722  0.969006   0.99842304 0.96885705
 1.224751   1.0010533  1.0064691  1.0182146  1.0004959  0.98669165
 1.0399891  0.96090907 0.97905535 1.0067774  0.9865185  1.0038217
 0.97802985 1.0133384  1.0565213  1.01065    0.958999   1.0050417
 0.9904667  1.0000536  0.95175767 0.9949425  1.0907757  0.9946249
 0.9774518  1.006423   1.0584332  1.0352887  0.9704617  0.9899154
 1.0365825  1.0856534  1.0054414  1.0140027  0.96261185 0.9945534
 0.9874776  0.9954674  1.0071051  0.9599259  0.97002226 0.99625725
 1.0199397  1.0050831  1.0175827  0.99648356 0.9875453  0.9584189
 0.97999877 0.967867   0.99415994 0.9763543  0.9670054  0.9936092
 0.94453806 0.9704295  0.9993788  1.0035586  1.0320944  0.984166
 0.9889883  0.96972317 1.0017928  1.0635122  1.0612168  1.017451
 0.9878837  1.1181277  0.98362005 0.98038286]
tensor_name:  TemporalFusionTransformer/layer_normalization_22/beta
[ 0.02411249  0.0741691   0.0231284  -0.05680475 -0.00444256  0.00096609
 -0.01538294 -0.03050273  0.02388273 -0.00884346 -0.04035815 -0.03861487
 -0.0170033  -0.04210009 -0.02046661  0.03378527  0.01982511 -0.00423066
 -0.04566031  0.03748343  0.0522593  -0.03699837  0.03276437  0.02596524
  0.04448079 -0.04892471  0.02399813 -0.02761221  0.01573594 -0.00078044
  0.00568833 -0.02702563  0.0205427  -0.03235912 -0.0061575  -0.02655151
  0.00734225 -0.01525371  0.02344022  0.03927034 -0.03276292  0.0270307
  0.04537767  0.03903096 -0.01167373  0.02667736 -0.01135333 -0.03530894
 -0.0303473   0.03469556 -0.02919333 -0.02381508 -0.0252476  -0.01536666
 -0.02909813  0.10476677 -0.00480062  0.00357442  0.00870552 -0.00560519
 -0.0259293  -0.0326589   0.03603359  0.03771713  0.05952749  0.04510922
 -0.0102514   0.02455159  0.00339309 -0.05877737  0.03817778  0.02557994
 -0.03670121  0.01162258 -0.00111733  0.00463702  0.02602066 -0.01432314
 -0.0040244  -0.00286105  0.01983411 -0.05342241 -0.04009067  0.02952919
 -0.01946211 -0.0150962  -0.01722598 -0.00491337 -0.01136251  0.00607448
 -0.00318326 -0.01612735  0.02496227 -0.03473449 -0.02901979 -0.0174684
  0.03988054 -0.04102572  0.01833744 -0.00687963 -0.01253226 -0.01638699
 -0.02421649  0.02815489 -0.02512342  0.03694769  0.03147575 -0.03324788
  0.01984131  0.01323987  0.00288388 -0.01351177  0.01939575 -0.0353443
 -0.01045437  0.04352189 -0.00736856 -0.05892037  0.00660917  0.01590875
  0.00745605 -0.00863513  0.05940384  0.04451949  0.00120801 -0.00032882
  0.00669547  0.01229654 -0.01992111 -0.02993529  0.01998048  0.02478734
 -0.02983462  0.03583016 -0.01446091 -0.00944581 -0.00399818 -0.02389154
 -0.00669758  0.06119155 -0.00740371 -0.02518687  0.00392256  0.00404537
  0.01487499 -0.02240655 -0.02838732 -0.01004476 -0.01894236 -0.00640483
  0.01270384 -0.02850474 -0.01640009 -0.121212   -0.00978788  0.03152241
  0.0123101   0.03696766  0.00101454  0.0191075 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_22/gamma
[0.98194903 0.9993885  1.0090513  1.0279635  0.9798193  0.98451424
 0.98292446 1.0046457  1.0338047  0.9908139  1.0351325  1.010438
 0.98533624 1.252267   1.0629176  0.9613163  0.9742609  0.97427267
 1.0609212  0.9933419  1.1302466  1.1696796  0.99201345 0.99156594
 1.0165809  1.0979735  1.051689   1.0311499  1.0008413  0.99042344
 0.9743145  0.98344326 0.9916231  1.0966332  0.97610277 1.0161628
 1.0044072  1.0204238  0.98778665 0.9811182  0.96668494 0.97822994
 0.9806229  1.036271   0.96999186 1.0047276  0.9674595  0.98504764
 1.0010008  1.0407053  0.9824935  1.0022769  1.0112317  1.0022181
 1.0128912  1.1095266  1.0330521  0.999033   1.038997   0.94171953
 1.1953995  1.0400565  1.0032514  1.0559341  1.0022836  1.003002
 0.99334854 0.9529135  0.98913157 0.9991621  1.0329005  1.0271821
 1.0020696  0.9956437  1.0543911  1.0057565  0.9949674  0.99576706
 0.9948245  0.9974325  1.0417529  1.0833726  1.0144962  0.9917709
 0.9936881  0.9958486  0.990803   0.9772326  0.9791944  0.96985716
 1.0128967  1.0615691  0.97871584 1.0237983  1.0042286  0.9933379
 1.0068018  1.0334029  1.017869   1.0986742  0.9979543  1.0183839
 0.99048847 1.0007298  1.1356623  0.9909758  0.9673505  0.99756527
 0.9730013  0.991602   0.9730996  0.97938126 1.0300299  1.0179348
 0.9533647  0.99927336 1.0838797  1.0378338  0.9894164  1.0760831
 0.98301786 1.0290458  1.0264828  1.1029359  0.97107524 0.9807576
 1.0100135  0.9763406  1.0322287  1.0003221  0.973849   0.9837231
 1.0501397  0.9810395  1.2068741  0.9783321  0.99339724 0.98960215
 1.0042984  1.1564851  0.99086535 1.0321357  0.9533033  0.9615261
 0.98852766 0.9922541  1.0259254  0.987148   1.22996    1.027784
 0.9947627  0.97611696 1.0018212  1.2417812  1.0177126  0.9958337
 0.9990402  1.0280449  1.0001255  0.9612684 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_23/beta
[-5.7454244e-03  1.5868928e-01  7.7752620e-03  2.3435683e-03
  1.2965868e-03 -1.5862180e-02  2.1233754e-02  3.5085292e-03
 -1.1965649e-02 -3.3924662e-02  1.1270589e-02 -6.0851574e-03
 -2.6168488e-03  5.4137181e-03  2.9068165e-03 -2.5846608e-02
 -4.0467829e-03  1.1508545e-02  9.7281523e-03  8.7977236e-04
  3.0680049e-02 -1.2015421e-02 -1.4893835e-02 -9.0475352e-03
 -7.9216529e-03  2.9587949e-02  1.0384331e-03  7.1709706e-03
 -3.2646328e-03 -1.2812852e-02 -1.0399969e-02 -8.6945696e-03
  5.1846202e-03 -6.3813352e-03  1.4394280e-02  7.7264220e-03
 -6.7048175e-03 -9.0468358e-03 -5.0495286e-03 -6.6228006e-03
 -3.5790846e-02  1.9215184e-04 -1.6619913e-02 -7.5212971e-04
  4.6783127e-03 -9.2486413e-03  3.1067992e-03  7.7422159e-03
  2.2701509e-03  2.2791641e-02 -6.2084133e-03 -5.0100922e-03
 -6.7096953e-03 -7.8557059e-03 -7.8648394e-03  1.5096807e-01
 -1.3741252e-03  6.2031555e-03  1.1559696e-03  2.6083377e-03
  6.2993551e-03  5.6030685e-03 -1.6760400e-02 -1.2568471e-03
 -3.0279731e-02 -1.3473467e-02 -3.8120789e-03 -1.2785185e-02
  1.1268206e-02 -4.6968110e-02  3.6317814e-02 -5.4245922e-03
 -4.3016784e-03  1.3279987e-02  1.5295072e-03  7.2822911e-03
 -1.1519386e-02 -2.1020896e-03  1.9161716e-03  1.0334366e-02
  3.2629598e-02  2.2733954e-03  1.2313203e-02  4.0182881e-03
  6.6726203e-03 -2.5757831e-03 -1.1070355e-02  8.3341384e-03
 -9.3754176e-03  4.2750663e-03 -1.0562535e-02 -6.9928942e-03
 -1.2483165e-02  3.2778399e-03 -1.1536719e-02  1.1209369e-03
 -1.1213577e-02 -9.1813365e-03 -8.6864242e-03 -6.7679295e-03
  6.0186572e-03 -5.8679860e-03  2.5507370e-02  1.1219532e-02
  1.1591507e-02  1.2312975e-02 -9.2509501e-03  1.7573753e-02
 -1.4752295e-02  4.6576108e-03  7.0187151e-03  3.6461707e-02
 -4.1462784e-03  2.3726234e-03 -1.7137622e-02  3.1374861e-02
  2.0875983e-02  1.8034410e-02  5.2340291e-03 -4.5238186e-02
  5.6272227e-04 -6.4199409e-03  4.3735527e-03 -3.5821111e-03
  1.5904188e-02  3.5238074e-05  2.9149246e-03  9.7963279e-03
  1.0580373e-03  5.3431024e-03  4.3618367e-03  1.2191320e-02
 -4.2832973e-03 -6.0276955e-02  1.3325061e-03  6.0835262e-03
 -4.5521697e-03  4.5127617e-03  8.5425731e-03  1.8297200e-03
 -3.7622936e-02 -3.1413594e-03  6.9856811e-03 -6.1889966e-03
 -5.3810226e-03  1.0912849e-02 -1.0778518e-02  1.4223721e-02
  1.2365565e-02  1.3899871e-02  7.3811942e-04 -6.8239262e-03
  6.2955990e-03 -1.5986006e-01 -8.2394341e-03 -7.8137318e-04
 -1.2732602e-02 -4.9471473e-03  4.2665238e-03 -8.0351839e-03]
tensor_name:  TemporalFusionTransformer/layer_normalization_23/gamma
[1.008722   1.2670482  0.9752692  0.9553335  0.9321213  1.032667
 0.9715591  0.947714   0.97675306 0.9897014  0.9031834  0.97144264
 0.9147604  0.9522397  0.9526287  1.0086735  0.8762827  0.9659238
 0.99391377 0.88455504 0.9895663  0.9982696  0.959431   0.9567366
 0.9659946  0.96919197 0.94805366 0.9391965  1.0325816  0.9744635
 0.9142378  0.9739599  0.99537826 0.95651746 0.9427708  0.9750054
 0.9528446  0.9822007  0.9664601  0.9606646  1.0321603  0.91655695
 0.9845201  0.98193145 0.94669497 0.93474984 0.98346204 0.921258
 0.96454024 1.0486764  0.97213113 0.97402424 0.9874669  0.92832816
 0.93377304 1.1509764  0.9352257  1.0583959  0.9579053  0.9832373
 0.89941454 0.95430017 1.0032275  0.97221977 0.97475666 0.92234355
 0.97227836 0.9492538  0.9657617  1.0858276  0.99145055 0.9585592
 0.96126217 0.96223974 0.9954818  0.981585   0.83391505 0.91565144
 0.9662021  0.9899064  1.0195458  0.9664218  0.97221154 0.8814076
 0.9902145  0.9599622  0.96509653 0.9444114  0.9808168  0.9469646
 1.0101674  0.9158336  0.97229886 0.95487165 1.0027567  0.99961114
 0.94011444 0.987756   0.92447305 0.9279932  0.98208374 0.98484707
 0.969134   0.8990729  0.9891859  1.1401817  0.88806146 0.9706902
 1.0326523  0.931802   1.0242643  1.0101464  1.0029384  0.9767766
 1.0138811  1.0093316  1.2351862  0.9837253  1.0141827  1.0690649
 1.0301049  0.9606777  0.9571564  0.9615746  0.9980226  0.9500568
 0.95454174 0.96108073 0.9478905  1.0185269  0.98194075 0.9836795
 0.9679532  1.0321473  0.9292109  0.9564841  0.9572955  0.9617996
 0.94897026 0.99854296 1.0077971  0.9883053  1.0281845  0.971285
 0.97820175 0.95949763 1.0231528  1.009324   1.0679346  0.89146674
 0.98504347 1.0325325  0.92081714 1.1570688  0.9445756  0.9779455
 0.9621105  1.0253345  0.9728104  0.9713115 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_24/beta
[ 0.01904651  0.00807427 -0.01002324 -0.00094363 -0.00705645  0.0153107
 -0.00381991  0.01273046 -0.02317832 -0.01063305 -0.0027848   0.00103411
 -0.00877798  0.02440514  0.00323224  0.00441625 -0.0304671   0.01976853
  0.01508643  0.00445073  0.01138558  0.00304218 -0.00519276 -0.02232267
 -0.00959258 -0.01562983 -0.01489564  0.00186361 -0.01327758 -0.00381207
 -0.01537755 -0.01858123 -0.00056508 -0.00437498 -0.00289315 -0.00485936
  0.00178678 -0.00929552  0.00657896  0.0084919   0.03564186  0.00387589
 -0.02149796 -0.01068538  0.00696824  0.02578318  0.02908356 -0.00324624
  0.00902056  0.00252778 -0.00654273  0.0082156   0.00542749 -0.00554466
 -0.01668094 -0.00750065 -0.01845648 -0.02463876 -0.01568578  0.00496532
 -0.00356617  0.01848162 -0.02407833  0.02849891 -0.00017392 -0.01127771
  0.02524417 -0.01379411  0.00791661 -0.01467843 -0.03506705 -0.01586168
  0.02238174 -0.00219166  0.00278364  0.01015798 -0.01250338 -0.00785528
 -0.00313132  0.00082148  0.00850934  0.02872819  0.0003256  -0.01668019
 -0.00545831 -0.00121709  0.00939082  0.00916776 -0.01350046 -0.01351639
  0.02204413  0.01061475 -0.00551705  0.00498091 -0.01770079  0.00733639
  0.01096904 -0.00417771 -0.00085805  0.00306287  0.02624284 -0.00109205
  0.01738142 -0.00285768 -0.00500875 -0.00207645  0.00431583 -0.02699497
  0.01377357 -0.00616446  0.01976011  0.00793674  0.00182465  0.00457116
 -0.00787487  0.01393805 -0.01014777  0.00789823  0.00272183 -0.02636752
  0.03465325 -0.00506706  0.00860866  0.00793866  0.02695323 -0.00974494
 -0.00213562  0.0005581   0.01543331 -0.01419415  0.00773151  0.01298593
  0.04534175  0.00791877 -0.00236781 -0.00010471  0.00626545 -0.00554819
  0.00869008 -0.00256919  0.00703662  0.0182728   0.01097916 -0.00850709
  0.01325851 -0.00479719 -0.00721579  0.04875199 -0.03062139  0.02098257
  0.00553938 -0.02400348  0.00220868  0.04232224 -0.00115212 -0.00055388
 -0.02777468  0.01027438  0.02832505 -0.02028084]
tensor_name:  TemporalFusionTransformer/layer_normalization_24/gamma
[0.94812685 0.9051587  1.0219768  0.9908603  0.95842576 0.9769566
 0.9987003  0.9605516  0.99491215 1.0119644  0.9705994  0.9788849
 0.97797424 1.0069941  0.96459895 1.017378   1.0330361  0.9888352
 1.0082924  1.0350941  0.9843061  1.0099446  0.99026567 0.98179924
 1.0325317  0.9756506  0.99914604 0.99229974 0.98377377 0.9882544
 1.0020089  0.99817085 1.0097045  1.000218   0.9812257  0.9853134
 0.9742993  1.0115806  1.0044799  0.9769097  0.9990087  0.9880657
 0.99260896 0.9956209  1.005797   0.98895085 0.99663705 0.99081373
 0.9644003  1.0047346  0.9793507  0.9952802  0.94227785 0.9861574
 0.9902807  0.9850392  0.97232926 0.97988564 0.97344023 0.99775624
 0.97629744 1.0216496  1.0475708  0.9661912  1.0049466  0.9852423
 0.9704732  1.0201436  0.98078054 0.96090174 0.949649   0.9959789
 0.9822428  0.9840276  0.93977547 1.0208478  0.9921234  0.98075086
 0.9826813  0.96938515 1.0137507  0.99014133 0.9888513  1.0149691
 0.96538484 0.9745213  0.99771965 0.96450907 0.98868454 0.9664848
 0.98602456 0.97306854 0.97997    0.9533819  1.0113243  0.99107754
 1.0161688  0.9868516  0.96873933 0.9847039  0.97963756 1.0380975
 0.9462212  0.9917349  1.0069202  0.9840271  0.983287   0.9849743
 0.9723282  0.9855804  0.9873966  1.0027624  1.0248289  0.97405016
 1.0507846  1.0005038  0.9527785  0.9689042  0.9783575  0.99510634
 0.9857573  0.9872761  0.99641806 0.98478574 1.0376548  0.99061984
 0.96474266 0.9777347  0.95048857 0.97644305 0.98767966 1.0352098
 0.9577341  0.98063445 0.94259596 0.9915912  1.0090585  1.0072087
 1.0149744  1.0098581  0.9981862  1.0068206  0.9919146  0.98353785
 0.97520703 0.92511535 1.0161536  0.9951172  1.0647457  0.9768556
 0.9985702  0.96146494 1.0117908  0.8908807  0.96640074 0.99427193
 1.0207164  0.99983954 0.9840827  0.99537635]
tensor_name:  TemporalFusionTransformer/layer_normalization_25/beta
[ 4.23831232e-02  2.10256856e-02  6.80486299e-03 -2.40568984e-02
 -4.69263159e-02  6.18365705e-02  5.09677529e-02 -1.27303265e-02
 -5.27275130e-02 -9.23835541e-05 -3.55087444e-02  1.53032094e-02
  1.63558256e-02  8.41191411e-03  2.12014979e-03  2.86945943e-02
 -8.89664292e-02  3.84821892e-02 -6.10902626e-03 -2.78118113e-03
  4.78495769e-02  1.92690399e-02  1.34838198e-03 -2.74849478e-02
 -2.57340446e-02 -6.35985285e-03 -2.75803562e-02 -6.22006832e-04
 -4.46746647e-02 -1.45848999e-02 -4.19968180e-02 -2.86536328e-02
  5.88006154e-03 -2.49805078e-02 -2.22077221e-02  8.01571831e-03
  3.19671221e-02  2.59378999e-02  3.71203199e-02  4.86922860e-02
  6.07630685e-02 -1.67063233e-02 -2.30573155e-02  1.54905329e-02
 -3.18128895e-03  1.13418535e-03  1.25604970e-02 -7.61295483e-03
  1.55173510e-03 -2.76596062e-02 -2.85653472e-02 -5.46345534e-03
  1.59698017e-02 -2.31664572e-02 -4.51691225e-02 -2.91344412e-02
 -7.06967264e-02 -3.35512273e-02 -2.76092975e-03 -1.37441577e-02
 -4.97057801e-03  6.23760968e-02 -4.42535207e-02  2.54859347e-02
 -2.25970037e-02 -4.44518253e-02  6.55846298e-02 -8.07884894e-03
 -8.24979413e-03 -2.96091922e-02 -9.68328677e-03 -4.03007716e-02
 -1.52702145e-02 -2.17192397e-02  3.12306508e-02  2.03154944e-02
 -2.25448459e-02  1.35641871e-03  4.75980854e-03  4.34665345e-02
  2.98437588e-02  3.45954038e-02 -1.32119739e-02 -6.18904084e-02
  1.40470604e-03  1.32907983e-02 -3.99962999e-03  2.25244872e-02
  3.25382361e-03 -6.22228682e-02  3.05883996e-02  4.01608832e-02
 -2.10407302e-02 -1.68232303e-02 -1.46765420e-02 -1.65444259e-02
  1.72812585e-02 -8.45240615e-03  2.04838254e-02 -7.33284140e-03
  4.00136858e-02 -2.78271027e-02  8.52618292e-02  2.76098978e-02
 -5.66842854e-02  4.04695570e-02 -7.80623173e-03 -2.46863961e-02
  1.34401890e-02 -9.46196914e-03  6.45218883e-03  6.25982359e-02
  8.59863707e-04  5.12335636e-03 -3.17422822e-02  4.66529354e-02
  2.79205404e-02  3.38610895e-02  8.24389886e-03 -3.93178873e-02
  2.25093514e-02 -1.78486500e-02 -3.94263212e-03  2.80709229e-02
  4.66355048e-02 -5.10890642e-03 -2.53391964e-03  1.62236660e-03
  1.25661083e-02 -3.17262895e-02  3.19563523e-02  1.72692984e-02
  5.79979271e-02 -1.23006785e-02  5.42695224e-02 -7.77233159e-03
  1.45858694e-02 -1.57622397e-02 -1.64824650e-02 -3.74338292e-02
 -9.14675836e-03  3.71456030e-03  5.45472689e-02 -4.64871861e-02
  2.79381201e-02  4.56674360e-02 -5.54960454e-03  5.02858385e-02
 -1.28180245e-02  7.91071057e-02 -5.82576264e-03  2.34928429e-02
 -1.94258094e-02 -6.73055323e-03  9.96378902e-03  4.58327006e-04
 -3.73319909e-02 -1.19232731e-02 -3.29322070e-02 -1.49796335e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_25/gamma
[1.0047268  0.9590885  0.974163   0.97226435 0.9972573  1.0131282
 1.0252842  0.96932393 1.0540955  0.9690302  0.97694194 1.0060245
 0.9939614  0.9982389  0.99852234 0.9724622  1.0910039  0.9812081
 0.972203   1.016898   1.0161039  1.012311   1.0006753  0.97470945
 1.001425   0.9954329  0.9978108  0.9938862  0.99825877 0.98678637
 0.9777392  1.0131824  0.99036825 1.0073591  1.0011468  0.98797953
 0.98597395 0.96126926 0.99346143 0.99320745 0.98086476 1.0010666
 1.0040417  0.9626376  0.9956855  0.954763   1.0099914  0.97004724
 0.9856226  1.0282209  0.99416834 0.9829119  0.9734724  0.99539715
 0.98190695 0.9696716  1.0603353  0.9964804  0.97148913 0.9726298
 0.9985968  0.9388098  1.0060787  1.0181863  1.016551   1.0151463
 1.0422022  0.97265124 0.9477234  0.96545094 0.9611403  0.9943378
 1.0057446  0.9881095  1.0127246  0.9966577  0.9872927  0.9884553
 1.0054809  0.9916322  0.990065   0.9739035  0.96760416 1.0179402
 0.995928   0.9667915  0.98790646 1.016689   0.98713595 1.0161684
 0.9682252  1.0113838  1.0070813  0.9424382  0.99385375 0.9666217
 0.9842346  0.9796282  0.9574875  0.9975857  1.0289904  0.97656566
 1.0459706  0.9897175  1.0287851  1.0258701  0.96999294 0.9728818
 0.96868247 0.99736094 0.9975731  1.0056282  0.98518753 1.0000803
 0.9823792  1.0286403  1.0231988  0.9762676  0.9992379  1.0152347
 0.9910807  0.9816993  0.9921525  0.96111625 0.9489197  0.9750343
 0.96739817 0.9917068  1.0087608  1.0272951  1.0129689  0.982766
 1.0364366  0.9987496  1.0208765  0.9963673  0.9748955  1.0247883
 0.9824212  0.9762468  1.0164598  0.9786964  1.0518166  1.0074111
 0.97581893 1.0293516  0.96615726 1.032604   0.958969   1.0148804
 0.9769616  0.99710685 0.99264514 0.98816884 0.9666816  0.9804861
 1.0543367  0.99373686 0.98121285 0.9903645 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_26/beta
[ 0.06443987  0.02882717  0.03423529 -0.05198516 -0.06186705  0.03073116
  0.05755487  0.01565796 -0.04808867 -0.0267749  -0.07861868  0.0122365
  0.05305891 -0.02428865  0.01144775  0.0098267  -0.09482878  0.05613005
 -0.02878658 -0.02704214  0.01091492  0.01892815 -0.00950318 -0.01229227
 -0.0487937   0.01189396 -0.02910685  0.04364081 -0.02082712 -0.03311666
 -0.01536082 -0.05517581  0.01805134 -0.05323812 -0.055648    0.02245861
  0.03475904  0.06756021  0.05668603  0.06857224  0.03273829 -0.03180054
 -0.01380211  0.00051634  0.05595417 -0.00058083  0.01954377 -0.06244381
 -0.00421012 -0.03503413 -0.04235831 -0.04441916 -0.00792323 -0.10021839
 -0.05684013 -0.02445821 -0.04879136 -0.04696085  0.0222079  -0.00528592
  0.01167151  0.02150842 -0.07479028  0.03493481 -0.02157668 -0.07312515
  0.09717656  0.03591205 -0.04504931 -0.04265293  0.02278046 -0.06161346
 -0.08015639 -0.04941107  0.08175019  0.00391933 -0.01923052  0.00199061
 -0.02437398  0.07405317  0.05888074 -0.00372632 -0.03953817 -0.05217456
 -0.0115378   0.04729141 -0.03803629  0.03443259  0.03024905 -0.0586511
  0.02400099  0.08430408  0.00104113 -0.03306736  0.01945116 -0.0312513
  0.01616255 -0.04472888 -0.00748719 -0.07186562  0.06430851 -0.05236267
  0.05076353  0.03847326 -0.05678965  0.0390088  -0.00518907 -0.04625347
 -0.03060162 -0.0181528  -0.00114629  0.07919908  0.01614861  0.00776421
 -0.00314683  0.05933871  0.06912562  0.06048771  0.04865682 -0.06917674
  0.01569523 -0.01027775  0.03189711  0.05874648  0.01925362 -0.01938475
 -0.02960756 -0.04187275  0.04832897 -0.0647558   0.05647508  0.03578493
  0.0872421  -0.02122991  0.05989923 -0.01991802  0.02446153 -0.0562515
 -0.03356975 -0.0525789  -0.00862899  0.00410348  0.05385475 -0.07079003
  0.05384102  0.08639998 -0.00539386  0.04275801  0.00895626  0.07590757
 -0.08706547  0.00568997 -0.0721758   0.02121302  0.0312731   0.04332453
 -0.0266335   0.0041441  -0.05286738 -0.02921713]
tensor_name:  TemporalFusionTransformer/layer_normalization_26/gamma
[1.0096197  0.95472866 0.9729436  0.9624889  0.9634561  1.0039661
 1.0120797  0.9779335  0.99972993 0.9774362  1.0407175  1.0214471
 0.99248135 1.0905728  1.0293788  0.9678024  1.0497533  0.9715585
 0.9828293  1.0619125  0.9779794  0.9890486  0.9867535  0.99272317
 0.9975879  1.0006568  0.99696505 1.0044148  0.98395306 1.0079197
 0.96997523 1.0108982  0.9930955  1.0077785  0.99163634 1.003089
 0.9861889  1.0016389  1.0340127  0.9689008  0.974528   1.0461814
 1.0286763  0.9854344  1.023331   0.9659248  0.9932215  1.0174813
 0.96100724 1.0899959  0.99398875 0.980755   0.98414433 1.0747955
 1.0806135  0.97022974 0.9982238  0.9825089  0.9749993  1.0120755
 1.0205791  0.95779663 1.0326831  1.0248891  1.0053722  0.9910168
 0.999007   0.988763   0.9654517  1.0286714  1.0857673  0.98556745
 1.0734767  0.98645437 1.0673459  1.0028206  0.99312276 0.9815089
 0.9817082  1.0036986  0.97270596 0.978548   0.9822761  1.0338185
 0.9974101  0.97356814 0.98650515 1.0540264  0.97565895 0.9839123
 0.96533716 1.0375923  1.0050778  1.0198225  1.0201298  1.0263529
 0.9830434  1.0463873  0.9627384  1.0332506  0.9942848  1.0021037
 1.0053117  0.9781818  1.0147092  1.0056711  0.9475937  1.0394007
 0.98354185 1.0312488  0.98860955 0.980439   1.022605   0.9991853
 0.9826523  0.9839307  1.0445385  0.99195296 1.0085773  1.0234222
 1.0063858  1.0085374  0.98410195 0.98236233 0.9617146  0.9905081
 0.99301434 0.9812996  1.0277872  1.0231048  1.0163342  0.97394323
 1.0404463  0.993005   1.0096952  0.97961414 0.986144   1.006711
 0.99602205 0.967342   1.0290549  0.9667582  1.008161   1.0647095
 0.9639062  1.0413094  1.0189663  1.0568775  0.96155536 1.0168611
 1.0444014  0.97778636 1.0556116  0.99147874 1.0628366  0.9766804
 1.1375374  1.0080153  0.9766756  1.0442692 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_27/beta
[-0.01289565 -0.02454067 -0.00715839  0.02842199  0.00305488 -0.008221
  0.00069287  0.01298202 -0.00960381  0.00936815  0.02530265  0.01040178
  0.0054521   0.02370753  0.00375008 -0.00322403 -0.01139095  0.00508008
  0.02625654 -0.01104484 -0.03584284  0.00499895 -0.01902626 -0.02162527
 -0.00847995  0.01705736 -0.0057684   0.0214008   0.00444059 -0.00694138
 -0.00739701  0.01350631 -0.00029867  0.02157423 -0.00086564  0.01907924
 -0.00459988 -0.0007927  -0.0070464  -0.0204622   0.03048027 -0.0087663
 -0.02228332 -0.01678389  0.00070509 -0.01293191 -0.0033454   0.00942496
  0.01620193 -0.0010489   0.01069555  0.00803451  0.00077105 -0.00166229
  0.00651523 -0.03498545  0.00420136 -0.00946353 -0.00292373  0.00364216
  0.00868347  0.01227743 -0.01650133 -0.01604146 -0.01365282 -0.01996538
 -0.00053687 -0.0180502   0.00612489  0.01273839 -0.02985222 -0.01297317
  0.01008164 -0.00741378  0.00354907  0.0021855  -0.01606333 -0.00146018
  0.0051625   0.00784517 -0.01401507  0.02219787  0.02070445 -0.01214461
  0.01491007  0.00180885  0.00395052  0.00707043  0.00864965 -0.004628
 -0.00454321  0.00386621 -0.01284447  0.01209707  0.00352107  0.01169696
 -0.01946158  0.01071605 -0.01346527  0.006139    0.01213843 -0.00051491
  0.00338094 -0.01100256  0.01417262 -0.00968334 -0.01593651  0.01079227
 -0.01764655 -0.00258156  0.00701422 -0.00432817 -0.01702561  0.00709415
  0.00254559 -0.02729393 -0.00642613  0.02526656  0.00574716 -0.00406512
  0.00790268  0.00210149 -0.02235233 -0.01313926  0.00420226  0.00020551
 -0.00146791 -0.00343868  0.0017837   0.00700018 -0.00535023 -0.0013273
  0.00311576 -0.01568538  0.02007937  0.00462389 -0.0045922   0.00831461
  0.00408595 -0.01634538  0.00474434 -0.00203927  0.00946552 -0.00565532
 -0.01129474  0.00635024 -0.00663296  0.01018083 -0.02389465  0.00677745
 -0.0036103  -0.00765801  0.00208247  0.07738962  0.0025265  -0.02354121
 -0.00453967  0.00436034  0.00349282 -0.00727886]
tensor_name:  TemporalFusionTransformer/layer_normalization_27/gamma
[1.0030155  0.9621666  0.94522536 0.9369583  0.9458675  0.98171186
 0.9684742  0.94561505 0.97752273 0.9121273  0.9112922  0.9596468
 0.9145776  0.92735535 0.9423818  1.0020105  0.89854    0.9317346
 0.95048904 0.9448975  0.9490214  0.9459392  0.9563881  0.93866193
 0.9616376  0.94292885 0.92647916 0.92701775 0.98673767 0.9477872
 0.95530653 0.9419036  0.9617636  0.94078505 0.97258866 0.94934034
 0.90821224 0.95246994 0.95494145 0.9731155  0.97192883 0.9295749
 0.95136905 0.94343334 0.9256374  0.913128   0.9623771  0.9373261
 0.96362656 0.92347056 0.95432067 0.9491306  0.9541538  0.91792494
 0.9551321  0.9595862  0.9422277  0.98735636 0.95049417 0.9741805
 0.91148967 0.94514513 0.99247164 0.9596709  0.9738604  0.91755486
 0.9337022  0.9447647  0.94645774 0.9178025  0.9514259  0.9440852
 0.94893634 0.9612275  0.88920635 0.95319986 0.9004043  0.9127382
 0.93593454 0.9315279  0.9623754  0.9143863  0.97980785 0.92101026
 0.95127666 0.9650432  0.95973206 0.9192393  0.95673233 0.92596203
 0.9601127  0.956067   0.9753576  0.9084616  0.9751164  0.98258865
 0.9452344  0.96857244 0.9341208  0.927996   0.9639433  0.9706412
 0.9642361  0.95000726 0.93742096 0.99981815 0.9018473  0.98081166
 0.9768129  0.9349951  0.9769536  0.9914844  0.96824336 0.9706929
 0.91960496 0.98493636 0.9722109  0.98444796 1.0062411  0.9982016
 0.9841781  0.90187144 0.942869   0.95426565 0.93399584 0.9401454
 0.9571999  0.945555   0.92860967 0.9758161  0.9763828  0.9013274
 0.9586814  0.9702219  0.9312515  0.90028095 0.90276617 0.9502374
 0.9414258  0.92562264 0.9668338  0.96388936 0.98721164 0.9675577
 0.9759756  0.9522688  0.9698979  0.97381747 0.907098   0.93754137
 0.9558916  0.9783336  0.93843025 0.9320705  0.9041896  0.95778656
 0.940361   0.9918083  0.9524789  0.88906205]
tensor_name:  TemporalFusionTransformer/layer_normalization_3/beta
[ 1.17629685e-03 -1.85558107e-02  5.72675839e-03  5.70766581e-03
  8.72254744e-03  3.52674979e-03 -4.08610003e-03 -7.27393781e-05
 -2.78918515e-03 -1.92879059e-03  1.55576048e-02 -7.03297462e-03
  4.46735328e-04 -3.56105459e-03 -1.03825619e-02  7.90666137e-03
  1.05688525e-02 -6.86856173e-03  1.99370855e-03  8.55133054e-04
  1.59737356e-02 -1.13890052e-03  5.03208349e-03 -7.05376733e-03
  4.75902716e-03  1.82936452e-02 -6.91381283e-04  7.26266159e-03
 -1.04135713e-02  6.48805220e-03  1.59544460e-02  9.65319853e-03
 -1.81565672e-04  1.23194493e-02  2.71941628e-03 -4.32679849e-03
  4.85450402e-03 -8.44079535e-03  2.08703149e-03  1.64592620e-02
  2.15830505e-02  4.26572934e-03  1.62542448e-03 -9.45386849e-03
  1.03401458e-02  5.50851878e-03  1.74698941e-02  1.20839328e-02
  2.68514268e-03 -5.32660354e-03 -1.04999179e-02 -2.19271127e-02
  1.13023957e-02 -7.40185846e-03  6.65271562e-03  9.29346352e-05
  6.05097879e-03 -6.88589737e-03  5.87936305e-03 -2.81469012e-03
 -4.74565988e-03 -5.46542695e-03 -1.38356048e-03 -1.11877650e-03
  1.60656217e-02 -3.92199261e-04 -3.85824963e-03  2.34410004e-03
 -6.21318631e-03  1.66965096e-04  1.95566053e-03  8.40672106e-03
 -1.11590438e-02  3.36289173e-03 -2.15972285e-03 -1.49796437e-02
  1.28987646e-02 -1.76178273e-02  1.50773628e-03 -4.03441023e-03
  5.30304946e-03  1.03293350e-02 -1.22503918e-02  5.30980527e-03
  8.34056549e-03 -7.98606873e-03 -1.29727125e-02 -2.64748419e-03
  1.53139969e-02  1.22046401e-03 -7.07054371e-03 -7.76630593e-03
  2.80287350e-03  1.04242004e-02  6.17666496e-03  9.76060145e-03
  7.81684835e-03 -5.44828456e-03  5.59435179e-03 -1.20298425e-02
  5.46472706e-03  7.97941990e-04  6.48481725e-03  5.79923508e-04
  1.47665245e-02  3.34818987e-03  7.71370204e-03  1.68145280e-02
  6.00299798e-03 -5.32185426e-03 -3.71716148e-03 -2.24844669e-03
 -8.27304088e-03  4.72239335e-04  3.60516086e-03  1.54031441e-02
  2.62310123e-03 -6.53803069e-03  2.44796113e-03 -7.76752224e-03
  1.24619761e-02 -2.31357710e-03  1.68498256e-03 -3.55383591e-03
  6.33269874e-03 -7.80934095e-03 -1.83254993e-03  6.17838698e-03
  5.33076189e-03 -3.32516385e-03 -2.03802032e-04  1.04963686e-02
  7.77801592e-03  1.22057814e-02 -1.36872353e-02 -1.21961664e-02
  1.81909241e-02 -8.79474264e-03 -3.47694289e-03  5.45856496e-03
  4.86215018e-03  2.73014442e-03 -8.58815014e-03 -1.06218727e-02
  1.03520881e-02  6.41183881e-03  3.29540647e-03  1.46638211e-02
  1.56234112e-02  2.76675797e-03  2.01388411e-02 -3.99345206e-03
 -1.06296092e-02 -1.16019817e-02  4.78035072e-03 -1.21927343e-03
 -7.93324318e-03  5.03564486e-03 -1.89052790e-03 -1.30500458e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_3/gamma
[0.9924494  0.96608245 0.9958117  0.9921023  0.9951314  0.99181235
 0.98303366 0.97532076 0.9794385  0.9839964  0.98709965 0.9838635
 0.98356616 0.9763539  0.98376423 0.97993636 0.9768654  0.993196
 0.9982388  0.97611237 0.99592537 0.98946434 0.99292815 0.97943634
 0.99307305 0.9897896  0.9934697  0.9837991  0.9924704  0.99543655
 0.9914192  0.9956996  0.9828281  0.9578662  0.9850396  0.9929568
 0.9734936  0.99775916 0.97845626 0.9780414  0.962432   0.98645467
 1.003494   0.9702716  0.98790944 0.98053795 0.9819767  0.9922628
 0.99987674 0.9884215  0.9938667  0.9829284  0.98915666 0.97954416
 0.97103965 0.9620125  0.9809774  0.96854585 0.9609549  0.9934121
 0.9738312  0.9952409  0.9911248  0.99619466 0.971092   0.98223984
 0.9791347  0.99638414 0.9787305  0.98581594 0.98678935 0.98420113
 0.9934372  0.9965098  0.9711924  0.9641886  0.98475367 0.99248475
 0.98774445 0.974733   0.9818338  0.9775501  0.9976527  0.9923897
 0.99530464 0.9771134  0.9848719  0.9957032  0.97730905 0.98146236
 0.9996451  0.97532517 0.97377187 0.9804448  0.988608   0.9877523
 0.99806076 0.9954713  0.99746144 0.9723522  0.98697203 0.9770217
 0.9869286  0.9883784  1.0007279  0.99092764 0.98641187 0.98764724
 0.98195416 0.98845    0.9916143  0.9967017  0.99598676 0.9824571
 0.9938147  0.9809013  0.96804774 0.99340415 0.99466527 0.9868673
 0.98922247 0.99848133 0.98149747 0.98927915 0.983792   0.9817063
 0.99864215 0.99666387 0.99033874 0.9920197  0.9935996  0.9922871
 1.0072308  0.9608606  0.9959771  1.0028101  0.9723037  0.98030984
 0.9796931  0.9907685  0.9916643  0.9987703  0.9885676  0.99191743
 0.98901695 0.99131775 0.9929009  0.9891768  0.98384225 0.9823488
 0.98575366 0.99464417 0.992067   0.9881982  0.9851651  0.98392284
 0.9687495  0.9721604  0.991836   0.9804728 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_4/beta
[ 0.00803404 -0.01331645 -0.02797797 -0.01679749 -0.01689788  0.01278934
  0.00522738 -0.00516058  0.01974374  0.00726029 -0.02602616  0.01750259
  0.0112576   0.02138055  0.00036514 -0.01809264  0.01544637 -0.06526471
 -0.01169538  0.0222794   0.06154009  0.01161563  0.00157788  0.06620746
  0.02371777  0.06353687  0.04469179 -0.0138058   0.04656254 -0.022925
 -0.01860368  0.01428332 -0.00213098  0.0627367  -0.02976643  0.00809743
  0.00159958 -0.02240147  0.00650047  0.0473286  -0.00246792 -0.03633484
  0.03098982  0.03516276  0.04124587 -0.01750028  0.02585995  0.00052807
 -0.02798719 -0.04954183  0.0190047   0.02464504 -0.00229997  0.02744018
 -0.00941635  0.02211599  0.02176791  0.03564553  0.02589094  0.04201697
 -0.00776976 -0.00519174 -0.01202077  0.0319715   0.03826862 -0.02853387
  0.04194206 -0.03834342 -0.00276586 -0.02042865 -0.01473852 -0.02345291
  0.01735299  0.03282673  0.03687423  0.02651914 -0.05391251  0.00280333
 -0.01906268 -0.05614711  0.00249593 -0.03309656  0.00373746  0.03037257
  0.01175166  0.03136407  0.00349707  0.06040541  0.01661047  0.0442112
 -0.03730479 -0.00774804  0.00177575  0.06062225 -0.02441708  0.00562656
 -0.03242026 -0.01983007  0.01986822 -0.02055172  0.04230629 -0.03174165
  0.00636638  0.03037852  0.04859294 -0.01760377  0.01735167  0.01252552
 -0.01615673  0.0165184   0.03097272 -0.03730021  0.02578647  0.02906994
  0.03600381 -0.00099225  0.01760182 -0.05903523  0.04552235  0.0349983
  0.02563073  0.01885269  0.05130905  0.0204035   0.04954462 -0.01450633
  0.01894997  0.00864363  0.02129785  0.02537272  0.01695625  0.00591558
 -0.03832138  0.0222039  -0.01307554 -0.01534188 -0.0094432   0.01596284
  0.00855676 -0.06314176 -0.009681    0.02418575 -0.00246426  0.00900032
  0.03569166 -0.01530139  0.00034555 -0.01039034  0.00193274  0.0306905
 -0.00760244 -0.01970146  0.01280917 -0.00873178  0.0606063   0.01495002
  0.02538548 -0.00865015 -0.04151994  0.01597994]
tensor_name:  TemporalFusionTransformer/layer_normalization_4/gamma
[0.97206205 0.9866368  1.0163674  0.9836746  0.99633384 0.9745537
 0.9645028  0.9097245  0.9385343  0.98641336 1.0039431  0.9786075
 0.9788658  0.9780887  0.9823227  0.9942226  0.99557763 1.0582218
 0.96380186 0.9216681  1.0498405  0.981254   0.9633807  0.9926756
 0.9902033  0.92318153 0.950242   0.9809428  1.0003121  0.99142385
 1.0021164  0.98487747 0.9947219  1.0607806  0.97926056 0.98067594
 0.96719205 0.9538754  0.98788095 0.96347106 0.9999261  1.0016137
 0.9906945  0.9786451  1.0351477  0.98653436 0.97691125 0.95521384
 0.99825466 0.9849529  1.0025563  1.0105528  0.967257   1.0221187
 0.9805634  0.9642729  0.98466086 0.94766676 1.0023491  0.9196627
 0.94920814 0.9744863  0.95760494 0.9624902  0.9521653  0.99624497
 0.94469786 1.025927   0.98168343 0.9798202  0.9720114  0.98770916
 0.9738777  0.98646563 0.9585629  0.968594   1.0201428  1.0374775
 0.98579735 1.026589   0.9625305  0.98905385 0.9834575  0.9595231
 1.0019562  0.976878   0.9935166  1.0488578  0.99009305 0.95381796
 1.0077564  0.988741   0.9865664  0.9766498  0.96645886 0.99921554
 1.0074713  1.0147026  0.9837355  0.9839088  1.0161988  1.0168
 0.9921199  1.0196449  1.008582   0.91764367 0.9916916  0.97028077
 1.0050687  0.8377388  0.9778858  1.0073441  0.9288863  1.0085697
 1.0491     0.9586698  0.9883989  1.0285045  1.034523   0.95714617
 1.0089386  0.9838879  1.0554618  0.9520545  0.96571004 0.99393445
 0.9923368  0.9726876  0.9886961  1.0101789  0.9219935  0.978146
 1.0106233  1.0005754  0.98567647 0.9637539  0.97090304 0.971071
 0.9622072  1.0269105  0.9616632  0.9743956  0.968831   0.9755681
 0.95049495 0.99396926 0.96082026 0.99174273 0.9975414  1.019623
 0.98335344 1.021462   0.985863   0.99364537 0.9656483  0.97241634
 0.95456064 0.9919807  0.9883885  0.94753224]
tensor_name:  TemporalFusionTransformer/layer_normalization_5/beta
[-0.01867663  0.10353576 -0.00317168  0.00540087 -0.01121669 -0.00855993
  0.03709668 -0.01075755  0.02397008 -0.00062436 -0.03811304  0.04259992
  0.00488438  0.07810547  0.04094319  0.00353131 -0.02000044  0.02203234
 -0.00061523  0.01478676 -0.04432944  0.0100517  -0.00566185  0.03026875
 -0.00515036  0.02477339 -0.0131594  -0.02799589  0.038046    0.00443859
 -0.05100603  0.01523238 -0.00697809  0.00304219  0.0225847   0.04892603
 -0.01075173  0.03927001  0.01486928 -0.0156236   0.0468699  -0.03409877
 -0.01349823  0.03125265 -0.04738854  0.01720538  0.03889001 -0.01854301
 -0.05202031 -0.0093942  -0.01718423  0.07839937  0.04044357  0.00354099
  0.05524756 -0.06450827  0.02023833  0.02282472  0.05105361  0.05032367
 -0.02863137 -0.0271156   0.05023121 -0.00319883  0.04957768 -0.02790661
 -0.00273478 -0.06903353  0.04750522 -0.02295437 -0.03892728  0.00180357
 -0.02706089 -0.0051411  -0.0022497   0.03714179 -0.01402437 -0.04464727
 -0.0386357  -0.00736244  0.03391291 -0.03158291  0.02672689 -0.00638035
 -0.00218304  0.04679801  0.01304649  0.01513265  0.00893352 -0.01535416
 -0.01763336  0.02591255 -0.00307509  0.01533444 -0.05547706  0.00449698
 -0.04094336  0.03379422 -0.06591535 -0.04594315  0.00472915 -0.11417593
  0.0230103  -0.05251108 -0.08566746 -0.00016528  0.07753635  0.04922058
 -0.03156418  0.01704323 -0.03792585  0.01084772  0.02480542  0.01270975
  0.0422467   0.05754896 -0.00437653  0.06037285  0.06198491  0.0390658
  0.04797148  0.02503378  0.04595099  0.02116303  0.0083875   0.03169281
 -0.04957364  0.0235728   0.03681029  0.01054761  0.01809055 -0.03404792
 -0.03117533  0.02273854  0.00093793 -0.01919851  0.06266511 -0.00648752
 -0.00694064 -0.03872074 -0.02493435  0.0429334   0.05122652 -0.02238191
  0.03096604  0.00537309 -0.02151404 -0.02370959 -0.04531883  0.03747943
 -0.04989544  0.00721365  0.02921519  0.02793334  0.01693834  0.00775244
  0.01058837  0.04217587 -0.01932293 -0.03956642]
tensor_name:  TemporalFusionTransformer/layer_normalization_5/gamma
[0.9450672  1.0810584  0.9588273  0.9873897  1.002425   0.99526787
 0.95511633 0.98478794 0.9678571  0.99716467 1.0121205  1.0251236
 0.9841252  0.989257   1.0426607  0.940921   0.98797226 0.9745615
 0.9878019  0.97129786 1.0304494  0.9982794  1.0247269  0.9960347
 0.9975513  0.96765226 0.99228007 1.0005126  1.0101473  0.9855235
 1.0427221  0.9882855  0.9942554  0.9971836  0.97921604 0.9806742
 0.9793986  0.9605754  0.9948237  1.0024681  0.9383514  0.97801405
 0.95344573 1.0044771  0.9968235  0.9751075  0.97639805 0.98859423
 0.9991     1.0157057  0.99658126 1.0779806  1.0134802  1.0048848
 1.0618244  1.0142618  0.9901617  1.0001061  1.0337188  0.9814812
 0.99193984 0.99841654 0.9833362  0.9849239  0.96847373 1.0204425
 0.93955994 0.9874494  0.99504167 0.954106   0.98871183 0.9923109
 0.9968461  0.98512954 0.99490494 1.0291703  0.99692017 0.9836261
 0.8640703  0.9872471  0.9615743  0.9876994  0.9749339  0.9353578
 0.9679945  1.0426459  0.991248   1.0008512  0.99188536 0.9777811
 0.9782409  1.0140257  0.9939584  0.9894024  1.0531262  0.97065705
 0.9869237  1.0134573  1.0320892  0.9993683  0.9843126  1.1213636
 0.9742846  1.0526638  1.0727695  1.0038682  0.9736096  0.9894185
 0.9797206  0.9853757  1.0085483  1.0084866  0.9862425  0.9822242
 0.9860826  1.001218   0.9579804  0.9888216  1.0382338  0.99670595
 0.99657726 0.98634875 1.0220292  0.9303489  0.935896   1.0026637
 0.9977666  0.96440524 0.9882441  0.9672372  0.97332567 1.0099117
 0.98943746 0.9958977  0.9818718  0.97836787 0.9670858  0.9896203
 0.98929083 1.018854   1.0123724  1.0408642  1.0147191  1.0148408
 0.9937186  0.9822371  0.9750802  0.99316543 1.0219122  0.98549706
 0.98795456 0.98663723 1.0130813  0.9852521  0.96785593 0.93143994
 1.009061   1.0384983  0.94179684 0.9937526 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_6/beta
[-0.12820786 -0.01532736  0.00181546 -0.04692048 -0.08321632  0.07149894
  0.16047536  0.00183649]
tensor_name:  TemporalFusionTransformer/layer_normalization_6/gamma
[1.1830384  0.93078405 0.9296417  0.9610344  0.9845875  0.87446046
 0.9805608  0.9920299 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_7/beta
[-7.8506041e-03  1.4637634e-03  1.3979981e-02 -1.5325174e-02
  4.7914456e-03  2.5182625e-03 -2.1559435e-03  6.8781553e-03
  7.7670282e-03  2.0123436e-03 -3.6106722e-03  1.5735827e-02
 -2.0653201e-02 -1.1682054e-02 -1.6437093e-03 -6.4071589e-03
  7.5315870e-03 -1.1060300e-03  2.8512219e-03  3.6284039e-03
 -6.1288904e-03  7.9958416e-05  1.6951761e-03  2.0170562e-02
  2.5914188e-03 -1.9476467e-03  2.2972189e-03 -3.3974750e-03
 -1.2647266e-02  1.2121385e-02 -6.5517034e-03 -1.0573186e-02
 -1.1778255e-02  8.7489299e-03  4.4414406e-03  4.8610510e-04
 -7.0207431e-03 -7.0776264e-03  9.3815140e-03  8.9985626e-03
 -2.6045281e-02 -3.9111013e-03 -1.6939705e-03  1.3097586e-02
 -4.2052474e-03 -2.2546193e-03  3.0274256e-03 -9.9796318e-03
  4.7807535e-03  7.6031662e-03  6.7110434e-03  5.4909824e-03
 -1.1630831e-02 -9.6076902e-04 -4.5739859e-03  7.8956233e-03
  1.1838295e-02  1.3918938e-02  5.3029903e-03 -2.6295239e-03
 -1.2902618e-02  1.0311179e-02 -7.7042757e-03 -2.9060969e-03
  5.0718794e-03  3.1967221e-03 -1.8900082e-02  9.3991263e-03
  8.9175142e-03  5.9189922e-03 -4.7146580e-03 -3.6045371e-03
  8.6352751e-03  5.0368649e-04  8.8704247e-03  1.2044228e-02
  3.3724234e-03  5.6829662e-03 -7.8252200e-03 -2.4507320e-03
  7.2211667e-04 -3.1664674e-03  3.3147621e-03  1.9765466e-03
  1.3951297e-02  4.2278026e-03  3.1631887e-03  1.6511695e-02
 -3.5998332e-03  5.7002548e-03  4.6844808e-03  2.6817864e-04
 -8.4016239e-03  1.7432643e-02  4.9317614e-03 -7.7395625e-03
 -4.9017547e-03  7.8545166e-03 -8.4813861e-03 -7.3917191e-03
 -3.1685394e-03 -2.9524024e-05 -8.5128518e-03 -9.6541019e-03
 -1.1756289e-02 -7.3721563e-03  9.1475695e-03 -4.9920511e-03
 -1.8832387e-04 -2.3518559e-03  4.9625320e-04  5.0744745e-03
  1.4335577e-02  7.3754163e-03 -1.6391255e-04 -1.3526642e-02
 -5.7269372e-03  7.7196863e-03 -3.0335356e-02 -2.4176233e-02
 -6.9361362e-03 -7.4298955e-03  3.5260194e-03  4.3655797e-03
 -3.5004036e-03  6.6505943e-04 -8.2878424e-03  5.8692265e-03
 -4.0708445e-03  4.8383088e-03 -1.6365316e-02  2.9563673e-03
 -1.0380780e-03 -1.4394521e-03  4.9559292e-03 -9.2135035e-03
 -1.1422426e-03  2.7202119e-03  4.6936581e-03 -7.8000450e-03
  1.9560298e-03 -7.1418770e-03  3.5312008e-03  6.2466599e-04
  7.2873062e-03 -2.3352276e-03  6.4996183e-03 -4.1827685e-04
 -1.0303660e-02 -5.4434310e-03  4.7738515e-03  1.7040903e-02
  3.4068006e-03  1.2961158e-02 -7.2471565e-04 -9.6309381e-03
  1.1053696e-02  6.8487236e-03 -2.2232141e-03 -3.8429203e-03]
tensor_name:  TemporalFusionTransformer/layer_normalization_7/gamma
[0.9862942  0.9740667  0.9916429  0.9851029  0.9837678  0.9701173
 0.9689304  0.9639954  0.9505819  0.99423254 0.97036904 0.99932927
 0.9862383  0.96999335 0.96148247 0.9848329  0.9792897  0.95689434
 0.9490931  0.9887708  0.97779405 0.96168274 0.9750668  1.0144701
 0.9446854  0.9884485  0.979195   0.98879355 0.98812705 0.9467366
 0.9766408  0.980801   0.9595228  0.9830742  0.99056345 0.9850744
 0.98567134 0.9315084  0.9582688  0.969878   0.99645805 0.95497495
 0.9987539  0.99623674 0.98517406 0.9939996  0.983384   0.9417674
 0.9680313  0.92749625 0.9676292  0.94174105 0.96396685 0.95818
 0.9769976  1.0068889  0.98835695 1.0048205  0.9936789  0.9807093
 0.9685375  0.9942427  0.9818583  0.96641374 0.97416776 0.9311778
 0.9990996  0.9579512  0.9768892  0.9597773  0.99785846 0.9549084
 0.94966334 0.9892831  0.94623554 0.9592766  0.92741084 0.99298674
 0.96035045 0.97938323 0.95432717 0.95921594 0.9421387  0.99370646
 0.97174984 0.95702285 0.9174205  0.9810854  0.97362566 0.96581936
 0.99054974 0.9847858  0.9474193  0.99197316 0.9761887  0.9911884
 0.9711728  0.9735858  0.9738305  0.9612561  0.9824222  0.99249375
 0.969999   0.97616684 0.95689285 0.9605989  0.9729581  0.9600823
 0.9820474  0.9845993  0.9590448  0.96533453 0.980835   0.96608734
 0.9646978  0.9860054  0.9669959  0.98407006 1.0267751  1.0455471
 0.96095455 0.94118434 0.9907812  0.9450472  0.9766992  0.9682867
 0.98226833 0.9733587  0.96263194 0.9923931  0.92572594 0.9667332
 0.99149895 0.97297764 0.96786034 0.98585373 0.97132844 1.0031947
 0.97110146 0.96815056 0.97762376 0.93994296 0.94553757 0.97435415
 0.96898794 0.96251047 0.92878246 0.98329365 0.98244745 0.99293256
 0.96699554 1.0100453  0.94461846 0.9576518  0.985727   1.0029466
 0.96719515 0.9745144  0.9601859  0.95662487]
tensor_name:  TemporalFusionTransformer/layer_normalization_8/beta
[-1.17904209e-02 -1.43809337e-03  1.73604768e-02 -2.37662215e-02
  1.80815384e-02 -6.72063883e-03 -2.11163163e-02  1.24232029e-03
  2.92833545e-03 -2.15927418e-03 -2.54406314e-03  4.79310155e-02
 -3.17041613e-02 -4.13810136e-03  1.06592542e-02  1.33941947e-02
  1.83861349e-02 -7.68697006e-04  1.56672243e-02  3.95368552e-03
 -9.47574992e-03  2.79793665e-02  2.90783122e-02  3.43727879e-02
  4.64709150e-03  1.42363636e-02 -1.55633260e-02 -3.14244628e-03
 -2.73333248e-02  1.06938602e-02 -2.12800428e-02 -2.08635870e-02
 -2.05552969e-02  3.81222228e-03  2.83906553e-02  9.99670289e-03
  4.96535888e-03  6.15949568e-04  1.63652487e-02  3.37406527e-03
 -2.04424933e-02 -1.31937778e-02  4.36140643e-03  2.57651098e-02
 -2.08096094e-02 -1.91725045e-02 -4.24184930e-03 -8.25587753e-03
  9.65884048e-03 -4.02348815e-03  8.60612653e-03  1.10152364e-02
 -2.17711739e-02  5.32744045e-04  1.26915434e-02  1.57663487e-02
  9.30283777e-03  1.95506904e-02  3.18677686e-02 -1.19326282e-02
 -1.28528094e-02  9.40019637e-03 -9.19216685e-03 -1.43593121e-02
  1.65768173e-02  3.37439887e-02 -3.39396298e-02 -2.64293072e-03
 -2.92657362e-03  8.54630210e-03 -4.06447332e-03 -1.30611453e-02
  2.07084585e-02  6.15302892e-03 -1.45604629e-02  1.62213836e-02
  3.27459127e-02  2.76796781e-02 -1.92950983e-02 -6.59185881e-03
 -3.57079841e-02 -2.00063046e-02 -1.15415566e-02  4.71401634e-03
  7.01345969e-03  8.22289195e-03 -1.74148753e-02  2.89151985e-02
 -4.24825726e-03  6.86280243e-03  3.33404075e-03  1.11727733e-02
  4.49494808e-04  1.26933074e-02  4.66054305e-03  5.38064865e-03
 -6.29172707e-03  3.40171158e-02  7.04330578e-03 -1.79066975e-02
  8.36124644e-04 -2.73122098e-02 -5.05811311e-02 -1.61163267e-02
 -1.41087873e-02 -1.56160295e-02  2.20546201e-02 -2.08735047e-03
 -2.59148125e-02 -1.33756045e-02  7.83059187e-03  1.75083466e-02
  9.11853183e-03  3.13784033e-02 -1.16403447e-02 -3.43220793e-02
 -2.65481547e-02  2.04394981e-02 -5.93168586e-02 -6.08343035e-02
 -3.48301651e-03 -1.04973130e-02  3.31336372e-02  1.86180510e-02
 -2.85542067e-02 -2.18774381e-04  2.87426775e-03 -1.86880759e-03
 -7.59296631e-03  6.33987971e-03 -1.54718896e-02 -3.89605673e-04
 -1.90585535e-02 -7.29580084e-03  4.09028173e-04 -1.96037106e-02
  2.75991280e-02  2.11630724e-02 -1.46402314e-03 -1.17505167e-03
  6.68295193e-03  1.61689240e-02  8.13942216e-03 -7.88900245e-04
 -1.50780543e-03 -5.41493343e-03  1.29540497e-02  3.18580237e-03
 -2.11576000e-02 -2.29770620e-03 -8.12347062e-05  2.71238275e-02
  2.64080754e-03  2.22284216e-02  2.70608049e-02 -1.53175956e-02
  1.07140373e-02  1.48734339e-02  1.48855790e-03  1.21892355e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_8/gamma
[1.1310034  0.9812504  1.0069883  0.88137424 0.8931227  1.0078838
 1.0140359  1.0111648  1.0575677  0.9973472  0.99422896 0.99694306
 0.9481706  0.91669595 1.0313407  0.9112263  0.9487436  0.96696657
 1.1227307  1.0167619  0.9742536  1.0534294  0.97902066 0.937342
 0.9560937  0.97108555 1.0356903  1.0613779  1.0671227  0.8162306
 1.0300561  1.0120347  0.9663767  0.99661833 1.0663449  1.0844309
 1.0160608  1.0871617  0.9838215  0.99184334 0.84271175 1.1080987
 1.0001653  1.063099   0.9654526  0.99481934 0.9247096  0.90649956
 0.9017405  1.0281909  1.0958228  0.9354655  1.0220611  0.9218159
 0.97721833 1.0392001  0.91018146 0.9449547  1.0030721  0.97889364
 0.9292432  1.0135802  1.0478238  1.0339782  0.93900174 1.02393
 0.995578   1.1457843  1.0634079  0.9696449  0.962958   1.0216545
 0.8889594  1.0765376  0.9530905  1.0707071  1.0459116  0.9518472
 0.9002109  0.983772   0.9254136  1.0137434  0.9153433  0.95146215
 1.0317922  1.0396091  0.9421062  0.98069197 1.0183561  0.8810552
 1.005798   1.0217685  0.9472229  0.89838797 1.0206109  1.0122738
 0.99990666 0.9684592  0.9213457  0.96083343 1.0385528  1.0509582
 1.0506442  0.9491097  0.99794865 1.1118338  1.0349784  1.0701493
 1.0600345  0.93788147 1.070403   0.9458175  0.9675308  1.0040847
 1.0303731  0.9489641  0.9507779  1.0508862  1.0164435  1.0292711
 0.9939656  1.0533077  0.99742085 1.106542   0.9918321  0.99614644
 1.089581   0.9151265  1.0695248  0.9241005  1.095405   1.0921463
 1.1313995  0.9643152  0.9459519  1.0254086  1.0444252  0.9610352
 0.9155104  1.0042787  0.9728159  0.9713277  0.96610475 0.926112
 1.0541531  0.9732206  1.068052   0.9970398  0.959142   0.96939796
 1.0028561  0.9795226  1.0220572  0.934516   1.0151509  0.9518288
 1.0173064  1.0238858  0.96034664 1.0888232 ]
tensor_name:  TemporalFusionTransformer/layer_normalization_9/beta
[-1.56025328e-02  1.33836446e-02  1.92087665e-02  5.37206128e-04
 -2.91841989e-03  1.18900593e-02  4.64961492e-03  4.12313966e-03
  1.56095913e-02 -3.65509000e-03 -6.55004801e-03  1.26522779e-02
 -1.76666174e-02 -1.24201560e-02 -1.06662307e-02 -6.94988947e-03
 -5.51261823e-04 -6.80063339e-03 -6.84714224e-03 -8.65923334e-03
 -1.46553796e-02 -8.60368088e-03  2.18875967e-02  1.36643481e-02
 -8.06126092e-03 -7.08948495e-03  6.48083258e-03  8.15300154e-04
 -1.13756889e-02  1.67198642e-03  1.09343668e-02 -2.92611122e-03
 -1.32820299e-02  1.45724583e-02  2.18033548e-02  1.17249051e-02
 -6.82038860e-03 -8.98503326e-03  2.77610030e-02 -1.28044607e-02
  7.40752509e-03  2.32374691e-03 -2.31714197e-03  1.04093077e-02
  2.08709650e-02 -1.22491876e-02  1.88944861e-02  8.61203671e-03
 -1.01600410e-02  2.52660811e-02  1.29026026e-02  1.10056496e-03
 -2.42144726e-02  4.52124327e-03  6.80054119e-03  1.80880446e-02
  1.77269429e-02  1.18263820e-02 -5.46736550e-03  4.63796919e-03
 -1.45624122e-02 -3.42870876e-03 -1.67572107e-02  3.98912048e-03
  8.50982219e-03 -1.69062465e-02 -2.87642907e-02  2.79726405e-02
  2.93166898e-02 -2.03028694e-03 -1.45471841e-02  1.61015557e-03
 -8.55244882e-03  5.74661233e-03  4.49942163e-04  2.18991078e-02
 -2.13081073e-02  6.21528877e-03 -5.78642450e-03  3.97412945e-03
 -2.27532070e-02  8.59787222e-03 -1.46340476e-02  1.61107704e-02
  1.96108986e-02  1.86648744e-03  2.96750106e-02  1.86806526e-02
 -8.00389051e-03  2.08753385e-02  8.15123785e-03 -6.84295036e-03
 -7.59091554e-03  1.52111957e-02  1.95569396e-02 -1.86896864e-02
  1.24036344e-02 -2.23448128e-02  5.67105925e-03  8.19759071e-03
 -6.78763026e-04 -2.35298499e-02 -1.91691797e-02  7.74678600e-04
 -1.67501699e-02 -2.30046269e-02  4.99010412e-03  5.58180548e-03
  1.69962626e-02 -2.77190004e-03 -1.46187609e-02 -7.37770554e-03
 -4.07844502e-03  1.03312340e-02 -1.03021357e-02 -1.96014028e-02
  6.39603054e-03 -1.38449715e-03 -2.85635833e-02 -3.49829867e-02
  5.20147663e-03 -1.96270319e-03  1.90915447e-02 -3.85693042e-03
  6.36407034e-03  5.91354119e-03 -2.33992767e-02  2.67887712e-02
 -4.29058680e-03  2.01417832e-03 -1.65708885e-02  9.66114551e-03
 -1.55195175e-02  2.79534496e-02  1.59906559e-02  1.56850473e-03
  5.18082269e-03 -2.62359390e-06  1.35236676e-03 -2.44282316e-02
  1.97753981e-02  2.58813123e-03  1.56400744e-02  1.21490853e-02
  1.48390606e-02 -1.28900139e-02  1.12519823e-02  2.33494863e-02
 -6.69344235e-03 -1.88090466e-02  2.12591793e-02  2.24994533e-02
  1.62158418e-03  1.14235487e-02  2.01641567e-04 -3.89565853e-03
  8.61308444e-03  2.20203288e-02 -1.03191575e-02 -1.04223657e-02]
tensor_name:  TemporalFusionTransformer/layer_normalization_9/gamma
[0.99299264 1.1616045  0.9345085  0.9085055  0.9134418  0.92900175
 0.95856166 0.9393624  0.9546473  0.9390177  1.00015    0.90865874
 1.0587031  1.1372452  0.9409071  1.0003171  0.92242056 1.0852668
 0.9392539  1.0122405  0.9497844  0.9473576  1.1021283  1.0395064
 0.91271853 0.983571   0.9751989  0.9950472  1.050869   1.0803164
 0.97875404 0.95935166 0.9692732  1.0798864  1.0775145  1.0178584
 1.0226517  0.90165293 0.97431594 1.0444944  0.9526678  0.97155297
 0.9485358  0.9447974  0.93258303 0.9983675  1.0092303  1.1986235
 1.0384393  0.93552047 1.0506645  0.9589619  0.99720657 1.0024966
 0.982044   0.9680384  0.98082036 0.9714592  0.9709651  1.0232607
 0.917526   0.92935055 1.0246747  0.94258314 0.97321284 0.9614767
 0.9981788  0.9477676  1.0570124  0.9398919  1.0391505  0.975387
 1.0222236  0.9322117  1.161111   0.9449491  0.9644517  0.9494419
 1.0305238  1.0082978  1.0286838  0.96707886 1.1391951  1.0358217
 1.1250964  0.9365488  0.948932   1.1480658  1.0170666  0.987806
 0.91905487 0.94753337 0.9604484  1.00107    0.93471956 1.0452942
 1.0262154  0.96221864 0.91977215 1.019113   0.95689976 1.0549027
 1.0742077  0.9802528  1.0154872  1.0546051  1.0457703  0.9329735
 1.0898958  0.92807484 0.91737    1.0207487  1.1043117  1.049297
 1.0150223  1.0231487  0.9078691  1.041001   0.98996335 1.0478499
 1.0666043  0.93446845 1.0746108  0.93016875 1.0188029  0.9579479
 0.99272835 0.9750901  1.0418005  0.94454485 0.9863206  1.023366
 0.9108996  1.1350287  1.0297922  1.042247   0.99145806 0.9874039
 0.96864057 0.94878376 0.9374797  1.292443   1.0909559  0.9815572
 1.0084019  1.099024   1.0824152  0.99952143 1.1011039  1.0841033
 0.9685678  1.1086773  1.0535886  0.939256   0.9240599  1.1435691
 1.0883125  1.0293747  1.0622244  1.0119671 ]
tensor_name:  TemporalFusionTransformer/time_distributed/bias
[-0.01695209  0.00387305 -0.02926997  0.01419239 -0.04925257 -0.0026319
  0.03511381 -0.02276842 -0.02054325  0.00424589  0.03642759 -0.03755873
  0.03981809 -0.02077752 -0.00501679  0.03645441 -0.01129469  0.02625278
  0.01596162 -0.02527189  0.04832106 -0.0136467  -0.02650836 -0.03393486
 -0.04427035  0.02764128  0.00493252  0.01239362 -0.02129039 -0.00756685
 -0.00320807  0.00746732  0.02454898 -0.04805503 -0.01184809 -0.01558851
 -0.01701533  0.00494931 -0.02227124 -0.00159841  0.01786688  0.01979774
 -0.03942707 -0.00504178  0.0329727  -0.04143099  0.00826174 -0.00474552
  0.03016988  0.00444555 -0.01110181  0.01545604  0.044207   -0.00665847
  0.03831273 -0.0338402  -0.04261887 -0.01552007 -0.00392062  0.0380187
  0.04758244 -0.02458814 -0.00973214 -0.04418926  0.02300919 -0.03324198
  0.03988117 -0.00522316  0.01659262  0.02938755 -0.04030208  0.04232466
  0.01515561 -0.00504917 -0.01870108 -0.00330605  0.02091731 -0.05933496
 -0.00412874 -0.00491421  0.02418687 -0.03814533  0.00842048 -0.00573406
  0.0031219  -0.00051038 -0.02017436 -0.03515394 -0.00464007 -0.02130061
 -0.0344175   0.0294433  -0.02334354 -0.02532329 -0.02549669 -0.02223842
 -0.02132761  0.04915572  0.02083026  0.02140514 -0.00370157  0.02475089
  0.02024719  0.02868724  0.0328016  -0.00058888  0.00941751  0.025115
 -0.03128123  0.01981565 -0.03022364  0.04594819  0.03382883 -0.01752818
  0.03050666  0.04255132  0.05964424 -0.03379511  0.05078049  0.03088825
 -0.00251065  0.02055116 -0.04202602 -0.02900675  0.02662995 -0.03817568
 -0.00012195  0.0402141  -0.00979672 -0.0499815  -0.00163034 -0.04087649
  0.02502343  0.03996259 -0.02389065 -0.02278085 -0.00174341 -0.04103612
 -0.01069447 -0.01257231 -0.02290924 -0.03287934  0.01583942  0.01600506
  0.03733244  0.02515125  0.02410749 -0.0398454  -0.02243374  0.02311306
 -0.00743139 -0.02857086  0.01727543 -0.03991632 -0.02739906  0.04067648
 -0.00026315  0.00428322  0.02746403 -0.02932206]
tensor_name:  TemporalFusionTransformer/time_distributed/kernel
[[-0.10046172  0.17471963  0.10707204 -0.018449    0.10425708  0.01240018
   0.09090362  0.15116207  0.16733176 -0.08593585 -0.14496905 -0.11913486
  -0.14025702 -0.13438942 -0.14677104 -0.04288342 -0.21100393  0.15663122
  -0.01967363 -0.17678547 -0.05826329 -0.0116386   0.05672515  0.14414944
  -0.20077091 -0.08867869  0.15926768  0.11547486  0.04150188 -0.0444223
   0.10661399  0.17146264 -0.1116561   0.1068149   0.10515139 -0.05654111
  -0.08078319  0.15553376  0.00651116  0.00297478  0.19468983 -0.01407984
   0.04125936 -0.09375814  0.10453975  0.01144396  0.1634808  -0.18301964
  -0.0822067  -0.01013157  0.01411546 -0.19913332 -0.0873068  -0.1295985
  -0.0754826   0.04593036 -0.05351141  0.1835958  -0.02398807  0.11437891
  -0.14060605  0.08954136 -0.15561298  0.12175237  0.0503211  -0.19369088
   0.02960842  0.07951138  0.19747056 -0.04103232  0.08279931  0.12265534
  -0.05169472  0.15450549 -0.10263375 -0.04567844 -0.03362647  0.02958942
  -0.07715497  0.01121372 -0.09923191 -0.11202859 -0.14941853  0.17823887
  -0.00730833 -0.14560601  0.03907606  0.02871161  0.02836171  0.18414874
  -0.00439695 -0.09028105 -0.00213317  0.06617705  0.15472499 -0.15824944
   0.13858756 -0.1177161  -0.08750281 -0.02041085  0.01645335 -0.08960745
   0.00650493  0.03860638 -0.1255095  -0.1827532  -0.12016191 -0.02725295
   0.11465196  0.07438927  0.00973356 -0.14221242 -0.1239302   0.00347503
   0.01760438 -0.04977752  0.1253227   0.09928582  0.05918414  0.08672207
  -0.05632428 -0.03099088  0.15474653  0.03828543  0.13459896  0.14417288
   0.04252058  0.17515641  0.05076062  0.10938619  0.00649702  0.18043636
  -0.07228675  0.14741743  0.04805379  0.09169441  0.06266568 -0.04575127
   0.15025872 -0.13096456  0.15449186 -0.02651251 -0.01150538  0.08916488
  -0.02947256  0.04218464 -0.10490058  0.19867775  0.07038554 -0.03927751
   0.18334958  0.0316626  -0.15116456  0.0207342  -0.01246203 -0.18271784
   0.00924443  0.17111208 -0.05869258 -0.070864  ]]
tensor_name:  TemporalFusionTransformer/time_distributed_1/bias
[ 0.0050372   0.08525873  0.02456138 -0.05427428  0.00391915 -0.03190066
  0.02159574  0.00292811  0.01463359 -0.05972395 -0.04371244 -0.01695234
 -0.02593458 -0.00177165 -0.02774076 -0.01772813  0.00286282  0.00043072
 -0.04042279  0.03106642  0.00234171 -0.03814778 -0.01163283  0.05069082
 -0.0305901   0.02438156  0.02641727 -0.03733642 -0.02199977 -0.011816
 -0.01272282 -0.03420058  0.02573734 -0.03458871  0.03245742 -0.02472899
 -0.03689811 -0.00741537  0.01348803  0.01724299 -0.04339277  0.02270023
  0.03714736  0.0312334  -0.03054365  0.01273011  0.0162467  -0.00106464
 -0.02320464  0.02857536  0.00606553 -0.03025901 -0.04247234 -0.03842355
 -0.02794169  0.11453468 -0.01426292  0.05263346  0.03622196 -0.03556939
 -0.04910786 -0.00916595  0.01531503  0.03903228 -0.00029401  0.02505575
 -0.01342503  0.00716541  0.00940629 -0.02446595  0.07368474  0.02787996
 -0.0375255   0.02848095 -0.0187252   0.00543036 -0.02379413 -0.01263573
  0.0107314  -0.01404725  0.01743123 -0.02838195 -0.03054981  0.03375957
  0.00820013 -0.0095338  -0.03778307  0.01826262 -0.03155896  0.01452725
  0.04998929 -0.04213032 -0.00695298 -0.00523921 -0.04481878 -0.03254136
  0.03260674 -0.0184645  -0.03577353  0.00376731  0.02430764 -0.05407331
 -0.00209695  0.02558914  0.02310381  0.03324325  0.00560282  0.01328629
 -0.01873167 -0.01992255  0.03152875  0.04001877  0.02417001 -0.02643049
 -0.05267268  0.0297777   0.04545029  0.031688   -0.00036057 -0.08042991
 -0.0012004   0.00277119  0.05507138  0.01585189  0.02075892  0.00119384
  0.00571214  0.0217805  -0.00749708  0.02046169  0.01888105  0.02884496
 -0.03332436 -0.04803946  0.01765273  0.03363508  0.01149501 -0.00011811
 -0.01085552  0.01692502 -0.02535086 -0.02072863  0.01882541  0.01899383
  0.00136323  0.01509047 -0.05144738  0.04984028  0.02878114  0.01080135
  0.02108218 -0.00801065 -0.00541778 -0.07986793  0.00910468 -0.00149997
  0.00367325  0.03271254  0.01497298 -0.02142896]
tensor_name:  TemporalFusionTransformer/time_distributed_1/kernel
[[-1.60061657e-01 -4.28261757e-02  1.83105141e-01 -1.45964682e-01
  -1.18814893e-01 -1.69726908e-01  1.78571761e-01  1.04772687e-01
   9.67185795e-02 -1.41231418e-01 -2.82940418e-02 -1.30740866e-01
  -1.58382028e-01  1.68368220e-04  1.88007951e-01 -1.56843141e-01
   1.10564649e-01  1.45726502e-02  4.85101044e-02 -8.54006410e-03
   1.69407398e-01  8.65762532e-02  5.96296191e-02  1.86226010e-01
   1.87674463e-01  8.32671225e-02 -7.54654855e-02 -3.05694193e-02
   1.07495725e-01  9.29840803e-02  1.29392624e-01  3.78979594e-02
   1.00945085e-02 -7.43017197e-02  1.59815371e-01 -1.47191182e-01
   9.63728130e-02 -1.28736973e-01 -3.17992866e-02 -1.61892697e-01
   3.97329628e-02 -9.02085230e-02  1.82824939e-01  1.10757351e-02
   2.05395818e-02 -1.62460983e-01  5.44412881e-02 -1.82711393e-01
   1.61257595e-01  1.81830347e-01 -1.51248455e-01  1.63244307e-01
  -1.35442689e-01  1.21121347e-01 -1.02969259e-02 -6.93165138e-02
   3.57728451e-02  4.85579371e-02 -6.21348619e-04 -4.74451184e-02
   1.26674712e-01 -1.11299865e-01  1.47290558e-01  3.22313756e-02
  -6.37939423e-02  1.42974645e-01 -1.45000204e-01 -1.46717206e-01
   9.44077075e-02 -5.65161854e-02  1.00981921e-01 -8.91299471e-02
   1.97683275e-02 -4.69762534e-02  1.34687483e-01  9.31837857e-02
   3.44274193e-02  2.54406631e-02  1.50593877e-01  1.04447812e-01
   2.76867300e-02 -8.40786472e-02 -7.41839409e-04  1.42792016e-01
   2.07128227e-02 -1.80258989e-01  1.30974710e-01 -1.04836486e-01
  -1.86965242e-01 -1.09525524e-01 -1.92936093e-01  1.00956440e-01
   1.31795466e-01 -1.66900828e-01  1.75864518e-01 -1.45468295e-01
  -9.31267068e-02 -3.35585326e-02  1.81158245e-01  1.21091694e-01
  -1.74703926e-01 -5.69691360e-02  7.96607137e-02 -1.73227146e-01
   1.64630383e-01  8.70548189e-02  1.48878217e-01 -1.43501326e-01
   9.02540386e-02  1.35618091e-01 -7.66666755e-02  1.60517067e-01
   5.41078299e-02  7.88387656e-03 -1.64489806e-01 -1.28149241e-01
  -1.62559569e-01 -1.04454793e-01 -1.17983893e-01  1.02132112e-02
   1.91153109e-01  1.84556574e-01  1.61958575e-01  1.84510142e-01
   3.62941325e-02  1.71110690e-01  1.51822418e-01  1.79572970e-01
  -1.54730052e-01  1.57311112e-02 -9.18735564e-02 -1.18452206e-01
  -1.30288705e-01 -3.36163044e-02 -1.65468320e-01  7.15596676e-02
   1.24798536e-01  1.77571207e-01 -1.82417929e-01 -2.54587531e-02
  -1.04964994e-01  7.36419261e-02  1.41369075e-01  9.01100636e-02
   4.01708931e-02 -1.21069290e-01 -8.68441164e-03 -1.52220160e-01
   2.22109705e-02  5.17282933e-02  8.58100951e-02 -1.87982976e-01
   8.55728686e-02  9.12073851e-02  7.50337243e-02  1.18370175e-01
   1.85417891e-01  5.30805737e-02 -7.46384487e-02 -9.52074900e-02]]
tensor_name:  TemporalFusionTransformer/time_distributed_10/kernel
[[-0.02774169 -0.00257782  0.01086549 ...  0.07960659  0.04861103
   0.02107202]
 [ 0.14564371  0.09841672 -0.08880995 ...  0.07857    -0.12345364
  -0.01668121]
 [-0.00636788  0.03587309  0.08589415 ... -0.07172152 -0.00549078
  -0.02499296]
 ...
 [ 0.07456886  0.07496473 -0.04481374 ... -0.15037178  0.00494259
   0.13865997]
 [ 0.00406012  0.10417736  0.10951617 ... -0.00268812  0.05836646
  -0.06497025]
 [ 0.07561359  0.06697735  0.10335404 ...  0.1138676   0.09396961
   0.05996679]]
tensor_name:  TemporalFusionTransformer/time_distributed_11/bias
[-0.03438922 -0.01436674 -0.02365943 -0.03017263 -0.03969957  0.04155267
  0.03163082  0.05131016 -0.01850344 -0.05006044 -0.04071537  0.06187368
  0.02858958 -0.03978046 -0.03522344 -0.04705    -0.01166259 -0.0162037
 -0.00531066  0.13611025 -0.00224359  0.04004189  0.02140709 -0.00329269
  0.02962865  0.03999201  0.00853873 -0.02691071 -0.01954116 -0.09823455
 -0.05123779 -0.01085139  0.07816143 -0.0113213  -0.00610907 -0.03679347
  0.0378386  -0.02972397  0.01933837 -0.03323209 -0.06370362  0.03970456
 -0.02700141 -0.02858776  0.06027727 -0.0088199  -0.03743406 -0.01584589
 -0.00714134 -0.05536076 -0.04666291  0.00964393  0.01134703 -0.001876
  0.02109109 -0.05345068  0.03344803 -0.03179564 -0.02380677  0.00254439
  0.08722091  0.00045323  0.03936368  0.0561262   0.00695562 -0.01445212
  0.00447418  0.03031589  0.01433203 -0.00537363  0.00090552 -0.0924338
 -0.02303167  0.10520325  0.02565742  0.03908855 -0.03446499 -0.02977956
  0.02875984  0.03361284 -0.03429499  0.03309686 -0.02852728  0.04334253
 -0.01507693  0.04054804 -0.02823084 -0.06501856  0.05778583  0.06690611
  0.03008105  0.00500251 -0.04466392 -0.00463515 -0.03738661  0.04077373
 -0.01771782 -0.00685967 -0.03635076 -0.00252401 -0.03522843  0.05414678
 -0.01384165 -0.0014142   0.0367363  -0.02624499  0.04864642 -0.01011475
  0.01821088  0.10309821 -0.02618122  0.03225373 -0.02148405  0.01147328
 -0.06915044  0.02116049 -0.03679235 -0.01022359 -0.00897815  0.03326505
 -0.04531858 -0.02974814 -0.03497182 -0.02822736  0.039297   -0.0014231
 -0.01896198  0.02534285  0.02957576 -0.01483737 -0.0120456   0.04070819
 -0.02665449 -0.07122318  0.04192421 -0.01262529 -0.08763634  0.00704523
  0.0123072   0.04655114  0.03958057  0.00160314  0.0130251   0.0110242
  0.0282433  -0.02736512 -0.01348208  0.03455655 -0.00500669  0.06116455
  0.01348306 -0.00066707  0.04068075 -0.0613951   0.02921954  0.00401157
  0.01205149 -0.03415116  0.02617525 -0.0350919 ]
tensor_name:  TemporalFusionTransformer/time_distributed_11/kernel
[[-0.00521629 -0.079158    0.1140959  ...  0.12150766 -0.06806776
   0.05124967]
 [-0.11744192  0.05550706 -0.03516776 ...  0.01039049  0.07718318
   0.06726352]
 [-0.03309499 -0.12026504  0.09231635 ... -0.1597172  -0.07035165
   0.05275308]
 ...
 [ 0.1175392   0.08791444  0.00269973 ...  0.07421812 -0.08753373
   0.00631419]
 [ 0.10376447  0.10240915 -0.05224116 ...  0.06285162  0.06114184
  -0.15993202]
 [-0.10775507  0.10192149  0.02979482 ...  0.03617181 -0.0023653
   0.18834014]]
tensor_name:  TemporalFusionTransformer/time_distributed_12/bias
[-0.12257396  0.02525228  0.03897659  0.0038584   0.0045438  -0.01683497
 -0.00971312 -0.01167894]
tensor_name:  TemporalFusionTransformer/time_distributed_12/kernel
[[ 0.0152351   0.08299889 -0.09818429 ...  0.14902979  0.04618431
   0.0982083 ]
 [-0.01747207 -0.1358982   0.11529393 ... -0.05061184 -0.08006305
   0.03734383]
 [-0.07435992 -0.09785797 -0.10944406 ...  0.14627361 -0.06483055
   0.08361308]
 ...
 [ 0.09768628 -0.10432467  0.00305913 ...  0.04726578 -0.02474417
  -0.11082338]
 [-0.03885106 -0.01147148 -0.00351758 ... -0.05469366 -0.1503283
  -0.14618048]
 [ 0.26712462 -0.07414218  0.07944826 ...  0.02972545 -0.1342372
  -0.09721652]]
tensor_name:  TemporalFusionTransformer/time_distributed_13/bias
[ 0.00065313 -0.00015746  0.00585142 -0.02294261  0.01044712  0.00068443
 -0.01539868  0.01423306]
tensor_name:  TemporalFusionTransformer/time_distributed_13/kernel
[[ 0.10970679  0.14522216 -0.11956378 ... -0.06120352 -0.11671994
  -0.14511123]
 [ 0.05508555 -0.19891752  0.20357426 ... -0.01444902  0.1333465
  -0.13784073]
 [ 0.10397498 -0.10648465  0.016233   ... -0.05867373  0.13739163
   0.10143477]
 ...
 [ 0.10143863 -0.14173697 -0.11556571 ... -0.17215073  0.07246541
  -0.0405729 ]
 [ 0.00843217 -0.12058442 -0.20947108 ...  0.08594077  0.13830622
  -0.06622078]
 [-0.16346082 -0.20812587 -0.19077626 ... -0.04020618  0.03185464
   0.06318522]]
tensor_name:  TemporalFusionTransformer/time_distributed_14/bias
[-2.10854854e-03 -1.64584897e-03 -3.22187948e-03  5.90254040e-03
  4.03939234e-03  3.13140219e-03 -3.51552246e-03 -4.68837284e-03
  2.66777561e-03 -2.95583811e-03  4.76214365e-04 -8.71917000e-04
  1.22581404e-02  5.84437791e-03 -6.82045287e-03 -3.05490056e-03
 -3.38387629e-03 -2.57309852e-03 -4.01097757e-04  9.43458360e-03
 -7.50998547e-03  5.12994593e-03 -6.38632663e-03 -2.23844917e-03
  2.61329580e-03  7.29189813e-03 -3.83136724e-03 -1.85706245e-03
  5.64706465e-03 -5.78397326e-03  1.08129149e-02  1.68651994e-02
 -5.32516045e-03  2.03775824e-03 -2.68977461e-03  8.54789652e-03
 -1.31924562e-02  1.14154797e-02 -5.60994120e-03  1.39664039e-02
  1.44263395e-05  9.73959919e-03 -1.54742086e-03 -3.58644500e-03
  6.04360178e-03 -4.17857757e-03 -1.24240376e-03 -1.97301270e-03
 -5.54855075e-03  4.32588579e-03  9.25517827e-03  4.03641304e-03
  9.39462427e-03 -3.65260197e-03 -5.57884853e-03  1.32649171e-03
  7.15670583e-04  6.44118711e-03 -8.10502656e-03 -1.37533117e-02
  1.98986474e-03 -1.79282425e-03  1.45939644e-03 -9.76741314e-03
  1.96347642e-03  1.38176130e-02 -1.45185115e-02  1.07188837e-03
 -1.19196519e-03  2.67298520e-03  2.17603240e-03 -1.31150186e-02
  4.44549555e-03 -6.08959189e-03  3.56707466e-03 -4.32991376e-03
  3.72247119e-03  5.04103862e-03  1.75643107e-03 -7.17645511e-03
 -6.33273879e-03  3.72089772e-03 -3.18536302e-04 -4.44388203e-03
 -1.88887410e-03  3.16800829e-03 -5.38326474e-03  6.77642878e-03
  8.68399814e-03 -8.54209438e-03 -8.22946522e-03 -4.45987983e-03
 -2.29681656e-03 -1.70598645e-03 -1.04373880e-02 -7.80357188e-03
  5.90828387e-03  3.90060898e-03  2.09656567e-03  1.09237037e-03
 -7.30201602e-03  6.38983445e-04 -1.14344722e-02  2.31517688e-03
  5.99991484e-03 -4.79205139e-03 -4.75750957e-03  1.45312147e-02
 -3.89033370e-03 -2.40351073e-03 -1.68254506e-03  6.01168303e-03
 -1.70001225e-03  7.76467426e-03 -3.59868188e-03 -6.40594028e-03
  1.57980551e-03  2.55581550e-03  5.39205968e-03 -6.57661865e-03
 -6.78577693e-03 -7.86660425e-03 -6.38182694e-03 -9.28756502e-03
  4.79726819e-03 -3.24050803e-03 -5.39752375e-03  6.75719837e-03
  2.76884381e-02 -5.74732618e-03 -5.34531148e-03  4.29862086e-03
  4.17857955e-04 -3.19913542e-03 -7.02108443e-03  4.24064463e-03
 -9.31221154e-03 -9.83719528e-03 -6.80509303e-03  7.08137639e-04
 -5.05702989e-03 -5.96416090e-03  1.63511131e-02  1.63864475e-02
  6.63481699e-03 -6.53980125e-04 -5.29166125e-03  2.25560996e-03
 -9.31425020e-05  7.31569063e-03 -1.02694891e-02 -6.04463799e-04
 -2.67534750e-03  9.23865999e-04 -2.35212967e-03  1.30379712e-03
 -2.94518773e-03 -4.20266250e-03  5.63054299e-03  1.89561094e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_14/kernel
[[-0.11543925 -0.02695799  0.00622183 ... -0.12128071  0.10823674
   0.09313133]
 [-0.14493449  0.04486689  0.03435391 ...  0.09727816  0.0458762
  -0.03733922]
 [ 0.05927799  0.02045481  0.11451511 ... -0.05998728  0.04014166
  -0.01780606]
 ...
 [ 0.10602959 -0.05985489 -0.13874604 ...  0.05550786  0.1464996
  -0.03046904]
 [ 0.09070048 -0.01098374 -0.03195089 ... -0.03392116 -0.05767684
  -0.06095881]
 [ 0.11551858  0.02741828 -0.0632675  ...  0.10308723 -0.00890593
  -0.12551925]]
tensor_name:  TemporalFusionTransformer/time_distributed_15/bias
[-7.0415814e-03  2.5461042e-02 -2.5634039e-03 -1.2791541e-04
  1.1272248e-02 -1.6041288e-02  2.0289149e-02  7.0839091e-03
  1.0538636e-02 -2.4719378e-02 -7.7155111e-03  5.0062449e-03
  8.2225725e-03  9.8658493e-04  4.5707906e-03  5.1445588e-03
 -5.9389826e-03  3.8908541e-04 -5.2814665e-03  6.7055160e-03
  9.9570882e-03  2.4112618e-02 -1.7676011e-02 -7.2863186e-03
  3.3066515e-03 -2.2949881e-03 -4.7762357e-03 -8.3675887e-03
  1.5298533e-02  5.7789949e-03  5.0289202e-03  1.0121216e-03
 -1.1924057e-02 -3.7815799e-03  2.3602840e-02  3.9473055e-03
  4.5068581e-03  1.2790099e-02  4.4313059e-03  4.8586871e-03
  3.0794155e-03  1.1972317e-02 -1.6503135e-02  8.9981956e-03
  2.7355691e-04  1.0043445e-02  1.0968547e-02  9.3887956e-04
  1.5692625e-03 -1.0177120e-02 -1.2292816e-02 -1.5623931e-02
  1.7742587e-02 -5.7286988e-03 -8.0981845e-04  1.9662380e-03
  2.7302124e-03  8.7609589e-03  1.1353381e-02  3.0603774e-02
 -6.5517210e-04 -8.0123069e-03 -9.0608941e-03  1.0038519e-02
 -3.1151930e-03  9.5048752e-03  1.1611657e-02 -1.5043312e-03
 -2.2477079e-03  2.1001557e-02  5.5884058e-03  3.8262992e-03
  1.7405551e-02 -9.3751894e-03  1.2004810e-02  4.1960021e-03
 -4.4912156e-03  7.2631566e-03  2.1183871e-02  1.1777821e-02
  8.6947726e-03  5.4446736e-04 -6.6359467e-03  1.1537194e-02
 -6.7846058e-03 -1.0967360e-02  1.4984755e-02  1.7801067e-03
 -7.1688672e-04  8.1374049e-03  1.5865499e-02 -7.5704562e-03
  1.6071310e-02 -5.5129984e-03  9.7223753e-03 -6.3599800e-03
 -6.0109128e-03  2.2786863e-03 -6.1659892e-03 -1.2594071e-03
 -1.3799478e-02 -8.3391303e-03  3.9777430e-03 -4.3937918e-03
 -1.6122440e-02  1.1637957e-02  2.1831377e-03 -3.7708450e-03
  2.2155126e-03  8.8216681e-03  1.8377407e-02 -3.6242299e-03
  2.4310867e-03 -9.1690887e-03 -6.2068491e-03 -1.7047467e-02
  2.9794464e-05  1.0429059e-02 -3.8060341e-03  2.8916879e-03
 -3.4908836e-03  1.8135675e-03  1.7911818e-02 -1.4227778e-02
  3.0538023e-03 -1.1630388e-02  3.3601655e-03 -1.1292440e-03
 -3.6740915e-03 -9.2008645e-03 -2.2836680e-02 -1.3434218e-02
  6.8677710e-03  7.7328482e-03  8.9440029e-03 -2.2275727e-02
 -1.1404881e-04 -1.9112248e-04  6.5137967e-03  6.2035182e-03
 -1.9639302e-02  4.0035760e-03  5.0705536e-03 -3.1523224e-02
 -4.9412702e-03  7.4517494e-03  1.7115487e-02  9.8829381e-03
  2.0945996e-02  1.6444806e-03  4.6647244e-04  1.2523245e-02
 -2.8288073e-03  9.4568087e-03 -5.0393729e-03 -1.0654696e-03
 -3.9280611e-03 -9.2196362e-03 -1.0713298e-02  2.3477082e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_15/kernel
[[ 0.05246225 -0.06279387 -0.12597659 ...  0.10803561  0.09843175
  -0.10312839]
 [-0.12539321  0.11773694 -0.06260729 ... -0.10054577  0.03871981
  -0.02390981]
 [-0.0389884   0.14012608 -0.04432094 ... -0.07202137  0.05648494
   0.03298803]
 ...
 [ 0.05144707  0.07473721 -0.08857159 ...  0.05125837  0.07905746
   0.07900874]
 [-0.01811103 -0.07594008  0.0071213  ...  0.10712332  0.02948149
   0.02213174]
 [-0.10470317 -0.082753    0.05762632 ...  0.03622533 -0.03179907
   0.11437817]]
tensor_name:  TemporalFusionTransformer/time_distributed_16/bias
[-9.13499389e-03  5.93869342e-03  1.92720126e-02 -1.89075377e-02
  2.64226645e-03 -9.07099713e-03 -5.87599352e-03  1.00906324e-02
 -1.43800932e-03 -1.30082946e-02 -6.18453138e-03  2.47119982e-02
 -2.52169501e-02 -8.33226368e-03 -1.08808228e-04 -8.92507844e-03
  4.75011393e-03 -4.42344695e-03  8.29212426e-04  1.38478959e-03
 -1.80145707e-02  8.11800928e-05  1.19111678e-02  2.67729983e-02
  5.20720566e-03 -5.14951814e-03 -7.61470292e-03 -1.08286412e-02
 -2.12648530e-02  6.23165024e-03 -5.98777551e-03 -1.22961244e-02
 -7.81358778e-03  9.23419558e-03  1.41774332e-02  1.18894083e-02
 -1.06313406e-02 -4.54893010e-03  1.08655365e-02  8.50473624e-03
 -1.85599253e-02 -3.40660033e-03  1.23574845e-02  9.73218307e-03
 -1.12990821e-02  4.99113696e-03 -1.88640878e-03  2.53439834e-03
 -3.34560149e-03 -1.21186509e-04  7.48379296e-03  6.97883498e-03
 -1.09843658e-02 -5.11786388e-03 -2.10677180e-03  1.34123797e-02
  1.82141345e-02  1.63300596e-02  1.01962294e-02 -9.81594156e-03
 -1.05282674e-02  1.31901577e-02 -1.55803869e-02  4.43822355e-05
 -9.71460063e-03  6.02624705e-03 -1.96610689e-02  7.38779735e-03
  7.30074942e-03 -5.83505584e-03  2.23419140e-03 -8.88643693e-03
  2.29756767e-03  7.15924241e-03  1.16820857e-02  1.14084659e-02
  1.02480138e-02  1.17508098e-02  1.97757082e-03 -1.37453005e-02
 -7.96529837e-03  4.15697368e-03  2.80456094e-04  1.00231832e-02
  1.17715262e-02  1.79165474e-03  7.18300696e-03  2.55216565e-02
 -5.14684198e-03  5.92926401e-04  5.98406885e-03 -6.03982480e-03
 -7.39737938e-04  2.18888335e-02  1.93027721e-03 -1.08977826e-02
  1.19880366e-03  1.04566170e-02 -1.60493348e-02 -1.32886339e-02
  3.58188455e-03 -6.00069202e-03 -1.47657963e-02 -1.23809557e-02
 -7.66031072e-03 -1.06878141e-02  6.89645857e-03 -2.85190763e-03
 -6.59315381e-03 -3.14136129e-03  1.70838868e-03  4.07336699e-03
  3.76414880e-03  1.09214084e-02 -8.49402510e-03 -1.32892476e-02
 -8.92568566e-03  7.30905728e-03 -4.38661426e-02 -5.39690703e-02
  8.89531802e-03 -7.29903299e-03  1.21483598e-02 -1.54851086e-03
 -2.46966016e-02  3.15535115e-03 -7.25201471e-03 -6.78258308e-04
 -4.25989833e-03  1.15318261e-02 -1.16189551e-02 -1.14156387e-03
 -1.35705704e-02 -2.96366774e-03 -7.65357283e-04 -1.26175340e-02
  5.27014083e-04  1.17904935e-02 -1.45417359e-03 -3.39668430e-03
 -6.11268263e-03  7.38356402e-03  6.76764688e-03  4.49441606e-03
  6.28510537e-03 -4.08573635e-03  5.46679273e-03  9.53796227e-03
 -8.26621801e-03 -8.83918256e-03  3.81493429e-03  2.17758100e-02
  3.09516280e-03  8.35595746e-03  7.87356216e-03 -1.47145791e-02
  9.41676088e-03  1.81116443e-02 -8.70788004e-03 -4.09801840e-04]
tensor_name:  TemporalFusionTransformer/time_distributed_16/kernel
[[-0.07447296  0.04286041 -0.06580468 ... -0.01061557  0.14663242
  -0.05794084]
 [-0.10979436 -0.00850636 -0.1021364  ...  0.05119384  0.10299951
   0.05013344]
 [-0.00133781  0.0242127  -0.06081362 ...  0.10487059 -0.00429846
  -0.04495521]
 ...
 [-0.11336737  0.01548554 -0.0671151  ... -0.09602241 -0.08612131
   0.08017113]
 [ 0.11864631  0.09093249  0.0599248  ...  0.01542285  0.03990177
  -0.06084678]
 [-0.00070435 -0.04386557 -0.10074612 ...  0.14111336  0.11835726
   0.02419733]]
tensor_name:  TemporalFusionTransformer/time_distributed_17/bias
[-8.4613916e-03 -2.3200609e-02 -1.1804352e-02 -7.3155803e-03
 -1.0419990e-02 -4.2283334e-02 -4.2387038e-02 -3.5314906e-02
 -3.8751218e-02  3.9542844e-03 -2.8475061e-02  2.2006501e-02
  6.4285630e-03 -2.3696490e-02 -4.1604534e-02 -1.5936477e-02
 -1.9183865e-02 -3.4946367e-02 -3.9836735e-02 -4.8595895e-03
  1.7605207e-03 -3.5102174e-02 -1.4624717e-02  5.3122222e-02
 -6.5660022e-02  9.4782263e-03 -9.4337715e-03 -3.4449769e-03
 -1.0176251e-02 -4.4264771e-02 -3.7085183e-02 -1.4600693e-02
 -2.8674381e-02  1.5856551e-02 -8.0232294e-03 -4.6144603e-03
 -1.0269867e-02 -7.3033527e-02 -4.0921472e-02 -2.8087292e-02
 -1.3022572e-02 -3.6045052e-02  1.5974607e-02 -8.0628190e-03
 -1.2834037e-02  2.2043679e-03 -2.4085658e-02 -4.9827278e-02
 -4.7234558e-02 -5.9588753e-02 -4.2885728e-02 -3.6972217e-02
 -3.6952946e-02 -3.5226833e-02 -9.8106423e-03  3.6952444e-03
  1.7378785e-02  1.2065549e-02 -1.0050427e-02 -4.4065237e-02
 -5.0677381e-02  2.0674679e-02 -1.0406124e-02 -4.1046809e-02
 -1.4519491e-02 -7.0038758e-02  2.1235408e-02 -3.1888422e-02
 -1.6517168e-02 -7.4543931e-02  9.0530552e-03 -7.0994213e-02
 -3.8746189e-02 -1.5074310e-02 -3.9239943e-02 -4.8312679e-02
 -5.3585701e-02  1.9051503e-02 -3.4726102e-02 -8.0472585e-03
 -2.0976946e-02 -3.0129662e-02 -5.4805089e-02  1.0587822e-02
 -1.9238595e-02 -3.3076409e-02 -7.0596702e-02 -3.6218115e-03
 -4.5313749e-02 -2.4544787e-02 -1.1543889e-05 -1.7850390e-02
 -3.7165850e-02  6.8911188e-03 -2.0282006e-02 -1.0798482e-02
 -2.8074006e-02 -1.7471194e-02 -3.1846315e-02 -3.0115962e-02
 -1.1019407e-02 -2.7949659e-03 -2.3021154e-02 -8.5560884e-03
 -2.3154825e-02 -2.2317128e-02 -2.8462091e-02 -3.6285546e-02
 -1.4306221e-02 -9.0261837e-03 -5.0900713e-02 -7.8179009e-02
 -3.5475153e-02 -2.8047940e-02 -5.7617314e-02 -7.4499790e-03
 -2.0466790e-02 -1.7547152e-03  7.1229383e-02  1.1342226e-01
 -2.7846130e-02 -2.7585180e-02 -1.5528747e-03 -3.7141755e-02
  9.9387830e-03 -2.4139851e-02 -1.9614098e-03 -2.2217620e-02
 -2.8473420e-02  6.5224683e-03 -5.5276595e-02 -2.9026676e-02
 -8.1248824e-03 -5.7398025e-02 -2.7888317e-02 -3.6562453e-03
 -2.3700224e-02  1.8155733e-02 -1.7096065e-02 -3.1672876e-02
 -2.8421326e-02 -4.8116989e-02 -5.4706603e-02 -3.0710001e-02
 -5.3465001e-02 -3.3661228e-02 -6.3259751e-02 -3.3390794e-02
 -6.1095236e-03  5.2546086e-03 -3.4657121e-02  3.6631804e-02
 -5.4845322e-02  1.0872560e-02 -2.5448897e-03  2.6527423e-02
 -3.0319786e-02 -4.4750823e-03 -1.1055645e-02 -2.7527412e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_17/kernel
[[ 0.11188358  0.05634843  0.0950907  ... -0.07750329  0.09243561
  -0.1038445 ]
 [-0.15229525  0.06494567 -0.14028335 ...  0.12928526  0.03796696
  -0.05160739]
 [-0.00157491  0.07924109  0.08921467 ...  0.0496963   0.0859993
  -0.05726818]
 ...
 [ 0.10748991 -0.11735699  0.00762858 ...  0.00739282  0.11674292
   0.08456169]
 [ 0.13737921 -0.06419754  0.07675448 ...  0.02413305  0.04465427
  -0.00309716]
 [-0.09377781  0.13691953 -0.04890055 ...  0.00996843  0.00499718
  -0.10997827]]
tensor_name:  TemporalFusionTransformer/time_distributed_18/bias
[ 4.87008272e-03  1.70425717e-02  1.43683264e-02  1.17739439e-02
 -1.70922056e-02  1.09630157e-04  1.57074258e-02  1.01429150e-02
 -2.94873817e-03  8.42774659e-03 -2.34108660e-02 -3.38162831e-03
  5.51601499e-03  1.40385935e-02  9.13745817e-03 -1.18069835e-02
 -6.69485703e-03 -1.77109130e-02  4.33739610e-02 -2.88970070e-03
  1.50300758e-02 -8.03499762e-03 -1.57946125e-02  1.72946751e-02
 -5.84880728e-03 -2.55385768e-02 -4.53075953e-03 -7.04114884e-03
  2.94136927e-02  5.31564374e-03 -1.62854213e-02 -2.10455973e-02
  1.07715698e-02  2.92150676e-02  1.32928239e-02  1.19763101e-03
 -1.05648758e-02  8.95678718e-03 -1.19586906e-03  2.03421433e-03
 -2.08182214e-03  1.61923235e-04 -1.75907388e-02 -3.08714481e-03
 -4.42884257e-03  1.58605147e-02  2.07727365e-02 -2.31736358e-02
 -1.08062029e-02 -6.66789897e-03 -1.33856563e-02 -1.40717365e-02
  2.91597028e-03 -1.08513713e-03  1.27879810e-02 -1.50329554e-02
 -1.07860509e-02  8.98671523e-03 -1.50550611e-03  6.91114459e-04
 -5.20070875e-03  1.26975561e-02  2.78950366e-03 -1.76016688e-02
  9.39639565e-03 -2.59757265e-02 -7.01635797e-03  1.37745449e-02
  2.82236957e-03 -1.20262038e-02  9.19400156e-03  7.29061663e-03
 -3.49228014e-03  2.88947225e-02  1.17447944e-02 -1.59670524e-02
  6.08905917e-03  4.95682657e-03 -3.33473459e-03 -1.07506826e-03
 -1.45256361e-02  4.21021273e-03 -2.98965133e-05 -3.37950629e-03
  7.79224792e-03 -2.43444145e-02 -4.99171717e-03 -2.42338628e-02
 -1.28169078e-02 -9.64705646e-03  4.46168240e-03 -9.18895844e-03
  1.64305214e-02  1.79689098e-02 -1.34870308e-02 -5.02323685e-03
 -5.59639605e-03 -1.71787646e-02  3.56092863e-03 -3.05803120e-03
  1.06676610e-03  8.72368179e-03 -1.34705100e-04 -1.85079519e-02
 -1.16062947e-02 -9.88028711e-04  5.85557520e-03 -1.95145626e-02
 -3.63119543e-02  2.41165217e-02 -2.32851356e-02 -1.06356677e-03
  5.88509580e-03  6.83018100e-03  9.27198771e-03  1.41434884e-02
  7.19127525e-03  2.37181801e-02 -2.35259105e-02 -9.23887268e-03
 -5.66196116e-03  3.21122515e-03 -2.82607996e-03 -3.68452980e-04
 -7.72734056e-04 -2.79909335e-02  3.36621366e-02 -2.11810973e-03
 -2.35491246e-02 -1.06392289e-02  1.46375680e-02 -1.70412436e-02
  2.64883935e-02  4.25937091e-04  1.86860356e-02  1.18235303e-02
  2.92835408e-03 -4.55876403e-02  1.02645112e-02 -1.15988562e-02
 -2.63112709e-02 -2.21631024e-02 -9.70946159e-04  1.62186865e-02
  1.48971435e-02  2.38600541e-02  1.43261626e-02 -2.37309113e-02
  6.74201874e-03  3.07449624e-02 -1.02529246e-02  2.09108531e-03
 -2.98867654e-02  2.63871439e-02 -1.92607418e-02 -2.65079690e-03
 -1.18787037e-02  1.18799070e-02 -7.04015745e-03 -1.01183439e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_18/kernel
[[-0.09531665 -0.14145486 -0.03369408 ...  0.1287232  -0.02195604
  -0.08815431]
 [ 0.142825    0.06026686  0.11556541 ...  0.00942537 -0.08901456
  -0.0870473 ]
 [-0.00686617 -0.0278964   0.02517872 ... -0.04744246 -0.07605577
   0.01997615]
 ...
 [-0.01157696 -0.08843009 -0.00562947 ...  0.07072654  0.07846832
  -0.01783907]
 [-0.00720675 -0.04623897  0.09096514 ... -0.12866527 -0.14791857
   0.04937327]
 [ 0.05410986 -0.05275548  0.12844238 ...  0.07913454  0.0979057
   0.12748905]]
tensor_name:  TemporalFusionTransformer/time_distributed_19/bias
[-4.5350526e-02  4.7220322e-03  3.7753157e-02 -4.4114636e-03
 -2.1954961e-03 -1.2733969e-02  2.6382402e-02  8.4390835e-04
 -1.4151003e-02 -5.7547691e-04  1.1493512e-02  3.2171562e-02
 -4.1584549e-03 -1.6943362e-02 -4.6054916e-03 -2.4774464e-02
  1.1425112e-02 -4.6281745e-03  1.7634587e-02  3.9651142e-03
 -3.3257985e-03 -5.7775457e-03 -1.0941278e-02  9.9149998e-03
 -3.8755960e-03  1.5687697e-03 -7.0866733e-03 -1.6938094e-02
 -3.0064786e-02  2.5873305e-04 -2.6632147e-03  7.2491691e-03
  2.7303347e-02 -4.2975107e-03  8.1181275e-03  2.9389016e-02
 -2.2786519e-02  1.5879900e-03 -3.8746212e-02 -2.8032076e-02
 -3.2621978e-03 -1.3848010e-03  3.1434540e-02 -1.3195915e-02
 -6.4230829e-02  2.0679424e-02 -8.4363017e-03 -1.2675016e-02
  1.4230444e-02 -1.6947402e-02 -2.9512960e-03 -3.1431850e-02
  1.7838394e-02  2.0703601e-03 -5.0063482e-03 -3.3500936e-02
 -3.6406429e-03 -4.2568124e-04  7.5727305e-03 -9.8872036e-03
  6.3017276e-03 -1.5588796e-02 -3.7236035e-02 -3.0882647e-03
  6.5392507e-03 -1.3262453e-02 -2.6051698e-03  2.4722577e-03
  2.8682530e-03  2.0264579e-02  3.5581149e-03 -2.8028561e-02
  1.9266009e-02  1.4681944e-02  4.2341962e-03  5.6285285e-03
  6.5532723e-03 -1.9590911e-02 -6.5846550e-03 -7.1469828e-04
 -1.9516557e-02 -4.2559477e-03 -1.1168640e-02  1.2878043e-02
 -8.6293637e-04  5.2633899e-04  3.1658001e-02  3.8244079e-03
 -5.7278085e-03 -1.4165994e-02 -1.3545060e-02 -2.2960313e-02
  3.1481304e-03 -3.4768367e-05 -2.7777365e-04 -3.6156658e-02
 -2.5061416e-03  4.1939441e-02  5.9979754e-03 -1.3620242e-02
  2.3307053e-02 -6.6860816e-03  5.4306616e-03 -1.2384259e-02
 -3.4137044e-02  2.1556437e-02  6.2288772e-03 -9.7281542e-03
 -1.5020062e-03  1.9638393e-02 -2.8316144e-02 -7.0352452e-03
 -1.4184905e-02 -7.7357395e-03  2.0607615e-02  5.3409468e-03
  3.5525119e-04 -1.5908728e-03  2.5878999e-02 -8.3387736e-03
  5.2581765e-03  3.2372985e-03  6.9362456e-03 -8.7482724e-03
 -2.0782977e-02  6.2164580e-03  1.1783517e-02 -8.6615346e-03
  1.9159984e-02 -2.5103160e-03 -2.0936064e-02  2.5211483e-02
 -1.8411901e-02 -3.6808767e-03 -2.3567578e-02 -1.5137965e-03
  2.0534588e-02  3.3079360e-02  2.7568496e-03  8.5529005e-03
 -8.3336271e-03  6.2641730e-03  3.0408024e-03  2.7658653e-03
 -9.9619497e-03 -4.1124164e-03 -2.4776751e-02 -3.9991733e-02
  1.1500410e-02 -5.0760242e-03 -9.2338296e-03  1.6674425e-02
  3.4015417e-02  2.4671664e-02 -3.8251359e-02  4.8991083e-03
 -1.0916606e-02 -1.1397913e-02  1.3441994e-02 -4.2350334e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_19/kernel
[[ 0.13217597  0.0958306   0.08937723 ... -0.00411097  0.01465712
  -0.04329534]
 [-0.05985722  0.11193971 -0.09267871 ...  0.01783819 -0.12395194
   0.14006758]
 [ 0.01212476  0.04215343  0.0685925  ...  0.09814167  0.06339246
  -0.03252907]
 ...
 [ 0.04564184  0.11989427  0.05970126 ... -0.0402275   0.06494041
   0.148151  ]
 [ 0.02395478 -0.05851354  0.09419231 ... -0.11131871 -0.09021206
  -0.15841457]
 [-0.10335044  0.03907221  0.0385043  ... -0.08947779  0.09416912
   0.0848452 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_2/bias
[-2.23689619e-02  1.46609873e-01  1.27939731e-02 -1.28615778e-02
 -4.59573790e-03 -4.20885570e-02  3.62763321e-03  2.53136195e-02
 -2.64601912e-02  2.45822892e-02  3.37560214e-02 -1.85529329e-02
  4.77112364e-03  2.76187202e-03 -2.93350243e-03 -5.85598275e-02
 -1.69017259e-02  6.35107514e-03  2.53666341e-02  4.08843020e-03
  3.24475244e-02  2.31706407e-02 -1.51590249e-02 -6.74752577e-04
 -6.61105849e-03  4.71497234e-03 -3.33202444e-02 -2.96539837e-03
  1.06715667e-03 -1.02494971e-03 -2.89278328e-02 -2.03806348e-02
  2.77763065e-02  1.85678806e-03  1.10973679e-02  3.75522338e-02
 -1.52883260e-02 -1.72259975e-02 -2.54308973e-02 -7.90148415e-03
  4.87441802e-03 -1.04559017e-02 -4.59148884e-02  3.67704593e-02
  1.16751157e-02 -3.15322395e-04  1.10480972e-02 -1.20030763e-02
  2.12978162e-02  6.30630627e-02  1.03481952e-02  2.12737615e-03
 -1.42503949e-02  1.01723731e-03 -8.50802695e-04  1.25283748e-01
 -5.35717350e-04 -5.10836355e-02 -3.33017274e-03  1.32060619e-02
 -6.73020212e-03 -2.28679925e-02 -4.16915119e-02  1.26867536e-02
 -2.21057273e-02  7.12328590e-03 -1.79681890e-02 -2.73626279e-02
  1.09299561e-02 -5.26502617e-02 -2.04320159e-02  4.46218578e-03
  5.24129625e-03  8.86425190e-03  1.83694940e-02  9.93295852e-03
 -2.88946182e-03 -2.05631517e-02 -5.51843829e-03  2.14640815e-02
  2.23092083e-02 -1.17175896e-02  3.97325233e-02 -5.60882967e-03
 -1.26878927e-02  6.68050721e-03 -1.47819771e-02  8.65543447e-03
 -2.94114780e-02  2.51493370e-03  4.06404305e-03  3.77165480e-03
 -2.13425886e-02  1.12766745e-02 -4.98279370e-02  5.75068593e-03
 -3.58826146e-02 -5.87661099e-03  4.62906761e-03  3.10637131e-02
  1.71910040e-02 -1.49695501e-02 -1.54390456e-02 -7.79854506e-03
 -3.36424517e-03 -1.99488457e-02  8.56485777e-03  4.09070067e-02
 -3.72055024e-02  4.70229704e-03  1.60183739e-02  4.58625816e-02
  3.30224214e-03 -1.04073995e-04 -4.02160957e-02  3.87462862e-02
  1.19128032e-02  5.54170795e-02  1.07137542e-02 -7.10389242e-02
  2.32840758e-02  1.17158378e-02  1.47452829e-02  2.21989937e-02
  3.82301956e-03 -1.76071171e-02 -2.40078615e-03  1.61086246e-02
 -4.90514282e-03 -1.72645580e-02  1.79339070e-02  1.80311799e-02
 -2.99486588e-03 -8.94414783e-02  1.33313295e-02  1.01641808e-02
  7.33008655e-03  8.94698035e-03 -3.91999260e-03  3.17648090e-02
 -2.97237504e-02  9.42872651e-03  2.65540946e-02 -1.19816288e-02
 -2.13633943e-02  5.33688173e-04 -2.86405720e-02  3.00778877e-02
 -3.90593335e-02  9.37438384e-03 -1.70952387e-06 -2.11524088e-02
  1.69806127e-02 -9.09057930e-02  1.74700574e-03 -5.36685227e-04
 -5.77460416e-03 -2.99596451e-02  8.66514910e-03 -2.63606887e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_2/kernel
[[-0.16795054  0.20318149  0.01942774 -0.05230247  0.00640672 -0.13665949
  -0.08011001  0.10674662 -0.1787138  -0.02504962  0.05959157 -0.09923969
   0.14335549  0.00684386 -0.01302195 -0.09459041 -0.02306281 -0.03006756
   0.10685747  0.07190948  0.08504501  0.16170289 -0.03575988  0.0535193
   0.16659133 -0.13883135 -0.06268075 -0.05951686  0.11224882 -0.00782071
  -0.11550775  0.05911469  0.12373122 -0.00835752  0.0270609   0.02850322
  -0.01838303 -0.04495662 -0.10344373 -0.02746809  0.00311296 -0.02028814
  -0.04054324  0.07033384 -0.10906871  0.1931935   0.12496623 -0.17847277
   0.05676284  0.16867694  0.17395839  0.12802151 -0.01999451  0.0761628
  -0.01119464 -0.29197204  0.00258012 -0.13334516  0.10782245  0.14270833
  -0.03851887 -0.08004823 -0.15617782  0.20874874  0.01365314  0.06347035
   0.13466161 -0.0501675  -0.02681313 -0.20595637 -0.06019699  0.13980348
   0.12083277 -0.13300438  0.01971228 -0.09517213  0.00239246 -0.13750397
  -0.00598598  0.03397322  0.01207882 -0.19284673  0.13788283  0.01002414
  -0.03594093 -0.15280217  0.09404883 -0.0209755  -0.17853351  0.00402065
   0.00212541 -0.01326605 -0.07706451 -0.19995518 -0.13786545  0.08837699
  -0.06431885 -0.19585082  0.01182683  0.0728382   0.1674583  -0.01812288
  -0.20746325  0.04137463 -0.03406972 -0.18575566  0.08659802  0.10425182
  -0.08551413  0.12395202  0.03344251  0.12017305  0.01685921 -0.1965225
   0.0704546   0.05765764 -0.00943527  0.13024354  0.20104966 -0.19600642
   0.13278565  0.04898374  0.23362646  0.15867603 -0.05762576 -0.12733458
   0.06359383 -0.15699251 -0.00637976 -0.18756168  0.0661587  -0.00720722
  -0.18474694 -0.07877387  0.04754766 -0.19153677  0.03047617 -0.09076341
  -0.08095954  0.21540734  0.14946215  0.01712864  0.11110649 -0.1287518
  -0.07874268 -0.12551126 -0.16466919  0.1185471  -0.09304082  0.00123969
   0.1403655  -0.20929144 -0.09421419  0.29320347  0.01493823  0.01449859
   0.15877454  0.0390828   0.13009132  0.01253655]]
tensor_name:  TemporalFusionTransformer/time_distributed_20/bias
[ 0.00690649 -0.01936498 -0.01877083  0.01477264  0.02544231 -0.03895234
  0.00932316 -0.03123049  0.00423878  0.00113423  0.00069312  0.0637436
 -0.02745235 -0.02308238  0.0131144   0.04111996 -0.00660053 -0.02531773
 -0.00669238 -0.01176766  0.01448168  0.00718291  0.05919405  0.01564843
  0.0186439   0.00712044 -0.03965513 -0.03988346 -0.04129522 -0.00257607
 -0.02500522 -0.01805149 -0.01811509 -0.00409494  0.0237949  -0.00449594
  0.0012992  -0.03901981  0.00208643 -0.0158444  -0.0180936   0.03240414
  0.02823182  0.03365882 -0.02762675  0.00137408  0.00892088 -0.00705482
  0.00556614 -0.00123598 -0.00190207  0.0249712  -0.00893995  0.02837119
  0.02250623  0.01426741 -0.01682927  0.00760039  0.03708391 -0.01755663
  0.01073641 -0.02051248  0.00019628  0.01079214  0.01316131  0.07945945
 -0.02132205  0.03681235  0.01873433 -0.02330187 -0.01600385 -0.07159977
  0.01287358  0.02904464 -0.00453047  0.0234829   0.04710355  0.02968217
  0.00040404 -0.04459228 -0.06070578  0.00913841  0.01462493  0.01125357
  0.04454909  0.06668869  0.01691711  0.05379542 -0.02466447 -0.00165369
  0.02311088  0.00531675  0.03513955 -0.00201663 -0.01071086  0.026407
 -0.00119501  0.00929139 -0.01004387 -0.00258167 -0.04423946 -0.01665481
 -0.05277163  0.0228195  -0.01629798 -0.01933535  0.03839104 -0.01999397
 -0.00451458  0.00527526 -0.0211642   0.01757306 -0.02599629  0.05672814
 -0.02265249 -0.02523455 -0.03285936  0.01380057 -0.08267008 -0.06260519
  0.04983978 -0.03130562 -0.00130257  0.0083515  -0.03213841 -0.01008455
 -0.02611475  0.0047991   0.00111959  0.00812831 -0.03071727 -0.03256014
  0.02117469 -0.01181769 -0.01127822 -0.03167289  0.01490732  0.003675
 -0.04513997 -0.01014686  0.03944701  0.01442406  0.01058059 -0.02393051
  0.01870922 -0.02619182 -0.0007474   0.01071507 -0.03316684 -0.01494776
 -0.01041829  0.00652769  0.02264148  0.03386543  0.01370125 -0.01141628
  0.00459805  0.02685849 -0.02363802 -0.01150151]
tensor_name:  TemporalFusionTransformer/time_distributed_20/kernel
[[-0.00135465 -0.07233392  0.05642043 ... -0.14142041  0.00458636
   0.00799042]
 [-0.18691897 -0.04835613  0.1525507  ...  0.0403964   0.05279281
   0.16565594]
 [-0.00226359  0.05560088  0.05346806 ... -0.00292698  0.07903899
   0.10311145]
 ...
 [-0.12151641 -0.05599623  0.10939133 ...  0.11939637 -0.10617568
   0.12142977]
 [-0.09091152 -0.06242388  0.03637628 ...  0.06341075 -0.11301398
   0.00671014]
 [-0.12656915  0.09991167 -0.03270775 ... -0.01998134 -0.07220975
   0.21735428]]
tensor_name:  TemporalFusionTransformer/time_distributed_21/bias
[ 1.07986994e-01 -9.56036448e-02  8.94824229e-03 -1.16598234e-01
 -9.11616087e-02 -1.62095949e-02 -8.23120028e-03  1.22028068e-02
  6.73257858e-02 -1.78941023e-02 -4.05660719e-02 -6.92745298e-03
 -3.68005484e-02 -8.91573206e-02  3.79435346e-02 -3.59618440e-02
 -4.00343910e-02 -5.11790626e-02  9.60833430e-02  1.91021687e-03
 -1.70471631e-02 -3.27740610e-02 -3.44561972e-02 -9.34810638e-02
 -4.42962572e-02 -2.15574503e-02 -1.10531496e-02  4.38604765e-02
  2.76787579e-03 -1.58701673e-01  2.34597991e-03 -2.15978250e-02
 -8.74492750e-02 -1.07657351e-02  5.45616373e-02  8.85653421e-02
 -1.69127379e-02  6.72844723e-02 -4.76105362e-02 -8.28385260e-03
 -1.24370463e-01  1.17607668e-01 -2.16849260e-02  2.65853573e-02
 -3.99746522e-02 -5.33303805e-02 -1.20440952e-01 -1.15226053e-01
 -1.06645666e-01  4.35789526e-02  8.53567645e-02 -2.49963757e-02
  7.87077285e-03 -2.76052319e-02 -2.73848809e-02 -2.91903093e-02
 -7.88021162e-02 -6.04131222e-02 -1.45413354e-02 -1.29524367e-02
 -6.52976409e-02  1.60098560e-02  1.02905892e-02  6.52146563e-02
 -5.24939671e-02  1.84668079e-02 -3.61600108e-02  1.56152621e-01
  3.43669504e-02 -6.00278117e-02 -6.55544251e-02 -1.20574674e-02
 -4.43614796e-02  2.80811228e-02 -3.08191646e-02  6.12737052e-02
  3.93572040e-02 -1.57939978e-02 -1.01532936e-01 -3.79061885e-02
 -3.90295424e-02 -3.06248534e-02 -8.42461735e-02 -5.52642979e-02
  4.58622584e-03 -1.27659133e-03 -2.09478606e-02 -4.58467677e-02
 -4.78222081e-03 -1.12697393e-01  1.44066871e-05 -1.42973056e-02
 -3.93816046e-02 -5.29814325e-02 -8.33023340e-02 -1.74645316e-02
  4.89724502e-02 -9.18812752e-02 -8.25770348e-02 -9.96876322e-03
 -2.67214724e-03  1.40901823e-02  2.25590561e-02 -3.92088518e-02
 -6.56633079e-03  7.66360164e-02  5.03279530e-02  8.56184680e-03
 -3.88998864e-03 -2.29305550e-02  7.20042810e-02 -3.29543017e-02
 -3.55154574e-02 -1.60629489e-02  2.04902869e-02 -5.58135547e-02
 -4.59249727e-02  3.38051170e-02 -7.87716731e-03 -1.69865396e-02
 -2.60704081e-03  2.05742605e-02 -6.40351921e-02  5.59515543e-02
 -1.80110428e-02 -1.51314819e-02  9.45375860e-02 -6.42138571e-02
  9.09338072e-02 -5.74722923e-02  2.43291259e-02  7.86832571e-02
  1.44665793e-01 -1.82613116e-02 -4.62289713e-02  2.17945930e-02
  3.95797007e-03 -1.31031517e-02 -4.69733737e-02 -1.61316562e-02
 -1.58214718e-02 -3.35538723e-02 -8.35986435e-02 -1.82677116e-02
  2.04979237e-02 -6.98862970e-02  7.83946831e-03 -4.52212319e-02
 -6.63244501e-02 -2.74625774e-02 -2.80802306e-02  1.40789431e-04
  6.24101190e-03 -7.44409189e-02 -2.23555788e-02 -4.62579243e-02
  1.55213401e-02  1.05017787e-02 -4.20384780e-02  1.09220274e-01]
tensor_name:  TemporalFusionTransformer/time_distributed_21/kernel
[[-0.07706525  0.10694329 -0.09349939 ...  0.05609306  0.06976464
  -0.14328565]
 [ 0.00895268  0.02091915 -0.107092   ... -0.10296893 -0.02968522
  -0.09680445]
 [ 0.0567263  -0.02534649 -0.00861031 ... -0.00804705 -0.05753832
  -0.02082136]
 ...
 [ 0.01885002  0.10226652  0.048028   ... -0.09662899 -0.05698142
   0.06029771]
 [ 0.10279983 -0.09796106 -0.02195048 ... -0.1350051   0.08702999
   0.01154197]
 [ 0.08124412  0.02333735  0.10695257 ... -0.12494561  0.03826993
   0.05379355]]
tensor_name:  TemporalFusionTransformer/time_distributed_22/bias
[ 0.01482161 -0.03158281  0.00639302 -0.01049265 -0.04307233 -0.00798582
 -0.02896977 -0.03747099 -0.001641    0.00141361 -0.04642005 -0.00440499
 -0.04792802 -0.05635529  0.01931639  0.01030905  0.0049339  -0.0414329
 -0.05620556  0.02376151 -0.03486149  0.02642886  0.0069166  -0.07040104
 -0.0383553  -0.00536768  0.01413411  0.00478124 -0.04594166 -0.02624168
  0.02354953 -0.04708416 -0.00272901 -0.01061995  0.00228421  0.01661864
 -0.00334008  0.01915978  0.01857161 -0.04573869 -0.03651727 -0.02967875
 -0.07632062 -0.02565787 -0.07391584  0.00625756 -0.04071286 -0.05514434
 -0.01771823 -0.0263662   0.02351839 -0.07327961  0.00666859 -0.00415813
 -0.06597153 -0.01520314 -0.04455239 -0.02173368  0.00142521 -0.07258892
 -0.02137638 -0.04627223  0.00154578  0.00476678  0.01267904 -0.03832067
  0.01459788 -0.0198905  -0.00469081 -0.03560273 -0.03537699  0.02221644
  0.02182539  0.00416476 -0.05901391 -0.02200769  0.01029628 -0.01722099
  0.01442766  0.01982455 -0.00098262  0.02196403 -0.00427693 -0.01159217
 -0.01367598 -0.03106038  0.05273229 -0.02533537  0.0099378  -0.01243232
 -0.00879436  0.02053929 -0.04306605 -0.00329397 -0.03120355 -0.02714616
  0.0090572  -0.03922982 -0.02409066 -0.00379732  0.003254    0.00686275
  0.02433829 -0.04022854 -0.01167761  0.01485611 -0.02661787  0.04685476
  0.02856517 -0.07326511  0.0130807  -0.01795365  0.00079062  0.00870645
  0.00264791 -0.01812091  0.01151112  0.03896213 -0.00072782 -0.03219618
 -0.01605586 -0.0096041  -0.05492147  0.03045458  0.01470872 -0.06625994
 -0.00240887 -0.04569546 -0.01768356  0.02338954  0.01222577 -0.01027154
  0.03897937 -0.02116633  0.0059103   0.01672332  0.02682238 -0.043411
 -0.04450838 -0.00982922  0.00859454 -0.00075797 -0.03441697 -0.00060945
 -0.02992147  0.01491185  0.00500664 -0.01609969  0.03649367 -0.01165819
 -0.06045405  0.03593752 -0.00836593 -0.00289274 -0.01861914 -0.02091728
  0.00328492 -0.00342502 -0.03497371 -0.01273712]
tensor_name:  TemporalFusionTransformer/time_distributed_22/kernel
[[ 0.12023445  0.04780594  0.09519057 ...  0.08752887 -0.02507703
  -0.04552503]
 [-0.11760411  0.0275385   0.11405036 ... -0.01287702 -0.09695018
  -0.02605527]
 [-0.12052612  0.14716999  0.06306806 ...  0.13059689  0.10039293
  -0.03723693]
 ...
 [-0.02106395  0.12167677  0.08720272 ...  0.00404556 -0.03843367
   0.02626454]
 [-0.07519971  0.00747451 -0.00253562 ... -0.08793153 -0.00853296
   0.0772649 ]
 [ 0.07170967 -0.07289038  0.06138641 ...  0.04997054  0.12067784
   0.02323779]]
tensor_name:  TemporalFusionTransformer/time_distributed_23/bias
[ 0.0188932   0.04052747 -0.00924257  0.03150829 -0.00130045 -0.02505714
 -0.03278308  0.01032872  0.03503595 -0.01348279 -0.0058496   0.01037958
  0.0278936  -0.00929298  0.00933071  0.01024378  0.03045405  0.00864252
  0.01763534  0.01140265 -0.03500919  0.00509707 -0.01624598  0.02521215
 -0.04514096 -0.00746793 -0.00528393 -0.0011049   0.00272203 -0.02519219
  0.02787118 -0.03846315  0.00266502 -0.00332074 -0.01798502  0.00158693
 -0.00565375  0.00620357  0.03159565 -0.00708095  0.03841322  0.03557923
  0.00805799 -0.00541223 -0.04248277  0.01049872  0.01004535  0.0589004
  0.01296768 -0.04645268  0.00645553  0.01559028 -0.02184834 -0.03469834
  0.05184676 -0.03920656  0.0049834  -0.03620157  0.00117199 -0.0423738
  0.01283103  0.00038828  0.00953605  0.0094539  -0.00687189  0.03951115
 -0.00905028  0.00888124 -0.01044537 -0.02669166  0.01212853  0.02894432
  0.04459816 -0.00607479 -0.00921648  0.00260058  0.02952613 -0.00883481
 -0.00341877 -0.03317449  0.02459807  0.00100809  0.02119872 -0.01852175
 -0.00983927 -0.03091641  0.02042962 -0.01079755 -0.0004444   0.00471124
  0.03857836 -0.01148064  0.01770294 -0.0078398   0.00773755 -0.02441232
  0.01646477 -0.00648108 -0.01304086 -0.03226199  0.0075693   0.00776358
 -0.00805463  0.00875011 -0.0028383  -0.03522952 -0.01252651  0.01054604
 -0.01299145  0.01275714  0.01125532 -0.00672768 -0.00777363  0.01326817
  0.01609189 -0.05082472 -0.001094   -0.01257003  0.00235083  0.03086135
 -0.00130884  0.00232204  0.02317707  0.01838097 -0.0158311  -0.00165472
  0.01357784 -0.01082969  0.00769017 -0.01398417  0.0240787   0.01652655
 -0.00151256  0.01261251  0.02235459  0.01042161 -0.00607527  0.03556829
  0.00079694  0.03686699 -0.02680911  0.0096485  -0.02624488 -0.05180055
  0.00934355 -0.02665833  0.01113224  0.01445336 -0.0142432  -0.00992876
 -0.01833807  0.02965124  0.0055952   0.04571161 -0.03144808  0.06178469
  0.04500068 -0.02435522 -0.00077486 -0.02872565]
tensor_name:  TemporalFusionTransformer/time_distributed_23/kernel
[[-0.08259168 -0.1210305   0.08910835 ...  0.12241892  0.04631646
   0.01835553]
 [-0.11393078 -0.02658066 -0.11215572 ...  0.10040718 -0.09721106
  -0.04539979]
 [-0.14470692 -0.01835533  0.11061254 ...  0.11215976 -0.14826104
  -0.0618246 ]
 ...
 [-0.00934395  0.08514894 -0.11945463 ...  0.09243355 -0.08961315
  -0.02549687]
 [ 0.0931305  -0.03089286  0.13894211 ...  0.11049438  0.07756796
  -0.06076976]
 [-0.0525315  -0.02309989 -0.00808492 ... -0.08440025 -0.0327694
  -0.06530546]]
tensor_name:  TemporalFusionTransformer/time_distributed_24/bias
[-3.65568465e-03 -4.38248254e-02  1.90511588e-02  3.58276442e-03
  1.98415834e-02  7.02366745e-03  7.59477587e-03  3.36719560e-03
  1.14644999e-02 -2.29224022e-02 -1.77642554e-02  9.21595376e-03
  6.81061158e-03  3.76724303e-02 -1.90208424e-02  6.67710276e-03
 -1.03846996e-03 -2.66030002e-02  4.20247787e-04 -1.52783860e-02
 -2.11334391e-03 -1.22479582e-02  5.30892052e-02  1.22077428e-02
 -2.00856198e-02 -7.10897474e-03  3.40905599e-03 -3.22225690e-03
 -3.47603150e-02 -1.27931442e-02  2.03969255e-02 -1.00010009e-02
 -2.23403703e-02 -3.82121722e-03  4.39708829e-02  1.25310943e-03
 -5.82625251e-03 -3.48328543e-03  4.11478616e-02 -4.75638127e-03
  3.77223175e-03  1.08381771e-02 -1.62121020e-02 -2.60882569e-03
  1.36921601e-02 -4.56240103e-02  3.29790637e-02  6.75008968e-02
 -5.46306372e-02  8.21160339e-03  7.25443568e-03 -2.08707526e-02
 -2.24543810e-02 -1.31808324e-02  1.47552257e-02  7.76866172e-03
 -1.04620389e-03  2.32980996e-02 -2.25559203e-03 -1.43658975e-02
 -2.57562529e-02  1.26652475e-02 -2.11639479e-02  9.40330047e-03
  1.66502111e-02 -6.31387287e-04 -6.05554208e-02  9.69459210e-03
  3.75571102e-02 -1.22576784e-02 -2.55253669e-02  1.55762890e-02
  2.18281075e-02  1.86778549e-02 -5.47773838e-02  2.13116724e-02
 -1.79514699e-02  2.31179222e-02 -2.97849495e-02 -1.36948312e-02
 -4.09844555e-02 -3.82949114e-02 -7.13916123e-02  3.47529016e-02
 -1.28658740e-02  6.31881040e-03  1.17742987e-02 -2.96644531e-02
  3.03461011e-02  3.13936174e-02  1.96489822e-02 -2.11189594e-02
  5.78706167e-05  3.28496359e-02  1.68522820e-05 -5.90531416e-02
 -7.61600313e-05 -1.82201602e-02 -7.11266138e-03  3.91176902e-03
 -7.22117722e-03 -4.31840718e-02 -3.76920588e-02  7.66270910e-04
 -2.98418272e-02 -5.79799293e-03 -4.25223401e-03  9.67710512e-05
 -2.28506960e-02  6.11295458e-03 -1.74673051e-02 -1.42552133e-03
 -4.19100747e-02  2.86666006e-02  5.99221140e-03 -2.21534725e-02
  7.50392023e-03  3.92185478e-03 -1.17773833e-02 -4.93209474e-02
  3.55125032e-02 -2.89211213e-03  4.30362374e-02  2.17631925e-03
 -1.49780679e-02  1.21388622e-02 -1.64442547e-02 -1.58723220e-02
  1.73272248e-02  2.26122960e-02 -1.31953005e-02 -2.91399676e-02
 -1.63933225e-02  3.83123010e-02  2.75111496e-02  2.22582314e-02
  3.47897895e-02 -5.52120153e-03 -6.63819432e-04 -1.97077487e-02
  1.14840260e-02  9.09757987e-02 -1.81723014e-02  3.79226729e-02
  2.55033001e-02  1.65177975e-02  4.84669060e-02  2.50352696e-02
  5.52165415e-03 -7.61501212e-03  2.15950068e-02  1.25295492e-02
 -1.71341151e-02  2.13298481e-02  9.54223424e-03  2.12408733e-02
 -6.26227260e-03  5.97524047e-02 -2.12389641e-02 -2.29387525e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_24/kernel
[[ 0.00640975 -0.18686494 -0.12810728 ... -0.0846229   0.04716386
   0.05258344]
 [-0.03773385 -0.17435531  0.0019719  ...  0.09789132  0.04418136
   0.04976341]
 [ 0.00894964 -0.05253422  0.11235646 ...  0.02917832 -0.02342878
   0.02696931]
 ...
 [ 0.09780685  0.02593147 -0.02041382 ...  0.13031815  0.04168117
  -0.06914271]
 [ 0.00867405 -0.01828136 -0.03654179 ... -0.11167348  0.04268822
   0.13414438]
 [-0.13034897  0.20173183  0.03477205 ... -0.06086414 -0.11700572
  -0.1381581 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_25/bias
[-0.01363126  0.09287766 -0.12178818 -0.08603318 -0.05693465 -0.05242215
 -0.10604869 -0.0336233  -0.0415734  -0.06416451 -0.02805301 -0.0881319
 -0.00806047  0.06353348 -0.04971534 -0.05536539 -0.03999006  0.03084918
 -0.06226508 -0.01795956 -0.0718386  -0.0821072  -0.03669005 -0.02625816
 -0.07385064 -0.0635303  -0.03452248 -0.03826302  0.00535319  0.01615298
 -0.0014755  -0.00102875 -0.05071206  0.03461017  0.03806196  0.02236053
 -0.06128985 -0.10225879 -0.02306076 -0.00759574 -0.07593345 -0.10463208
 -0.0669337  -0.11980525 -0.13915782 -0.10222056 -0.01300861  0.06730287
 -0.01180741 -0.03429801  0.06220806 -0.05995362 -0.03702221 -0.04171167
  0.02843864 -0.07450771 -0.04592751 -0.05607758 -0.04592041  0.00604597
 -0.07853732 -0.1045787   0.0220409  -0.06970599 -0.03188832 -0.01842245
  0.03652837 -0.12301213 -0.03765037 -0.10144552  0.01801254  0.04206999
 -0.04376585 -0.12740913  0.01346851 -0.09305283 -0.1535645  -0.10535897
 -0.01267796  0.00351574  0.03802963 -0.05743046 -0.00054849  0.01661308
  0.05833179 -0.05802862 -0.11215216  0.05231348  0.03608416 -0.04792935
 -0.07603417 -0.04997788 -0.04893976 -0.01734687 -0.0890017   0.01559963
  0.00938219 -0.07278677 -0.0447658   0.00836948 -0.04282433  0.10798938
  0.06072497 -0.03313817  0.02613061  0.0221383   0.01499968 -0.0678683
 -0.03951478 -0.09843408 -0.06786755  0.0106511  -0.02186879 -0.03317016
 -0.01259215  0.01223869 -0.09158809  0.03685373  0.00752867 -0.02438653
  0.00086401 -0.06337932 -0.02610138 -0.07422331  0.00885002 -0.04846459
  0.00303303 -0.07140574  0.05523971 -0.10146978  0.01292675 -0.00736494
 -0.08005729  0.05712437 -0.05401633  0.02017832  0.00330788 -0.03366854
 -0.01532806 -0.04555518 -0.09636422  0.1261814  -0.01714137 -0.03611362
 -0.02334852 -0.0484636  -0.03995262 -0.03757666  0.04554325  0.03361598
 -0.06449383  0.05298564  0.0430178  -0.07897755 -0.04721191  0.07796776
  0.05418914  0.05414973 -0.02718266 -0.11019031]
tensor_name:  TemporalFusionTransformer/time_distributed_25/kernel
[[ 0.05819831  0.0242427  -0.08579595 ...  0.12854286 -0.03021315
  -0.01785236]
 [-0.13161024  0.10507829 -0.22044285 ...  0.13396722 -0.07557318
  -0.08492897]
 [-0.08523523 -0.03409902  0.11638261 ... -0.02948954  0.16534452
   0.01543915]
 ...
 [ 0.10841309  0.08878999  0.14069332 ...  0.11098772  0.05909298
   0.12360653]
 [-0.01469384 -0.05336944 -0.08577831 ... -0.11548111 -0.10382473
   0.14224848]
 [-0.05663219  0.09580564 -0.03419252 ... -0.06466478  0.1313672
  -0.07667979]]
tensor_name:  TemporalFusionTransformer/time_distributed_26/bias
[ 0.01561453 -0.03498007  0.01873814  0.04647775 -0.11327682 -0.08724836
 -0.08748032 -0.01280045 -0.08738516  0.02222252 -0.08106543 -0.01594837
 -0.00111436 -0.00524504 -0.08511072 -0.0353434   0.00259154 -0.05033764
  0.01664145  0.03808083 -0.06903272 -0.04336119  0.00275515  0.03598651
 -0.00877319 -0.05615582  0.02263129  0.03891545  0.04413351 -0.03693088
  0.03312704 -0.05351309  0.0067387  -0.00808452 -0.0821669  -0.05368777
  0.00842142 -0.08371961 -0.0140427  -0.00783904 -0.01473492 -0.00405692
  0.01792677  0.00092934 -0.05604431  0.00495681 -0.04171881 -0.01087188
 -0.03817004  0.04099909  0.00317064 -0.06453595 -0.07475323  0.03147557
  0.04244821  0.01363479 -0.01075514 -0.00183    -0.00644797 -0.07114758
 -0.06070263 -0.01786171  0.01101173  0.01880751 -0.02029288  0.01603407
  0.01046157  0.01881183  0.00560514 -0.01346648 -0.04850631 -0.0722386
 -0.07278241 -0.02730372 -0.00194371  0.03196696  0.04953312 -0.0056867
 -0.08048059 -0.01655975  0.01765188  0.06901835 -0.06039322 -0.0816898
 -0.07309734 -0.07186943 -0.06487371 -0.00708505 -0.01317269  0.01141026
  0.06589065 -0.00149279  0.01917072 -0.00267298  0.01766375  0.02812319
  0.01257992  0.00850848 -0.01910185 -0.02146128  0.01934868 -0.00415052
 -0.04344063 -0.00898346 -0.00599062 -0.00528868 -0.04758197 -0.03123174
  0.02907831  0.06997157 -0.04169361  0.01286862  0.0392517  -0.03074953
  0.01416837 -0.04363514  0.02342473 -0.00226328 -0.00805345 -0.0153292
 -0.0347327   0.01620463 -0.08542692 -0.01825068 -0.00807867 -0.08086554
 -0.00824264 -0.00684626  0.00969708 -0.0080882   0.06034515 -0.05616304
  0.01321478  0.03838371 -0.08952948  0.00626793  0.05508947  0.00274161
 -0.00309572  0.05377088  0.04598149 -0.07645515  0.01064091 -0.01707478
  0.00268297  0.00109049 -0.00683203  0.03413691  0.04370033 -0.04231492
  0.03085952 -0.00542299  0.06586643  0.02835781 -0.00639784 -0.06714977
  0.00172563 -0.05813726 -0.0030279  -0.06898431]
tensor_name:  TemporalFusionTransformer/time_distributed_26/kernel
[[ 0.1101933  -0.07985688 -0.10496181 ...  0.07546288 -0.06696817
   0.06610876]
 [-0.01831342 -0.04545148 -0.06140894 ... -0.06057116 -0.12442665
   0.05125692]
 [-0.10122947  0.05962654  0.03095651 ...  0.03159501 -0.02628298
  -0.07605239]
 ...
 [-0.03974375  0.06682054 -0.14277585 ...  0.02249695 -0.0881158
  -0.02008118]
 [-0.12078701  0.10985889  0.04384993 ... -0.02064417 -0.01347866
  -0.04907091]
 [-0.07200273 -0.03269017 -0.01076516 ... -0.12129164 -0.04465953
   0.04740705]]
tensor_name:  TemporalFusionTransformer/time_distributed_27/bias
[ 0.03359639 -0.02572174 -0.07098876 -0.034124    0.04135782 -0.01298237
 -0.06609777  0.03784412  0.02367258  0.02235462 -0.01580688  0.04080713
  0.06590254 -0.04671862 -0.07825734  0.05335658 -0.05177671 -0.01432671
  0.06234808 -0.04519375 -0.02421144 -0.01903111 -0.0219901  -0.05902506
 -0.03464467 -0.05574272  0.01843341 -0.01459148 -0.02183279 -0.01256581
 -0.05361385 -0.03626227  0.05104099 -0.01096768  0.08899021 -0.03326304
  0.02808604 -0.04499539 -0.01713417 -0.08599982  0.01473461 -0.03931829
  0.00677787  0.02415274  0.03783817 -0.01752988 -0.01615855 -0.01869402
  0.05145073 -0.06321321  0.01321618  0.00509808 -0.01580378 -0.01355538
 -0.07959481  0.02566297 -0.04135783 -0.02364519  0.00350859  0.05409675
  0.06091291  0.01433451  0.0377441  -0.05978779  0.00959116 -0.00643565
 -0.06575448 -0.05351796  0.0649044  -0.01125139 -0.03111917 -0.03380045
 -0.05416686  0.05315206 -0.00136015 -0.07767786  0.0580363  -0.01391256
 -0.0235961   0.03505339  0.03284234  0.01861848 -0.05067131  0.01020419
 -0.08921188 -0.06773365  0.00024461 -0.03404973  0.01699813 -0.05316823
  0.02190676 -0.00248751 -0.00929853 -0.00924417 -0.01526132 -0.03190688
 -0.04366836 -0.06674851  0.06929695  0.04852852  0.04427104 -0.0284758
 -0.00935326  0.05124262 -0.07798272 -0.01035022  0.08905112  0.05151511
  0.01762231  0.02747419 -0.05685821 -0.03408653 -0.04008758  0.00586805
  0.02346444 -0.02352159  0.02320177  0.00157353  0.07180098 -0.01741618
 -0.01033032 -0.0331095  -0.04185845 -0.04516903  0.0028499   0.0199935
  0.01948217  0.02626769 -0.04457312 -0.04123678  0.00054075  0.00561504
 -0.03080854  0.09183602  0.04381959 -0.00671809 -0.00101508  0.04069069
  0.04958626  0.02792263 -0.0406222  -0.02513549 -0.01595457  0.0647058
  0.020633   -0.06279221  0.06057722  0.00233098 -0.02820589  0.01886641
 -0.07326025  0.02911078 -0.06723483 -0.02424176 -0.05739311 -0.00536202
 -0.06195792 -0.06145221  0.03481203  0.02732651]
tensor_name:  TemporalFusionTransformer/time_distributed_27/kernel
[[-0.07942473  0.09573258 -0.02365406 ... -0.03562748 -0.02756745
  -0.08238907]
 [-0.01363875  0.11115478  0.04366292 ...  0.05929262  0.01122528
  -0.12569301]
 [-0.12198605  0.06785757  0.10729364 ...  0.03868503  0.10212626
  -0.11348812]
 ...
 [ 0.09158146 -0.07373835  0.10358816 ...  0.06764851 -0.12006953
   0.03457218]
 [-0.04744421 -0.00541604 -0.12480499 ...  0.08486759  0.07028365
  -0.02660467]
 [ 0.04002983 -0.04518825  0.02317069 ...  0.07262324 -0.09177801
  -0.14306755]]
tensor_name:  TemporalFusionTransformer/time_distributed_28/bias
[ 0.01061815 -0.01026267  0.05233786  0.0380316   0.02035093  0.03645205
 -0.01838167 -0.00848714  0.00417158  0.00206033 -0.01071884  0.05951057
 -0.0277584   0.01557552 -0.02909469 -0.07011899  0.03877385 -0.05207914
 -0.02998083 -0.00330271 -0.04390987 -0.03319332  0.00921946  0.02308367
  0.01504076 -0.00642962 -0.01833349 -0.01538777 -0.04312797 -0.02552087
  0.01440555 -0.05335629 -0.007179   -0.00014364  0.01880788  0.00336149
  0.00573062 -0.06013231  0.06049181 -0.02185841 -0.03143635  0.03020415
 -0.01914217 -0.01603122 -0.01144782  0.02390889 -0.00961781  0.0324603
 -0.01332676  0.02888343 -0.00599281 -0.00029289 -0.0030093   0.03190457
 -0.01326757  0.03071949  0.05754512  0.02107608 -0.02329338 -0.01369537
 -0.01311273 -0.00763244  0.03077224  0.02017742 -0.0158671  -0.00430038
 -0.09790806  0.05913526  0.0507286  -0.02091831 -0.01575519 -0.03676344
 -0.0078984   0.0360411   0.03423677  0.07574205 -0.08773334  0.01855071
  0.05205461 -0.0169132  -0.04337131  0.02803745  0.01771595  0.01477245
  0.01955588  0.00163427  0.0685721   0.02073877  0.00427619  0.00148532
  0.0321667  -0.03878865  0.01624864  0.02542343  0.01571039 -0.01292135
 -0.02882122 -0.04432133  0.01360197  0.040397   -0.0322684  -0.0056543
 -0.02612277 -0.03179799 -0.02131267  0.02119002 -0.00677606 -0.01509374
  0.00520201  0.01489439 -0.01624496 -0.02021068  0.01052992  0.02548276
 -0.01986191 -0.03437242  0.00732898 -0.01442306 -0.07735258 -0.01665437
  0.02636894 -0.0209492   0.01054229 -0.03638995 -0.00281048  0.04402407
 -0.05110539 -0.0301204   0.01361585  0.02230938 -0.0663727  -0.05117316
  0.01317637 -0.01236753  0.04303372 -0.01440055  0.01743496  0.00360751
 -0.02981997 -0.00659376  0.00089379  0.01917956  0.02318413 -0.00111307
  0.03163681 -0.03412384  0.0632195  -0.02291586 -0.01007141 -0.0139801
 -0.02172002  0.03715894  0.00863486  0.03037398  0.00350821 -0.0036695
  0.02090964  0.00907476 -0.01622289 -0.0163156 ]
tensor_name:  TemporalFusionTransformer/time_distributed_28/kernel
[[-8.72038007e-02 -5.09869643e-02  9.49790999e-02 ...  5.44792823e-02
  -8.58293921e-02 -7.33716339e-02]
 [-4.39891182e-02 -9.92436558e-02  2.94985976e-02 ...  1.11727096e-01
  -3.61048542e-02 -8.44466314e-02]
 [-3.03558819e-03 -8.09185952e-02 -2.43885685e-02 ... -8.46082568e-02
   2.09918506e-02  3.51743922e-02]
 ...
 [-1.83133651e-02 -2.83513106e-02 -5.66942282e-02 ...  3.04525048e-02
   3.08146421e-02  4.12218347e-02]
 [ 7.31045827e-02 -4.71275821e-02  1.05165504e-01 ...  7.21917599e-02
  -1.48945525e-01  2.94228103e-02]
 [ 2.32722871e-02 -1.38343254e-04 -1.52999192e-01 ... -7.51997977e-02
  -7.13124797e-02 -1.02630936e-01]]
tensor_name:  TemporalFusionTransformer/time_distributed_29/bias
[-3.67999338e-02 -4.98100333e-02  5.11704013e-02 -2.49764621e-02
  1.20897172e-02 -2.69442219e-02  1.16157167e-01 -1.02587901e-02
 -3.46033685e-02 -7.85071775e-02 -5.17490022e-02  1.30756078e-02
 -2.23981682e-02 -9.50625464e-02  1.68046877e-02  4.43079136e-02
  3.36633250e-02 -9.38572921e-05  5.87881245e-02  2.64391638e-02
  4.24110144e-02 -3.73991765e-02  5.06226793e-02 -8.31007864e-03
 -3.88155505e-02 -7.44896382e-02 -3.50645855e-02 -3.10806325e-03
 -1.30524952e-02 -1.29193896e-02 -4.41594161e-02 -8.85284622e-04
 -1.13340594e-01 -7.58590251e-02  3.00488174e-02 -1.95042696e-02
 -6.97294027e-02  5.10541536e-02  3.73986848e-02  2.58041127e-03
  6.48703426e-03  4.14270768e-03 -6.48763357e-03 -6.67349696e-02
  1.08961649e-02  3.87069769e-02 -7.16535896e-02 -4.08535525e-02
 -9.77864563e-02 -3.80466692e-02 -3.56549677e-03 -8.60619098e-02
  4.55572717e-02 -3.04150512e-03 -7.28875846e-02  7.99799897e-03
  1.52680874e-02 -2.45117061e-02 -9.28500220e-02 -8.55925158e-02
 -6.28659800e-02 -1.27925083e-01 -5.99318035e-02 -2.43427046e-02
 -3.92051972e-02 -2.42218785e-02  7.84289315e-02  5.79563975e-02
  1.63273960e-02  1.75226722e-02 -1.82495192e-02  4.30997927e-03
 -2.21728906e-02  3.75655331e-02 -6.08476736e-02  1.03025272e-01
 -3.50718647e-02 -6.21709600e-02  5.00421412e-03 -6.85731322e-02
  1.27275595e-02 -4.60688360e-02 -1.41500905e-01 -5.40659055e-02
 -2.74488889e-02  1.23269707e-02  1.56299695e-01 -5.26766479e-02
 -5.50857894e-02 -2.42053233e-02 -1.16982479e-02 -2.60136817e-02
  2.46508848e-02 -3.97493392e-02 -3.95779796e-02  1.36259636e-02
  8.01962893e-03 -1.10082896e-02  1.45212479e-03  1.07077628e-01
 -4.33847271e-02  8.15512426e-03 -2.18189247e-02 -5.25724096e-03
 -4.00292389e-02 -9.65298563e-02 -3.53341140e-02  2.98370421e-02
 -5.25931641e-03 -3.22551429e-02  6.85462505e-02  5.47714196e-02
 -5.85750639e-02 -1.47050051e-02  8.08472093e-03 -2.82426048e-02
 -4.51837778e-02 -4.71287668e-02  4.34097648e-02 -5.85427247e-02
 -1.39682526e-02 -6.24534413e-02  2.40595024e-02 -3.09578404e-02
 -3.58287953e-02  1.37250423e-02 -5.29822602e-04  2.53869290e-03
  1.92008726e-02 -8.67034197e-02  2.91643310e-02 -4.34787758e-02
 -8.51631686e-02  2.43587922e-02  3.85018252e-02 -1.99997369e-02
 -2.75669210e-02 -7.51504451e-02 -1.76788252e-02 -9.18574035e-02
 -1.04868524e-02 -4.53839675e-02  2.81596519e-02 -5.87812252e-02
 -4.12189849e-02 -2.29634121e-02  4.27668616e-02  1.69194043e-02
 -9.61180776e-02 -4.70081829e-02 -5.92389330e-02  3.25041674e-02
  1.69779435e-02 -1.02477875e-02 -1.86116528e-02 -1.19982824e-01
 -7.18227541e-03 -4.87621650e-02  6.79571554e-02 -6.14470094e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_29/kernel
[[-7.6095857e-02 -6.9131143e-02 -3.5325930e-02 ... -7.3200012e-05
   1.1337625e-01  2.3578485e-02]
 [ 8.6710185e-02 -1.1124806e-02  1.2436285e-02 ... -1.0651088e-01
  -9.3463890e-02 -5.9487171e-02]
 [-3.0623522e-02  1.0587521e-01  1.2349646e-01 ...  9.1378041e-02
  -1.6071096e-02  1.5458912e-01]
 ...
 [ 1.2004811e-01 -7.4540742e-02 -6.8448372e-02 ... -3.9397877e-02
   1.0193866e-01  9.4954185e-02]
 [-5.4073129e-02 -1.4379424e-02  5.0630305e-02 ... -1.3114434e-01
  -5.9338775e-02 -9.1142453e-02]
 [ 1.4897768e-03  4.1457873e-02  1.8777225e-02 ...  1.3688163e-01
  -6.6081613e-02  5.6433108e-02]]
tensor_name:  TemporalFusionTransformer/time_distributed_3/bias
[-0.0075569  -0.01807711 -0.06330784  0.00070213 -0.06150082  0.00231731
  0.05110499  0.02587048 -0.03411435 -0.12746821  0.00040228  0.06277903
  0.01720835  0.07050094  0.0606507  -0.06977098 -0.03575739 -0.07029815
  0.02080175 -0.04920387  0.00646897  0.03581756  0.02786997 -0.05731742
  0.01474724 -0.02289853 -0.03895348  0.01618958 -0.03325629  0.03388756
  0.0012578   0.06034929  0.02841762  0.01296617 -0.00337636  0.06230373
 -0.05937568  0.02821882  0.00970581 -0.0183371  -0.01262924 -0.0028295
 -0.0861813  -0.08101808  0.07413857 -0.07343236  0.06650285  0.02031505
 -0.05782385  0.03001981  0.03763214  0.0431683  -0.04341117 -0.06185423
  0.00573492  0.09323575 -0.06734003  0.02515373 -0.00886469 -0.02239058
  0.04155865  0.03113919  0.03915417  0.05614762 -0.0241186   0.06465361
  0.04284629  0.0001947   0.03712659 -0.10952759  0.07459836  0.04679093
  0.0528498   0.00823262 -0.07671013 -0.04933386 -0.05667993 -0.00658223
  0.02625694  0.0496681   0.02836421 -0.04440771 -0.03107245 -0.00545813
  0.02608149  0.05197513  0.05384175  0.03772907 -0.01188591  0.06243712
  0.0972319   0.02134014  0.06943054  0.09184956 -0.04244684 -0.07472325
  0.02251873 -0.0472032  -0.03021576 -0.05184259  0.05079611  0.00638352
 -0.04836136  0.06099127 -0.01180464 -0.00212179 -0.02367284 -0.01243908
 -0.03902619 -0.06402723 -0.06176079  0.0773401  -0.0788436   0.06175104
  0.00668564  0.05572223 -0.02402673  0.04670592  0.02391176  0.08073206
  0.03823873 -0.0039155  -0.04977005 -0.04084729 -0.02191883 -0.0146084
 -0.04226525  0.01362769  0.03746458  0.04659406 -0.02181585 -0.00168044
  0.0288085  -0.04553593  0.04289056  0.01967091 -0.00090688 -0.03303481
 -0.00545057 -0.09352012 -0.0078071   0.06841018  0.03067205  0.08572397
  0.05083986 -0.00053152  0.06067587  0.01796288  0.04492028 -0.02496741
  0.09164626 -0.00200827 -0.03144209 -0.07056835 -0.00613356  0.04502478
  0.02162067  0.01117054  0.04663112 -0.0352459 ]
tensor_name:  TemporalFusionTransformer/time_distributed_3/kernel
[[ 0.0458984   0.18533903  0.09763604 -0.00748017 -0.02890693  0.14353606
  -0.06711389  0.12353045  0.0222422  -0.01202559 -0.03113094 -0.05145316
   0.06525899  0.13392565 -0.02563519  0.10485706 -0.07923164  0.03022099
  -0.08085877 -0.01186619 -0.09771474 -0.1578579   0.09949377  0.11923386
  -0.01829399  0.19221385  0.15881602 -0.09427394  0.10801875 -0.23886381
   0.08119754  0.08780104 -0.17295125  0.1598679   0.1336971  -0.15044683
   0.03711121  0.1374876  -0.16979446 -0.08093618 -0.02007192 -0.15045106
   0.14607     0.05309108 -0.02788063 -0.13357268 -0.11315062 -0.00846875
   0.1983461  -0.05577014 -0.06377933 -0.0905574   0.0932673   0.09166083
   0.0324918   0.1909156   0.06344002 -0.11104967 -0.00145883  0.13299227
  -0.04636701 -0.06646272 -0.07022627 -0.04850112 -0.11893242  0.01023421
   0.09099099 -0.18320768  0.07919523  0.05750929  0.1253672  -0.10611989
   0.06703448  0.07854473 -0.26081792  0.18329029 -0.22984107  0.189922
  -0.14045626 -0.10667029 -0.16276556  0.17703173 -0.17937069  0.13673685
   0.01249231 -0.06158876 -0.15384963 -0.1085389  -0.17706709 -0.0193803
  -0.11780807 -0.16104093 -0.10524684 -0.10052451  0.05445275  0.11470542
   0.01370948  0.16491358  0.15017246  0.16032012 -0.01143613  0.12192779
   0.15147796 -0.04440088 -0.08558217  0.15183108 -0.09103806 -0.02611444
   0.01535178 -0.0796928   0.09873407 -0.07894927 -0.09051775  0.02884237
   0.15452516  0.00060905 -0.2032389  -0.14671463 -0.16019629  0.01972318
   0.11803005 -0.21011075  0.13072228  0.00370979  0.1797993  -0.06723856
   0.02414925 -0.11756775 -0.1734105   0.08404053 -0.051027   -0.08564584
  -0.07075591 -0.07953248  0.06289411  0.04768243  0.06104123  0.10573467
   0.13085258 -0.00309128 -0.18755656 -0.07360525 -0.16244137  0.0228362
  -0.15853146 -0.05487013  0.07032215  0.1559706   0.18003936 -0.08394417
  -0.03039247  0.04161252 -0.14258315  0.15406017 -0.15478703 -0.12627298
  -0.14810823  0.19149466  0.2015678  -0.12024862]]
tensor_name:  TemporalFusionTransformer/time_distributed_30/bias
[ 1.03134625e-02  4.15894203e-02 -5.48470244e-02  1.78302322e-02
  1.13317249e-02 -3.20287049e-02 -4.20027524e-02  6.66320790e-03
 -1.50629645e-02  4.86568175e-03  5.97896148e-03  3.13121714e-02
 -5.34082949e-02 -2.84754415e-03  2.67125070e-02  1.80361792e-02
 -2.96643302e-02 -3.90386060e-02 -3.78035661e-03 -1.90300904e-02
 -7.91688450e-03  5.40949451e-03 -4.36507985e-02 -2.92872321e-02
  1.55826686e-02  1.16301770e-03 -3.49100381e-02 -3.04259919e-02
 -1.26754930e-02  1.07637653e-03 -1.80501759e-03  3.02314386e-03
 -5.18082455e-03 -2.16687974e-02 -2.24612299e-02 -1.28679359e-02
  2.36310959e-02 -8.13049823e-03  1.29828032e-03 -4.09141518e-02
 -1.13674495e-02  1.17281172e-02 -2.39637345e-02  1.86944865e-02
  3.93683203e-02  1.66533720e-02 -4.19314131e-02  5.87741192e-03
 -2.36151647e-02  2.33785175e-02 -8.41936693e-02  2.00848710e-02
  1.00700902e-02  3.08472645e-02 -2.00984441e-02 -5.48230447e-02
 -4.86283340e-02  3.72102447e-02 -4.90642674e-02  2.02760044e-02
  1.54434415e-02 -6.07106872e-02 -1.92825589e-02  7.22094788e-04
 -1.34311046e-03 -2.48356648e-02 -4.86948788e-02  2.82420870e-02
  2.51435302e-02  2.58048493e-02  1.29525913e-02 -7.72659853e-03
 -6.20124629e-03  4.22655754e-02 -4.20992188e-02  2.38167141e-02
 -3.55494022e-02  3.55731649e-03 -3.59925665e-02 -2.45731324e-02
  2.92327143e-02 -3.11366990e-02 -1.98639892e-02  2.05464531e-02
 -3.67710032e-02 -6.07626000e-03 -8.57606938e-05  2.32225321e-02
 -2.23735124e-02  2.96289753e-02 -4.77819750e-03 -3.58544365e-02
 -1.48549480e-02 -4.50047366e-02 -7.19343722e-02 -2.22873297e-02
  2.73318626e-02  4.10814025e-02  4.74868268e-02 -5.22407843e-03
 -1.10048633e-02  7.45252846e-03 -2.05045529e-02  2.20998265e-02
 -5.11854775e-02  1.12388888e-03 -4.53732088e-02 -7.15812221e-02
 -2.24146191e-02  1.07535161e-02 -6.86758058e-03 -1.14651835e-02
 -2.95289420e-02 -6.66252598e-02 -1.99306384e-03 -1.72347054e-02
 -2.90954076e-02 -5.45327067e-02 -6.81875795e-02 -3.09955664e-02
  3.23517062e-02  5.13842702e-02 -3.60537246e-02 -4.85217618e-03
  8.25885683e-03 -4.00657346e-03 -2.36144103e-02 -4.67386693e-02
 -7.18392655e-02 -4.77855206e-02  3.35401520e-02  1.53613137e-03
 -3.99863720e-02  4.85251024e-02  1.89605914e-02 -4.26220372e-02
  9.26278532e-03  3.50980051e-02  3.45832594e-02 -1.35103129e-02
  5.46391821e-03  2.51457449e-02 -1.38573884e-03 -6.63086846e-02
  4.94206604e-03 -7.53361499e-04  1.82019118e-02 -3.16831991e-02
 -5.01644500e-02 -4.34444584e-02  2.05639061e-02  1.10872323e-02
 -6.59581050e-02 -8.24833382e-03 -1.05260452e-02 -4.21395078e-02
 -3.54567496e-03 -2.68589221e-02  1.74243189e-02 -2.18566097e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_30/kernel
[[-1.04344591e-01 -1.06075682e-01  1.42856941e-01 ... -6.17830665e-05
   3.75230312e-02 -2.62476392e-02]
 [ 5.09002693e-02  7.61976317e-02  1.22770756e-01 ... -1.42218962e-01
   2.19504721e-02  1.30021214e-01]
 [ 4.43646796e-02 -6.29889891e-02 -8.96616504e-02 ...  8.52313787e-02
  -6.46117330e-02 -9.72972885e-02]
 ...
 [-1.38981029e-01 -2.97034252e-02  1.45297438e-01 ... -1.70233324e-02
   1.10497884e-01  3.62880304e-02]
 [-7.34346062e-02  5.42225167e-02  1.33152887e-01 ... -8.69696736e-02
   2.74220314e-02 -4.88796458e-02]
 [ 3.78042087e-02 -8.27854201e-02 -2.72125471e-02 ... -1.23247020e-02
  -8.85947272e-02 -3.13363485e-02]]
tensor_name:  TemporalFusionTransformer/time_distributed_31/bias
[ 0.01285636  0.02353556 -0.00726814 -0.01233996  0.08163118 -0.0763126
  0.04299378 -0.02871165 -0.0199659   0.04529643 -0.00178679  0.01601199
  0.05809874 -0.01184323 -0.00762358 -0.01279767  0.01919859 -0.03242457
  0.0005857   0.00555296  0.0241285  -0.04466018  0.0207639  -0.05706657
 -0.02030536  0.02050141 -0.04503991  0.0231242  -0.01950602 -0.0325193
  0.01304298 -0.05620786 -0.03967382 -0.0500486  -0.02135287 -0.06046408
 -0.08948302 -0.01415931 -0.0104597   0.0396377  -0.03118381 -0.00328943
  0.06333343  0.02212943 -0.02003174 -0.04351149 -0.0487352  -0.02024952
  0.02815204  0.00773816  0.04063702 -0.01970798 -0.04160454 -0.02386349
  0.0390733   0.00087034 -0.00224788 -0.01599905 -0.03730626 -0.07551075
 -0.0100688  -0.02652725 -0.01567688  0.05451353  0.06221301 -0.05638615
 -0.00273032  0.0228009  -0.04978004  0.02268848  0.05279962 -0.04329058
 -0.00162405 -0.05608169  0.07556522  0.01259919 -0.0010126  -0.00585734
 -0.03069332  0.00705285 -0.0065209  -0.06642748 -0.02444979  0.00288899
  0.10508481  0.00223015  0.01868732  0.03597214 -0.02134005  0.0337394
  0.05189598 -0.02524804 -0.00073071  0.01509416  0.00829839 -0.06474494
 -0.06062086 -0.07238029  0.04104986  0.02737908  0.06965949  0.05662543
 -0.04590534 -0.00230093 -0.05195437 -0.0735897   0.02492997  0.00240055
  0.02739997 -0.0106483  -0.04066997 -0.02828726 -0.02599015  0.00363726
  0.03605818  0.04322929  0.0284707  -0.00363835 -0.0191923  -0.03487131
 -0.03291846 -0.00761977  0.05222217  0.05204879  0.06272774  0.04786224
  0.02895898  0.0037372  -0.0283845   0.05337252 -0.03337614  0.02673003
 -0.00440055  0.03042864  0.04893649  0.03775786  0.04695928 -0.01892347
  0.00811719 -0.09501589  0.01107489  0.0349905   0.0638589  -0.0300783
 -0.00449376 -0.02168194 -0.04409274  0.00499138 -0.04057525 -0.021511
 -0.01080669  0.0389987   0.02958842  0.06742487 -0.02138705 -0.01728444
 -0.01467345 -0.0260165  -0.01655175  0.06867845]
tensor_name:  TemporalFusionTransformer/time_distributed_31/kernel
[[-0.04202015 -0.05802943 -0.03346093 ...  0.13819131 -0.00307112
  -0.12747137]
 [ 0.07033522  0.05040879  0.00141184 ... -0.05889006 -0.06985732
  -0.0156441 ]
 [-0.00083263 -0.05784993 -0.02028403 ...  0.04517718 -0.07100297
  -0.11525124]
 ...
 [ 0.08343945  0.0697896   0.02438112 ... -0.00537728  0.06898645
  -0.08063131]
 [-0.05185677  0.01824388  0.03867066 ... -0.01318065 -0.0499336
   0.04968996]
 [-0.05751728 -0.00423802  0.14906646 ...  0.0023393   0.04329755
  -0.05094765]]
tensor_name:  TemporalFusionTransformer/time_distributed_32/bias
[ 0.01041082 -0.00660534  0.05262682  0.06277624  0.02212787  0.03250788
  0.02246125 -0.02183003 -0.00154576  0.00906285 -0.01150788  0.05603659
 -0.01851718 -0.00023009 -0.03194657 -0.05436226  0.01488499 -0.03595018
 -0.01279278 -0.00215386 -0.03331208 -0.0316912   0.02199973  0.02119958
  0.01227095 -0.00474523 -0.01859656 -0.0208223  -0.04952927 -0.05223106
  0.01223721 -0.04362269 -0.02373342  0.00462363  0.01332603  0.00857622
  0.00153458 -0.05502918  0.05948488 -0.02145377 -0.0249225   0.01841692
 -0.03076447 -0.01026233  0.00058837 -0.01234434 -0.00540362  0.02611588
 -0.01589726  0.03061329 -0.00065999 -0.00041689  0.01730194  0.0295885
 -0.00463394  0.0369988   0.04359331  0.01688862 -0.00879516 -0.01126028
 -0.00616126  0.0027757   0.02001505  0.01525789 -0.00928827 -0.0113242
 -0.09195483  0.05642788  0.04769862 -0.02394868 -0.03664291 -0.03806877
 -0.00337065  0.03981896  0.03471264  0.08208403 -0.02207294  0.01538842
  0.04171282 -0.00212404 -0.03347216  0.02166815 -0.0069434   0.01543077
  0.02823361  0.01701195  0.08238236  0.03462299 -0.00037077  0.01370852
  0.0334064  -0.03999827  0.02049711  0.02789263  0.01109336 -0.01763439
 -0.00863164 -0.02721752  0.02383672  0.00041646 -0.0380584  -0.01361447
 -0.02269322 -0.02183303 -0.0291924   0.0107847  -0.00371616  0.00077782
 -0.00545621  0.00637575 -0.02781631 -0.00703721  0.0101296   0.03055779
 -0.01872118 -0.02168104  0.00252625 -0.00912913 -0.08358427 -0.01951461
  0.01625128 -0.00886558  0.01251881 -0.03924162  0.01407767  0.02512015
 -0.0451938  -0.03275837  0.00235597  0.01801843 -0.0503758  -0.02754372
  0.00716694  0.00283563  0.01708307 -0.01777991  0.00462327 -0.00279872
 -0.02467352 -0.01643138  0.01441784  0.01138433  0.0136676   0.00385638
  0.02104637 -0.02790831  0.05567396  0.00304334 -0.01677508 -0.0240092
 -0.02033197  0.05324162  0.00132883  0.01944003  0.00401811 -0.00461195
  0.02414974  0.01506372 -0.02783533 -0.01690701]
tensor_name:  TemporalFusionTransformer/time_distributed_32/kernel
[[ 0.04725207 -0.01084262 -0.17242427 ...  0.01841611  0.05997128
  -0.00377256]
 [-0.10449166 -0.01446404 -0.03457762 ... -0.06602341  0.11127479
  -0.03118218]
 [ 0.10310174 -0.02532714 -0.17603156 ...  0.16071127  0.26806107
   0.12027615]
 ...
 [ 0.03647615  0.01281962 -0.14144713 ... -0.01798995 -0.0752268
   0.03295373]
 [-0.14008786 -0.09231565  0.09755539 ... -0.03100983  0.0811532
   0.06040091]
 [-0.12457162  0.00234454  0.13934724 ...  0.11810636  0.01137422
   0.11935452]]
tensor_name:  TemporalFusionTransformer/time_distributed_33/bias
[-8.69011208e-02  4.69123293e-03  6.31729066e-02  2.79511977e-02
 -3.74653526e-02  2.69303992e-02  1.20598905e-01  7.18588894e-03
  6.91469945e-03 -3.94590981e-02 -5.35684898e-02  2.41353270e-02
 -5.32846116e-02 -8.63169134e-02 -1.82202943e-02  9.06702783e-03
 -3.64175742e-03 -1.10525815e-02  4.59770113e-02  2.43437439e-02
  1.18097924e-02 -2.22353749e-02  2.66354103e-02 -1.27496133e-02
 -3.15820761e-02 -6.19835444e-02 -2.50336304e-02 -3.87346782e-02
 -1.43452105e-03  3.94953303e-02 -5.16075827e-02 -1.33960750e-02
 -1.10131495e-01 -6.11794181e-02  3.69602218e-02 -1.95787530e-02
 -6.68052807e-02  3.40317227e-02  2.94608586e-02 -8.75597727e-03
 -2.49984730e-02  2.65016481e-02  4.36404571e-02 -4.99072149e-02
 -4.07419503e-02 -2.54947320e-02 -1.06283501e-01  1.35650800e-04
 -1.25351533e-01 -5.10291196e-02 -1.07434737e-02 -2.76980791e-02
  2.53745671e-02  1.16790803e-02  4.12215516e-02 -2.76755262e-02
  1.10916803e-02 -3.05512976e-02 -7.50456899e-02 -7.16193467e-02
 -3.51843275e-02 -1.28743857e-01 -2.42250655e-02 -2.46276334e-02
 -7.58522600e-02  5.32864174e-03  5.99452965e-02  4.91783731e-02
  2.66401889e-03  1.24191061e-01  2.44927779e-02  8.70426651e-03
 -1.35927871e-02 -5.19328844e-03 -5.45162112e-02  1.08903810e-01
 -1.28583983e-01 -4.04034629e-02  1.38095417e-03 -1.06406257e-01
  4.05030027e-02 -5.32288998e-02  8.20940919e-03 -3.39963138e-02
 -6.41359342e-03 -5.92103451e-02  1.53666005e-01 -4.90111932e-02
 -5.36424629e-02 -9.85827446e-02 -6.57285610e-03  2.00685905e-03
  4.22788523e-02 -4.30468991e-02 -4.20198701e-02 -4.35709879e-02
 -4.51733321e-02  2.76019685e-02 -2.48997230e-02 -5.84878772e-02
 -2.56643947e-02 -6.68199267e-03  4.75887815e-03 -5.71250692e-02
 -9.88751929e-03 -3.54186967e-02 -9.78641585e-02 -7.82743469e-03
 -6.59502894e-02 -3.43380757e-02  9.01478902e-02  1.77195221e-02
 -3.26039717e-02 -3.07297297e-02 -2.35702861e-02 -2.08727345e-02
 -5.18750213e-02 -4.78290766e-02  8.27734768e-02 -5.50698675e-02
 -1.98565796e-03 -3.42667513e-02 -4.70548170e-04 -1.75148100e-02
 -2.76683625e-02 -2.04263045e-03 -1.46122444e-02  2.31445841e-02
  2.24320311e-02 -3.82162025e-03  5.38782589e-03  5.38753495e-02
 -2.03067493e-02  1.17848711e-02 -3.43065858e-02 -4.04561572e-02
 -5.52539267e-02 -7.30586797e-02 -5.15209802e-04 -9.70377848e-02
 -4.29573581e-02  2.11818777e-02 -8.28848407e-03 -7.17975646e-02
 -6.60286620e-02  6.43678289e-03  3.62956189e-02 -9.88533273e-02
 -1.87383760e-02 -5.93938380e-02 -9.94455069e-02  2.97201192e-03
  5.72210702e-04 -7.16994032e-02 -9.42798555e-02  3.78688332e-03
  4.73341197e-02 -3.22553813e-02  1.49429962e-01 -8.64327848e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_33/kernel
[[-0.10998604 -0.08578468  0.18114491 ...  0.06280316 -0.03795715
   0.0701142 ]
 [ 0.07147007  0.08245258  0.02083265 ...  0.07172596  0.12003624
  -0.09033106]
 [ 0.11235792  0.03330395 -0.09335691 ...  0.1436054  -0.07115901
   0.02539836]
 ...
 [ 0.0796606   0.14594346 -0.05093678 ... -0.04469759 -0.00737009
   0.08859973]
 [-0.04477568 -0.10275942  0.08254727 ... -0.10981195 -0.00666767
   0.05758006]
 [ 0.00490228 -0.0693819   0.231269   ...  0.03666536  0.18859595
  -0.10395274]]
tensor_name:  TemporalFusionTransformer/time_distributed_34/bias
[-9.08477884e-03  1.30109461e-02 -5.28824376e-03  1.27168940e-04
  2.37101819e-02  4.81220707e-02 -6.54941425e-02  1.17863659e-02
 -1.63175836e-02 -4.23465110e-02  2.28276732e-03  4.50618216e-04
  6.17748639e-03 -2.81425714e-02 -5.11577204e-02 -3.58394608e-02
 -1.52358525e-02  6.94969017e-03  1.58189852e-02 -7.10791489e-03
 -8.43224823e-02 -6.28684983e-02 -3.53108048e-02 -3.13056260e-02
  1.55163812e-03  1.19623970e-02 -2.54390668e-02  7.63466256e-03
 -4.10064310e-03  2.08331160e-02  6.67834505e-02  2.26246603e-02
  1.38385845e-02 -2.54331920e-02  8.88623111e-03  1.15138164e-03
  4.11874987e-02  8.81004788e-04 -1.34558845e-02 -4.56296988e-02
 -4.93465886e-02 -2.67156353e-03 -5.29509708e-02  5.39058372e-02
  7.34726898e-03 -6.54048380e-03 -2.05810135e-03 -8.48150719e-03
 -1.07503021e-02  4.13194038e-02  3.24890390e-03 -1.77752599e-03
 -1.01577339e-03 -2.87284725e-03  1.40769659e-02 -1.52261639e-02
 -1.03147052e-01  6.26679044e-04 -1.25653334e-02  2.33506039e-02
 -2.26279881e-04 -4.01541367e-02  2.01283954e-03 -2.02712859e-03
  1.02065401e-02 -1.18250120e-02  1.75834596e-02 -4.73583443e-03
  5.97248203e-04 -1.76735464e-02 -2.13414580e-02 -1.34685729e-02
 -8.36509392e-02 -9.38179493e-02 -1.85334738e-02 -8.33940580e-02
 -2.82004126e-03  1.71735440e-03 -3.42046726e-03 -7.53789321e-02
 -5.67579605e-02 -5.68130240e-02 -7.79458508e-03 -9.76607502e-02
 -7.40952119e-02  1.08071528e-02  7.26157008e-03 -7.13391975e-02
 -2.62564663e-02 -7.87757635e-02 -3.47075379e-03 -1.44213706e-01
 -1.40689015e-02  2.70714029e-03 -1.01647995e-01  2.56721880e-02
 -3.78530696e-02  7.29253609e-03 -3.39461789e-02  2.77074073e-02
  9.44112986e-03  8.17751419e-03  7.24322814e-03 -5.23243695e-02
  2.55693309e-02 -3.61055322e-02 -1.41358795e-02 -3.12751979e-02
  4.81123890e-04 -7.28840306e-02 -9.35658172e-04  8.57848022e-03
  7.82994926e-03 -1.03973903e-01 -9.24615772e-04  1.05717732e-03
 -5.27583063e-03 -4.52051423e-02  7.16133136e-03 -8.21216851e-02
 -1.80216450e-02 -5.08460999e-02 -1.78277455e-02 -5.53558730e-02
 -2.76391804e-02 -6.17630780e-02 -5.43620698e-02 -7.50114992e-02
 -2.43930873e-02  3.93938795e-02 -6.68756962e-02 -7.89543847e-04
  1.84011087e-02  1.60277355e-02  8.82102642e-03  4.80416510e-03
 -1.44059751e-02 -1.02434615e-02 -5.32068871e-03 -1.14447912e-02
  5.21525182e-03  9.39492583e-02  8.33825581e-03 -2.30720937e-02
 -4.99786586e-02 -2.35749707e-02 -6.59174006e-03  1.26587087e-02
  1.34430230e-02  4.03542109e-02  1.48425822e-03 -4.93209735e-02
 -2.52604522e-02 -2.66764797e-02 -1.18527263e-02 -5.34212962e-02
  1.58110652e-02 -3.00258063e-02  7.99637754e-03 -9.48237553e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_34/kernel
[[ 0.07491311  0.05427358  0.09450304 ...  0.10162304  0.1052219
  -0.1237247 ]
 [-0.04935687  0.07615603 -0.01733203 ... -0.04897242 -0.07070448
   0.06648799]
 [-0.0205727  -0.1178213  -0.08371276 ... -0.01560436  0.10064973
   0.2013397 ]
 ...
 [-0.01794693  0.06401096 -0.14089663 ...  0.06014602 -0.00822388
  -0.13020761]
 [ 0.1219862   0.10987529  0.01241505 ... -0.1508323  -0.02239341
  -0.10747071]
 [ 0.03442745  0.07112175 -0.06692761 ... -0.03788112 -0.01415697
  -0.22612967]]
tensor_name:  TemporalFusionTransformer/time_distributed_35/bias
[-0.04074438  0.01812434  0.05509486  0.0395513  -0.07433068 -0.05854566
 -0.04257422 -0.03978264  0.03427321  0.03090846  0.00543054 -0.02499204
  0.0502006   0.05296392 -0.01381125 -0.03967254  0.07949975  0.01191843
 -0.09794533 -0.00405889  0.00068181 -0.08118109 -0.0444898  -0.07020388
  0.05883616  0.0109091  -0.04360211  0.01375536 -0.00240445 -0.0109804
  0.03745066  0.13263509  0.01175263 -0.03937637  0.04776429 -0.08261412
 -0.03874661 -0.02563995  0.01925646 -0.00586836  0.02845599 -0.09318566
 -0.09669045 -0.02363544  0.05144813  0.03567956 -0.00213789 -0.03816807
 -0.03726103 -0.02587152  0.07825805 -0.0110408   0.0277328  -0.03404271
 -0.02668183 -0.01318837  0.01259318 -0.02143826  0.01902679  0.01031353
  0.04884974  0.0476026  -0.03240609  0.05250688 -0.073404    0.04365865
  0.04907695 -0.0678467  -0.0043643   0.04076385 -0.00332804 -0.02146082
  0.12810174 -0.01674273 -0.00245475 -0.02514459 -0.03651927 -0.00682738
  0.12973188 -0.0306038  -0.05930271 -0.04972947 -0.01991489  0.01781781
  0.01039656  0.08122279  0.01542544  0.04860221  0.02179503 -0.01296386
  0.02946381 -0.02347828 -0.03762555 -0.05146766 -0.00735682  0.00448997
  0.00749226 -0.02645039 -0.07114927 -0.0319915   0.00493757 -0.03117155
  0.0352841  -0.08627736 -0.02652277 -0.12317498 -0.0449877  -0.01163441
  0.00198421  0.11094774 -0.04117333  0.0363645  -0.10460138 -0.07275504
 -0.00057954  0.00207528 -0.05314586  0.02785068 -0.02044617  0.0358198
  0.00178774 -0.04071109  0.00218469  0.02019547 -0.05484223 -0.00760002
 -0.02245339  0.0516075   0.00321015 -0.03787104  0.02018202  0.0527817
 -0.04799525 -0.03263559 -0.01456467  0.04655617 -0.0349991  -0.02585868
  0.03815999  0.03521576 -0.0537656  -0.05360876 -0.01460038  0.03504332
  0.05430003  0.01559803  0.00377086 -0.00266227  0.03164403 -0.06036933
 -0.01790824  0.03053996 -0.06470659  0.01343194  0.00123636  0.02588293
  0.06697774  0.04770018  0.00344979 -0.05122425]
tensor_name:  TemporalFusionTransformer/time_distributed_35/kernel
[[-0.013331    0.12397325  0.01505283 ...  0.00819948 -0.09672178
  -0.0982481 ]
 [ 0.07235195  0.04653515 -0.13000257 ...  0.08376444 -0.05722714
  -0.07683589]
 [-0.07834641  0.07089286  0.14786395 ...  0.10378666  0.11183011
  -0.00121487]
 ...
 [ 0.03691547 -0.11535805  0.0123329  ... -0.04624599 -0.1035211
   0.07142601]
 [ 0.05704083  0.02596094  0.06703943 ... -0.09382946 -0.07627216
   0.11051297]
 [ 0.13154154  0.05656069 -0.14469951 ...  0.06583416  0.13817604
   0.16661361]]
tensor_name:  TemporalFusionTransformer/time_distributed_36/bias
[ 0.00510265 -0.01280711 -0.01178522 -0.05666639 -0.02389267 -0.020575
 -0.00506074  0.02299888  0.00601889  0.0089087  -0.00133862  0.02667858
 -0.01918762 -0.0499443  -0.00095674 -0.03309867 -0.0137928   0.04218062
 -0.0074701   0.00464453  0.00101908 -0.03217028  0.00913833 -0.01388057
 -0.00817859  0.00677474  0.03919792  0.01742762 -0.01789545  0.017887
 -0.0051885   0.00985291 -0.02178244  0.00651036 -0.01437819 -0.01617397
 -0.0092935  -0.02452532 -0.01017309  0.03463124  0.03318138 -0.00472185
  0.04097674  0.00402192  0.01428099 -0.0012821   0.03090832 -0.08331485
  0.03517174 -0.05086544 -0.00442194  0.03468961  0.03091187  0.00178598
 -0.00633532  0.00326812  0.0098202   0.02162114  0.02422334 -0.01918571
  0.00107943  0.02787463 -0.01624462  0.03494927  0.02317366  0.05049195
 -0.00775105  0.00195606  0.02464963  0.0028591   0.03370763  0.01720962
  0.00411798  0.00834323  0.00664661  0.01816465 -0.00904876  0.00153133
 -0.0224645  -0.04762986  0.01444438 -0.02227829  0.07531238  0.00311114
  0.0164049   0.00092647  0.00545369  0.05742515  0.01422681 -0.04470827
  0.00424265 -0.01085148 -0.04532394  0.01030568  0.00067692 -0.01076473
 -0.01310899  0.04142769 -0.0386449  -0.01048499  0.01485864  0.00718037
  0.0232169   0.00856629  0.01249957 -0.03276332  0.01053078 -0.02253538
 -0.01292191  0.04935559  0.01433983 -0.05108287  0.02237482 -0.01299683
 -0.01114411 -0.03653764  0.00333566 -0.03276169 -0.03547377 -0.00311814
 -0.04238674 -0.03966249 -0.03655938 -0.00459082 -0.02012713  0.00211484
 -0.01656954  0.02483072  0.01075824 -0.00015703 -0.00570241  0.0076188
  0.03280319  0.05501228 -0.00829782  0.00855453  0.03586341 -0.01851953
  0.01566917 -0.00820148  0.01281375 -0.02606643 -0.00248831 -0.01077155
  0.05099322  0.02055175 -0.03303972 -0.03748138 -0.05528267 -0.02658632
  0.0344234   0.01988401  0.01991851  0.01515205  0.00457233 -0.02871249
  0.02322414  0.02584421 -0.01010475 -0.01613815]
tensor_name:  TemporalFusionTransformer/time_distributed_36/kernel
[[-0.01356902  0.00693258 -0.05506636 ...  0.0738425   0.08569355
   0.01122916]
 [-0.11550948 -0.04523899  0.10579122 ...  0.0426311  -0.11030588
  -0.06148895]
 [ 0.1067203  -0.07136721 -0.05509976 ...  0.13914545 -0.12069412
  -0.00552131]
 ...
 [ 0.01098216 -0.07060544  0.12214781 ...  0.11720689 -0.1409623
   0.08736522]
 [ 0.04872046 -0.05421443 -0.16730696 ... -0.04952553  0.01192756
  -0.12987687]
 [-0.11737197  0.00727966 -0.09468918 ... -0.1276421   0.02302451
  -0.02114335]]
tensor_name:  TemporalFusionTransformer/time_distributed_37/bias
[ 0.01153379 -0.04869163 -0.01671572  0.31052548 -0.10840905  0.15466416
 -0.05636608  0.08574948  0.14927319 -0.12055397 -0.05802514 -0.03049115
 -0.16656741 -0.03946093 -0.07741387  0.00520042 -0.04058006  0.00067033
  0.0070959  -0.03146808 -0.08730595 -0.01603774 -0.08926255 -0.06909331
 -0.00152392 -0.1037635  -0.20510246  0.09331721  0.00782879  0.21528807
 -0.04277172 -0.04475594 -0.02902018 -0.1398811  -0.03860217 -0.04038037
 -0.13560979 -0.07380614  0.03653098  0.05944825  0.08109127 -0.07280251
  0.0684687  -0.08579819  0.04005501 -0.00627957 -0.08656802 -0.00699595
 -0.0297485   0.00497189  0.10098342 -0.00337024  0.04303039 -0.08438767
 -0.05228052 -0.05990641 -0.07202867 -0.05149385  0.01339398 -0.0998194
 -0.13264385 -0.01744056 -0.11438107 -0.00699679 -0.07466565  0.23945694
 -0.08705631 -0.10883185 -0.05459271 -0.03036949  0.10238065 -0.09278788
 -0.10207433 -0.1160288  -0.08604462  0.04808878 -0.04608084 -0.02200292
  0.10855088  0.07265841  0.10663678 -0.0005994  -0.02025785 -0.07387739
 -0.01916282 -0.04757333  0.09230015 -0.01591061  0.02158099  0.02543203
 -0.04966064 -0.04882498  0.07131192 -0.08681935 -0.07390339 -0.03017767
 -0.03696773 -0.03337988  0.16620311 -0.03051993 -0.02707357  0.06481861
 -0.08868162 -0.08935326 -0.04353203  0.11015209 -0.09142349  0.14441437
 -0.00041428 -0.01015462  0.07414475 -0.00069631 -0.06569333  0.01709888
 -0.0328003   0.01057629  0.05075112  0.03408611  0.02966852 -0.002975
 -0.06308416  0.06401089 -0.0157914  -0.0914674  -0.12061513 -0.10532168
 -0.07590339 -0.09763139  0.04479105 -0.1785587  -0.1308397  -0.11940503
  0.06033489  0.14137709 -0.10828143 -0.01286621 -0.11288217  0.02526663
 -0.11737014 -0.07652938 -0.00046966 -0.10588178  0.11670078 -0.04647925
  0.00574189 -0.14707164 -0.00042765 -0.00515463  0.0144609  -0.02354251
 -0.06718255 -0.03164681 -0.0794595   0.01515948 -0.04465146  0.04066347
  0.05735936 -0.04415847  0.01577537  0.03882266]
tensor_name:  TemporalFusionTransformer/time_distributed_37/kernel
[[-0.05826937 -0.06104894  0.05220557 ...  0.06283765 -0.04249242
   0.1282208 ]
 [-0.00863952 -0.15126996 -0.00507597 ... -0.05733215  0.09288429
   0.0289852 ]
 [ 0.11066832  0.05043839 -0.0490162  ... -0.0251204  -0.07704269
   0.02326344]
 ...
 [ 0.14289555 -0.08724476  0.03388553 ...  0.05290404 -0.01932351
   0.10465789]
 [-0.12635604 -0.0783693  -0.10316734 ... -0.12098227  0.06664594
  -0.09472951]
 [ 0.02718483  0.05567662  0.04283912 ... -0.06800002  0.16230579
   0.12286697]]
tensor_name:  TemporalFusionTransformer/time_distributed_38/bias
[-2.79625948e-03  1.10452995e-02 -4.17653122e-04  8.55935179e-03
 -1.86210554e-02 -2.65128575e-02 -5.25427889e-03 -1.76397320e-02
 -3.00261360e-02 -4.11256962e-03  5.07017318e-03 -6.50152855e-04
 -4.48666476e-02  1.01091061e-02 -7.76791247e-03 -5.38571365e-03
  3.18942452e-03  9.86458268e-03 -1.66347101e-02 -1.16858808e-02
 -1.56910233e-02  3.43225501e-03 -1.42354332e-02 -2.36582235e-02
 -1.03079239e-02  1.45191988e-02  2.76535675e-02  7.49034481e-03
 -1.59153603e-02 -1.55898454e-02 -8.29239748e-03 -9.81480815e-04
 -2.30573323e-02 -1.74369086e-02  1.38409920e-02  1.59867555e-02
 -1.70002244e-02 -2.00512968e-02  2.42014639e-02 -8.89130030e-03
 -6.50216965e-03  9.10715200e-03  1.71973221e-02  5.35953604e-03
 -2.35406198e-02 -1.63199157e-02  2.12995317e-02  1.74848586e-02
 -6.69640908e-03  7.41920061e-03 -3.96090420e-03 -1.22907746e-03
  5.29887341e-03 -5.52641833e-03  1.72863156e-02  1.82911102e-02
  1.29746059e-02  2.03411095e-03  9.32911597e-03  1.97867677e-02
 -9.87385586e-03  1.37242442e-02  8.92241672e-03  7.82897044e-03
 -1.15355570e-02 -5.08934725e-03 -2.78871809e-03  5.54665644e-03
 -1.81673858e-02  2.19626594e-02 -1.34899816e-03 -1.47044854e-02
 -4.87501919e-03  1.81855485e-02 -4.08147369e-03  1.21046836e-02
 -7.73472886e-04  1.04223788e-02  1.66713651e-02 -2.31811125e-03
 -6.24039629e-03 -8.65094084e-03 -5.35905128e-03 -2.05860310e-03
  4.60066553e-03  1.05570480e-02  1.00890575e-02 -5.73500246e-03
 -2.49756612e-02  1.56241274e-02  9.20317427e-04  1.31736947e-02
  1.69355981e-02  1.06253130e-02 -9.35771223e-03 -5.68710594e-03
  5.54313231e-03 -2.25984491e-02 -5.19612990e-03 -1.73844639e-02
  1.53982081e-03 -3.57283987e-02 -3.35723087e-02 -2.62340698e-02
  1.06693590e-02  3.42362188e-03 -3.72857340e-02  2.73897708e-03
 -5.17614326e-03  1.29821030e-02  5.18388534e-03  1.79411508e-02
 -3.24730622e-03 -8.32305383e-03 -4.60659433e-03 -9.68233403e-03
  1.73846278e-02  6.11770153e-03  6.79661427e-03  1.64035112e-02
 -3.93680930e-02  1.29508702e-02  6.21305453e-03  1.40008014e-02
 -1.02036577e-02 -3.54592875e-03 -1.34028215e-02 -2.44433898e-03
  3.90478596e-03  9.02474113e-03  1.33233108e-02 -1.87756438e-02
 -2.83133630e-02  9.35607962e-03  9.98709351e-04 -1.25721516e-02
 -1.59770343e-02 -3.03676929e-02  1.47197247e-02 -1.32289063e-02
  5.66953211e-04  3.25979874e-03 -8.87058850e-05 -4.27525910e-03
  3.58030433e-03  2.19142027e-02 -6.90067001e-03 -2.25447137e-02
  2.35545877e-02 -9.41442046e-03 -1.43791572e-03 -3.11503354e-02
 -2.49347985e-02 -2.59132311e-03 -2.06962600e-02 -1.39271505e-02
  6.50944887e-03  2.52696639e-03  2.71860790e-02 -4.49486338e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_38/kernel
[[ 0.10645228  0.08982936 -0.00118911 ... -0.10983945 -0.12201998
   0.0628616 ]
 [ 0.04975645 -0.06412429 -0.04517188 ... -0.01205331 -0.03161717
  -0.14397834]
 [-0.09765462 -0.09521377  0.00532664 ...  0.01863601  0.02332872
   0.14969066]
 ...
 [-0.07122465 -0.11513658 -0.13453346 ...  0.01663073  0.02086246
  -0.06770921]
 [-0.07325304  0.0664093   0.08624873 ... -0.04856597 -0.09530275
   0.05706384]
 [-0.0537711   0.08741002  0.05869922 ...  0.02343387  0.08198924
  -0.03556012]]
tensor_name:  TemporalFusionTransformer/time_distributed_39/bias
[-0.06412736  0.05557832  0.05308281 -0.00295501 -0.01594842 -0.06036463
  0.02375412  0.00999007  0.00356626  0.01074827  0.00841119 -0.00135289
  0.0209194  -0.00501428 -0.0002261  -0.01440047 -0.04396702  0.03697026
 -0.02028407  0.03601299  0.02127635 -0.010706    0.0687283   0.01841382
  0.0083177  -0.04215148  0.03668825 -0.00666811  0.00437231 -0.01752012
 -0.01532296  0.02038664  0.04955643  0.05678076 -0.04994988  0.05436492
 -0.02881931  0.04537064  0.01485427 -0.02833096 -0.02589242  0.02161351
  0.0763936   0.01756233  0.00024817 -0.00964512 -0.0026031   0.01995058
  0.02705654 -0.00437411 -0.00820563 -0.02105759  0.00888188 -0.0221264
  0.04071422 -0.01478522  0.02450787 -0.01634862 -0.04799868  0.02955795
  0.03971672  0.00772051  0.02561747  0.01031789  0.03808653 -0.04595366
  0.01375367  0.01986926  0.0475431   0.02482395  0.02522508 -0.00989876
 -0.02142169  0.00531588 -0.0129544  -0.00187759 -0.00189767 -0.01000976
 -0.00952065 -0.02222201  0.02459376  0.0054234   0.03031031  0.04242127
  0.02835889 -0.02477276  0.012322   -0.0225456  -0.00614089  0.00926768
  0.05355437 -0.00295303  0.02196233 -0.02721379  0.02537665  0.01613961
  0.00518799 -0.02312548 -0.00184343 -0.02547096 -0.03187943  0.09323894
 -0.01244163  0.03321617  0.01145283 -0.00184737 -0.03870987 -0.01552367
  0.02856504  0.03201992 -0.00326146 -0.01702997 -0.0002113   0.00953375
  0.04353304  0.01484911 -0.02281387 -0.05333007 -0.04022843 -0.00499836
 -0.03486748 -0.04961281  0.00159888 -0.04671874 -0.03933012 -0.02144099
 -0.0595664  -0.01329809 -0.03572543  0.06852654 -0.00538451 -0.03437694
 -0.03161252 -0.00038786 -0.01430598  0.02041231 -0.00870844  0.00158302
  0.05463438 -0.02809796  0.02811627 -0.02717479  0.05651093  0.04239465
 -0.02551655  0.02155461  0.00703497 -0.01140834 -0.02885331 -0.03557966
  0.01272207 -0.02991538  0.05013156  0.04064276  0.00607005  0.00142507
 -0.00250593  0.00893069 -0.00193221 -0.02805314]
tensor_name:  TemporalFusionTransformer/time_distributed_39/kernel
[[ 0.08406739 -0.0158102  -0.05193953 ... -0.10616631  0.06662885
   0.13754503]
 [-0.09799612 -0.10227219 -0.01163919 ... -0.10082708  0.11060439
   0.11344911]
 [ 0.04957474  0.06423803 -0.06476121 ... -0.091125    0.00021196
   0.03321831]
 ...
 [ 0.04108356 -0.08372817 -0.02853478 ...  0.10080158  0.08051056
  -0.01800822]
 [ 0.01068135  0.13138081 -0.07421198 ... -0.05832029  0.06944787
  -0.05183674]
 [ 0.0467451  -0.18263133  0.01641893 ... -0.12381487  0.09464695
   0.08877324]]
tensor_name:  TemporalFusionTransformer/time_distributed_4/bias
[-0.01331969  0.07040589  0.02620164  0.07732427  0.03484089 -0.00624782
  0.04361381  0.00187694 -0.04551933  0.02192243 -0.01899096  0.01498218
 -0.01118394 -0.04175993 -0.04129407 -0.03341887  0.00166775  0.04592979
  0.00366986  0.00114554  0.04818489 -0.02386969 -0.05328475 -0.00154388
 -0.06119395  0.07187042 -0.01122063  0.02266195  0.00222377 -0.04083678
  0.02374839 -0.00825062  0.00467029  0.04674755  0.01709837 -0.01727257
 -0.06984948 -0.04745101  0.03594329 -0.01788558  0.02198647 -0.00332609
 -0.07988258  0.03135767  0.00675187 -0.01789231  0.0013938   0.05587978
  0.01772385 -0.00605799  0.01441397 -0.01079076 -0.038524   -0.01435393
 -0.0238588   0.07010351  0.00076847 -0.05338595 -0.01379602 -0.03724845
  0.00957407  0.01872948 -0.02885715  0.02277926 -0.04092507 -0.06272208
 -0.04349203  0.02638136  0.0441872  -0.07022541 -0.0005636  -0.04563968
 -0.02490063  0.01325564  0.05975712  0.04891472 -0.04377618 -0.02764034
  0.03783621  0.01108918 -0.02106     0.06086468 -0.00682012 -0.00058939
  0.02311308 -0.00407181  0.01769137 -0.01157402  0.02460163 -0.0008098
  0.07833239 -0.05176248 -0.03597732 -0.00236666  0.01205079  0.00564614
 -0.00851367  0.00424328 -0.02594642 -0.00953781  0.02913678 -0.05211988
  0.01829671  0.01047172  0.02039018  0.04303548 -0.01682526 -0.00564447
 -0.01514238 -0.02697681 -0.0048128  -0.0299066  -0.06350481  0.0127278
 -0.02347915  0.02324288 -0.0272037   0.02644826  0.0311996  -0.04705127
  0.05379559 -0.02998038  0.0190063  -0.07064205  0.02279357  0.02589287
  0.00714604  0.03372062  0.02824911  0.02204689 -0.01031471  0.03074958
  0.04638486 -0.04694863  0.05856589  0.00726578 -0.01886185  0.01372985
 -0.01428566 -0.02316019 -0.05287962  0.02001832  0.06022712 -0.008234
 -0.02692421  0.03668464 -0.02380871  0.02071243  0.01903354  0.02867674
 -0.03672167  0.00674134  0.04652159  0.00224484 -0.01138563  0.01406452
 -0.05268126 -0.03491489 -0.03384613 -0.01156875]
tensor_name:  TemporalFusionTransformer/time_distributed_4/kernel
[[ 0.14299966  0.02648866 -0.00194863  0.10254894  0.13963908  0.1485095
   0.15345207 -0.05035067 -0.17113517  0.16853915 -0.10249215  0.11236948
   0.1357624  -0.14093028 -0.02003874  0.10040121 -0.16358007  0.07232052
   0.1137768   0.08141313  0.04734469 -0.02618644 -0.11075836  0.14078215
  -0.10689549  0.14335851 -0.00781841  0.07432176 -0.00066691 -0.04929163
   0.17531148  0.09957526 -0.17830557  0.11628526 -0.02008616 -0.17940369
  -0.11544316  0.00498647  0.04748845  0.1787774  -0.15391602 -0.09507786
  -0.05609391  0.14062452 -0.15044366 -0.14014621  0.03329418  0.1418289
   0.15818445 -0.02309685  0.07363486 -0.00084111 -0.05249309 -0.09212378
  -0.15251015 -0.04365652 -0.14732556 -0.17644185  0.08882022 -0.01594529
  -0.1177106   0.00994776 -0.10872706  0.09939855 -0.01001054 -0.04996258
   0.15842277  0.01841037 -0.18887292 -0.11219932 -0.02376825 -0.09026685
  -0.05030951 -0.04118504  0.1343723  -0.09662694 -0.10049451 -0.08422513
   0.07779023 -0.00804778 -0.04726661  0.16069697 -0.1546228  -0.01855916
  -0.04159166 -0.00489582 -0.08663644 -0.13320413  0.02328431 -0.02080672
   0.09883627 -0.05641671 -0.1292708  -0.11273878  0.07251344  0.05324259
   0.08710881  0.11259171 -0.18602304 -0.17222397  0.05467293 -0.13524806
   0.11112873  0.13592069  0.02272037  0.02608098  0.19425677 -0.07479618
   0.15735091 -0.15644793 -0.15699767 -0.04681256 -0.07490104  0.02943085
   0.1109297   0.02075241 -0.17544776  0.05715993 -0.00074179 -0.10727435
   0.1468084  -0.13197225  0.02997737 -0.08927491  0.04863697  0.05829096
   0.12305766  0.04009388  0.03807727  0.14714962 -0.00047384  0.11511348
   0.17642146 -0.17947835  0.02383674  0.11781769 -0.02739374 -0.0157545
  -0.13524163 -0.11129726 -0.10930213  0.0356676   0.05907923 -0.038376
  -0.14808267  0.0818043  -0.14570911 -0.01128279  0.05308934  0.01417224
   0.08053546  0.01040056  0.05907099 -0.21264881  0.1241831   0.01829043
  -0.10876597 -0.06589305 -0.13006388  0.1104387 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_40/bias
[ 0.00408089  0.03176784 -0.00755356 -0.10421673  0.00207953 -0.05138158
 -0.00292967  0.02905809  0.03636876 -0.00241015 -0.025273    0.02481792
 -0.03846131 -0.0190098   0.01189576  0.01599142  0.0127379  -0.0179901
 -0.01448087 -0.01211512 -0.04309934 -0.00525148  0.0007622   0.01985682
 -0.00573272 -0.00925101 -0.00748828 -0.01949265 -0.05064955  0.0342951
 -0.00034603 -0.01456605 -0.02598657  0.00871495 -0.04254868 -0.02762268
 -0.00278104  0.00082402 -0.00411486  0.02026933 -0.02164709 -0.00012184
  0.01695818  0.02478868  0.00337648 -0.02522223  0.03607774 -0.02637701
  0.04646758 -0.00691903 -0.02407373 -0.00752011  0.00708067 -0.00695414
 -0.0080144   0.03061628  0.01790045  0.06756275  0.02555805  0.00991658
 -0.02056422  0.02659332 -0.01721018  0.01223541 -0.05850499  0.03691138
 -0.02889816  0.04045192  0.01024531  0.00119725  0.04077802 -0.04422612
  0.04571482  0.05803083  0.01690874  0.03665807 -0.02525812  0.03031465
 -0.03871495 -0.04014743  0.02500905 -0.06474985  0.01626736  0.02053466
  0.01204792  0.00119974 -0.0090299   0.06701694 -0.00497271 -0.02978437
  0.03948461 -0.00114456  0.00619001  0.01964152  0.0260291   0.03008008
 -0.01941597  0.07300802 -0.04253841  0.00875757  0.00173021  0.0080151
  0.01901857  0.02161262 -0.00220842  0.00090258  0.00101389 -0.04297829
 -0.00278267 -0.0242753  -0.01086549 -0.02099796 -0.01424149  0.00161417
  0.05077334 -0.03753754  0.02383337  0.00283807 -0.00127108 -0.02456989
 -0.06414405 -0.03510249  0.00373454 -0.02714417  0.01997541  0.01013837
 -0.01882907  0.00311293  0.02140862  0.00897412 -0.0616025  -0.00811275
  0.01219402 -0.0183221   0.02687257 -0.00214022  0.02211458 -0.00749382
  0.03651301 -0.02709987  0.00424885  0.00706319 -0.00436606  0.01051384
  0.0208465   0.00532489 -0.02285639 -0.04715352 -0.00603992 -0.02120312
  0.01333548  0.03003515 -0.01271418  0.03649621  0.01769098 -0.02039881
 -0.01116589 -0.0001984  -0.02084175 -0.02344649]
tensor_name:  TemporalFusionTransformer/time_distributed_40/kernel
[[-7.35566095e-02 -6.58777133e-02 -4.50799577e-02 ... -1.23551123e-01
  -1.44247204e-01 -1.10086553e-01]
 [ 2.17630863e-02 -3.42240073e-02 -1.18040226e-01 ... -6.61673322e-02
   3.12064886e-02  2.09197104e-02]
 [ 2.76780054e-02  1.06503285e-01 -1.78352311e-01 ...  4.89064045e-02
   6.92042150e-03  1.60520189e-02]
 ...
 [ 1.06178910e-01 -1.43930361e-01 -1.18491001e-01 ... -7.69301550e-05
   8.57490897e-02  1.14154182e-01]
 [-7.97203705e-02  8.48407373e-02  1.03382148e-01 ...  3.88076641e-02
  -7.41411895e-02 -3.30282077e-02]
 [ 1.09326467e-01  1.37253981e-02  8.59571919e-02 ... -1.28850594e-01
  -4.05075960e-02 -8.77750516e-02]]
tensor_name:  TemporalFusionTransformer/time_distributed_41/bias
[-0.1221533  -0.07645352  0.02001615  0.12668769 -0.03955052  0.1752608
 -0.05178738 -0.07368062 -0.03930139 -0.0757103   0.04254847 -0.07852601
 -0.03368874 -0.10662205 -0.04562882 -0.0590694  -0.05887985 -0.03852913
 -0.07029906 -0.06352713  0.01590087 -0.0620841  -0.0303769  -0.0866771
  0.06313732 -0.02424971 -0.0278917  -0.09117336  0.01591992 -0.01808962
  0.08958075 -0.09702215 -0.07001626 -0.04946042  0.03003262  0.02302752
  0.03157491 -0.02913231  0.04521512 -0.04351168 -0.04476935 -0.06848221
  0.00479488  0.00090969 -0.10163479  0.06263661 -0.05337245  0.10975804
  0.1493776   0.12068801 -0.11370066 -0.01038513 -0.0338386  -0.13428591
  0.08662556 -0.00427303 -0.06583375  0.10055909 -0.04373738  0.00189434
 -0.06264208 -0.05439041 -0.06612618 -0.06345242  0.45371374 -0.01221835
 -0.04009258 -0.04211048 -0.07566176  0.04289591 -0.04891837  0.10262915
  0.0277676   0.01521158 -0.10923346 -0.03233226  0.1071718   0.00910498
  0.03762125 -0.0430661  -0.06343832  0.20371003 -0.00646555 -0.0712361
  0.03675976 -0.06035965  0.12328888 -0.02257244  0.33225822  0.04601307
  0.00985852  0.01238269  0.03757863 -0.04909746 -0.05108066 -0.00188525
 -0.04935576  0.11592117  0.00878709 -0.07664665 -0.07766839  0.06770493
  0.02166555  0.04175836  0.05391328 -0.07883058 -0.12502554 -0.01400815
 -0.03824791  0.038489   -0.00436454  0.04650656  0.00087661  0.06672369
 -0.04218861  0.03100086  0.0115605  -0.14837444  0.02451082 -0.0665478
  0.04076346 -0.03707563 -0.03158491 -0.03262474 -0.02459543 -0.07380436
 -0.06076194 -0.0779093   0.01946847 -0.0616578   0.03206668 -0.01945551
 -0.11900204  0.00608557  0.0026278  -0.02444262 -0.10050706 -0.0509754
 -0.05005926 -0.01296815 -0.03919182  0.08595034 -0.10234636 -0.11537685
 -0.03980405 -0.12048369 -0.02903221  0.02085636  0.1430782  -0.06965607
 -0.03211365  0.01740609  0.1311748  -0.00456602 -0.03507265 -0.03229039
 -0.01656925 -0.01357636  0.0266348  -0.11286844]
tensor_name:  TemporalFusionTransformer/time_distributed_41/kernel
[[-0.03491491  0.08164048 -0.01089844 ...  0.13851017  0.08876394
   0.08854429]
 [-0.03687692 -0.05302717  0.07245918 ...  0.12669948 -0.10919019
  -0.05905649]
 [-0.04502785  0.10335974 -0.08160488 ...  0.00040836 -0.12757562
   0.0174055 ]
 ...
 [-0.02315303  0.00510743 -0.02642757 ... -0.04043999 -0.1083808
   0.09968887]
 [ 0.02517356  0.02600995 -0.07256399 ...  0.08123778  0.04331682
   0.05394977]
 [-0.01860609  0.09600043 -0.03366461 ... -0.00719398  0.08271408
  -0.03695821]]
tensor_name:  TemporalFusionTransformer/time_distributed_42/bias
[-1.2505618e-02  7.9923961e-03  2.6424494e-02  1.1263698e-02
 -8.5227033e-03 -4.7805728e-04 -1.6911995e-02 -7.0570642e-03
 -3.1278394e-02  1.8586669e-02 -2.9968126e-02  2.1592198e-02
  2.0094104e-02  7.0300288e-03 -2.0070896e-02 -3.2915290e-02
 -1.5520952e-02 -2.2285329e-02 -2.3406416e-02 -1.0862716e-02
 -1.7213617e-02  1.7415520e-02  1.5322356e-03 -5.9842272e-03
  1.3251188e-03 -6.3246982e-03 -5.3804353e-02  9.1206962e-03
 -1.8499430e-02 -3.1187586e-02 -6.9646598e-03  8.0690281e-03
 -1.0737004e-02  1.5042329e-02  1.1685330e-02  1.2280897e-02
  3.7734206e-03  2.9600922e-02  1.8216006e-02  3.0899564e-02
 -2.9439763e-03 -2.6369706e-02 -6.6999188e-03  2.0979008e-02
  4.4882586e-03 -5.9010722e-03 -1.4341052e-02 -1.4709802e-02
 -5.8590703e-02  6.0166367e-03  1.9581616e-02 -5.0579317e-02
  1.3056962e-02  2.5674991e-02 -7.3366109e-03 -5.6377086e-03
 -1.4141129e-02 -6.4917852e-04 -3.5039522e-02 -2.7031180e-02
 -4.3217279e-03 -7.8772577e-03 -5.0816149e-02 -1.4997677e-02
 -3.3987638e-02 -7.3482348e-03 -2.5860574e-03 -3.2812309e-02
 -1.5688485e-02 -1.4204865e-02 -1.6680723e-03  4.0319916e-02
  8.8165337e-03 -5.1983602e-02 -1.3510209e-02 -2.1043826e-02
  1.9170012e-02  7.6925526e-03  3.5714664e-02 -2.9877868e-02
 -2.1667751e-03 -3.3623695e-03  4.2207814e-03 -1.4270152e-02
 -1.9102106e-02 -1.8445397e-02  1.9258698e-02 -4.4051364e-02
  1.1807382e-03  1.3218197e-02  1.0760470e-02 -2.8491339e-02
 -8.4398938e-03 -1.0369535e-02  4.0118969e-03  1.0835573e-03
  7.5976830e-03  2.5805052e-02 -8.5348506e-03 -4.3000691e-02
  1.2117180e-02  2.9467786e-02  1.3210840e-02 -1.2326729e-02
 -1.2059997e-02  1.8727444e-02  2.0777922e-02  2.0611741e-02
 -2.7943119e-02  5.7680923e-03  1.2224059e-02 -1.2898931e-02
 -4.1438309e-03 -2.2920191e-03  1.4707327e-02  1.3250127e-04
 -2.6813973e-02  3.7266631e-03 -4.5952057e-03 -8.5462742e-03
  5.2259740e-05 -1.0806393e-02 -1.2849703e-02  2.6197175e-02
 -2.6153505e-02  1.1462178e-03 -1.0997527e-02  2.0464724e-03
 -5.9683700e-03  2.1860895e-03  3.9623040e-03  1.2422866e-02
 -3.2862242e-02 -2.9827742e-02 -2.0493861e-02  4.0198485e-03
 -2.3513800e-03 -3.5137694e-02  7.0124137e-04  3.2624349e-03
 -7.5632697e-03  2.5032630e-02 -2.8509602e-02 -9.1247745e-03
  4.2015128e-02  2.3744883e-02  5.7264987e-02  2.4942681e-02
 -2.3414386e-02 -6.3407674e-02 -7.2195783e-02  1.2220026e-03
 -6.5360283e-03  2.9231369e-02 -1.2032011e-02 -1.5152532e-02
  3.4289018e-03 -1.3700274e-02 -3.5558995e-02  8.3840732e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_42/kernel
[[-4.09894735e-02 -1.28364101e-01  4.95176725e-02 ...  3.24354470e-02
  -6.45101955e-03  3.61041748e-03]
 [-6.39139488e-02  7.57338703e-02 -1.07557967e-01 ...  1.04669802e-01
  -4.67562536e-03 -6.42334297e-02]
 [-2.38185469e-02 -8.35429964e-05 -1.96111272e-03 ...  7.21406937e-02
   1.40217945e-01  8.70156884e-02]
 ...
 [-1.26431614e-01  1.28040582e-01 -1.05407953e-01 ... -4.65195440e-02
  -1.07159302e-01 -6.40820265e-02]
 [ 1.33825675e-01  1.05427511e-01  1.19947948e-01 ...  8.50838497e-02
  -1.32753879e-01  9.24003273e-02]
 [-1.22518204e-01 -1.19653679e-01 -7.56891444e-02 ... -4.43099625e-02
   1.20596498e-01  2.06440054e-02]]
tensor_name:  TemporalFusionTransformer/time_distributed_43/bias
[-0.06106262 -0.04359658  0.02404699 -0.04151983  0.05963003 -0.03936644
 -0.05258411 -0.00644002  0.0447471   0.04259551  0.03787687  0.02982442
  0.06386025  0.06151906  0.01264979 -0.01211121  0.00677012 -0.03432543
 -0.01988777 -0.01467075  0.00145608  0.01124973  0.06857367 -0.01329794
  0.03348951 -0.02780662  0.04528561 -0.0255361   0.04337493  0.02555874
  0.00752813 -0.02446114 -0.00652178  0.00233668  0.00310839 -0.04038791
 -0.05580101 -0.01117687  0.01590992  0.03704461  0.0343478  -0.01589238
  0.06117477  0.04285076  0.02858491 -0.04790081  0.02453285 -0.02440976
  0.04984508 -0.01669573 -0.0018452  -0.00568379  0.00715223 -0.03697899
  0.00897981  0.03618684 -0.02128883  0.03318726 -0.03393133 -0.03099092
  0.01781171 -0.08336452  0.03225171 -0.01953329  0.01021198  0.03834104
 -0.04368483  0.03308315  0.01344056  0.02779689 -0.0170975   0.01703864
  0.02482159  0.00986841  0.02848896  0.05130193  0.00886524  0.01121666
  0.00774461 -0.01281932 -0.01443345  0.04657248 -0.03523137  0.02455913
  0.03185096  0.01220253  0.03894671 -0.01704782 -0.00661557  0.07225915
  0.00967458  0.06085228 -0.02904031  0.04400406 -0.02580618 -0.02063483
  0.00435862 -0.0503688  -0.01690438  0.00287353 -0.02144371  0.00602205
  0.0564921  -0.03265139  0.01040993  0.02963737 -0.01183929  0.04096711
 -0.02173597 -0.01470196  0.01373399  0.01781783 -0.03074907  0.00442872
 -0.00983959 -0.0756754   0.04332796 -0.00323768  0.00021408  0.0553089
 -0.01041674  0.06623735 -0.0203894   0.0632611   0.06993704  0.02329344
 -0.02314875 -0.03957338 -0.04505853 -0.01676399 -0.00634031  0.02491284
 -0.05660069  0.00044749 -0.02844718 -0.03043525 -0.03095976  0.03007459
  0.02442377 -0.00303575  0.04323546  0.01778025 -0.0260667  -0.02654907
  0.03810289  0.01890898  0.00074196  0.03116333 -0.00311441 -0.04920316
 -0.02899767 -0.04018408 -0.05052275 -0.01500817 -0.03636314  0.00560593
 -0.04845575  0.00953724 -0.05419609 -0.0047973 ]
tensor_name:  TemporalFusionTransformer/time_distributed_43/kernel
[[-0.12636194 -0.08222074  0.09760958 ...  0.08433035 -0.00259563
  -0.02690862]
 [ 0.07862113 -0.05289982 -0.08238737 ... -0.06485704  0.03693841
  -0.08593558]
 [-0.11715762  0.0512018  -0.05693987 ... -0.11884009 -0.05271581
   0.08281369]
 ...
 [ 0.02796943 -0.03853783  0.06252538 ...  0.13489036 -0.07642224
  -0.10937911]
 [ 0.03944568  0.02836768  0.09758398 ... -0.13050516  0.08255229
  -0.07060184]
 [-0.05107517  0.01586572 -0.0020739  ...  0.01259408 -0.13989358
  -0.108731  ]]
tensor_name:  TemporalFusionTransformer/time_distributed_44/bias
[-0.03240171 -0.02792068 -0.00485484 -0.01299913 -0.09683846  0.04953858
  0.0784732  -0.02726859 -0.00105483  0.02802561  0.0257101  -0.09023608
  0.08614788 -0.01525349 -0.04103339  0.04726433 -0.05396008  0.0316096
 -0.02584602 -0.05574528  0.07403355 -0.03305538 -0.06512231 -0.05599782
 -0.06732418  0.02967635  0.0386608   0.02112541  0.02036648 -0.02449933
  0.01710715  0.061081    0.05420746 -0.04659284 -0.00155566 -0.0309215
 -0.03166763  0.01959168 -0.02236117 -0.02318543  0.11014379  0.04169285
 -0.02766814 -0.03090692  0.06860931 -0.08176089  0.03011676 -0.0218609
  0.01400231  0.00052067 -0.00166955 -0.00255199  0.03273027 -0.03384747
  0.0312175  -0.0526079  -0.06910806  0.00729601 -0.04641731  0.06195711
  0.03651643 -0.0210995  -0.0282497  -0.00377404  0.02893377 -0.05180718
  0.05775121  0.00617495  0.05943212  0.02377231 -0.07678821  0.08103765
 -0.05137715 -0.02841388 -0.01023304 -0.00769693 -0.06821161 -0.09748968
 -0.03559813  0.01212622  0.04071987 -0.03271193 -0.01573063 -0.00661413
  0.01895799 -0.00408156  0.0027085  -0.0747983   0.02779512  0.01033839
 -0.06736557  0.03118321 -0.03266484 -0.02449053 -0.01141656 -0.05315207
  0.01620165 -0.01446997  0.06369669  0.03443268  0.04166004 -0.00550311
  0.05894817  0.05740106  0.03084656 -0.031967    0.00155606  0.02840752
  0.02480894  0.04777633 -0.0211052   0.04344968  0.0067827  -0.05503039
  0.03365742  0.06455693  0.14449817 -0.03823598  0.08839331  0.09623747
 -0.02336583  0.02944835 -0.02478654  0.01051285  0.09162343 -0.01652062
 -0.01208747  0.08235367  0.0161612  -0.05987925  0.0395541   0.00195732
 -0.0012018   0.07498328  0.0101582   0.00951925 -0.03321898 -0.08929097
 -0.00298885 -0.02320073 -0.00685221 -0.03117772 -0.00860729  0.00471072
  0.04099109  0.05237726  0.00951434 -0.03161883  0.01447391  0.03709851
  0.06066629 -0.04543083 -0.01388404 -0.07398666 -0.08097138  0.05916602
  0.02127854 -0.00171512  0.00851266 -0.0419051 ]
tensor_name:  TemporalFusionTransformer/time_distributed_44/kernel
[[-0.00783158  0.01039872 -0.01962826 ... -0.11432662 -0.11954149
  -0.0249618 ]
 [ 0.10988051 -0.10390805 -0.02801581 ...  0.11866543 -0.02945136
  -0.02260896]
 [-0.12434482 -0.026926    0.02094608 ... -0.00567944 -0.01839941
  -0.02479004]
 ...
 [-0.11162023 -0.07605324 -0.12801822 ...  0.14417706  0.01447101
   0.12330181]
 [-0.02266963 -0.10013805 -0.03627414 ...  0.11853933  0.01725647
   0.02145903]
 [-0.14414258 -0.01604324 -0.1152146  ... -0.12079541  0.01923712
   0.11905038]]
tensor_name:  TemporalFusionTransformer/time_distributed_45/bias
[-0.03403102 -0.0471512  -0.08782025 -0.0716453  -0.00048337 -0.05368026
 -0.02322136 -0.0692683  -0.06406017  0.00289489 -0.06167017 -0.02809345
 -0.02403852 -0.11519074 -0.04826207 -0.11480025 -0.02573076 -0.0424836
 -0.03364036 -0.01575904 -0.07031381 -0.02611237 -0.00639366 -0.05689615
 -0.01818856 -0.05103268 -0.03238705 -0.01168255 -0.08400604 -0.10672277
 -0.07164048 -0.00614763 -0.03533193  0.01376565 -0.11359565 -0.05888762
  0.0115053  -0.08921476 -0.0607118  -0.04881436 -0.03046722 -0.04987321
 -0.03322128 -0.06714541 -0.00885839 -0.04020143 -0.06331933 -0.07446346
 -0.07318557 -0.05174585 -0.10452472 -0.07013813 -0.05648902 -0.0622155
 -0.04646732 -0.03015101 -0.02802291 -0.08189168 -0.03727459 -0.04948496
 -0.00492815 -0.00960641 -0.02335776 -0.03979071 -0.08001826 -0.03981316
 -0.04358207 -0.0234787  -0.00898815 -0.02384986 -0.00527774  0.00993577
 -0.01992514 -0.00413522 -0.06533705 -0.04973919 -0.0811232   0.01333656
 -0.06609229 -0.09007059 -0.04988421 -0.07862501 -0.10512538 -0.04543803
 -0.08085685 -0.05705575 -0.16346994 -0.08431409 -0.09047122 -0.04919977
 -0.01721272 -0.03676871  0.00477233 -0.02896661 -0.04017625  0.01797801
  0.00230101 -0.05494377 -0.03407984 -0.040047    0.00209608 -0.04572882
 -0.07302779 -0.05543737 -0.04355443 -0.04785104 -0.06754429 -0.00050717
 -0.03836083  0.01849998 -0.11343265 -0.06096787 -0.04544683 -0.03260501
 -0.12928957 -0.03372412 -0.00479407 -0.06723736 -0.0502556  -0.01757124
 -0.07003156 -0.05447417 -0.0491625  -0.07279669 -0.00968543 -0.10223998
 -0.10117347  0.03535282 -0.03075493 -0.01452858 -0.00276408 -0.10877724
 -0.18320814 -0.01187173 -0.06460969 -0.06464457 -0.0619399  -0.02475762
 -0.09904454  0.03273659  0.00203217 -0.09359855 -0.04399593  0.00833902
 -0.0857913  -0.05964617 -0.11834678 -0.06719628 -0.06823057 -0.0112748
 -0.01658306 -0.06589217 -0.04856247 -0.02884846  0.01283795 -0.04312924
 -0.03676915 -0.08580688 -0.00128447 -0.10244124]
tensor_name:  TemporalFusionTransformer/time_distributed_45/kernel
[[ 0.00588187  0.13604586  0.02825703 ... -0.01355258 -0.04384803
   0.00039707]
 [ 0.04408278  0.20582634  0.13182527 ...  0.08112427 -0.13238128
   0.21872757]
 [-0.09318244 -0.07513253 -0.037217   ... -0.06786914 -0.04213229
  -0.12275679]
 ...
 [-0.04557794 -0.01952454 -0.08845031 ... -0.01673943 -0.0033486
   0.03726156]
 [-0.08065056  0.13043025  0.00621868 ...  0.21118228 -0.04636855
   0.14392395]
 [ 0.07123613  0.1444109   0.12529168 ... -0.00515966 -0.16039859
   0.07787704]]
tensor_name:  TemporalFusionTransformer/time_distributed_46/bias
[-0.01838619  0.0867595  -0.00056365 -0.04153209 -0.00376688 -0.04957839
 -0.00115779]
tensor_name:  TemporalFusionTransformer/time_distributed_46/kernel
[[ 0.01523708 -0.04505781  0.01508247 ... -0.07221959 -0.10821294
   0.07230032]
 [ 0.01532898 -0.05080228  0.06180964 ... -0.0956211  -0.03567787
  -0.00663987]
 [ 0.01852557  0.04696503  0.06475881 ...  0.03562455  0.05638964
  -0.08452567]
 ...
 [ 0.04139086 -0.09652004  0.02401186 ... -0.07451306  0.07604805
   0.02770532]
 [-0.0412034   0.15125193  0.08221588 ...  0.04945248 -0.1273755
   0.03443787]
 [ 0.04030199 -0.07407715 -0.02286819 ...  0.03548531 -0.03804905
   0.04285826]]
tensor_name:  TemporalFusionTransformer/time_distributed_47/bias
[-0.02387934  0.0380162   0.01427153  0.01708476 -0.00951316  0.01089096
  0.00550605 -0.018747    0.00700881  0.0507216   0.01764273  0.01602342
  0.01163069 -0.01978079  0.01334947  0.00870035  0.01336679 -0.03676464
  0.00233734  0.03291903 -0.00762565 -0.02207685  0.00509595 -0.00903638
 -0.01382926  0.00634273 -0.05230441 -0.01532134  0.00955783 -0.03159144
 -0.00479336 -0.01784198 -0.0028636   0.01313248 -0.00800005  0.03826982
 -0.01005472 -0.01872263  0.01757918 -0.02662046 -0.02388506 -0.01393875
 -0.018099   -0.01248583 -0.03529459 -0.02987065  0.02431987 -0.02269691
  0.00403514 -0.015543   -0.01701448  0.00485585 -0.0323949   0.01503708
 -0.01691497 -0.02699272 -0.0145213   0.00466573 -0.00385671 -0.00302056
  0.0089296   0.0074399  -0.01567842  0.02119249  0.01329875  0.01054805
  0.00570665 -0.00878816 -0.00336118 -0.01793456 -0.00127924  0.03876829
 -0.04036766  0.00019229  0.02026255 -0.00047447  0.02926962 -0.03037846
 -0.02462373 -0.02016029 -0.01713163 -0.01951569 -0.01778694  0.0059428
 -0.0203078  -0.04422111 -0.0290166  -0.02208167 -0.03010527  0.02882054
 -0.00090493  0.00519615 -0.02000514 -0.01812475  0.00604314 -0.00488896
 -0.03352046  0.03524284  0.01802181  0.00529754  0.01997032  0.05834323
  0.00977818  0.01699731 -0.04972488  0.00330143 -0.02312989  0.01249797
  0.01508438  0.0027477   0.02325297 -0.01669951 -0.01665067 -0.01127171
  0.01023782 -0.02363515 -0.00184841  0.0465633  -0.0051259  -0.01047155
 -0.00917318  0.00863784  0.01586169 -0.06179178 -0.00676129  0.00844739
  0.0061684  -0.01049696  0.01947123 -0.03794388 -0.03290054  0.00788321
  0.0451256  -0.02171937  0.03174495  0.0148103  -0.01856574 -0.01732725
  0.03311842 -0.02530174 -0.03727067 -0.03626274 -0.03465145 -0.0230019
  0.01691686 -0.02441034 -0.02826541 -0.00543958  0.01691135  0.02313183
 -0.00895303  0.01406801  0.02585959 -0.01022867  0.00912291 -0.01445413
  0.01505925  0.01236608  0.03741796  0.03094183]
tensor_name:  TemporalFusionTransformer/time_distributed_47/kernel
[[ 0.03580602 -0.01158403  0.00062645 ...  0.05957854  0.00297969
   0.0408995 ]
 [ 0.04458279  0.03268803 -0.06511323 ...  0.07841695  0.01926503
  -0.10192617]
 [ 0.02249692 -0.01689221 -0.02230013 ...  0.05929675 -0.00602084
   0.01880009]
 ...
 [-0.05922246  0.04400544 -0.05321724 ... -0.04883697  0.05380818
  -0.04974622]
 [ 0.02018422  0.078377    0.04150607 ... -0.00777676  0.01383493
  -0.03459144]
 [ 0.04420681  0.0451193   0.05224333 ... -0.00957175 -0.01547587
  -0.09278729]]
tensor_name:  TemporalFusionTransformer/time_distributed_48/kernel
[[-0.12422659  0.06278561  0.00021948 ... -0.05523612 -0.13311167
   0.03216581]
 [-0.07460873  0.03078393 -0.04929058 ... -0.01635874  0.02886761
  -0.00132772]
 [ 0.06243407  0.11830253  0.05102908 ...  0.12750284  0.05090449
  -0.0767671 ]
 ...
 [-0.11840831 -0.1202255  -0.03290797 ...  0.12444452  0.04044847
   0.01901712]
 [-0.12478822 -0.092002    0.13526666 ...  0.06844196 -0.07730356
  -0.07782482]
 [ 0.11147302  0.02366169 -0.08253774 ...  0.08041692  0.04571849
   0.07186847]]
tensor_name:  TemporalFusionTransformer/time_distributed_49/bias
[-0.00413224  0.05794824  0.0537503  -0.06210172  0.03586477 -0.00832864
 -0.05057912  0.04438428  0.03841354 -0.04928485 -0.04920204  0.0617029
  0.07579952 -0.05607852 -0.05839715  0.03687847 -0.06457759 -0.01135352
  0.04529184 -0.04096758 -0.07024996  0.04388131  0.06506979  0.03427926
 -0.00690129  0.01515447  0.04711828  0.01267382  0.03034368  0.0442277
  0.03956486 -0.04706597  0.07250275  0.02691873 -0.04661623  0.03475467
 -0.03318247  0.02106065  0.03851945  0.0295233   0.04892841  0.04245231
  0.05728624 -0.04389835 -0.0324497  -0.00042195 -0.04467404  0.00490713
 -0.07555763 -0.03834096  0.04889567 -0.00025373 -0.0001276   0.03840426
  0.00040918 -0.0118464  -0.05552168 -0.00494095  0.06184338  0.02748265
  0.07307329 -0.02524442 -0.04780142 -0.08323517  0.01870522 -0.00264596
 -0.01936014 -0.06401358  0.0475123   0.053631   -0.03446584 -0.0644168
  0.06569508  0.01961796  0.02643303 -0.0454724  -0.0597418  -0.05498102
  0.07717662 -0.03590871 -0.08254988  0.03671683  0.04832929  0.02435894
 -0.06354704  0.04229819 -0.06557637 -0.04030498 -0.02032233  0.05453031
 -0.07247985  0.0704132   0.05139212 -0.05211911  0.05939561 -0.04342751
 -0.01086773  0.0083263  -0.05020179  0.03033297 -0.02871438 -0.03057164
  0.03637258 -0.06778767  0.03562522 -0.02591971  0.04404564  0.0504587
  0.04839359 -0.06107734  0.056029    0.05860655 -0.0397975   0.03032584
  0.00854428 -0.0502028   0.05737269  0.07703759  0.06698173 -0.06997053
 -0.02578973  0.04481433  0.06178921 -0.04960427 -0.02823906  0.04296114
 -0.03649212  0.0275913   0.04629375  0.03672046  0.03680087  0.03405507
 -0.06625216  0.05872514 -0.03213903  0.0545812  -0.02694549  0.0092142
  0.0504781   0.06372388 -0.01784567 -0.02335974 -0.0456729   0.04416199
  0.05658309  0.03479522  0.05066455  0.04636145  0.05625469 -0.01011229
  0.02756188 -0.05188582  0.02675201 -0.0193914   0.0629034   0.04945624
  0.05720163  0.04642064  0.05436942  0.03240127]
tensor_name:  TemporalFusionTransformer/time_distributed_49/kernel
[[-0.02020968 -0.08897962  0.0759018  ... -0.10918841  0.0439224
  -0.10091329]
 [ 0.06295415  0.06058123  0.02996049 ...  0.12674607  0.12175889
  -0.00425791]
 [-0.05896584  0.02029905 -0.03113459 ...  0.10475166  0.0563508
   0.04384597]
 ...
 [ 0.03413324  0.05691574 -0.00795495 ...  0.01524888 -0.06399246
  -0.0950714 ]
 [ 0.05737074  0.12721412 -0.12333647 ... -0.04405176  0.06108914
   0.02057141]
 [-0.03005026 -0.02306498  0.16302288 ...  0.18713862  0.0116848
   0.19354671]]
tensor_name:  TemporalFusionTransformer/time_distributed_5/bias
[-1.19149797e-02 -7.40445033e-02 -2.10491498e-03  3.59651968e-02
 -3.93650122e-03  4.17571031e-02  3.51732634e-02 -1.38758626e-02
 -2.68097166e-02 -8.63205362e-03 -2.86673643e-02  6.58335239e-02
 -1.37498574e-02  2.65142098e-02  4.31167020e-04 -6.10410236e-02
 -3.08979466e-03 -4.61334409e-03 -6.22361228e-02 -3.95225994e-02
 -1.66323222e-02 -5.60185537e-02  3.44375148e-03 -1.47731164e-02
  6.34431420e-03  6.86481670e-02  5.57480054e-03 -2.53307912e-02
 -4.45732810e-02 -3.24400142e-02  6.09251251e-03 -7.83271343e-02
 -1.96328014e-02 -6.17379621e-02  2.42378227e-02  2.09736973e-02
 -1.41464248e-02 -5.86942695e-02 -4.01838403e-03 -2.08524577e-02
  2.86904704e-02  8.64560890e-04 -8.42185169e-02 -3.16414908e-02
 -1.64444037e-02 -3.26203182e-02 -3.07418290e-03  3.67026702e-02
 -3.00107920e-03  5.33599779e-02 -3.65134440e-02 -2.10007522e-02
  2.95380354e-02 -2.10432839e-02  1.63762947e-03  1.01739570e-01
  4.25390452e-02 -2.68964507e-02 -3.60855996e-03 -9.09694843e-03
  5.59352487e-02  1.83632039e-02 -6.66598324e-03  3.85364401e-03
 -7.88124576e-02 -4.34455909e-02 -6.64921179e-02  4.16518301e-02
  1.45820305e-02  7.33255222e-02  1.79657023e-02 -2.31954288e-02
 -9.50024871e-04 -2.00191792e-02 -2.82866671e-03  2.40392089e-02
 -8.07966515e-02  1.08064339e-02  6.43552989e-02  2.44887592e-03
  9.70984530e-03  1.49896750e-02  3.31789181e-02 -8.64405558e-03
  2.37771552e-02  5.21506518e-02  5.13235386e-03  2.02753972e-02
 -3.33634615e-02 -1.95727106e-02  3.68039757e-02 -8.83441791e-03
 -9.73614957e-03  2.82921176e-02  5.83279654e-02 -1.24344919e-02
 -5.71788214e-02 -2.69417595e-02 -2.29483210e-02  1.25862034e-02
  2.55163200e-02  9.59877949e-03  3.73876281e-02  8.83651339e-03
 -2.45902818e-02  3.88312116e-02 -3.91017050e-02  4.59096879e-02
  8.29112902e-03  6.70407084e-04 -3.81379835e-02  4.93108816e-02
 -4.13585342e-02  3.12117487e-02 -3.23441774e-02  1.12919174e-02
  6.33970797e-02  1.36274099e-02 -6.48892904e-03 -5.26906550e-02
  4.60950432e-05 -1.73827093e-02  9.78497975e-03 -5.48664592e-02
  4.54691388e-02  1.88944209e-02 -5.28638102e-02 -7.83989963e-04
  1.09367464e-02  2.77642850e-02 -1.97746456e-02 -1.29159614e-02
  3.89467701e-02 -5.34660704e-02  1.46499667e-02  1.16146803e-02
 -1.31444703e-03  3.22699212e-02 -2.24209944e-04  1.21299527e-03
 -5.47038354e-02  1.51752708e-02  9.96407587e-03  1.12545080e-02
  3.03740855e-02 -2.03943830e-02  6.05439059e-02  2.56609935e-02
  5.49104325e-02  1.25800092e-02  6.18669158e-03  4.12317812e-02
  3.88021134e-02 -6.13509826e-02 -2.30385773e-02  8.78035463e-03
 -2.81315837e-02 -4.06827740e-02 -1.13146873e-02 -9.18816030e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_5/kernel
[[-0.14106742 -0.06511349  0.14022213  0.08990194  0.00217621 -0.00455823
  -0.03330542 -0.01244974 -0.00893393  0.10849795  0.1360946  -0.0670686
  -0.15731588 -0.01797728  0.10642487  0.12023845  0.07648471  0.12993114
  -0.01286102 -0.04959625  0.15834577  0.11234178 -0.09275176  0.1262449
  -0.0027191  -0.02563706  0.06417283 -0.0338671   0.01412642  0.02071829
  -0.15593168  0.03671925  0.0499105   0.02603258  0.10122027  0.16303036
  -0.01294021  0.0263029  -0.09729261  0.1361188   0.08907717  0.15380107
  -0.06872058  0.11148071 -0.02942238 -0.04057914 -0.00220632 -0.02131569
   0.14961015 -0.00772811 -0.03680291 -0.16300516 -0.12155111  0.07416198
  -0.02015237 -0.16630079 -0.00365447 -0.11208045 -0.01044696 -0.01701712
   0.0489704   0.04068829  0.02567436  0.11187867 -0.15724446  0.05978923
   0.03346823 -0.08059145  0.07575546  0.01191203  0.01232234  0.05099002
   0.10389091 -0.07760954 -0.15854485 -0.01966992  0.04072421  0.07357099
  -0.04308377  0.05892276 -0.14540727 -0.02538401  0.04661855 -0.01013772
  -0.06351173  0.02063564 -0.03564087 -0.16603556  0.00783309 -0.17196123
  -0.07247594  0.14977813  0.06063608  0.09740228  0.06575776  0.1656441
   0.02157668 -0.0526702   0.107471    0.05441749  0.18090434 -0.08592223
   0.02040765 -0.0101703  -0.07475518  0.01869849  0.13913596  0.03018658
   0.14915454 -0.1422747   0.11788993  0.03053691 -0.08552269 -0.10058729
  -0.18204793 -0.08294403 -0.0318199   0.14532322  0.00832332 -0.02839506
   0.0890349  -0.04946834  0.0043964   0.13917685 -0.09263184 -0.04507127
  -0.02103986  0.17936121  0.0362622  -0.07790096 -0.01397904  0.11779819
   0.129195    0.06127781  0.09241585 -0.07957847  0.01222232  0.16762562
  -0.13874978  0.00066746  0.05530123 -0.0811442   0.13566393 -0.03961602
  -0.12774602 -0.10756896 -0.05931725 -0.14672214  0.14712916 -0.01029121
   0.15636943 -0.00441016  0.16595878  0.07307454 -0.17436945  0.15045133
  -0.08519746 -0.08471482 -0.14024958  0.00606155]]
tensor_name:  TemporalFusionTransformer/time_distributed_50/bias
[-0.00102274  0.0841611  -0.0044964  -0.00475076 -0.00652547 -0.00191516
 -0.00184585]
tensor_name:  TemporalFusionTransformer/time_distributed_50/kernel
[[-0.09839094 -0.019367    0.00662851 ... -0.10075574  0.05260142
  -0.03626821]
 [-0.08849628  0.05750653  0.09965442 ... -0.21474269 -0.18190853
   0.15157242]
 [-0.0677049   0.07855567 -0.05240149 ... -0.13687235  0.09387747
   0.1351759 ]
 ...
 [-0.02662815  0.05861855 -0.11967679 ...  0.07006123 -0.08296639
   0.05632757]
 [ 0.03894291  0.02733284 -0.07081022 ... -0.00924488 -0.18385434
   0.09027287]
 [-0.09544838  0.01054756 -0.13617633 ...  0.00676197  0.00158528
  -0.01664527]]
tensor_name:  TemporalFusionTransformer/time_distributed_51/bias
[-0.00715694  0.01760478 -0.03701473 -0.00836636 -0.01234251 -0.01198889
 -0.00718239]
tensor_name:  TemporalFusionTransformer/time_distributed_51/kernel
[[ 0.10239779  0.12380604 -0.0129368  ...  0.08552848 -0.10729913
  -0.17635037]
 [-0.0141337   0.2328579  -0.17638619 ... -0.20528194  0.12923516
   0.05994172]
 [-0.10135134 -0.08943014 -0.16837007 ...  0.16532049 -0.08430904
   0.03972756]
 ...
 [ 0.07367141  0.00179465  0.13050517 ... -0.03006098  0.00044708
  -0.11642392]
 [-0.19646677 -0.00993779  0.06794542 ...  0.04199838 -0.07824093
  -0.13648492]
 [ 0.17684786 -0.11438622  0.22442487 ... -0.0061548   0.09213352
   0.09236144]]
tensor_name:  TemporalFusionTransformer/time_distributed_52/bias
[-5.30283106e-03  2.88214739e-02  5.13903750e-03 -1.16004748e-02
  8.21910240e-03 -5.18928468e-03  6.68127323e-03 -7.69320270e-03
  1.41686974e-02 -3.07224784e-03 -9.88258180e-05 -1.56128509e-02
  8.55892990e-03 -6.02213759e-03 -1.96171249e-03  1.60348117e-02
 -1.35646686e-02 -1.34394951e-02 -8.71205050e-03 -3.54892947e-03
 -1.57839656e-02 -8.37575272e-03 -1.17937680e-02  2.22875457e-03
  2.65446436e-02  1.01665482e-02  2.22655377e-04 -2.97735468e-03
  7.68608588e-05 -7.08387792e-03  1.02963252e-02  1.65418647e-02
  2.53123958e-02 -4.30975435e-03 -3.12309666e-03  1.74463037e-02
 -6.97441632e-03  8.06684606e-03  6.98305899e-03  1.95771642e-03
  1.57083590e-02  6.22790027e-03  1.67051721e-02 -2.94666644e-03
  1.41006485e-02  9.62096034e-04 -8.02795123e-03  4.50074812e-03
  2.93550733e-03 -7.39669381e-03  8.78255162e-03 -2.36841827e-03
  7.62576796e-03 -1.67541914e-02 -1.38628557e-02  2.20855605e-02
  1.06022405e-02 -6.63171662e-03 -4.62725526e-03  4.44886135e-03
  2.41912138e-02  8.80338997e-03  1.78892110e-02 -4.20263154e-04
  1.86017025e-02 -2.12987475e-02 -3.37565807e-03  2.16205250e-02
 -1.83708034e-02  1.50840394e-02 -9.13184020e-04 -9.91521031e-03
 -1.49337100e-02 -1.27711631e-02  8.26656033e-05 -2.92337337e-03
 -1.95127837e-02 -3.05793318e-03 -2.01897640e-02 -3.73712815e-02
  1.64664388e-02 -4.47537005e-03 -1.76007804e-02 -8.91647860e-03
 -1.04387244e-02  3.06044728e-03  1.62585806e-02 -5.08677401e-03
 -7.94948172e-03  1.39947627e-02 -9.19707865e-03 -1.12010054e-02
 -3.91143002e-02  1.00068087e-02  6.98093465e-03 -1.10504916e-03
 -1.14419069e-02 -7.32775405e-03 -1.77116226e-02  9.04213637e-04
 -1.34720672e-02  1.03204129e-02 -5.97842690e-03  1.00286668e-02
  1.52166979e-03 -1.94897596e-02  2.24093720e-03  5.43571636e-03
 -1.02100689e-02 -1.99149549e-03  1.72325037e-02  8.10586754e-03
 -2.87370775e-02 -1.70950759e-02  2.49762237e-02 -2.14597508e-02
  6.59217499e-03 -1.45824142e-02 -5.31850522e-03 -8.01886246e-03
 -6.86598010e-04 -8.05322255e-04  1.25496676e-02  5.38307359e-04
  7.80140283e-03 -8.13775696e-03 -2.52215266e-02  1.83447897e-02
 -1.84965525e-02  1.48865376e-02 -2.27521989e-03 -6.25671726e-03
  1.60751157e-02  2.69816350e-02 -2.42212806e-02  1.66550744e-02
 -4.11881087e-03  1.00527657e-02 -6.87552430e-03  8.54027108e-04
 -9.92226508e-03  2.76837908e-02  1.68556478e-02 -6.60336809e-03
 -6.92317681e-03  3.49506247e-03 -4.76847729e-03 -1.65668242e-02
  2.40571126e-02 -1.43770529e-02 -2.83738226e-02 -1.95158459e-02
  2.68623140e-02  1.07625630e-02  1.20392423e-02 -2.02315990e-02
  1.84601545e-02 -6.14369335e-03 -1.45955235e-02  2.16808394e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_52/kernel
[[ 0.08640366 -0.0894616  -0.01150297 ...  0.03179169 -0.1021281
   0.08082534]
 [ 0.02221107 -0.08359287 -0.08946073 ... -0.14857334  0.00129547
   0.01875077]
 [ 0.02858819  0.01822972 -0.10000133 ... -0.06453794  0.03675429
  -0.09713022]
 ...
 [ 0.03252341 -0.04561947  0.14578983 ...  0.01198622 -0.00926504
  -0.13370204]
 [ 0.11086845  0.0749288  -0.01869119 ... -0.04434801 -0.1184944
  -0.0048214 ]
 [-0.10862905 -0.01112237  0.0699689  ... -0.05630786  0.07693823
  -0.12453875]]
tensor_name:  TemporalFusionTransformer/time_distributed_53/bias
[ 1.2027700e-02  6.9626374e-04  2.3635939e-02  3.3202875e-02
  1.4436127e-02  2.8284583e-02 -2.9061152e-02 -2.1911319e-02
  1.6755020e-03 -1.6133187e-02 -1.7492903e-02 -3.2174364e-02
  6.6924207e-03 -2.7170464e-02  8.6517334e-03  1.5583976e-02
 -3.3716191e-04  2.0980924e-04  1.5090889e-02  1.3233066e-02
 -1.7748913e-05  2.1188892e-02  8.8060048e-04  3.6246504e-03
  1.2839819e-02  3.3036280e-02  3.1111578e-03  1.7657105e-02
  1.3303895e-02 -2.0209324e-02  7.2867721e-03  2.5678584e-03
 -4.7399395e-04 -5.1201852e-03  1.7979192e-03 -2.5647094e-02
  5.8844467e-03  3.3994573e-03 -1.3323867e-03  3.9841644e-03
  9.7427834e-03 -1.9135838e-03 -1.7350852e-03 -9.4867647e-03
  4.4900548e-02 -2.7549261e-02  6.4688131e-02  4.6239467e-03
 -2.8453292e-02  1.7626876e-02 -5.9404485e-03  1.4243904e-02
 -7.4733612e-03 -2.0473124e-03 -4.4424431e-03  2.2085062e-03
 -1.9008750e-02 -1.7202547e-02 -1.7093068e-03 -1.1437353e-02
  2.4661420e-02 -6.5492005e-03 -7.2256620e-03  8.3116964e-03
  1.8091474e-02 -2.9027045e-02  1.6468058e-03 -2.0225614e-02
  5.9085647e-03  1.6498247e-02  2.7117174e-02  2.5475409e-03
  9.4127096e-03  3.8691767e-04  9.8407613e-03  7.2567416e-03
  5.3386181e-03  2.9935434e-03 -2.2430904e-02 -1.6866667e-02
 -4.4734697e-03  6.3905679e-03  1.4286573e-02  4.4544819e-03
  1.3529180e-02  2.8426861e-02  8.9622447e-03 -3.4865860e-02
  9.6772434e-03  3.4917702e-03  7.5155348e-03 -2.3496356e-03
  1.3978665e-02  1.6521765e-02  1.2990774e-02  3.0918039e-02
 -7.9132238e-04  6.0634146e-04 -4.1026524e-03 -1.3918931e-02
 -1.0304756e-02 -1.4499738e-02  7.6298071e-03  1.3713038e-02
 -2.6892156e-03  7.4853175e-03 -5.7450117e-04  1.5416547e-02
  7.4698459e-03  1.9199350e-04 -1.7769668e-03  8.3697680e-03
  5.2480102e-03  6.4724335e-03 -2.0827698e-02  9.3992404e-04
 -1.3737065e-03 -1.2396322e-02 -9.8607391e-03  2.6691307e-03
 -4.7869561e-03  2.0921433e-02 -5.0779502e-03 -3.4001162e-03
 -2.9347122e-02  3.5635069e-02 -1.3891498e-02  6.3560888e-02
  4.9536735e-02  7.7043958e-03  1.0361764e-02 -2.5125382e-02
  1.4014215e-02 -9.8678246e-03  6.3422387e-03  2.0000853e-02
 -2.2071347e-02 -7.9810992e-03  9.5434295e-04 -1.6433336e-05
  1.9594342e-02  8.7419702e-03 -9.3904892e-03  9.1200257e-03
 -8.5299592e-03 -5.3584143e-03  5.5234516e-03  1.8907866e-02
 -3.0740495e-03 -1.5424455e-03  1.6555697e-02  6.9006588e-03
  4.5987861e-03 -1.8707775e-02  1.7179411e-03 -3.3391118e-03
  1.5695998e-02 -8.4381672e-03 -1.6820913e-02  1.1087924e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_53/kernel
[[-0.0251005   0.11078684  0.02796813 ... -0.09741573 -0.01167743
  -0.06293364]
 [-0.0656881  -0.04870184  0.01650769 ... -0.10138093 -0.13546753
  -0.08471925]
 [-0.10730878  0.00971111 -0.02111734 ...  0.10258843  0.09698372
   0.03406756]
 ...
 [ 0.0459754   0.104441    0.06366223 ...  0.11123849 -0.00592122
   0.08543798]
 [ 0.07515976  0.09869543  0.07634136 ...  0.04168148 -0.02001478
   0.11876357]
 [-0.07472399 -0.05808902  0.1068152  ...  0.1182813  -0.04903093
  -0.04973448]]
tensor_name:  TemporalFusionTransformer/time_distributed_54/bias
[ 1.51013145e-02  5.09888045e-02  1.01726241e-02 -3.67587171e-02
 -5.88758150e-03 -4.67222603e-03  6.73360797e-03 -4.44417633e-03
  9.73729044e-03 -2.22579576e-02 -1.13536138e-02 -1.60952155e-02
 -3.65111884e-03 -4.01380938e-03 -5.77198435e-03 -1.36525603e-03
  2.73488089e-03 -4.64849360e-03 -1.49902152e-02  1.77487172e-02
  2.49287747e-02 -1.90362055e-02  1.04689198e-02  1.63560174e-02
  6.98063662e-03 -2.35437043e-03  8.93507618e-03 -9.93018132e-03
  2.94180610e-03 -5.66507783e-03  2.22871476e-03 -7.94281065e-03
  8.27521738e-03 -2.84968056e-02  3.20132636e-03 -1.97336525e-02
 -9.25822940e-04 -7.01639336e-03  1.13922020e-03  4.40836977e-03
 -3.38432342e-02  7.86133949e-03  7.73638673e-03  1.87658314e-02
 -1.20972539e-03  1.41780945e-02 -8.93849065e-05 -7.75178242e-03
 -1.90974232e-02  1.75847821e-02 -7.59895239e-03 -1.62362959e-02
 -6.19246042e-04 -9.66882892e-03 -5.18282223e-03  6.45068064e-02
 -8.81509483e-03  5.28065488e-03  1.23313880e-02 -6.36108732e-03
 -6.91045821e-03 -1.76237170e-02  1.97008736e-02  1.13121523e-02
  1.48079256e-02  9.17932205e-03  1.80104871e-05  1.30495252e-02
  8.77514132e-04 -3.02476548e-02  2.99943797e-02  1.42635824e-02
 -1.30873537e-02  4.67435131e-03 -1.11504635e-02  7.65312463e-04
  8.68138671e-03 -1.26207247e-02  7.74268107e-03  8.70808028e-03
  2.30193455e-02 -2.81397235e-02 -2.24114209e-02  8.98773689e-03
 -1.12219062e-02 -3.61139933e-03 -8.79643578e-03 -3.46028362e-03
 -1.69834122e-02  2.60922778e-03  1.24361785e-02 -8.00025649e-03
  1.07498812e-02 -1.56920925e-02 -1.08970832e-02 -1.16299102e-02
  1.95463020e-02 -1.37793822e-02  8.89219344e-03 -5.30753937e-03
  1.34170591e-03 -3.82070593e-03 -2.87934183e-03  1.40380077e-02
  1.20689126e-03  3.13736685e-02  1.60642676e-02 -9.71321296e-03
  7.12886406e-03  2.58981343e-03  1.37646985e-03  1.45608624e-02
  1.29043953e-02 -1.26983961e-02 -5.23893163e-03  1.94164421e-02
  1.80722438e-02 -1.74161885e-02  4.92945197e-04 -8.21154827e-05
  9.43384133e-04 -4.20139870e-04  3.56449448e-02  1.13129858e-02
  1.69291534e-03 -2.60993908e-03 -2.49586417e-03  5.46601089e-03
 -5.57541614e-03 -1.14566656e-02  4.83484287e-03  1.19090499e-02
 -1.23540955e-02 -1.19074658e-02  8.64560308e-04  8.09395511e-04
 -1.09059177e-03 -1.27180694e-02 -6.65515242e-03  2.90907733e-02
 -1.33901434e-02 -4.86988062e-03  2.58524809e-03  4.01157327e-03
  1.03927692e-02 -1.22723794e-02 -1.19781764e-02 -1.61108281e-03
  9.93151311e-03 -7.30426284e-04  8.81172623e-03 -1.06890099e-02
 -1.23168575e-02 -6.87485188e-02 -1.06731907e-03  1.98181346e-02
  4.80997050e-03 -1.29436539e-03  5.46238991e-03  5.37732476e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_54/kernel
[[-0.05904489 -0.08269304  0.07870854 ...  0.05280517 -0.12416603
   0.01631024]
 [ 0.07375932 -0.02270963 -0.05948253 ... -0.00574758  0.09086726
   0.08459567]
 [ 0.01438499  0.05588709  0.07037569 ... -0.01458051 -0.00571216
   0.0928645 ]
 ...
 [-0.03329667 -0.04636732 -0.00014256 ...  0.03871083  0.11169914
  -0.06430568]
 [-0.05863733 -0.04295466 -0.04609798 ...  0.08663208  0.06562229
   0.04254648]
 [-0.06653097  0.07496583  0.11216426 ... -0.09290361 -0.06177119
  -0.02301735]]
tensor_name:  TemporalFusionTransformer/time_distributed_55/bias
[ 0.00497097  0.05116985 -0.02900585  0.06204917 -0.01818377 -0.0315891
 -0.01324249 -0.04085902  0.00121561 -0.03890481 -0.0076591   0.02077007
 -0.003533   -0.03314438 -0.02265093 -0.03203289 -0.02665378 -0.03207983
  0.03227368  0.02920187  0.04739476  0.01509089  0.01776503  0.0208561
 -0.04424198 -0.03005725 -0.01918956  0.02191424 -0.02815937 -0.0578974
 -0.00578036  0.00767338  0.00633347  0.04308872 -0.00813022  0.04085251
 -0.01269977 -0.00032668 -0.05019265 -0.04309836  0.0368153   0.00100761
  0.04763488  0.02237984 -0.04747604  0.00493457 -0.0198823  -0.00817817
 -0.00172845 -0.00039186 -0.0190331   0.01126498 -0.03984183 -0.03660611
  0.00248044  0.07577425 -0.00808856 -0.05287402 -0.0126469  -0.06363427
 -0.01379664  0.02221944  0.02726768  0.02561144  0.03422125  0.02833677
 -0.03352508  0.02585522 -0.01798075  0.04584744  0.03748689  0.0122619
 -0.00937735 -0.00344919 -0.02000997 -0.03135592  0.01318136 -0.00502732
 -0.03227525 -0.03247861  0.00541781  0.04842689  0.0408198   0.01141062
 -0.00356357 -0.00757657 -0.0112639  -0.03842769 -0.0025031  -0.0554163
  0.00017761  0.00135037  0.008184   -0.01842548  0.01042861  0.00102488
  0.04103009  0.02505314 -0.00142306 -0.02209655 -0.00960149 -0.03700377
 -0.02854825  0.02468969 -0.01581919  0.03081215  0.02736726 -0.02788388
 -0.01271645  0.00074535 -0.01802265 -0.02477895 -0.01181048  0.0275629
 -0.00729861  0.02591573 -0.01695942  0.01222215 -0.02323967 -0.00775694
 -0.01626885 -0.02645418  0.06997401  0.0366454  -0.03101577 -0.01840029
 -0.03230003 -0.03767347 -0.03026652  0.0200529   0.00603268  0.00092041
  0.01714663 -0.04418949 -0.04037804 -0.0205901  -0.01867839 -0.0009547
 -0.00793924  0.05491434 -0.00975436  0.00194078 -0.03074354 -0.05498755
  0.00325951  0.00359974 -0.02058399 -0.04334259 -0.02158315 -0.03158254
  0.00152512 -0.0287416   0.00415965  0.06102377 -0.01063236  0.0131949
 -0.01106059 -0.02835421 -0.02769306 -0.03684742]
tensor_name:  TemporalFusionTransformer/time_distributed_55/kernel
[[-0.03249341 -0.02215457  0.092661   ... -0.07273592 -0.16254564
   0.00039329]
 [-0.04839421 -0.06884487 -0.06080464 ...  0.02808634 -0.06561045
   0.0432697 ]
 [-0.12934506 -0.05342274  0.05493704 ...  0.02465538 -0.0465023
  -0.03901295]
 ...
 [ 0.06067867 -0.156762    0.02449863 ...  0.15129147 -0.06883049
   0.12518871]
 [-0.05807974 -0.11748761  0.02802346 ...  0.07401231  0.15213013
   0.03099851]
 [ 0.07706659  0.06899449 -0.02786255 ... -0.13147104  0.01309794
   0.10525587]]
tensor_name:  TemporalFusionTransformer/time_distributed_56/bias
[-0.0158445   0.01126617 -0.00458715  0.00287818 -0.01570608  0.0126524
  0.00410174 -0.01622839  0.01072087 -0.00381186  0.01095383  0.01754203
 -0.00170099  0.01051054 -0.02533592 -0.0035044  -0.0192521  -0.00180937
  0.02280876 -0.02652033  0.0152746   0.01319957  0.00651512 -0.00970024
 -0.00949599 -0.01168754  0.00286579  0.0083698   0.00057632  0.01413029
  0.01818029 -0.00360638 -0.02333656 -0.00480066 -0.0284714  -0.00280978
 -0.0350345   0.00934491 -0.0137879  -0.00269963 -0.0160217   0.01472075
 -0.02779153  0.00989784 -0.01841076  0.00944224 -0.03138153 -0.02410558
  0.01187634  0.0077206  -0.02565281  0.00126013  0.0107017  -0.00303592
  0.02537308 -0.0028533  -0.01616647 -0.0018169   0.01724425 -0.02583071
  0.00050287  0.00552394 -0.00133614  0.00625261 -0.00630602 -0.00078328
  0.01015126 -0.00949767 -0.00969067 -0.01500595 -0.01988354 -0.00237145
  0.00504143 -0.00365297 -0.00477116  0.01410043  0.00273476 -0.00283074
 -0.02288806  0.00973316 -0.02156151 -0.00654337  0.00123377  0.0016494
 -0.01202309 -0.01889019  0.02552235 -0.00300341 -0.00890311 -0.02658123
 -0.04053808  0.02037818 -0.0095182   0.00258207 -0.01004744 -0.01925068
 -0.0185237   0.01439073 -0.00172726  0.03895928  0.00947618 -0.01210098
  0.01164195 -0.003592    0.0125796  -0.01806289  0.02262998 -0.01345373
 -0.01682797 -0.00672263 -0.01521701  0.04598304  0.00533218 -0.00314536
 -0.00952316 -0.02817596 -0.00311382  0.01502418 -0.01838282  0.00473238
 -0.00409581  0.0052138  -0.03212468  0.01076855 -0.00908834 -0.0151642
 -0.00508405 -0.01546831 -0.01226134  0.00974703 -0.00461679 -0.0145447
 -0.005794    0.01001476  0.00782257 -0.02308349 -0.02727987  0.03080096
 -0.01384306 -0.01325327  0.00325191  0.00457579  0.01474059 -0.00867911
 -0.00663453  0.00249136  0.00701775 -0.00081159  0.01543549 -0.02378334
 -0.02791686 -0.01277721 -0.00517815 -0.00593948  0.01614792 -0.01389967
 -0.02026372  0.00613017 -0.02834933  0.00258927]
tensor_name:  TemporalFusionTransformer/time_distributed_56/kernel
[[ 0.00496349  0.01640286 -0.00343148 ...  0.00777589 -0.08132097
  -0.10553396]
 [ 0.05317013  0.02320907  0.11079258 ... -0.03048585  0.0470363
   0.09845765]
 [ 0.06418954 -0.06312898 -0.12304612 ...  0.04919372  0.11628498
   0.10111826]
 ...
 [ 0.12118379  0.0922833   0.06436964 ... -0.02625115 -0.06799488
  -0.08968485]
 [ 0.08056897  0.12135752 -0.09865887 ...  0.01658839 -0.12444732
  -0.13778555]
 [ 0.0427201   0.05064347 -0.02755378 ... -0.09630559  0.01341856
  -0.033194  ]]
tensor_name:  TemporalFusionTransformer/time_distributed_57/bias
[-0.0349835  -0.06125759 -0.00541512  0.03765952  0.02756017 -0.02966269
  0.00073709  0.00934845  0.0061285   0.04340874 -0.05358347  0.03172246
  0.03264277  0.01020958  0.01001426 -0.00907454  0.0158547   0.04682536
 -0.01513936 -0.01712899 -0.04485145 -0.00761183  0.0489173   0.01323339
  0.01715546  0.04637038 -0.01534098  0.02576933 -0.03199947  0.00257989
 -0.01359951  0.0337347  -0.06155958 -0.00564316  0.01994045 -0.0596403
 -0.01691255  0.03902762 -0.03788811 -0.00361691 -0.01621582 -0.00985154
 -0.01879541  0.0248345   0.01298249 -0.01744852  0.00205445  0.05615025
 -0.00840974  0.03271476  0.00871711 -0.00272889 -0.00505005 -0.03444303
  0.05156745  0.00936779  0.014938    0.012975   -0.01806396  0.06183219
 -0.02479835 -0.01646072 -0.0241207   0.02325279 -0.03354338  0.01914446
 -0.00762896  0.05028329 -0.03740564  0.02404502  0.0210416   0.02385633
 -0.04592027 -0.02184897  0.02938637  0.03448936 -0.02245981 -0.03043498
 -0.00757576  0.01224361 -0.03353404 -0.02588383  0.02239353 -0.01843346
  0.01176277 -0.02133656 -0.03171087  0.0250012  -0.0099234  -0.02601489
 -0.02452691  0.00937382 -0.00789945  0.00107874 -0.039237   -0.00455146
 -0.02792304  0.04647059 -0.03449342 -0.04601606  0.01678635  0.01990552
  0.02076392 -0.00210881 -0.00279181  0.04179521 -0.04457315  0.03691607
  0.03794713  0.03099668 -0.02367348  0.03399444  0.02757923  0.03616883
 -0.02254062 -0.02664316  0.02605702  0.03886573  0.01588712  0.0214553
 -0.01174214 -0.02376557  0.01827493 -0.05263043 -0.04217007  0.04202458
  0.03412769  0.05392906  0.03690188 -0.00248844 -0.03563309  0.0102923
  0.02392829  0.02829017  0.02085274  0.04422398 -0.03887931  0.03787534
 -0.00094964 -0.02262061 -0.01163678  0.00090397 -0.03187026  0.03233976
 -0.01200819  0.01573817  0.00926213  0.0192347   0.01836991 -0.02495958
  0.00430777  0.04586138  0.02464936  0.01744008 -0.06496627 -0.00144977
 -0.04465025  0.0100366  -0.0028046   0.01337241]
tensor_name:  TemporalFusionTransformer/time_distributed_57/kernel
[[ 0.08144835 -0.08009791 -0.01491054 ... -0.00058162  0.09499948
   0.07970537]
 [-0.05745554  0.02426344 -0.03335916 ...  0.01804756 -0.13035601
   0.09266768]
 [ 0.13737617  0.0872504   0.05445112 ...  0.07257037  0.00501399
   0.08689573]
 ...
 [-0.02601356  0.01481564  0.05067907 ... -0.00197198 -0.09586795
  -0.02825546]
 [ 0.08329395  0.0651935  -0.04243474 ... -0.05764183  0.05459755
   0.02958765]
 [ 0.01675988 -0.0747421  -0.03750503 ...  0.06673008 -0.00165726
   0.0495942 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_58/bias
[ 8.7520406e-03  1.9861437e-01  3.4742486e-02 -1.6207654e-02
 -1.8846478e-02 -3.3489935e-02  3.0825026e-02  2.5898658e-03
  3.5642008e-03 -2.2071924e-02  2.2128984e-02 -1.6955303e-02
 -2.2456313e-02  2.6699822e-02  3.2848485e-02 -5.0219230e-02
 -2.8671524e-03  2.4008255e-02  2.2693668e-02 -1.2463148e-03
  2.2503844e-02 -1.0719224e-02  1.7092506e-04 -2.2160890e-02
 -2.5569176e-02  7.6001003e-02 -2.8499663e-02  3.0177858e-02
 -2.6598001e-02  1.0235280e-02 -7.4427947e-03 -4.3030120e-02
  9.0139210e-03  1.7565330e-03 -3.4623675e-03  3.6306091e-02
 -1.1165388e-02  1.0057036e-02  6.3541085e-03  2.4211027e-03
 -1.4726413e-02 -1.2920381e-02 -4.9244434e-02  3.6597509e-02
  2.5439456e-02 -2.2101562e-02 -5.8986074e-03  3.1612184e-02
  1.2080400e-03  5.9375733e-02 -3.7611220e-02 -4.0871203e-02
 -2.9252924e-02 -1.4036760e-02  1.2672205e-03  2.4351186e-01
 -1.1435388e-02 -2.6487155e-02 -3.4175925e-02 -5.7092062e-03
  6.3955560e-02 -4.6413764e-03 -1.9841664e-02 -6.7890775e-03
 -3.2892808e-02 -4.2932704e-02 -4.3510117e-02 -2.5847632e-02
  2.1593304e-02 -5.9035856e-02  2.0598942e-02 -1.4310433e-02
 -1.9771259e-02  3.6394861e-02  3.0928032e-02  2.3883205e-02
 -3.1689696e-02  9.8075196e-03 -1.3996287e-02  1.0525288e-02
  7.6279439e-02  8.1829857e-03  1.0727005e-02 -4.6329196e-03
  1.7905002e-03  1.0630994e-02 -3.4255337e-02  1.0845497e-02
 -7.2905994e-03 -7.0019900e-03  2.5388238e-03  1.4260942e-02
 -2.8292050e-03  3.2017801e-02 -4.3502808e-02 -1.7253889e-02
 -2.2386041e-02  1.6758135e-02 -3.0844477e-03 -1.4436681e-02
 -2.4841707e-02 -1.9188676e-02  3.6969345e-02 -1.2623361e-02
  3.1910736e-02  4.8845574e-02 -1.7315332e-02  1.8849209e-02
 -2.0348720e-02 -1.0253682e-02  1.8752461e-02  3.8722385e-02
  1.3054187e-02  5.2180528e-03 -9.6400045e-02  5.5667937e-02
  5.6559540e-02  1.3832117e-02  5.0803483e-04 -5.9405088e-02
 -7.1841562e-03 -2.2118928e-02  3.2004367e-03 -2.4187736e-02
  3.0581905e-02 -1.0453751e-02 -2.3332452e-02  3.7509762e-02
 -6.3186430e-04 -9.9355001e-03  1.0885203e-02  2.5114611e-02
  2.6368683e-02 -1.0781115e-01 -6.5386831e-03  3.0705545e-02
 -8.3400067e-03  3.3212531e-02  2.0355035e-02  1.6992793e-03
 -9.2506915e-02  2.4735829e-04  1.6372934e-02  2.3697496e-03
 -1.7287525e-04  2.4835672e-02  4.1510435e-03  1.6535759e-02
 -2.6877992e-02  1.7014058e-02 -4.3497298e-02  2.6323639e-02
  3.4075867e-02 -1.8747772e-01 -3.2789789e-02  8.4556616e-04
 -3.7261702e-02 -6.6652417e-02 -9.6162129e-03 -3.0271655e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_58/kernel
[[-0.01599598  0.13916801  0.08763422 ... -0.03893702  0.10111926
  -0.07019763]
 [ 0.11153974 -0.14245956 -0.10090321 ...  0.14982651  0.1252059
  -0.13843496]
 [ 0.11591808 -0.1978414   0.10812218 ...  0.00038996 -0.1369229
  -0.03692663]
 ...
 [ 0.06200459  0.04858771  0.00022686 ... -0.04296065  0.06427205
   0.07925601]
 [ 0.07318969 -0.20405473  0.06311119 ...  0.10934063 -0.02205211
  -0.06128046]
 [ 0.00504192 -0.04764035 -0.01641166 ... -0.1150974  -0.1406174
  -0.07773079]]
tensor_name:  TemporalFusionTransformer/time_distributed_59/bias
[-0.0503167   0.17135066 -0.02722249  0.03485925 -0.03801306  0.00593972
 -0.02274257 -0.05927357 -0.06411219 -0.12065011 -0.0826414   0.00306274
 -0.01033311 -0.08687187 -0.05902233 -0.04101961 -0.04157037 -0.02493243
 -0.0974987  -0.06883123  0.00688516 -0.02036099 -0.02105881 -0.01879327
 -0.04446526 -0.09808581 -0.07068225 -0.05083932 -0.01548115 -0.10092459
 -0.03703061  0.01402158 -0.05231808 -0.03736676 -0.05106391 -0.07868256
 -0.01092223 -0.12068458 -0.03317167 -0.02968065 -0.01000274 -0.08841759
 -0.08174016  0.0136337  -0.06821264 -0.07851262 -0.0344805  -0.02905931
 -0.10085302  0.07587817 -0.01107463 -0.07099649 -0.05290333 -0.06420759
 -0.06725183  0.20908701 -0.07622844 -0.00740506 -0.01143394 -0.04920666
 -0.03813696 -0.01723033 -0.03473262 -0.00625602 -0.05056207 -0.05581786
  0.01378891 -0.03003132 -0.09814914  0.0849044  -0.01831929 -0.01613801
 -0.0489343   0.00220209 -0.03998291  0.00273457 -0.0738404  -0.04081454
 -0.00479003 -0.05411458 -0.00490248  0.02535904 -0.10448437 -0.05948736
 -0.05375437 -0.03900585 -0.01285019 -0.07099725 -0.00609929 -0.0074528
 -0.1016328  -0.08586895 -0.08218323 -0.0149534   0.02124907 -0.03383077
 -0.07648264 -0.00712681 -0.08078859 -0.04968334 -0.04925274  0.00612571
 -0.02362754 -0.07628876 -0.12157339  0.0483057  -0.07078558 -0.0549789
 -0.03377789 -0.09985024 -0.0195632  -0.03617463 -0.05009243 -0.0917407
  0.03162256  0.01794667 -0.09412831 -0.08037101 -0.02524684  0.03199108
 -0.06008459 -0.10305644  0.00500297 -0.07799216  0.00516089 -0.0413954
 -0.035496   -0.00928643 -0.03455558 -0.00442039 -0.00954306 -0.00389215
 -0.04078026 -0.02020861 -0.08259036 -0.05152335 -0.04040104 -0.01186218
 -0.05093255  0.03198943  0.00812297 -0.04504302 -0.01509986 -0.03042932
 -0.10064291 -0.01175841 -0.07762791 -0.03373873 -0.05748502 -0.08417077
 -0.01474906 -0.05483403 -0.03639007  0.13747059 -0.00395878 -0.02486604
 -0.04256786 -0.0399869  -0.01140772 -0.01868917]
tensor_name:  TemporalFusionTransformer/time_distributed_59/kernel
[[ 0.05569495 -0.08087131  0.09307226 ...  0.00904343 -0.05803292
   0.0659575 ]
 [ 0.09209029 -0.17836647  0.14871581 ... -0.021494    0.12219159
   0.10864137]
 [ 0.06432695 -0.01366825 -0.076387   ...  0.1531206   0.06274244
  -0.0717039 ]
 ...
 [ 0.08364803 -0.0372576   0.02938147 ... -0.0499292   0.07188048
  -0.09719466]
 [ 0.1410668  -0.0717898   0.02379589 ...  0.09354141 -0.0836826
   0.1657187 ]
 [-0.11079104 -0.07209946 -0.04361501 ...  0.00597256  0.10033628
   0.02701599]]
tensor_name:  TemporalFusionTransformer/time_distributed_6/bias
[ 0.0335951   0.07061598  0.00096927 -0.06141842 -0.00984992  0.00227892
 -0.0216158  -0.02795839  0.02991762 -0.05042401  0.00333254  0.05160308
 -0.00223607  0.00550046 -0.03644007  0.00593858 -0.01513746 -0.0033233
  0.00407136 -0.01870747  0.03255366 -0.00541563  0.04347237 -0.00614493
 -0.01635646  0.01326597  0.0129465  -0.01028082 -0.01376458 -0.00117543
 -0.00648087 -0.04041184  0.03217103 -0.03841409  0.04023324 -0.06046775
 -0.00458698  0.00402731  0.0175863  -0.01143628 -0.0354183   0.03555521
 -0.03254697 -0.02346774  0.02710792  0.00058509  0.00996289 -0.01902166
 -0.03822448 -0.03574657  0.0100417  -0.00937676  0.02885872 -0.02114226
 -0.00121537  0.05094098 -0.0263469   0.06448717  0.0139751   0.01483536
 -0.00107953  0.03101552 -0.01753039 -0.0038492   0.01749611 -0.00177664
  0.01595911 -0.01042631  0.00261926 -0.01363351  0.04945739 -0.00352887
 -0.024785   -0.00095615 -0.04597154  0.00788116 -0.00828152 -0.00135932
  0.01659868 -0.00916638  0.06592226 -0.03808176  0.00963425  0.00893414
 -0.03296907  0.01967644 -0.00566472 -0.01406025 -0.0061389  -0.0178692
 -0.00127827 -0.00666121 -0.02158456 -0.01250644 -0.03494119 -0.06905124
  0.02174137  0.03450048  0.01406632 -0.02384304  0.00709977 -0.01548826
  0.02298354  0.04203159  0.03867179 -0.00683569  0.02946526 -0.02790242
  0.02275536  0.00530627  0.00030512  0.02898714  0.05075783 -0.02419368
 -0.01990177  0.01396039  0.07062053 -0.0247284  -0.00809446 -0.01630935
 -0.05375683 -0.00287566  0.05499283  0.00071017  0.00057206  0.01832757
 -0.03347323  0.03081007 -0.01794948 -0.01693217  0.00196194  0.02024249
 -0.01533099 -0.00778778 -0.03515348 -0.00855822  0.01643171 -0.00584049
 -0.00144085  0.01272026 -0.01718469  0.01222335 -0.03155367  0.03015409
  0.03475314 -0.03143074 -0.04276393 -0.01569986 -0.02764317 -0.04516749
  0.04644381 -0.00239548  0.01117134 -0.05473811  0.01570012  0.01450891
  0.01203627 -0.04667904 -0.00802473  0.04440618]
tensor_name:  TemporalFusionTransformer/time_distributed_6/kernel
[[ 0.05678621  0.18675411  0.114961   -0.1642941   0.0825073   0.00588322
  -0.10224926 -0.03918729  0.0972188   0.00855989  0.04480907  0.17931873
   0.09553917  0.01827977 -0.15261862  0.17913492 -0.12475067 -0.17084482
   0.12456355 -0.17886893  0.02615892  0.11818489  0.0772607   0.16574655
  -0.03644546 -0.00970866 -0.11618522  0.05211958 -0.13315652 -0.09745877
   0.159699   -0.14271589  0.0913917  -0.03262489  0.16824938 -0.17091264
  -0.10621943  0.13720584  0.11874241 -0.16299844 -0.04570384  0.15340413
   0.04197239 -0.08811899  0.12208997 -0.20088516 -0.0342663   0.18811326
   0.02279395 -0.19899833  0.14814708 -0.01077093  0.2007231   0.06597872
  -0.01943737 -0.09849284 -0.0817414   0.16120937  0.09867525  0.13928005
  -0.21767795  0.12698907 -0.17828909 -0.03842409  0.18541962 -0.20990308
   0.16515195 -0.02692316  0.12254573  0.13447909 -0.05202559 -0.07133812
   0.0492157  -0.05301694 -0.10095553  0.18133679 -0.15505977 -0.00205216
   0.1255332  -0.01985854  0.01608062  0.00918601  0.13711762 -0.11698057
  -0.12430464  0.17350507 -0.03629723 -0.04614304  0.1901769  -0.04735127
   0.163415   -0.11407889 -0.1644772   0.17256398 -0.19910327 -0.14892475
  -0.0654278   0.05834914  0.12478554 -0.13082047  0.12953405 -0.21572344
  -0.03103932 -0.02434426  0.09731629 -0.1823696   0.121118    0.01265189
   0.10337445 -0.17965294 -0.08835296 -0.01150681  0.18025441 -0.08867455
   0.11646079 -0.08546031  0.16135086  0.05718579  0.0330157  -0.0209872
  -0.1904828   0.09370469  0.19369343 -0.00386339  0.04433466  0.16432732
  -0.14183986  0.18732832 -0.08078825 -0.08855256 -0.08346726  0.1655154
  -0.08818903 -0.17595859 -0.07989172 -0.09077068 -0.02916966  0.01582705
  -0.00717143  0.09962703  0.01029882  0.1689781  -0.07362674  0.12642065
   0.01285517 -0.17650492 -0.0930287  -0.18643743 -0.00749265 -0.15840459
   0.11333319 -0.10561823  0.08911179  0.071257    0.06400415 -0.05028975
   0.19082959 -0.14088961 -0.17623651  0.02488372]]
tensor_name:  TemporalFusionTransformer/time_distributed_60/bias
[ 0.04822807  0.05830158  0.04235414  0.04158747  0.00246094  0.01772227
  0.0303559   0.027467    0.02513763  0.04501161  0.04466896  0.04528431
 -0.02586217 -0.06644648 -0.04016679 -0.02248202  0.02561058  0.04911823
  0.00925577 -0.00859535  0.04520984 -0.00520261 -0.01482857  0.03491547
  0.0248279   0.01226526 -0.00400372 -0.02209169 -0.06162116  0.02770091
  0.00640423  0.02872934  0.0290378   0.04179485 -0.00767819  0.02421471
 -0.01017234 -0.00530179 -0.04802863 -0.01128874  0.04300838  0.01610191
  0.01919298 -0.01933433  0.03463765 -0.00207705 -0.0242667   0.05696831
 -0.03569109 -0.01337675  0.00019558  0.00871935 -0.02573542  0.00709922
  0.00814562 -0.10498881 -0.02697293 -0.05952528 -0.05940539  0.05541276
  0.00113909 -0.05844998 -0.00072804  0.06197097  0.00970938 -0.02600301
 -0.08809507  0.02810067  0.00275495 -0.00880311  0.0237535  -0.0043882
 -0.01607352  0.01346691 -0.05490622 -0.04097474 -0.04152783 -0.02798449
 -0.04682252  0.02150343 -0.02451655  0.04986817  0.00563122  0.02710368
  0.02496037  0.00128813 -0.02012813 -0.03101564 -0.02028953 -0.0138887
 -0.02327223  0.00959015  0.02361342 -0.01343934 -0.02407391 -0.02750866
  0.01092699  0.02213887 -0.00206889  0.02152064  0.02278021  0.04074175
 -0.07198131 -0.01231918  0.0138328   0.01706829 -0.0048201  -0.0300773
  0.01719494  0.01848515 -0.02027538 -0.11578062 -0.11506904 -0.0747273
 -0.00373052  0.01838934 -0.00636882 -0.04089266 -0.03848707  0.00112533
  0.02650508  0.04629666 -0.06474809 -0.06737929 -0.05334603  0.01131036
 -0.0422556   0.07340065 -0.00697219  0.00135196 -0.02670258 -0.01471194
 -0.06048522 -0.11773889 -0.02706005  0.01036246  0.01714739 -0.02875646
 -0.00552975  0.00536174  0.0039803  -0.02853635 -0.03243533  0.01798736
 -0.04657084 -0.08392172 -0.00913711  0.00086381  0.04770777  0.02027071
 -0.04800598  0.02236323  0.02121221  0.02487063  0.01159369 -0.04578079
 -0.04229425 -0.01140397 -0.00315838  0.00172397]
tensor_name:  TemporalFusionTransformer/time_distributed_60/kernel
[[ 0.11308723 -0.0673121   0.0861303  ... -0.09731402 -0.10745728
   0.07732743]
 [-0.0499132  -0.02311865 -0.09274457 ... -0.09645846 -0.04157225
   0.14808229]
 [-0.03810542 -0.10304959 -0.13759162 ...  0.13254233  0.09112395
   0.00613247]
 ...
 [ 0.07152151  0.09480591  0.07236236 ... -0.09973932 -0.06546381
   0.04710007]
 [ 0.03830926  0.00114911 -0.07642533 ...  0.10813931 -0.08472916
   0.11040682]
 [-0.14648041 -0.09991043  0.02938152 ... -0.12226962  0.01591746
  -0.12117084]]
tensor_name:  TemporalFusionTransformer/time_distributed_61/bias
[-0.00779203 -0.05354559 -0.057268    0.01656754  0.03522401 -0.00817827
  0.01529116  0.02239293 -0.0252244  -0.01529988 -0.04503902  0.00064207
 -0.02470783  0.03605772  0.01400907  0.01603169 -0.00028366  0.00966101
 -0.00218527 -0.01007157  0.00531911 -0.00277458  0.01299631 -0.03590685
  0.03048167  0.00080866 -0.02259866  0.03389493  0.0254172   0.00517752
 -0.03038674 -0.02800448  0.00557696 -0.00383008  0.03776206 -0.00886488
  0.01682328  0.02076286 -0.05960793  0.01257875 -0.01344388  0.00150327
  0.02660043 -0.01860872 -0.02278955  0.04244608  0.03457178 -0.03536004
  0.01774978 -0.05243234 -0.01609292  0.00206768  0.01072151 -0.048912
 -0.03561423  0.01414142  0.00299996 -0.0008175  -0.02857441  0.03544329
 -0.02174614  0.0316815   0.00328031  0.02928017  0.00380332 -0.03804413
  0.00059547 -0.01115543 -0.00256446  0.02562753 -0.01562812  0.00415011
  0.03384544  0.00290247 -0.01304548 -0.01897111 -0.04657773 -0.01966897
 -0.00642434  0.0175579   0.03749846  0.03083893 -0.01948076 -0.0297007
  0.00397233  0.00314469 -0.0119762   0.05165604  0.03627601 -0.00244411
 -0.02574715 -0.02573216  0.01267262 -0.02418098 -0.04221863  0.01005654
 -0.00086567  0.02711689  0.0164105   0.04333885 -0.032315    0.04548221
 -0.03128395 -0.00192158 -0.0262929   0.00417342 -0.00040612  0.04821927
  0.01831054 -0.03267974 -0.03987343 -0.02476922 -0.00762887 -0.02836798
  0.03399673 -0.01397481  0.03548191 -0.01981299  0.00620305 -0.0087704
  0.00433628 -0.00187624  0.02301374  0.01831746  0.0056404   0.0541763
 -0.01330514 -0.03372613  0.00610856  0.00397016 -0.05907415 -0.01415246
  0.01362618  0.0337844  -0.04369395 -0.00021493  0.02494785 -0.0267942
 -0.00974995  0.05325639  0.01247257 -0.00508958  0.01033055  0.01381905
  0.03137133 -0.03371019  0.02822977  0.02441474  0.01117741 -0.01434013
 -0.02618288  0.00491751  0.00726219 -0.00714387  0.00841262 -0.00167917
  0.02862873 -0.01286161 -0.00325839  0.02248523]
tensor_name:  TemporalFusionTransformer/time_distributed_61/kernel
[[-0.02196666 -0.19641615 -0.09742928 ... -0.05612763 -0.07653575
   0.16129683]
 [ 0.02029109  0.00840751 -0.01277217 ...  0.00089941  0.06657865
  -0.01114732]
 [ 0.06376565 -0.12862928 -0.13306287 ... -0.06076905 -0.01388672
   0.05265855]
 ...
 [ 0.05198192  0.02266341 -0.00769165 ... -0.05240137 -0.119194
  -0.04855048]
 [ 0.07278928  0.02464341 -0.0935185  ... -0.11882979  0.0857856
   0.09783882]
 [ 0.00582444 -0.02518414  0.05521051 ...  0.13829823  0.01833194
   0.1385506 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_62/bias
[ 1.20808566e-02  3.27613279e-02 -7.62613351e-03 -1.49759930e-02
 -8.07644613e-03  6.13072561e-03  6.91227708e-03 -2.45274534e-03
  1.44927874e-02 -5.45803532e-02 -1.35578373e-02 -1.19934473e-02
 -6.45217858e-03  1.86840771e-03 -4.35572554e-04 -8.41677655e-03
 -1.33166741e-05 -3.24507640e-03 -2.06251163e-02  7.07357144e-03
 -1.55213801e-02  8.92866962e-03  1.90670118e-02 -8.33019894e-03
  1.79482177e-02  1.13687217e-02  7.70073477e-03 -2.11436469e-02
 -5.15519083e-03 -8.07502400e-03  6.98846532e-03  6.68796618e-03
  4.27744025e-03 -4.48180027e-02  1.13225006e-03 -3.40058748e-03
  5.12966374e-03  5.85910529e-02  6.29596226e-03 -1.79671831e-02
 -1.04980431e-02  2.48543248e-02 -8.35820008e-03 -1.32201584e-02
  5.93025284e-03 -9.57376324e-03 -8.58309679e-03  7.35444017e-03
 -1.14506381e-02 -1.23161066e-03 -1.46009140e-02 -1.48880994e-02
  4.78336820e-03 -1.99043527e-02 -2.45959358e-03  7.66226575e-02
 -1.01004550e-02 -4.68593236e-04 -1.81687474e-02 -7.13734934e-03
 -7.18494586e-04  1.36658559e-02  1.25100501e-02  1.26649216e-02
 -1.04137734e-02  3.97748221e-03  2.78382702e-03  5.78258652e-03
  4.01125243e-03 -4.21678387e-02  6.52090162e-02 -9.42232553e-03
 -1.29138092e-02  4.71052341e-03 -4.11494635e-02 -5.55558736e-03
  8.52117408e-03  1.26819359e-03 -6.86647953e-04  4.79487033e-04
 -5.67634124e-03  1.31354958e-03 -7.75236776e-03  6.17631571e-03
  2.11026836e-02  5.95282856e-03  4.80123301e-04  9.29454342e-03
 -7.29253469e-03  6.77942997e-03 -7.20120966e-03 -5.88795170e-03
  2.78727966e-03  2.83277710e-03 -9.44568310e-03 -2.07037330e-02
  2.60987580e-02  1.82880145e-02  6.38292124e-03 -2.67853364e-02
 -7.80347094e-04  5.60844038e-03  1.81838162e-02  2.30911709e-02
  1.93010718e-02  1.13098398e-02 -1.73766763e-04 -4.42115590e-03
  2.08251588e-02  9.96990944e-04  1.10138708e-03  1.39636872e-02
 -1.29280575e-02 -2.10620067e-03 -7.96974637e-03  7.88224954e-03
 -2.24794336e-02 -8.99907015e-03  5.75057184e-03  5.34040621e-03
  1.91012695e-02 -6.97593167e-02  4.79036756e-03  1.09221926e-02
  3.20874184e-04  5.17491659e-04 -3.55216558e-03  1.48823904e-02
 -1.43192206e-02 -8.82020313e-03  9.14496370e-03 -5.94508252e-04
 -8.80190171e-03 -1.31022418e-02 -3.05611338e-03  1.19069554e-02
 -7.53379427e-03  6.70667691e-03 -4.20604041e-03 -3.30124535e-02
 -2.40173768e-02  5.71234152e-03  8.31638405e-04  2.77730380e-03
  2.04579861e-04 -8.66718870e-03  1.55526577e-02  1.63841527e-03
  9.91925448e-02 -2.14690412e-03  1.22392608e-03  5.43608982e-03
 -6.75139530e-03 -7.98396692e-02 -2.72344891e-02  6.94921846e-03
 -1.50137665e-02  2.49031791e-03  7.04673259e-03 -1.16960099e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_62/kernel
[[ 0.04988863  0.06626172  0.0151344  ... -0.07421477  0.01670933
  -0.15039489]
 [ 0.08203866 -0.03284619 -0.03044784 ... -0.02948305 -0.07581183
   0.13067888]
 [ 0.11195987 -0.16393498 -0.01442484 ... -0.09895259 -0.03552611
  -0.0088203 ]
 ...
 [-0.01817345  0.02472435 -0.08347794 ... -0.03926735 -0.06386226
  -0.10363761]
 [-0.00110989  0.07602137 -0.02391336 ... -0.01431545 -0.08543444
  -0.00579042]
 [ 0.09976094 -0.122795    0.13088168 ... -0.08310692  0.11077315
  -0.14461808]]
tensor_name:  TemporalFusionTransformer/time_distributed_63/bias
[-9.61370970e-05  3.66980322e-02 -2.02730428e-02 -2.99998652e-02
 -2.54345760e-02 -3.94305363e-02 -4.13807780e-02 -1.63491592e-02
 -6.73484802e-03  6.18644468e-02  1.65445823e-02 -1.39778703e-02
 -3.50056998e-02 -7.18413889e-02  9.09680780e-03 -3.70581746e-02
 -3.98419164e-02 -5.15648536e-02 -3.70861739e-02 -3.05368155e-02
  3.14728096e-02 -1.37638012e-02 -1.78504491e-03 -2.05169581e-02
  1.80260986e-02 -5.02514094e-02 -1.50329713e-02  3.91809642e-03
 -4.39768471e-02 -2.12487802e-02 -2.56294087e-02 -3.08099519e-02
 -1.85009148e-02  3.77825685e-02 -1.80297270e-02 -4.46542539e-02
 -9.17155854e-03  9.51632485e-02 -3.10340784e-02 -2.83297151e-02
 -8.00484605e-03  3.02303489e-02 -4.79766317e-02 -1.33794472e-02
 -2.99734566e-02 -1.21964458e-02 -4.25011329e-02 -1.04831299e-02
 -2.95735635e-02 -3.18271220e-02  9.12915915e-03 -2.44779177e-02
 -2.78452579e-02  4.05700412e-03 -2.42405683e-02  6.15606233e-02
  1.04024233e-02 -1.42705506e-02 -2.78052501e-02 -4.14639190e-02
  5.59816044e-03 -1.33701256e-02 -8.08979850e-03  5.30320778e-03
 -4.56893370e-02  2.69702473e-03 -2.13557985e-02 -4.18564305e-02
 -4.19071205e-02  9.49881878e-03  4.33220901e-02 -3.82535122e-02
 -2.52654636e-03 -1.92474406e-02  2.75722183e-02 -3.53514366e-02
 -1.47673497e-02 -2.11605504e-02 -1.61454324e-02 -5.98319806e-02
  8.66736993e-02 -3.11637484e-02 -2.22098995e-02 -2.57270224e-02
  5.83553538e-02 -3.63811222e-03 -1.18766669e-02 -4.47974727e-02
 -2.65937075e-02  4.47150925e-03 -2.27532294e-02 -1.89931337e-02
 -2.82471664e-02 -4.30799462e-02 -1.75795034e-02  4.18088352e-03
  2.75221374e-02 -1.51065765e-02 -8.96117650e-03  1.34108318e-02
 -4.36167456e-02  7.05229538e-03 -2.93560531e-02  4.31527123e-02
 -7.09098065e-03 -1.89929213e-02 -3.01184654e-02 -2.03276053e-02
  2.03050636e-02 -2.91412044e-02 -2.54226662e-02 -1.81873403e-02
  5.94874471e-02 -5.24547659e-02 -2.85490695e-02 -2.38276329e-02
  2.98062749e-02 -4.44128597e-03 -1.44509599e-02 -6.01688400e-03
 -2.40396112e-02  9.02608261e-02 -1.29061684e-01 -2.58017089e-02
 -2.00090967e-02 -2.30146274e-02 -9.88599379e-03 -1.19547555e-02
  1.74955539e-02 -4.80965562e-02 -4.00887663e-03 -3.64609249e-02
 -4.80103865e-03 -4.80900519e-02  3.59627488e-03 -5.26122078e-02
 -3.77639867e-02 -5.91366775e-02 -4.40685777e-03  2.19336096e-02
 -3.85006703e-03 -4.89654057e-02 -4.20253761e-02 -3.32554877e-02
 -3.76346670e-02 -1.47665665e-03 -3.25939618e-02 -4.05539684e-02
  7.21005350e-02 -3.27755213e-02 -6.18932722e-03 -1.69657357e-02
 -3.78893390e-02  6.00244775e-02  5.13036251e-02 -3.84112746e-02
 -2.72254255e-02 -2.08017044e-02 -3.28199342e-02  5.72232855e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_63/kernel
[[ 0.0255159  -0.10873654  0.08637135 ... -0.06648677 -0.02648619
  -0.15725037]
 [-0.13862807 -0.15487365 -0.05422793 ... -0.11247801 -0.07564122
  -0.09401648]
 [-0.12968978 -0.17351447 -0.03401221 ...  0.09542371 -0.05133268
  -0.12257819]
 ...
 [-0.11478104 -0.11783514 -0.02988942 ...  0.13716337  0.15743919
   0.0590084 ]
 [-0.11545187  0.07346795  0.05085211 ...  0.01424826 -0.07977641
   0.05332519]
 [ 0.06350881  0.03450128  0.16487743 ... -0.03233542  0.0548359
   0.02893561]]
tensor_name:  TemporalFusionTransformer/time_distributed_64/bias
[ 1.23239309e-02  1.18155312e-02  2.05243360e-02  1.21394703e-02
  2.09620744e-02 -9.32579278e-04 -1.96556235e-03  1.55359684e-02
 -4.37238999e-02 -1.44194383e-02  2.51347013e-02 -1.67646687e-02
 -2.58195736e-02  7.04644574e-03  2.10962314e-02  6.43647881e-03
 -1.24188587e-02  2.46049277e-02  3.55135016e-02 -2.06613149e-02
 -7.00155040e-03  1.69759654e-02  1.04040764e-02  1.03789326e-02
  4.53444384e-02  4.12632851e-03 -8.89526214e-03  2.95866188e-02
  1.35035934e-02  1.29833613e-02 -7.64258904e-04  1.83155015e-02
  6.06977055e-03  2.54418538e-03 -2.56401282e-02  3.95941064e-02
  2.72171274e-02  1.72843933e-02 -2.72661503e-02  2.46426556e-03
  1.89005956e-02 -1.62253119e-02 -3.79229225e-02 -1.46187888e-02
 -1.50786703e-02 -1.95994731e-02  4.87987064e-02 -2.50608698e-02
  9.54312913e-04  3.41690215e-03  2.28257012e-02 -1.07181324e-02
 -2.40225364e-02  2.31221039e-02 -2.47951038e-03  1.18655283e-02
 -2.86635384e-02 -1.85827110e-02  1.30548542e-02  2.75466517e-02
  2.07586922e-02 -9.22387931e-04  1.76243335e-02  8.16262886e-03
 -1.90843735e-02 -3.39439744e-03 -6.87276479e-03  9.77536291e-03
 -4.89153527e-03  2.01085559e-03  2.70238402e-03  9.98941716e-03
  1.64313484e-02  1.36890244e-02  1.89281087e-02 -1.09991124e-02
  5.01787150e-03 -1.26757696e-02  3.94048579e-02  1.24729360e-02
 -3.85082662e-02  2.25280523e-02 -9.36347642e-04 -1.25888335e-02
 -2.82746740e-02  7.58860214e-03 -1.86563954e-02 -2.89236614e-03
 -2.91760848e-03  4.27165302e-04 -2.62276437e-02 -5.36739547e-03
  4.88521680e-02  1.00877304e-02 -4.10224963e-03 -1.56875346e-02
  1.79374439e-03 -2.42167944e-03 -8.32030270e-03  1.28210522e-02
 -3.46321170e-03 -1.97895500e-03 -2.09694244e-02 -1.94676802e-03
  1.17934085e-02  1.16617177e-02  5.40933199e-03  7.34444102e-03
 -1.76652372e-02  1.69550553e-02  2.15894915e-02  7.21399439e-03
 -1.11531001e-02 -1.45173520e-02 -3.90451401e-02 -6.66413782e-03
  4.91253100e-03  4.12177248e-03  1.05764146e-03  1.68647859e-02
  2.27730758e-02  3.11872754e-02  7.37509318e-03  2.40702033e-02
 -3.91964167e-02 -2.84349676e-02  1.55200260e-02  9.21258889e-03
  2.79930811e-02  2.61318963e-02  5.67364460e-03 -3.69313871e-04
 -1.27261998e-02 -4.03090045e-02  1.13134813e-02 -4.59623116e-05
  3.39689516e-02 -2.45783739e-02  1.27283437e-02  1.61758866e-02
  3.76575184e-03  1.27888350e-02 -2.11794060e-02 -8.78373347e-03
 -5.71905030e-03 -1.44321285e-02  1.29984075e-03 -1.70133018e-04
 -2.50206403e-02  8.12384952e-03  2.24100854e-02 -3.23755201e-03
  1.25964414e-02  4.02208231e-03  1.16817877e-02 -2.67796908e-02
  1.67017372e-03 -1.72800217e-02 -3.31954397e-02 -4.68408735e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_64/kernel
[[ 0.06007959  0.04991445 -0.02308506 ...  0.01126928  0.13647936
  -0.09463684]
 [ 0.12782632 -0.05185011  0.03094247 ... -0.12964033 -0.08884457
   0.07607866]
 [-0.11737776  0.13162845  0.00958568 ... -0.07318123  0.00415491
   0.0496611 ]
 ...
 [ 0.03514867  0.01583397  0.03810495 ...  0.04315881 -0.1230685
  -0.11167435]
 [ 0.07824151 -0.10688509  0.07468745 ... -0.06205848 -0.09827356
  -0.04947244]
 [-0.08878267  0.13184229 -0.1187062  ...  0.09951892  0.15304385
   0.04378921]]
tensor_name:  TemporalFusionTransformer/time_distributed_65/bias
[ 0.01375724 -0.01565355 -0.01109907  0.00072822  0.00739129 -0.0134781
 -0.00248673 -0.00537439  0.00652072 -0.00512772 -0.02997174 -0.0502233
 -0.01832527  0.00224942 -0.00317739 -0.00880175  0.02632374  0.01786628
  0.01959333 -0.01108898 -0.02731473  0.00441107  0.01489404 -0.02145593
  0.01726309 -0.00686656  0.01045182 -0.01595166  0.01485298  0.01261689
 -0.00925573  0.03016631  0.00662388 -0.01642926  0.02569368 -0.01107603
 -0.02475428  0.01981529 -0.02104082 -0.01900301  0.00088973  0.02643301
 -0.01644536  0.00032446 -0.02738532  0.01869277 -0.01780603 -0.04130583
  0.03659298  0.00685167 -0.01843809  0.01507026  0.01119686 -0.02294156
  0.00413388 -0.02426385 -0.03259543  0.01217757  0.01063168  0.01825945
 -0.03319675  0.00366166 -0.00263749  0.0142876   0.00036124 -0.05370419
  0.0007504  -0.01990464  0.0009942  -0.01876846 -0.01260635 -0.00559248
  0.02216749 -0.01851852  0.01000804  0.02962206 -0.03695564  0.01333753
  0.01630384 -0.01597792 -0.02170433 -0.00739356  0.02966165  0.00610479
  0.01484647 -0.03718501 -0.00619304  0.03287934  0.00110762 -0.01700919
 -0.03071751 -0.001102    0.03940106  0.00064715  0.01829828  0.01430474
  0.01419028  0.01710154 -0.00407597  0.04640733  0.01892861  0.06081999
 -0.03221132  0.00861831 -0.00966579  0.00522387 -0.00333463  0.00962387
 -0.00922748 -0.01066104 -0.03249522 -0.00347577  0.02514393 -0.01602113
  0.03267233 -0.02649737 -0.02491391  0.02066332 -0.00807139  0.00982635
 -0.00067995 -0.00643788  0.02158856 -0.00287155 -0.00730104  0.0023935
 -0.00421801 -0.0079309   0.00029003  0.01041738  0.07067073 -0.02658876
  0.02089066  0.01244867  0.0357281   0.01228461 -0.00076092  0.02243403
 -0.00937025 -0.02083796  0.02752025 -0.04564691  0.01513765 -0.0105374
 -0.02666971 -0.02609094 -0.0116253  -0.00409993  0.01268043 -0.00042444
  0.03794841  0.031987    0.00135228  0.00537953 -0.01628668  0.04792149
 -0.00566128 -0.01395725  0.02172364  0.01603217]
tensor_name:  TemporalFusionTransformer/time_distributed_65/kernel
[[-0.15135792  0.102911   -0.05464659 ... -0.08448377  0.13011737
  -0.13367335]
 [ 0.05995032  0.0250769   0.11024654 ... -0.0484618  -0.09806785
   0.12413494]
 [ 0.01624034 -0.02661376 -0.06155667 ... -0.12186608 -0.1276641
   0.07050838]
 ...
 [ 0.05829882  0.07011436 -0.04685873 ... -0.11439379  0.02780892
  -0.00473293]
 [ 0.02346597  0.09214233 -0.03824427 ... -0.08987385 -0.07362169
   0.09534892]
 [ 0.11820807  0.10654634 -0.05485298 ...  0.12182489 -0.0308153
  -0.08218334]]
tensor_name:  TemporalFusionTransformer/time_distributed_66/bias
[-0.01236988  0.03441015  0.03470305 -0.00802378  0.00952451 -0.03439137
 -0.00696134 -0.00593497  0.00499505 -0.02564803  0.01016213 -0.04016563
 -0.03308943 -0.00690893 -0.01600069  0.02001807  0.02043119  0.02946603
 -0.0016096   0.02857281  0.0043373  -0.01987138  0.00621386 -0.00306692
  0.01866581  0.02296094  0.01291912 -0.00091879  0.02388032 -0.02835488
 -0.00857605 -0.03989867  0.03496246 -0.02453406  0.00113245  0.02698662
 -0.01611505 -0.02316058  0.0220806  -0.00433727  0.01022696  0.02878195
 -0.03065897  0.01403085  0.00613258 -0.00751789 -0.02850954  0.00327557
  0.00855236  0.03421893 -0.00905377 -0.03395006 -0.02110634 -0.02733267
 -0.01170761  0.04430364 -0.00341711 -0.03228267 -0.01627938  0.01232411
  0.01240774 -0.00198254 -0.00656328  0.00187169  0.02432739 -0.0124531
 -0.0343771  -0.00468149  0.02749109 -0.014346    0.02787005 -0.00380137
 -0.02089146  0.02474499  0.01807117  0.02889404  0.01359049 -0.0053277
 -0.02528901  0.04722932 -0.00319623 -0.00653526  0.00118759  0.02149587
 -0.00167735  0.00262518 -0.03029563  0.02625954  0.01310931  0.00328275
 -0.0042619  -0.02133594 -0.01375923  0.01723579 -0.04524554  0.00384008
 -0.0108013  -0.02173749 -0.00925331 -0.01581491 -0.00463138 -0.02426115
  0.00014996  0.02484292  0.03577084  0.00053596 -0.00780845  0.00237521
 -0.02470393  0.00590781  0.03206936 -0.02339588 -0.01204108 -0.02966561
 -0.04569484  0.00165954  0.04348975 -0.02081469  0.0352809   0.0044838
  0.03016726 -0.00977749  0.02759228  0.00087399  0.03545264  0.00532991
 -0.00870096  0.03956932 -0.01360698 -0.04336176  0.02923762  0.01938541
 -0.01984819  0.01576003 -0.01505876  0.01352203 -0.02401275  0.01460579
  0.00547207  0.02818923 -0.02336425 -0.02790285  0.03037731 -0.01729336
 -0.0186553   0.00801729 -0.03245671  0.02557459 -0.01814603  0.01864507
 -0.0150127  -0.0341924   0.01409328 -0.00263086 -0.02980383  0.00524712
 -0.0271127   0.02115597  0.0055501  -0.01947608]
tensor_name:  TemporalFusionTransformer/time_distributed_66/kernel
[[-0.0286739  -0.08711227 -0.07401887 ...  0.11919528  0.07330916
   0.00233126]
 [ 0.03416541  0.07958177 -0.06664842 ... -0.02515838 -0.10100663
   0.01430862]
 [-0.00842606  0.03179363  0.06211189 ... -0.05616407 -0.02432967
  -0.01176154]
 ...
 [ 0.0213046  -0.18933746  0.03020692 ... -0.10123724 -0.05483869
   0.01962299]
 [-0.01150057  0.05249745  0.05121554 ...  0.04437019  0.00085054
   0.03034356]
 [-0.01481863 -0.01335537  0.08238007 ... -0.06758398  0.12144471
  -0.06745768]]
tensor_name:  TemporalFusionTransformer/time_distributed_67/bias
[-1.98011827e-02 -2.54569706e-02  3.18861217e-03  1.89375840e-02
 -1.89255141e-02 -4.83844280e-02  1.11520011e-02  3.93171189e-03
 -3.40102427e-02  5.01792096e-02  1.11333236e-01  2.60781255e-02
  5.91986754e-04 -3.69898230e-02  2.19816598e-03  5.47955791e-03
 -3.41104306e-02 -3.18451300e-02 -2.42816214e-03 -2.09381964e-04
 -3.21593471e-02  7.81326089e-03 -2.38033198e-02  1.70564987e-02
 -3.41890589e-03 -1.21102266e-01 -3.70115899e-02 -1.11462129e-02
 -1.54419560e-02 -2.97648758e-02 -4.25799973e-02 -1.29416073e-02
  1.56183364e-02  2.55290815e-03 -3.48256230e-02 -3.69581170e-02
 -1.52141247e-02 -1.30174542e-02 -1.78873744e-02 -8.05867650e-03
  9.46315154e-02 -4.92132083e-03 -7.09939003e-02 -1.18028745e-02
 -2.88097020e-02 -1.39608011e-02 -1.18088303e-02 -4.39065918e-02
 -3.30909640e-02 -7.71838846e-03 -1.47183789e-02 -2.87084398e-03
 -2.22316068e-02 -4.38373536e-03  5.36433309e-02 -2.20322870e-02
 -1.31755546e-02 -2.39425544e-02 -6.21003881e-02 -1.06631173e-02
  2.36315131e-02 -1.68240368e-02 -2.69331560e-02 -1.20654255e-02
  1.53029468e-04  1.25563651e-01 -7.38382759e-03 -2.12873444e-02
 -1.29620740e-02 -3.26263867e-02 -1.06560159e-02 -2.34096870e-02
 -1.93894301e-02 -2.67602876e-02 -2.49218456e-02 -1.35866962e-02
 -1.38090579e-02 -1.93453282e-02  1.02463048e-02 -9.01400857e-03
  1.34069407e-02 -3.98530401e-02  5.79081289e-03 -2.67254524e-02
 -2.08085328e-02 -2.86846198e-02  6.37200242e-03 -3.45906653e-02
 -8.76960810e-03 -2.05463991e-02 -1.05384625e-02 -3.26268077e-02
 -3.07354536e-02 -7.54195005e-02  2.28331164e-02 -2.55891476e-02
  3.14732864e-02 -1.95763912e-02 -2.37970091e-02 -7.08535127e-03
 -4.65168618e-03 -2.10815854e-02 -1.62688643e-02 -4.10620635e-03
 -3.61165181e-02 -1.70482546e-02  3.08995927e-03 -3.48561034e-02
  6.31019324e-02 -9.25534312e-03  8.12366698e-03 -1.79195628e-02
  5.01635522e-02 -3.61730135e-03 -1.40131991e-02 -3.88872474e-02
  4.90541337e-03 -1.59222800e-02 -3.08323163e-03 -7.27815926e-03
 -1.15860617e-02 -1.25160292e-02 -8.31962388e-04 -4.26805131e-02
 -1.42256217e-02 -1.90298315e-02 -1.97835676e-02  7.13648787e-03
 -3.98779213e-02  4.68122289e-02  1.56460656e-03 -6.29413221e-03
  1.98484445e-03 -7.63936294e-03 -3.77522372e-02 -1.57102346e-02
 -2.32111830e-02 -3.33183110e-02 -3.95847335e-02  4.81713284e-03
 -2.87436768e-02 -3.13871205e-02 -9.41720698e-03 -4.42368872e-02
 -3.71143073e-02 -1.57398712e-02 -3.00959521e-03 -5.10450862e-02
  2.54557002e-02 -2.04348117e-02 -2.84790285e-02  1.31077981e-02
 -3.71649899e-02  1.56940848e-01 -1.36277778e-02 -1.72330271e-02
 -5.86149059e-02 -1.72189204e-03 -2.12466754e-02 -5.35831004e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_67/kernel
[[-0.09566189 -0.0695776   0.03285434 ... -0.10395106 -0.07452303
  -0.0948498 ]
 [-0.12023205 -0.0064584  -0.00128044 ...  0.06605399  0.08369754
   0.02471   ]
 [-0.15377282  0.22183293 -0.01259356 ... -0.04208891  0.09649734
   0.06838493]
 ...
 [ 0.07091991 -0.07616132 -0.07116245 ...  0.08180144  0.03404883
   0.06551302]
 [-0.16530159  0.04461526 -0.08632102 ...  0.1115215   0.03186989
  -0.11847242]
 [-0.05503298 -0.11048414  0.01546824 ... -0.06764107 -0.10212645
  -0.04537275]]
tensor_name:  TemporalFusionTransformer/time_distributed_68/bias
[ 3.20607275e-02  2.28311140e-02  6.46521673e-02 -2.48504058e-02
 -2.35241782e-02  4.16625999e-02 -3.58342528e-02  2.18020286e-02
 -4.05830853e-02  2.70163901e-02 -1.69009566e-02  1.77933206e-03
  3.78496083e-03 -4.57581729e-02  6.37594983e-02  1.82676576e-02
  2.28965599e-02  1.93248992e-03 -4.66488823e-02  3.78208235e-02
  7.33687505e-02 -3.61620262e-02  3.29909064e-02 -4.08973619e-02
 -3.06459749e-03 -1.21776136e-02 -5.33285597e-03  7.90458992e-02
  4.16289680e-02 -3.16249169e-02 -3.54427029e-04  4.12911177e-02
  4.45545353e-02  1.49203027e-02  7.08891591e-03 -4.60160518e-04
 -2.41337176e-02  2.06335075e-02 -2.32100743e-03 -3.92259061e-02
  7.10611716e-02 -4.37300615e-02  7.51891285e-02 -5.05364500e-02
 -3.44253331e-02 -9.66295302e-02  6.09926246e-02  2.18211561e-02
 -1.59980133e-02  3.43622640e-02 -1.96314435e-02  3.19676101e-02
  7.67771155e-03 -1.47567298e-02 -4.09714170e-02  8.75456929e-02
  6.05675997e-03 -9.93058830e-03 -4.68426831e-02  4.45160605e-02
  1.78370532e-02 -1.63190644e-02 -6.27584457e-02  3.65839303e-02
 -1.44005548e-02  3.63904871e-02 -4.50350121e-02  5.53856343e-02
  3.73253450e-02  2.18591634e-02 -6.86762631e-02  3.58590670e-02
  2.95332819e-02  5.95425032e-02  1.57561321e-02 -6.78482698e-03
  2.58021466e-02 -5.52225597e-02  6.72642589e-02  2.77312193e-02
 -2.53961980e-02  4.63129841e-02 -4.79742810e-02  2.06150655e-02
 -3.37733664e-02 -1.34263905e-02 -1.39192613e-02  5.97378565e-03
 -1.67581961e-02  6.61833510e-02  2.63690948e-02 -6.65956810e-02
 -2.66136657e-02 -3.80360894e-02 -4.29816917e-02  5.90055170e-05
 -1.61721278e-02 -2.59569492e-02  3.45293544e-02 -3.84263583e-02
 -2.76991725e-02 -4.94781025e-02 -9.53967683e-03 -1.77876391e-02
 -1.59693770e-02  3.86815704e-02 -8.54017027e-03  3.43290903e-02
  7.64353648e-02  4.50684093e-02 -3.25253122e-02 -3.64762880e-02
  7.49655766e-03 -3.24819423e-02 -2.01554839e-02 -4.77071814e-02
 -1.59412697e-02 -2.77999770e-02  4.32514846e-02 -4.59276736e-02
  4.59670350e-02 -2.63206325e-02  6.91173747e-02 -7.38891661e-02
  1.38583230e-02 -4.85015772e-02  2.51090880e-02  4.63300310e-02
 -7.24244267e-02 -1.40615916e-02  6.48097843e-02 -2.82297283e-02
  3.52417715e-02  3.27237397e-02  3.73628289e-02  9.55915302e-02
  6.00360218e-04  2.41470020e-02  1.84779186e-02 -1.68389715e-02
 -4.58921529e-02  1.42791504e-02  4.98290583e-02  4.31632586e-02
  1.78881884e-02  2.00685952e-02  2.28864234e-02  4.22788486e-02
 -1.58858262e-02 -1.01896906e-02  5.28414808e-02  1.39885172e-02
  2.03588530e-02  2.59276833e-02 -1.00526521e-02 -3.82881649e-02
 -2.76760887e-02  5.96177354e-02 -8.52601416e-03 -2.93730642e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_68/kernel
[[ 0.1420968  -0.0793461   0.08796227 ...  0.11161028 -0.00311959
   0.02118351]
 [-0.11842474  0.04923438 -0.08355993 ...  0.13318942  0.12887052
   0.04960135]
 [ 0.10766581 -0.09724443 -0.131282   ... -0.09978865 -0.00439374
  -0.10635026]
 ...
 [-0.06895211 -0.09546382 -0.04727624 ...  0.14643453  0.05041142
  -0.00296057]
 [ 0.06383877  0.1240166  -0.05570627 ...  0.14273284 -0.00825642
   0.00924011]
 [-0.1161598  -0.08422203  0.07408979 ... -0.09043303  0.00411096
  -0.01664154]]
tensor_name:  TemporalFusionTransformer/time_distributed_69/bias
[ 1.9884694e-02 -9.3467049e-03 -1.3942035e-02  3.4803722e-02
 -2.0822197e-02 -2.7106436e-02  3.3727005e-02  8.6108681e-05
  1.4324206e-02 -6.7970278e-03  5.0477637e-03 -2.6565475e-02
  2.6416732e-02 -1.8760672e-02 -3.2033842e-02  3.1261381e-02
 -1.6159516e-02  2.2504847e-03 -6.8632751e-03  2.5104688e-02
 -2.3734337e-03  5.5861272e-02  1.2454161e-02 -1.7632954e-03
  4.8729028e-03  1.7093422e-03 -1.2203932e-03  3.1958856e-02
  8.3210124e-03  2.3161627e-02  2.9415926e-02  6.2375376e-03
  2.8496522e-02 -2.3396794e-02 -1.5927963e-02 -1.3903573e-02
 -1.8207707e-02 -1.5032946e-02 -2.3177195e-02 -4.1348659e-02
  1.2068555e-02  2.2135464e-02 -2.5061347e-02  3.4749862e-03
 -1.5197990e-02 -9.5348991e-03  4.1244630e-02  2.1513011e-02
  7.6587148e-02  1.3753486e-02  2.6088363e-02 -5.8846087e-03
  3.1673491e-02 -2.3222817e-03  2.7736340e-04 -1.0039433e-02
 -9.5454287e-03 -2.6701648e-02  7.4843434e-03 -1.5992226e-02
 -7.3018350e-02 -1.2837668e-02 -1.5148711e-02 -3.8203278e-03
 -1.9462461e-02 -2.2422075e-02 -8.4481835e-03 -2.3737313e-02
 -6.9674379e-03  3.1370033e-02  1.3596308e-02  3.2709341e-02
  1.0586524e-02  3.1773683e-02 -3.0132632e-03  2.4149762e-02
  4.3457560e-03  1.9803924e-02  5.4740743e-03  2.4968924e-02
  4.6269234e-02  6.5762050e-02  1.1280268e-02 -1.7189080e-02
 -4.6675168e-02 -3.3174243e-02 -5.9570861e-03  5.8688088e-03
 -3.1656317e-02 -5.8762650e-03  7.6624271e-03  2.0112049e-02
 -3.4798717e-03 -2.2741705e-02  2.5579078e-02  7.4621802e-03
  2.5806388e-02  1.1430481e-02  3.0443961e-02 -2.9474704e-02
  2.3808202e-02  6.7083053e-02  2.0983044e-02  3.7614556e-03
 -2.5059361e-02  2.7865216e-02 -4.5629344e-03 -1.0556345e-03
  3.4846161e-02  7.9288904e-04  2.7987165e-02 -3.6732562e-02
  2.5229998e-02 -1.7010262e-02 -3.0399070e-03 -3.0083951e-02
  1.1052534e-02 -1.8629977e-02 -7.0809983e-03 -2.7112676e-02
 -3.3706754e-02 -2.4285039e-03  3.8637307e-02 -5.1089674e-02
  2.5049435e-02 -9.8205376e-03  4.1455712e-02 -2.7240656e-02
  2.7588954e-02  2.0286452e-02 -4.4394433e-02  2.4827287e-02
 -3.0535838e-02  1.9985216e-03 -6.9997169e-02  1.6687674e-02
  1.4076433e-02 -6.5300154e-04  1.5398797e-02 -5.7747966e-04
 -4.9286289e-03 -1.6852424e-02  5.4080296e-02  2.1983420e-03
  3.8775872e-02 -3.3164430e-02  8.0209719e-03 -2.6391311e-02
  1.8830779e-03 -3.8429953e-02  1.4533937e-02  9.0228980e-03
 -8.2416736e-02  4.1889949e-03 -8.0555715e-02 -5.4795466e-02
  1.6964873e-02 -6.0450179e-03 -9.2596374e-03 -7.4647544e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_69/kernel
[[ 0.03013465  0.0508198  -0.11664926 ... -0.1017804  -0.07821695
  -0.11323968]
 [-0.02043061  0.05658926 -0.07059413 ...  0.11546594  0.120304
   0.01818609]
 [ 0.038068   -0.10212724 -0.05715532 ... -0.10323816  0.12536219
  -0.09265359]
 ...
 [ 0.13182198  0.02444565 -0.01152108 ...  0.12518752 -0.13508867
  -0.10962246]
 [-0.00412437  0.0377987  -0.0477073  ...  0.02216481  0.0423487
   0.04325897]
 [-0.12199243  0.10849649 -0.11632814 ...  0.09303908  0.07265791
  -0.01448906]]
tensor_name:  TemporalFusionTransformer/time_distributed_7/bias
[ 0.00304088  0.01431359 -0.0210555  -0.02995998 -0.02577525 -0.04290844
 -0.01224015 -0.00017259  0.03407821  0.01098117 -0.01725961  0.01607344
  0.00178151  0.01053041  0.01302926  0.03113887  0.00479706  0.00105286
 -0.03368361 -0.00167014 -0.00950243 -0.0284046   0.01357115 -0.02694657
  0.00572418 -0.02002723  0.00978187 -0.01993293 -0.0210718  -0.01786466
  0.00617748 -0.00029879  0.00283444 -0.0224259  -0.0013525  -0.00809253
  0.01891726  0.01937181 -0.01322616 -0.00341815 -0.00835384  0.01729523
  0.02268918 -0.0158893  -0.02463613 -0.02498755 -0.01028737  0.00381626
  0.02603866 -0.03179487 -0.0313355   0.00053617 -0.02547103 -0.00112522
 -0.0103418   0.03806323  0.01660599 -0.00211932 -0.00768558 -0.00032558
  0.01203962  0.02563873 -0.005002    0.00293615 -0.06027792 -0.01474291
  0.00762866  0.03477549  0.00491055 -0.02529493  0.03377967 -0.031245
 -0.00750211  0.00250692 -0.01409321 -0.0016673  -0.04317641  0.01402656
  0.02198311 -0.02003915 -0.0055116   0.00291295 -0.00539044 -0.01700708
  0.00470351 -0.00040296  0.0177601   0.0052974   0.00134877 -0.0265088
  0.02598011 -0.01189541  0.00723243 -0.00286532 -0.00597872  0.01223155
 -0.00273667  0.01078148 -0.02969186 -0.010067    0.01945754  0.02130345
  0.03021209  0.05291919  0.02369751  0.00769309  0.00890011  0.00491904
  0.01307925  0.01601482 -0.00930331 -0.01313894 -0.03510929  0.02363957
  0.0290097  -0.00199312  0.00607756 -0.01755015  0.02853388  0.02429843
  0.02596332 -0.05049551  0.03686561 -0.0207251  -0.00332449  0.02057204
 -0.01000798  0.0096093   0.00117331  0.00590389  0.00118963 -0.01128205
 -0.00179189 -0.02602534  0.02264511  0.0258819  -0.00129016 -0.00944206
 -0.00547798 -0.02221317  0.02672363  0.01089886 -0.02364225 -0.01537175
  0.01639418 -0.02271935  0.01498227 -0.00530497  0.05216425 -0.01261555
  0.01632974  0.02015009 -0.03138939 -0.00392459  0.01825618  0.00166829
 -0.02401516 -0.0076442   0.01458421 -0.02972804]
tensor_name:  TemporalFusionTransformer/time_distributed_7/kernel
[[-0.15253069  0.09425237 -0.10244066 -0.07442448 -0.15724236 -0.12761836
  -0.07476621 -0.02441057  0.16550794  0.09759852 -0.12689756  0.20746931
   0.02555837 -0.15793811  0.13030386  0.13855015  0.0967177   0.00574609
  -0.19023845 -0.02150895  0.01543255 -0.18695033  0.13042653 -0.16839592
   0.01790346 -0.08336578  0.10778625 -0.10299884 -0.10421918 -0.13899265
   0.02399931 -0.00949552  0.14025128 -0.20840622  0.06208919  0.07637084
   0.07192479  0.15288085 -0.09540261  0.00646331 -0.16993076  0.04486412
   0.13956217 -0.06270569 -0.18818095 -0.17028579 -0.1276164   0.09510905
   0.11591158 -0.22061951 -0.1111882   0.11459498 -0.14768358  0.05177462
  -0.11183505 -0.04719216  0.16139528 -0.07318131 -0.14503385 -0.09623262
   0.07629497  0.11868391 -0.06412179  0.01404731 -0.22751701 -0.22896229
   0.20990357  0.08628582 -0.1262579  -0.1848614   0.10866489 -0.228851
  -0.10446835 -0.1828469  -0.12309971 -0.05801021 -0.23937497  0.08694314
   0.22560412 -0.157008   -0.03794046  0.05989954 -0.08703218 -0.11337804
  -0.03915236 -0.04565126  0.18034396 -0.02708506  0.02737178 -0.04428009
   0.08714035 -0.1022939   0.14538276  0.01388834 -0.02071459  0.04232061
  -0.03417906 -0.20701732 -0.20135888 -0.08030935  0.1897216   0.1663728
   0.21703316  0.19310144  0.19563745 -0.0110865   0.0758647   0.09499143
   0.05947652  0.19585706 -0.03249266 -0.06728061 -0.13305907  0.24046423
   0.05686058  0.10744617 -0.06278872 -0.21403228  0.19661947  0.04630289
   0.18842874 -0.17268185  0.18500267 -0.07790482 -0.15426967  0.19369398
  -0.01709452 -0.06809683 -0.00984803  0.15229262  0.0058394  -0.03126794
  -0.02915329 -0.17988372 -0.03576973  0.06880556 -0.00909648 -0.03570619
  -0.2041885  -0.05811388  0.10769458  0.11921366 -0.14254701 -0.1130326
   0.15242101 -0.17911583  0.20798807  0.05854565  0.20259306 -0.02969654
   0.14848125  0.16956832 -0.10681017 -0.0251878   0.15369976  0.03581075
  -0.13202302 -0.09168019  0.20352717 -0.1127492 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_70/bias
[ 2.76315175e-02 -3.35688591e-02  1.87258497e-02 -2.91803349e-02
 -1.33289341e-02  6.85866177e-03  5.11302752e-03 -1.33833028e-02
  2.04687286e-02  8.07129312e-03 -5.05973250e-02 -9.93872713e-03
 -8.72170087e-03 -2.34351996e-02  5.72658284e-03  1.12612946e-02
  1.57700814e-02  5.34300460e-03 -4.90515307e-02  1.35426577e-02
 -2.64150836e-03 -2.99919359e-02  2.81747933e-02  2.09707916e-02
  7.37224612e-03  4.64977250e-02  1.87224448e-02 -4.51080967e-03
  3.40376212e-03 -1.54044051e-02  8.37901235e-03 -2.27701757e-02
  7.27907708e-03 -3.42944898e-02 -5.37671905e-04 -1.76809393e-02
  2.62921397e-03 -8.11380707e-03  8.69366713e-03  6.90218294e-03
 -5.28897718e-02  3.51182796e-04  2.25791242e-02  1.16865095e-02
  2.54291482e-03  4.88360925e-03 -8.69309902e-03 -6.60439837e-04
 -2.36879941e-02  4.98849433e-04 -1.37319714e-02 -2.35315263e-02
 -1.45199336e-02 -1.93333887e-02 -7.35982647e-03  5.96907735e-02
  1.25810886e-02  5.00451727e-03 -2.74084918e-02 -9.41141695e-03
 -6.33446453e-03 -6.28491631e-03  2.25934666e-02  2.66570668e-03
  2.51222937e-03  3.66602689e-02 -1.21766068e-02  1.56963877e-02
 -8.26286909e-04  9.91160888e-03  3.34118456e-02 -1.81026850e-03
 -1.44822523e-02  1.29868519e-02 -1.01148402e-02  7.06278486e-03
 -1.81326142e-03  9.52336192e-03  2.67632375e-03 -7.72291981e-03
 -2.70997453e-02  6.18331693e-03 -2.29801256e-02  1.52878575e-02
  1.39172422e-02  7.55970250e-04 -2.58611087e-02  5.21863392e-03
 -5.36976475e-03 -1.53780775e-02 -4.65847179e-03 -9.72221047e-03
  5.60266478e-03 -5.89532126e-03  2.55249185e-03 -2.24372298e-02
  2.70115230e-02 -2.84781144e-03  5.65853296e-03 -1.05961775e-02
 -7.93729722e-03  2.40227324e-03  5.26992930e-03  2.59761605e-02
 -5.82800526e-03  4.43445519e-02  7.73363421e-03 -1.47670098e-02
  2.71089561e-02  1.09511344e-02 -5.69053600e-03  1.70024636e-03
 -3.46276425e-02 -3.64017603e-03 -3.46025219e-03  3.06187067e-02
  7.15338215e-02 -3.21757942e-02  2.84086145e-03  3.53841148e-02
 -1.55151682e-03 -3.79055813e-02  1.55828968e-02  3.41399340e-04
  9.08899400e-03  3.10620037e-03 -9.25473869e-03  1.49693200e-02
  1.65553865e-04 -9.36669577e-03  5.47894929e-03 -2.34394846e-03
  1.69492560e-03  4.58365167e-03 -1.99852511e-02  9.07478668e-03
 -1.08475359e-02  1.30168945e-02 -1.80601759e-03 -1.04491459e-02
 -2.04465408e-02  5.06534614e-03 -9.63027030e-03  1.83612423e-03
  9.65015497e-03 -2.32783868e-03  1.56655360e-03  9.34541039e-03
  8.60415548e-02  1.49815790e-02 -1.24937575e-03  5.64065669e-03
  4.68263123e-03 -5.82756624e-02 -3.35959904e-02  2.12108735e-02
 -1.79517884e-02  5.20109013e-03  6.36627374e-05  1.02907303e-04]
tensor_name:  TemporalFusionTransformer/time_distributed_70/kernel
[[ 0.04745925  0.05260172  0.10073251 ...  0.03384406 -0.0638861
  -0.01698284]
 [ 0.01504472  0.12770195  0.0055475  ... -0.0217333   0.03531028
   0.1224301 ]
 [-0.05924534  0.04028923  0.04276614 ... -0.02476598  0.03808079
   0.05687669]
 ...
 [-0.05714782  0.23245789  0.1412441  ...  0.09645586 -0.14472334
   0.10032272]
 [-0.14312866 -0.05708491  0.02402274 ...  0.1113222   0.07567382
  -0.05968316]
 [-0.03326198 -0.03907766  0.03093828 ... -0.08179314 -0.11899767
  -0.01529413]]
tensor_name:  TemporalFusionTransformer/time_distributed_71/bias
[ 1.99763495e-02  2.09190622e-01 -1.94705818e-02  9.17857047e-04
 -3.08379321e-03 -3.81939625e-03 -3.82605288e-03 -1.79752596e-02
 -4.65663299e-02  4.18572165e-02  5.85062765e-02 -2.09774431e-02
 -7.47021511e-02 -5.20035513e-02 -3.17956763e-03 -8.04505218e-03
 -2.29863841e-02 -3.10192071e-02  5.89752160e-02 -3.52092609e-02
 -4.99908701e-02 -1.79352257e-02 -7.33894901e-03  8.14709533e-03
 -2.65425015e-02  1.25294439e-02 -2.99724285e-03 -3.32420990e-02
 -2.05524098e-02 -3.27689052e-02  4.97493846e-03 -4.13706228e-02
 -4.35520289e-03 -2.11313590e-02 -2.44153440e-02 -7.37360911e-03
 -2.87873168e-02 -3.94508019e-02 -2.79713366e-02 -2.34628208e-02
  1.28920719e-01  7.05703720e-02 -2.74659321e-03 -2.50886232e-02
 -3.07633411e-02 -1.23564918e-02 -2.63437536e-02 -1.06240697e-02
  9.09059402e-03 -1.63044129e-02 -3.96580733e-02 -1.53275561e-02
 -2.84839161e-02 -4.97638546e-02 -4.70342254e-03  3.66885737e-02
 -4.78057675e-02  1.76547971e-02  1.08716600e-02 -1.51386540e-02
 -7.10268468e-02  1.61152869e-03  1.03092724e-02  1.79105196e-02
  4.91672254e-04  3.04696932e-02 -7.55191445e-02 -4.43568118e-02
 -3.56305689e-02  7.39847496e-02 -4.12930502e-03 -5.53944008e-03
 -6.40471652e-03 -1.70983225e-02 -2.77091265e-02 -2.59092748e-02
 -2.35523749e-02  1.38300769e-02 -1.28722219e-02  5.46179665e-03
  4.84365784e-02 -1.82144269e-02  4.81875101e-03  3.54846008e-02
 -1.62193105e-02 -3.92424464e-02  5.97002869e-03 -1.27134491e-02
 -2.65534073e-02 -8.59678199e-04 -3.15603316e-02 -4.39887270e-02
 -3.83829959e-02  7.69765675e-03 -1.11723104e-02  1.90962269e-03
 -1.84456963e-04 -4.38878173e-03 -7.15198927e-03 -2.69908048e-02
 -3.83438244e-02 -2.04539802e-02 -9.48744919e-03  2.62212902e-02
  4.02692147e-03  6.55641127e-03 -1.08595267e-02 -1.12433387e-02
  7.19381589e-03 -8.00174195e-03 -3.61192562e-02 -6.47669716e-04
  7.26282373e-02 -4.33223881e-02 -4.18700352e-02  6.30505309e-02
  1.18871476e-03  3.05325426e-02 -5.63734546e-02  3.07454765e-02
 -3.79997492e-02  2.21942179e-02 -5.25857359e-02  1.05275465e-02
 -3.33290473e-02 -1.65163241e-02 -2.25955080e-02 -1.64800137e-02
 -2.35975739e-02 -1.01966448e-02 -2.37943865e-02 -2.96775736e-02
 -1.35238320e-02 -3.20994668e-02  2.74332939e-03 -7.42251649e-02
 -3.03020477e-02 -2.74851685e-04 -6.66760048e-03 -1.98080242e-02
 -2.59806532e-02 -1.42482342e-02  7.59138120e-03  1.39113013e-02
 -1.88755784e-02 -2.27624029e-02 -1.14614964e-02 -3.35526839e-02
  1.24809548e-01  1.49075817e-02 -3.34439203e-02 -1.08548701e-02
 -4.27615689e-03  6.88722031e-03 -2.58769048e-03 -3.28841172e-02
 -1.21350344e-02 -4.42626216e-02 -5.45236543e-02 -5.21395961e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_71/kernel
[[-9.10825580e-02  1.15873873e-01 -1.21389017e-01 ... -1.08319357e-01
  -1.22992545e-01  6.53409064e-02]
 [ 9.35627446e-02 -1.02083094e-01 -4.37462851e-02 ...  1.46240771e-01
  -2.98860781e-02  7.74436146e-02]
 [ 8.29729214e-02  3.17035131e-02  3.99819836e-02 ...  1.06261268e-01
  -1.17189705e-01  7.22022355e-02]
 ...
 [ 9.51330960e-02 -2.63419897e-05  1.48744240e-01 ...  1.23482808e-01
   6.26067370e-02  1.37001947e-01]
 [ 1.18687823e-01 -1.59914829e-02  1.07634783e-01 ...  5.34691736e-02
  -5.26944585e-02 -1.04221672e-01]
 [ 7.05837384e-02  1.99346934e-02  4.07366008e-02 ... -5.61090782e-02
   1.04783155e-01 -3.40480986e-03]]
tensor_name:  TemporalFusionTransformer/time_distributed_72/bias
[ 0.00879608  0.043121    0.02655556 -0.00790073  0.03032996 -0.00368698
 -0.00621407  0.00855185  0.03224419  0.00540441 -0.01601859 -0.03076327
 -0.02364549 -0.02971731  0.05661697  0.01114855  0.02760815  0.038658
 -0.02938364 -0.00432603  0.03512539 -0.0101432  -0.01252782 -0.03452154
  0.00904824  0.06274456  0.03069443 -0.012797    0.01938368  0.0462531
 -0.03785102  0.00174456  0.00769188 -0.0287737   0.01940552 -0.06682027
 -0.00318727 -0.00331168 -0.04672891  0.07890478  0.04098791  0.07656069
 -0.00241279 -0.00336006 -0.01654629  0.00036977  0.03468525 -0.01314881
 -0.00161577  0.01684783  0.02831951 -0.03017483  0.06520568  0.02564226
  0.01558184  0.00147422 -0.03359644 -0.03868987 -0.01525225  0.03705758
 -0.02376964 -0.03953413  0.0482916   0.04629056  0.01454398 -0.02844262
  0.01535566  0.00044185  0.01353128 -0.03128344  0.01914749 -0.04192118
 -0.01212862  0.05074794  0.00816387  0.00743917  0.01316283  0.00868251
 -0.07289904  0.00584799 -0.0266491   0.00689368  0.05610337 -0.06610093
 -0.02756013  0.00221998  0.03389418  0.01619907 -0.02785554  0.09124073
  0.0357884  -0.02967768 -0.01701535  0.01518972  0.00594191  0.00157267
 -0.0061658  -0.02256675 -0.01009715 -0.01744884 -0.00933724  0.0308216
 -0.03783248 -0.01120355 -0.01151748 -0.02456672  0.00349433 -0.03511018
  0.01504496 -0.06843911  0.022836    0.02625728  0.05069334  0.04752105
 -0.01183766 -0.08653891  0.04261027 -0.04947855  0.04528952 -0.06793429
 -0.02167123  0.00631214 -0.03507779 -0.01401765 -0.03762679  0.00317858
 -0.03567398  0.02315515  0.01770117 -0.02222684 -0.02435951 -0.04183268
  0.0063031   0.01248569 -0.06898658  0.02854116 -0.02845493 -0.02416673
  0.0303605  -0.04732952  0.04344208  0.00066608 -0.00745982  0.04226618
 -0.02040744  0.11579637  0.00040994  0.07235718 -0.00361179 -0.01824101
  0.04735411 -0.04171879  0.00307252 -0.02820507 -0.00752823 -0.01232724
  0.03754325  0.05035784 -0.01051868  0.00104435]
tensor_name:  TemporalFusionTransformer/time_distributed_72/kernel
[[-0.08071943 -0.05929356  0.06419004 ...  0.05186422 -0.12393246
  -0.0372658 ]
 [-0.14514674 -0.0328285   0.11126432 ...  0.05603126  0.07083751
   0.13006897]
 [-0.10536111 -0.12953392  0.13020633 ... -0.11281787  0.0134901
  -0.04131087]
 ...
 [ 0.05145906 -0.08420446 -0.06730143 ...  0.05962555  0.11065196
   0.04689157]
 [-0.02678709  0.11182019  0.10013466 ...  0.09781572  0.10817073
  -0.08984431]
 [ 0.07659326 -0.00301567  0.13872963 ...  0.16372873 -0.12604895
   0.12302019]]
tensor_name:  TemporalFusionTransformer/time_distributed_73/bias
[-0.03817936  0.06561861 -0.01983238 -0.02724347 -0.00074753 -0.01491873
  0.02502977  0.05760584 -0.02871439 -0.00084315 -0.00911618  0.00211825
  0.02165289 -0.03735243 -0.00586633  0.00686585  0.01228829 -0.00862163
  0.00283594 -0.03132543 -0.03022255  0.00837473 -0.01441867 -0.00961223
 -0.03731563 -0.00147347 -0.0060235  -0.01066506 -0.00063106  0.03629697
  0.00013135  0.00149802  0.02869169  0.05976928  0.0266293   0.00283268
 -0.00084471 -0.01331719  0.04969685 -0.00747738  0.02180541 -0.04838248
 -0.02840115  0.00538538 -0.00504736  0.02590181 -0.04899503  0.01962666
  0.00931131  0.02611385 -0.0158187  -0.01842954 -0.05866429  0.03154832
  0.00838339 -0.03972686 -0.00661558 -0.00603531 -0.01103     0.0186319
 -0.03337632  0.05204755  0.00677096  0.04356911 -0.0582259   0.01024793
 -0.0380018  -0.00490773 -0.03173004  0.04134981 -0.04870597 -0.01623782
  0.02391473 -0.03494454  0.03124358  0.02115291 -0.01469189  0.0006032
 -0.02451881  0.02746358  0.04767769  0.01297307  0.03800058 -0.01614511
  0.02251601  0.00116381 -0.02780457  0.03780492  0.00616324  0.03773461
 -0.00430682 -0.00571246 -0.03098335  0.03920427  0.01930361 -0.0175008
 -0.01431347  0.01506279 -0.01168012  0.00808705 -0.01526826 -0.0143523
 -0.00734997  0.03711851 -0.00754344 -0.00142954  0.03977237 -0.030814
  0.01625193 -0.00933098 -0.05796792  0.00214267  0.01785761 -0.02707301
  0.0321263  -0.04078632  0.04669551 -0.01111392  0.0034897  -0.01506936
 -0.00937426  0.01783547 -0.03384617  0.0679156   0.01600174  0.00560391
  0.03909455  0.04591059 -0.02170505  0.0461282  -0.02615865 -0.00694106
  0.00378589  0.01175429  0.00846613 -0.02552507 -0.00140695 -0.0021118
  0.04114565  0.02289633 -0.03653051  0.05527724  0.00093582 -0.02619016
  0.00264034  0.00742992  0.04896769  0.04221489 -0.00422155  0.0434992
 -0.00465341 -0.00043844 -0.01802454 -0.02470335  0.01886845  0.01891437
 -0.01498988  0.02569111  0.00346144 -0.07272241]
tensor_name:  TemporalFusionTransformer/time_distributed_73/kernel
[[-0.1392991  -0.11483809  0.01393051 ...  0.05528502  0.10565573
   0.01697471]
 [-0.0124798  -0.04308416 -0.11294338 ... -0.07737915 -0.04848357
  -0.1450584 ]
 [ 0.02513839  0.08167576 -0.03644259 ...  0.12781851 -0.01676037
  -0.05915151]
 ...
 [-0.04651029  0.11040952 -0.10557167 ... -0.00157376 -0.00364839
  -0.10995305]
 [ 0.02535789 -0.0390421  -0.10092791 ... -0.00445843  0.05318389
   0.03172976]
 [-0.0935638  -0.14072487 -0.1048656  ... -0.1161302  -0.0688038
   0.0151348 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_74/bias
[ 2.53606383e-02  6.40659183e-02  1.47232618e-02 -5.02908230e-02
 -3.78227234e-03  9.48174205e-03  2.28864490e-03 -1.90176591e-02
  1.93208791e-02 -1.21314727e-01 -3.35923955e-02 -1.15301954e-02
 -9.35119856e-03  2.17361096e-02 -1.82494540e-02  1.97259877e-02
  1.08827846e-02 -1.04179569e-02 -2.53632274e-02  1.57107972e-02
  2.83280294e-02 -1.60500538e-02  3.08746193e-02  1.60864890e-02
  2.47713532e-02 -4.00427962e-03  8.11059773e-03 -2.12192759e-02
 -1.10002002e-03  6.27112051e-04  1.26341172e-02 -3.20854895e-02
  9.47678462e-03 -2.10615955e-02  6.74078614e-03 -1.49046592e-02
 -3.04366485e-03  1.07358871e-02  1.69288609e-02 -6.15853816e-04
 -4.44517136e-02  3.46268751e-02  2.85734404e-02  1.38341775e-02
  1.87786156e-03  1.33294221e-02 -5.73282316e-03 -1.17640160e-02
 -3.09670586e-02  6.66479487e-03 -1.43466471e-02 -2.30073873e-02
  6.38400624e-03 -1.52415643e-02 -1.94610283e-02  8.81803930e-02
 -3.39798792e-03  1.91134289e-02 -3.16795231e-05 -3.15085356e-03
 -1.62456569e-03 -1.18380990e-02  1.81383975e-02  1.82135683e-02
  1.51515584e-02  1.84534788e-02 -7.48333288e-03  2.23061107e-02
  1.29081658e-03 -3.06817405e-02  5.41975424e-02  5.89439273e-03
 -2.36606486e-02  1.08786700e-02 -9.46016703e-03  6.05582632e-03
  2.00540740e-02 -4.72341571e-03 -9.84649407e-04 -1.57302506e-02
  2.64014285e-02 -2.34279856e-02 -2.33270172e-02  2.39832364e-02
 -3.36117973e-03 -1.26950536e-03 -8.82285833e-03 -7.06337485e-03
 -1.02977408e-02  5.38568525e-03  2.73576169e-03 -1.12515036e-02
  1.38172833e-02 -2.49508116e-02 -1.23828435e-02 -2.54467707e-02
  3.74969244e-02 -1.31264981e-02  3.19641903e-02 -2.03317460e-02
 -1.33426590e-02 -5.72704570e-03 -7.69923383e-04  2.70299856e-02
 -3.08421981e-02  2.37816740e-02  1.26890289e-02 -3.31977084e-02
  3.30568105e-02  1.10221666e-03 -3.57915158e-03  1.15197664e-02
  5.61823063e-02 -1.77609213e-02 -1.23592606e-02  3.11034452e-02
  3.90222706e-02 -3.49411368e-02  2.16010679e-03  1.11503312e-02
 -1.26759224e-02 -9.47013218e-03  3.64578739e-02  3.17627862e-02
  4.80622472e-03  6.09564548e-03  1.85973116e-03  1.00391200e-02
 -1.92823783e-02 -1.21254129e-02  1.07093435e-02  8.21550190e-03
 -1.51583841e-02  2.86685233e-03 -3.05725797e-03 -3.80477752e-03
 -2.90356064e-03 -1.58554595e-02 -5.76842204e-03  2.03760471e-02
 -1.91867072e-02  7.89579761e-04 -7.46853696e-03  1.61127597e-02
  9.81846545e-03 -1.27507709e-02 -4.49112430e-03 -8.11613165e-03
 -1.06591370e-03 -2.15225536e-02  2.08548317e-03 -1.11538917e-03
 -1.28917852e-02 -4.44824994e-02 -5.07706031e-03  2.35950779e-02
  3.10644065e-03 -1.27898743e-02  9.43642983e-04  9.70353838e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_74/kernel
[[ 0.09709618 -0.17522986  0.03549718 ... -0.04001559 -0.09667782
  -0.08074035]
 [-0.00997826  0.06890284 -0.0241632  ... -0.05839539  0.12521987
   0.00579425]
 [ 0.08074021  0.03189406 -0.03758474 ... -0.02750714 -0.11759637
   0.16603157]
 ...
 [ 0.06077015 -0.03949078 -0.00462396 ... -0.09757956  0.13387397
   0.0503142 ]
 [-0.11531803  0.01050614 -0.01018688 ...  0.16639706  0.11888462
   0.01605074]
 [-0.05432425 -0.12256702 -0.13061148 ...  0.03436064  0.12730356
   0.07263614]]
tensor_name:  TemporalFusionTransformer/time_distributed_75/bias
[-1.32412119e-02  1.64128002e-02 -1.50600623e-03  4.23012301e-02
 -5.61983977e-03 -3.34737785e-02 -2.57321130e-02 -1.41466307e-02
 -2.87126959e-03  1.95058748e-01 -1.06923264e-02  3.88276167e-02
 -3.43139619e-02  2.98414044e-02  2.77753025e-02  2.93376204e-02
 -2.52395794e-02 -3.14942338e-02 -1.38423070e-02 -5.80649008e-04
 -5.74772283e-02 -1.80828280e-03 -3.10105905e-02 -3.05870865e-02
  2.29460970e-02 -5.55919856e-02  1.45707903e-02  1.07521582e-02
 -3.36441174e-02 -4.98787090e-02 -1.26214186e-02  4.10784688e-03
 -6.72463747e-03 -7.26248743e-03 -1.43484371e-02 -2.67976560e-02
 -1.50054516e-02  9.82467271e-03 -8.46815389e-03  9.36657265e-02
  1.68597326e-02  1.41761382e-03  5.41687533e-02 -5.04196398e-02
 -3.50250751e-02 -2.63468362e-02 -1.24687152e-02 -3.80469821e-02
  1.83125623e-02 -2.88276356e-02 -2.84300577e-02 -3.18132155e-02
  2.51199827e-02 -2.32432131e-02  1.05593782e-02  8.62206519e-02
  3.11146192e-02  9.50036477e-03 -1.80258490e-02 -2.89813131e-02
 -1.23034222e-02 -5.89513965e-02 -8.27035960e-03 -5.98284137e-03
 -2.05930322e-02  5.49153872e-02 -4.79571968e-02 -2.16166805e-02
 -2.60760691e-02  2.91972421e-02  4.38140444e-02 -8.93212296e-03
  9.96084884e-03 -2.10434869e-02 -5.97615242e-02 -4.81189750e-02
  2.68747099e-03 -1.71031151e-02 -1.97632555e-02 -7.36312289e-03
  1.78197753e-02  4.29891143e-03 -1.10678561e-02  1.11722890e-02
 -3.63949197e-03 -3.09189875e-02  6.29466143e-04 -3.58335078e-02
 -2.60557625e-02 -3.86450440e-02  1.21519879e-01 -1.74886012e-03
 -4.62329201e-03  4.13793512e-03 -6.00969559e-03 -1.61311179e-02
  2.26408280e-02 -4.35938090e-02 -1.92976600e-04  1.24967145e-03
 -2.64191255e-02 -2.73753069e-02 -2.60959612e-03  1.88671146e-02
  5.86351044e-02 -5.75119955e-03  8.74572527e-03  3.29905655e-03
  2.29415037e-02 -1.69634651e-02 -4.71680909e-02 -2.75225518e-03
  5.87940812e-02 -1.24781877e-02 -3.55917700e-02 -1.58812050e-02
  2.71029919e-02  3.58634628e-02 -2.95720212e-02 -2.07460895e-02
  2.24493369e-02  6.55769333e-02 -2.12683100e-02  1.11454232e-02
 -3.88755202e-02 -1.52839627e-02 -3.18538174e-02 -1.38833495e-02
  7.34589202e-03 -3.41341905e-02 -1.57695338e-02 -2.91807670e-02
  8.56208801e-03  1.42995594e-03  1.59217119e-02 -2.69840881e-02
 -1.05188703e-02 -3.79350930e-02 -2.08984893e-02 -3.28909829e-02
 -1.75373710e-03 -4.05685492e-02 -1.86214577e-02  3.90625035e-04
 -4.40176353e-02 -1.36415986e-02 -2.62249261e-03 -2.13148724e-02
  6.30913861e-03 -2.34940834e-02  4.86364029e-03 -7.30151162e-02
 -1.31367221e-02 -1.63157936e-02  4.75938022e-02  7.88404047e-03
 -3.70837562e-02  2.52568759e-02 -4.52997498e-02 -2.20859237e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_75/kernel
[[ 0.04549636 -0.09613766  0.10695244 ... -0.05323747  0.17773676
   0.08107347]
 [-0.02572791  0.03726587 -0.14242746 ... -0.06436788  0.04848672
   0.13247634]
 [ 0.11459113  0.06710038  0.0944011  ... -0.05822897  0.11921256
  -0.07490631]
 ...
 [ 0.04472675  0.2271682  -0.1202427  ... -0.10814651 -0.09421127
  -0.02741206]
 [-0.12899363 -0.16067587  0.12030238 ... -0.0926108   0.03123204
   0.02583568]
 [ 0.12145802  0.06179666 -0.07730847 ...  0.0687186   0.11925386
  -0.13135478]]
tensor_name:  TemporalFusionTransformer/time_distributed_76/bias
[-1.47936363e-02  2.10226444e-03 -1.05798189e-02 -1.12841162e-03
 -8.73715617e-03 -2.02056952e-02 -3.49376947e-02  8.09631590e-03
  1.56960879e-02  4.62757833e-02  3.29807587e-02  4.31586355e-02
  2.90492792e-02 -3.32705453e-02  4.32848893e-02 -2.70795524e-02
 -5.24644973e-03 -3.53134088e-02 -2.35385019e-02 -1.36987185e-02
 -1.28041189e-02 -4.16695401e-02 -7.73547171e-03  7.82179064e-04
 -1.27462493e-02 -4.47074994e-02  4.52681370e-02  3.71189341e-02
  3.10443006e-02  3.25580798e-02  1.02646081e-02 -1.97893096e-04
  1.73232257e-02 -2.78769061e-02 -5.67783415e-02  5.00189774e-02
  1.42828526e-03 -9.48944781e-03 -2.91154366e-02 -2.19214838e-02
  5.53779071e-03 -3.98169225e-03  2.28975918e-02  4.18187166e-03
 -1.75577626e-02 -2.50478052e-02  5.50857466e-03  5.84823033e-03
  2.75592203e-03  4.61329259e-02 -6.52512244e-04 -1.62703695e-03
 -1.79454610e-02  7.81397894e-03 -2.31049284e-02 -4.88482341e-02
 -5.71549172e-03  9.43209790e-03 -2.26542503e-02  5.02261445e-02
 -1.28551554e-02 -1.18455505e-02 -2.06817174e-03 -4.17990014e-02
 -1.13214403e-02 -2.10312307e-02  1.05447397e-02 -2.28406861e-02
 -8.67568597e-05  3.07198074e-02 -4.06759651e-03 -5.64918341e-03
  8.46277643e-03  3.00352145e-02 -9.47957765e-03  2.09326707e-02
  3.55535261e-02 -5.61191477e-02  1.24653205e-02  2.83226427e-02
  7.72520760e-03 -2.18101479e-02 -1.47841088e-02 -3.53878178e-02
  6.97262073e-03 -1.12907235e-02 -3.56601588e-02 -3.21590863e-02
  7.32141174e-03  3.40043902e-02  1.25200776e-02  1.82382353e-02
 -2.61768587e-02 -6.54610246e-03  2.58487021e-03 -4.81549799e-02
  7.23700523e-02 -1.63762551e-02 -3.87593918e-02 -4.89238612e-02
 -5.38888089e-02  2.22362187e-02 -3.85227799e-02 -4.54318151e-02
 -7.44238775e-03  1.17996801e-02 -5.95442485e-03  5.61426207e-03
 -2.53405310e-02 -2.15523671e-02  1.46441981e-02 -1.52949486e-02
 -3.26750278e-02  4.44759764e-02 -1.18932296e-02  1.82484984e-02
 -1.94763802e-02 -1.65547375e-04 -2.14820281e-02 -5.27418703e-02
 -5.08620124e-03  4.15132614e-03 -5.20139700e-03  1.80034228e-02
 -3.17487679e-02  2.38687620e-02  1.01085333e-03 -1.60304550e-02
 -1.56994872e-02  1.85599532e-02  2.11773254e-02  3.67755047e-03
  4.48001847e-02 -8.29605386e-03  6.75518066e-02  2.38367468e-02
  1.92430224e-02 -8.72008409e-03 -8.04515835e-03 -5.04122712e-02
 -9.29169822e-03 -1.08631374e-02  1.04637537e-02  6.59094006e-02
 -1.44305127e-02 -1.47751141e-02  4.08681706e-02  4.50359620e-02
 -1.34038115e-02  1.11271609e-02  4.45440449e-02  8.75095278e-03
 -2.85473019e-02 -3.48155424e-02 -1.04380241e-02 -3.36117595e-02
  3.12047862e-02  2.51625851e-02 -4.21910249e-02 -2.30405834e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_76/kernel
[[-0.09451623  0.00331664  0.10947898 ... -0.03433763  0.13447843
   0.01263842]
 [ 0.09096225 -0.12167121 -0.05792698 ... -0.1022816  -0.10903887
   0.05822992]
 [-0.08934861 -0.13138829 -0.05432035 ...  0.05578895  0.13173974
   0.12739468]
 ...
 [ 0.08643698  0.02652015 -0.12739845 ... -0.1433851   0.1423529
   0.05091281]
 [-0.00941202  0.12913156  0.12887405 ... -0.06692091 -0.03643075
  -0.06190362]
 [ 0.04171773  0.06894583 -0.12403379 ... -0.12055073 -0.00315965
   0.07493768]]
tensor_name:  TemporalFusionTransformer/time_distributed_77/bias
[-1.27701825e-02 -4.69767787e-02  9.20405053e-03 -2.61907540e-02
  3.18589574e-03  5.51237306e-03  6.27936749e-03 -1.30945873e-02
  2.89255586e-02 -2.53686253e-02  2.38098809e-03 -1.05331400e-02
 -6.61186036e-03 -3.42110768e-02 -3.62189375e-02 -1.58751290e-02
 -7.82256073e-04 -1.27898669e-02 -1.65987632e-03 -1.37548381e-02
 -1.15137431e-03  3.15052515e-04  5.34676127e-02 -5.89234801e-03
 -3.23780663e-02  4.12825942e-02  1.46202305e-02  1.01586552e-02
 -4.65123579e-02  5.14152972e-03  1.24110654e-02  4.95715858e-03
  2.36582235e-02  3.27483256e-04  2.68461425e-02  5.54601895e-03
 -3.65755893e-02  3.45753580e-02 -3.14292428e-03  9.15365480e-03
 -1.29728690e-02 -5.20691648e-03 -6.97888806e-03 -2.47866251e-02
  7.60794943e-03  1.59399733e-02  3.22511606e-02  1.22751268e-02
  6.75062090e-03  3.42410468e-02  1.83419269e-02 -1.91928521e-02
  1.36125674e-02  1.48738746e-03  4.10423502e-02  1.81324724e-02
 -2.85409167e-02 -3.27080907e-03  2.37731170e-02 -2.40141004e-02
  3.95997874e-02 -3.25416736e-02  2.03424077e-02  2.01776437e-02
 -2.55189668e-02  7.96448160e-03  3.37982997e-02  1.53547442e-02
  2.71907188e-02  2.84560136e-02 -2.35392433e-02  7.34420270e-02
 -3.21875364e-02 -1.17041112e-03  3.78001761e-03  7.12122675e-03
 -2.68364251e-02 -2.71840729e-02 -5.29319514e-03 -5.08098230e-02
  6.23314753e-02  9.50853061e-03  2.37880796e-02  1.20495167e-02
 -1.46474866e-02  4.56072055e-02 -2.02551261e-02  1.54036609e-03
 -9.71024740e-04  2.34855916e-02  4.89140600e-02  2.60745939e-02
  7.11097149e-03  1.91328768e-02  7.45916157e-04  2.81566288e-02
 -6.17082901e-02  4.03378718e-02 -2.84542404e-02  2.08706292e-03
  2.67318188e-04 -3.31491716e-02 -2.10018121e-02  7.55035318e-04
  3.04354541e-02 -6.97855279e-03  1.72483213e-02  1.04266871e-02
 -2.72972342e-02  3.36871035e-02 -1.86994132e-02  1.49387540e-02
  5.87623753e-03  1.16623333e-02  4.26187791e-04  1.10421870e-02
  4.53597982e-04 -2.13514771e-02  1.10777440e-02 -3.52448830e-03
 -9.94470529e-03 -2.41595600e-02 -2.52240105e-04 -8.33095983e-03
 -2.50578614e-05  1.00488216e-02 -6.62873238e-02 -3.87201272e-02
  8.69658962e-03 -2.80965306e-02 -7.23860553e-03  3.92517820e-02
 -2.02058419e-03  7.62568042e-03  3.88310254e-02 -1.09622097e-02
  1.58524083e-03 -8.44647363e-03 -2.82478388e-02  2.12025139e-02
 -7.15123564e-02  4.73805796e-03 -2.88846605e-02  9.88330133e-03
  2.46334597e-02  6.71951100e-03 -8.53097625e-03 -3.64061445e-02
  6.22324971e-03  1.78422723e-02 -1.70535147e-02 -1.01984050e-02
 -1.69076130e-03 -1.09993815e-02 -3.62320356e-02  1.89134739e-02
  1.62757635e-02 -2.07441784e-02 -1.15729244e-02 -2.59865075e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_77/kernel
[[-0.02535769 -0.12052622  0.10834266 ...  0.02888383 -0.0907907
  -0.04645316]
 [-0.09710325  0.10886249  0.0633906  ...  0.08990688 -0.04068204
  -0.09246487]
 [-0.10989279 -0.04618096 -0.02410839 ...  0.0406656  -0.08084249
  -0.11242026]
 ...
 [ 0.06440244 -0.06597718 -0.05139022 ... -0.14253432 -0.10343055
  -0.14022937]
 [ 0.08346195  0.0886066   0.07108396 ... -0.0455577   0.0977355
   0.13961159]
 [ 0.02177835 -0.06956232  0.05107388 ...  0.12338553  0.06542906
   0.05902464]]
tensor_name:  TemporalFusionTransformer/time_distributed_78/bias
[ 8.33604671e-03  9.33959382e-06  2.41965093e-02 -1.92825478e-02
 -3.27928737e-03 -2.41784402e-03  8.14593397e-04 -1.39304064e-02
  3.27582005e-03 -2.48537995e-02 -9.50429402e-03 -2.62831859e-02
 -1.63788553e-02  3.80176418e-02 -1.02191027e-02  1.73155162e-02
  7.32699735e-03  9.20974929e-03 -1.16705596e-02  2.03887969e-02
 -9.77526978e-03 -6.56839274e-03  9.37664323e-03 -1.51034549e-03
  9.77479853e-03 -3.43793700e-03  1.25615103e-02 -1.72352716e-02
  2.49612611e-02 -1.82323586e-02  2.96652853e-03 -5.32924477e-03
  1.09687820e-02 -7.89870415e-03  1.91418536e-03 -2.00550761e-02
  1.76039641e-03 -1.68327615e-02  1.11890156e-02  9.71556455e-03
  1.93036976e-03  2.08509341e-02  1.17404209e-02  1.86257996e-03
  6.37734728e-03  6.89428952e-03 -1.38865141e-02  1.76687201e-04
 -1.14617068e-02  1.37602556e-02 -1.56078646e-02 -2.74738669e-02
 -1.59009751e-02 -2.08049566e-02 -3.07429442e-03  7.28113502e-02
 -9.54799727e-03 -1.40135214e-02 -5.01196971e-03  3.49072996e-03
  1.40789822e-02 -4.27463884e-03  1.73216555e-02  2.09344123e-02
  1.16216913e-02  1.36223035e-02 -1.21419933e-02  6.55685738e-03
  1.41716050e-02 -2.26276908e-02  2.79390384e-02  8.82937666e-03
 -2.41714306e-02  8.69268831e-03 -9.97521728e-03  9.34172142e-03
  1.45960320e-02  2.28644189e-04  2.21910421e-03  1.31182764e-02
 -9.04444978e-03 -1.85302552e-02 -1.20173367e-02  1.28385322e-02
  1.18547790e-02  2.40854477e-03 -1.71693545e-02  6.83649257e-03
 -7.93439336e-03 -4.50532977e-03 -1.55553110e-02 -2.44221464e-03
  6.11362932e-03 -7.45334523e-03 -2.33131107e-02 -8.54499545e-03
  1.89264398e-02  5.72479423e-03  8.11783690e-03 -1.61547642e-02
 -3.40475584e-03 -6.75973436e-03 -5.19092707e-03  1.89519711e-02
 -1.42310385e-03  1.71424095e-02  1.17135476e-02 -1.90176275e-02
  1.50101203e-02  3.03118117e-03  1.32624609e-02 -1.10690482e-02
 -1.61908306e-02 -1.98371541e-02 -1.03371544e-03 -6.98466832e-03
 -1.91861962e-03 -2.12704167e-02  1.56350955e-02  1.27700614e-02
  1.54265705e-02 -5.60345352e-02  4.09172997e-02  1.08565548e-02
  3.64170945e-03  2.83985236e-03 -1.33774253e-02  1.62497796e-02
 -1.94077790e-02 -1.90685708e-02  1.70505308e-02 -5.44446171e-04
 -1.76767893e-02  1.22016184e-02  4.11106683e-02  8.16758163e-03
 -8.57600477e-03 -4.40207135e-04 -4.71291784e-03 -1.45533429e-02
 -1.14583382e-02 -1.66264195e-02  1.05812857e-02 -4.90354374e-03
 -2.69936491e-03 -5.03050955e-03 -1.22365346e-02  6.88369665e-03
  1.13365740e-01 -4.04321792e-04  3.43617541e-03 -1.91620849e-02
 -1.61728170e-02 -4.86037992e-02 -2.75951382e-02  5.01182745e-04
 -4.44961386e-03  3.83661874e-02  2.18071160e-03  3.07985162e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_78/kernel
[[ 0.03060798  0.0533297  -0.10980543 ...  0.09882192 -0.01730145
  -0.07174127]
 [-0.01208364 -0.01141306 -0.0802771  ...  0.01348245  0.03330197
  -0.10682589]
 [-0.02262956  0.00082493  0.06865749 ...  0.12454549 -0.08677056
   0.03976098]
 ...
 [ 0.10277592  0.07350463 -0.09406216 ...  0.03216359 -0.02254196
  -0.12271486]
 [-0.07640839 -0.05360464 -0.01190884 ... -0.08226592 -0.09643012
   0.02013937]
 [-0.01269052 -0.06066042  0.12030868 ... -0.03897595 -0.01250892
   0.09446213]]
tensor_name:  TemporalFusionTransformer/time_distributed_79/bias
[-0.03663632 -0.02518718 -0.00865836 -0.00472361 -0.01798509 -0.00738682
 -0.01901648  0.00149107  0.00696892 -0.01363846  0.02875163 -0.01149464
 -0.00678664  0.04481539  0.01770693 -0.01292633 -0.0194917  -0.02777189
  0.00501111 -0.0061715  -0.02454705  0.11818083 -0.01292333 -0.01672453
  0.01371824  0.04694844  0.0346817   0.01105999 -0.00740349 -0.00736643
 -0.01805967 -0.01474589 -0.00353232  0.03288177 -0.026075    0.00497491
 -0.01082397  0.00296403 -0.03151346 -0.00951926 -0.01852518 -0.02372788
 -0.03479485 -0.02530397 -0.02275844 -0.00236333 -0.02957192 -0.00245445
  0.00134241 -0.025472   -0.02073683 -0.01134452 -0.00503169  0.00594357
 -0.09842677 -0.00548434  0.01587683 -0.01597276  0.02619152 -0.0257151
  0.10655435 -0.00430445 -0.00812486  0.00253111 -0.00670622 -0.01620681
 -0.04765509 -0.01272178 -0.02033788  0.00229709  0.02465146  0.0211859
  0.00592371 -0.02672919 -0.0010852  -0.00353702 -0.0134504  -0.01064454
 -0.01665303  0.00207493  0.00658869  0.01001423 -0.01255902 -0.0114219
  0.0022665  -0.00551929 -0.01504311 -0.00796149 -0.01993714 -0.01786168
  0.01034662  0.05809515 -0.02602199  0.00145584  0.00372633 -0.00887659
 -0.00791401 -0.03570416  0.00800924  0.01887622 -0.0020941  -0.03439351
 -0.02285683 -0.00519318  0.07336599 -0.01600359 -0.00354971 -0.01731723
 -0.00861004  0.00217902 -0.01418099 -0.00895869  0.0132719  -0.01582015
 -0.00648814 -0.00879038  0.03347413  0.00587648 -0.03169224  0.00863963
 -0.01743255  0.02247904  0.0095396   0.02329825 -0.02149652 -0.00680301
 -0.01125191 -0.00636736 -0.00068609 -0.01317678 -0.03119799 -0.02399149
 -0.02270302 -0.02954821  0.03270146 -0.01241224 -0.00077774  0.01074274
 -0.00055063 -0.04896787 -0.00352427 -0.03758746 -0.01715494 -0.02566505
 -0.02228663 -0.04619516 -0.04890328 -0.02289372  0.05249771  0.03187376
 -0.0174574  -0.01655631 -0.01642252  0.06472071  0.00817309 -0.02444524
 -0.00394386  0.01128917 -0.00275997 -0.02327103]
tensor_name:  TemporalFusionTransformer/time_distributed_79/kernel
[[-0.10595682  0.19881666  0.08742008 ... -0.00476695 -0.05542384
  -0.03190509]
 [ 0.05155157  0.00385047  0.10501572 ... -0.0104507   0.11843505
   0.00234573]
 [ 0.02292069 -0.07094373 -0.12393004 ... -0.09521553 -0.11981225
   0.00872966]
 ...
 [-0.10142088 -0.0177818  -0.00296755 ... -0.06879662  0.02301279
  -0.02625723]
 [ 0.06704    -0.01109545  0.12244811 ... -0.09465188  0.08317706
   0.01667703]
 [ 0.11898816 -0.06089152 -0.02683422 ... -0.13479967  0.05298459
  -0.04382376]]
tensor_name:  TemporalFusionTransformer/time_distributed_8/bias
[-0.12389632  0.02640178  0.03998335 -0.03150731 -0.07012045 -0.00720666
  0.07969704 -0.01098383]
tensor_name:  TemporalFusionTransformer/time_distributed_8/kernel
[[ 0.001606   -0.00268855 -0.08714727 ...  0.0419604   0.07866347
   0.03968586]
 [ 0.02164739  0.05128681 -0.10377654 ...  0.05054836  0.10679835
  -0.00675899]
 [-0.02469425  0.02677285 -0.07211275 ... -0.10645267 -0.02103399
  -0.02169462]
 ...
 [-0.13558902  0.07841758  0.05756285 ... -0.0242836   0.14999145
  -0.01164355]
 [ 0.06454608  0.00286794 -0.11285847 ...  0.03862073 -0.19118859
  -0.03834172]
 [-0.00852862 -0.05476182 -0.00266813 ...  0.11488207  0.00964647
   0.0042712 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_80/bias
[ 6.47561578e-03  9.54538807e-02  3.18104438e-02 -4.03531827e-02
 -2.21109972e-03 -4.39378396e-02  3.42092942e-03 -1.61313340e-02
  1.67836193e-02 -4.31470051e-02 -2.78164670e-02 -2.81232856e-02
 -1.16870757e-02 -1.92438811e-02 -1.08533641e-02 -6.01184648e-03
  1.86346173e-02  2.19040625e-02 -3.83407697e-02  1.91051457e-02
  6.91823587e-02 -4.55626212e-02  9.00208019e-03  1.52254058e-02
  1.23530179e-02  1.66059453e-02  3.62929367e-02 -8.84260703e-03
  6.72375550e-03 -1.31484857e-02  1.04147485e-02 -4.49671820e-02
  4.53507248e-03 -3.81464325e-02  5.78681380e-03 -3.00322776e-03
  4.61298833e-03 -1.41919907e-02  1.42108276e-02  3.27483751e-02
 -6.63802624e-02  4.00061235e-02  2.00096611e-03  3.31290811e-02
  1.67458365e-03  1.71197671e-02 -1.15816584e-02 -2.19091610e-03
 -2.19333638e-02  4.49224003e-02 -1.57374702e-02 -3.50498930e-02
 -2.03179009e-02 -2.14415230e-02 -2.01696418e-02  1.12874687e-01
 -3.39987967e-03  5.47783496e-03 -1.03884852e-02  2.75238324e-03
 -8.63007084e-03 -2.09491048e-02 -1.37592410e-03  1.20250778e-02
  5.54380566e-03  2.36401279e-02 -1.28808683e-02  7.69267231e-03
  2.93364655e-02 -4.92702797e-02  7.10511506e-02  9.07192007e-03
 -2.04875208e-02  2.58943178e-02  3.14229168e-02  1.71891861e-02
  4.12618415e-03 -1.06667429e-02 -1.14096384e-02  2.62053497e-02
  3.36049385e-02 -3.06159835e-02 -2.26363353e-02  2.31837202e-02
 -1.45297758e-02 -8.18693079e-03 -1.86964665e-02  1.83098149e-02
 -6.80691004e-03  3.97476688e-05  1.44851655e-02 -8.71888734e-03
  5.19336108e-03  2.46967888e-03 -2.67789736e-02 -7.60462228e-03
  2.37853695e-02 -2.33153440e-02 -1.58295326e-03 -9.88607574e-03
 -1.21182005e-03 -9.26836580e-03 -3.22223804e-03  2.50172969e-02
  2.62197368e-02  3.84613760e-02  1.18058641e-02 -1.06010847e-02
 -1.83762126e-02  6.65697968e-03  2.88459696e-02  2.28759125e-02
  1.97664928e-02 -1.43704787e-02 -2.28234157e-02  3.75054963e-02
  2.82002687e-02 -2.54247785e-02  4.67976322e-03 -4.70195822e-02
  3.90398735e-03 -3.41376700e-02  3.27384025e-02  1.22085996e-02
  7.91022833e-03 -6.54810341e-04  2.41556787e-03  2.85775382e-02
 -2.45110947e-03 -1.34532526e-03  3.23632061e-02  1.99073497e-02
 -1.12041496e-02 -4.99109477e-02 -1.85451694e-02  2.05680039e-02
 -1.33488635e-02  3.01894848e-03 -4.90681222e-03  4.10798229e-02
 -4.41953875e-02 -1.67404711e-02  3.12788785e-02  3.65942065e-03
  4.97911766e-04 -4.99678496e-03 -2.96484865e-02  8.40746611e-03
  2.57315896e-02  6.00924110e-03 -4.51307697e-03 -8.07480514e-03
  4.63403389e-03 -1.43901557e-01 -3.68070416e-02  1.49109457e-02
 -4.71855653e-03  5.29481983e-03  4.10630554e-03 -3.70373875e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_80/kernel
[[-0.0767436   0.0572869  -0.10797391 ...  0.04651602 -0.01302457
   0.07450111]
 [-0.0723033  -0.10054128  0.08014766 ...  0.11049268 -0.04863446
   0.13354193]
 [ 0.14582114  0.39107585  0.07751848 ...  0.05453455  0.12615591
   0.02131336]
 ...
 [ 0.12368301  0.02725232 -0.03874241 ... -0.06619428  0.12157574
  -0.13308825]
 [ 0.1052681   0.08489107 -0.12680492 ...  0.00762021 -0.05613371
   0.10388466]
 [-0.01027396  0.16362229 -0.12206098 ... -0.01421155  0.11646429
  -0.12197444]]
tensor_name:  TemporalFusionTransformer/time_distributed_81/bias
[-0.04953087  0.13296944  0.06365433  0.01581762 -0.05873284  0.03764867
 -0.00893743 -0.03009984 -0.08505294  0.1106976  -0.08625924  0.00887194
 -0.04215916 -0.08419268 -0.03285233 -0.01434329 -0.05484532  0.0104341
 -0.04958097 -0.06952549  0.09022309  0.05297549 -0.07390232 -0.04551015
 -0.08767449 -0.00582169  0.02165059 -0.00167729  0.06158344  0.01487229
 -0.05620269  0.05250907  0.02483927  0.01680042 -0.08411978 -0.01900604
 -0.00763458 -0.0361136  -0.05631761 -0.05635365  0.05522952  0.01092019
 -0.02042705  0.02610966 -0.02337076 -0.05021947 -0.01203146 -0.02307712
 -0.04763532  0.12048646 -0.0038142   0.02059866  0.02395204 -0.04032664
 -0.016056    0.07298013 -0.0654062   0.00530179 -0.01868268 -0.05839135
 -0.05669043 -0.07842638 -0.02852304 -0.05857309 -0.06069686 -0.05792113
  0.00109297 -0.05291465 -0.00445282  0.10377897  0.07357951 -0.04421619
 -0.01848133 -0.01164586  0.05561095 -0.01400846 -0.017874   -0.03841272
 -0.01859507  0.01839983  0.00353233  0.00071845 -0.10945353 -0.05449967
 -0.00924448 -0.0709929  -0.01585566 -0.00512271 -0.02501747 -0.05415828
 -0.00868568 -0.02363115 -0.06779134  0.02556871  0.01554035 -0.03053458
 -0.06412955 -0.03406014 -0.0437736  -0.0148744   0.00820466  0.01627906
 -0.03808037 -0.00411281  0.02610891  0.05465584 -0.06391563 -0.08025961
  0.03499119 -0.03201299  0.01641963 -0.00852393  0.01561817 -0.05766196
  0.12400827  0.01364869  0.05875595 -0.07991234 -0.00595924  0.03948442
  0.04792006  0.05194217 -0.07791035 -0.05630549  0.05848243 -0.00789693
 -0.06567936  0.00703828 -0.03737204 -0.03656805 -0.04772105  0.0462128
 -0.02970207 -0.03975113 -0.0248408   0.03790726 -0.01974707 -0.00972467
 -0.0352014   0.06268258  0.03939294  0.00605291  0.01936396 -0.0583391
 -0.02590653 -0.03424639  0.04333821  0.00105699  0.06760008 -0.07151998
 -0.03675729  0.08750196 -0.04952775  0.09111069  0.01379149 -0.00034389
 -0.06366917 -0.02710258 -0.01457461  0.01856154]
tensor_name:  TemporalFusionTransformer/time_distributed_81/kernel
[[-0.10267272  0.05677229 -0.13734248 ...  0.0021055  -0.11358845
   0.01171325]
 [-0.06862629  0.05714916  0.16232768 ...  0.07048292 -0.01724378
  -0.00331849]
 [ 0.01741648  0.16746801 -0.08668985 ... -0.01188476 -0.02203082
   0.10697104]
 ...
 [-0.10244521  0.07033412 -0.02281084 ... -0.10528614 -0.03943811
   0.11912479]
 [-0.07681321  0.07102747 -0.06758905 ... -0.11999826 -0.13135454
  -0.08411955]
 [ 0.09934428  0.15455316 -0.09279109 ...  0.05880589  0.08144415
  -0.11682435]]
tensor_name:  TemporalFusionTransformer/time_distributed_82/bias
[-4.72396100e-03 -1.67098753e-02 -1.56433471e-02 -7.65599823e-03
  3.49161192e-03 -3.37974820e-03 -2.21032482e-02 -3.51994531e-03
 -4.16667387e-03 -1.44437253e-02  2.84070172e-03 -1.43152466e-02
 -9.15214128e-04 -1.15307141e-02 -1.98318642e-02 -1.01920767e-02
 -8.60597100e-03 -9.47570801e-03 -1.02071539e-02 -4.90905205e-03
  8.81121680e-03 -1.52669670e-02 -1.26690716e-02 -3.42986058e-03
 -7.29732215e-03  5.41834719e-03 -2.10657134e-03 -3.49487038e-03
  2.00181734e-03  1.22535881e-02 -6.28923718e-03  1.02042500e-03
 -2.31650975e-02  8.47417396e-03  2.00495101e-03  5.93071338e-03
 -3.60049133e-04 -7.67000439e-03 -7.50892935e-03 -1.37357153e-02
 -5.98590821e-03 -7.40853837e-03 -7.21847778e-03 -9.42619983e-03
 -5.17046964e-03 -6.89519756e-03 -2.19227243e-02 -1.56402737e-02
  1.09258015e-02 -1.94980123e-03 -1.34293614e-02  4.20310767e-03
 -7.97190820e-04  1.03241298e-02 -6.83414331e-03 -2.73949071e-03
 -5.03377349e-04 -4.61734366e-03  1.37051765e-03 -1.15571236e-02
 -9.19345580e-03 -1.77653413e-02 -6.46483526e-03 -1.53112579e-02
  7.20357988e-03  2.32512783e-03 -1.30860591e-02 -9.34961066e-03
 -8.17858521e-03 -7.26659829e-03 -9.36829112e-03 -1.15507527e-03
  1.00034662e-02 -1.03451964e-02 -1.91607643e-02 -4.11282340e-03
  4.01381683e-03 -5.06404787e-03 -6.62175519e-03 -1.20960446e-02
 -3.32722743e-03 -5.49271703e-03  3.99261992e-03  4.72857989e-03
 -8.49875808e-03 -9.55883879e-03 -4.13571950e-03  9.53169802e-05
 -4.88363020e-03  6.03182381e-03 -1.11125316e-02 -2.73196883e-02
 -6.53399527e-03 -1.40388692e-02  3.21873976e-03  1.16423629e-02
  9.58619360e-03  2.45722919e-03  1.54537498e-03 -7.76331825e-03
  7.29553076e-03  2.80931289e-03 -3.74076131e-04 -8.82873370e-04
 -1.20979697e-02  7.39455735e-03  9.70946334e-04 -7.21504446e-03
  1.55281974e-02 -1.95532423e-02 -1.33116664e-02  9.13826097e-03
 -7.05650728e-03 -1.12780128e-02  5.83391869e-04 -4.42975247e-03
 -6.73838193e-03 -1.10059162e-04 -1.20616909e-02 -1.49586331e-02
 -8.38142168e-03  4.70767869e-03 -1.69564430e-02  8.90879333e-03
 -4.41053789e-03 -1.18294442e-02  4.82107559e-03 -1.26212090e-03
 -1.93610694e-03 -1.28402300e-02 -1.49626601e-02  6.93493476e-03
  2.13878881e-03  1.49448477e-02 -1.56441517e-02  6.14957418e-03
 -1.05509290e-03 -1.39923301e-02 -4.03157482e-03  5.17151644e-03
 -1.20029068e-02  4.88552498e-03 -1.76337790e-02 -1.22393724e-02
 -4.05190932e-03 -9.03694518e-03 -6.34661550e-03  1.79597351e-03
 -5.43680321e-03 -7.03162421e-03  5.94030088e-03  5.22273220e-03
 -1.91295035e-02  3.43510328e-04 -2.76153395e-03 -1.39098139e-02
 -6.53741090e-03 -6.14559837e-03  4.27434035e-03 -9.58916917e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_82/kernel
[[ 0.15119061 -0.00897414  0.09565484 ... -0.08280068  0.11152563
  -0.03179795]
 [-0.088043    0.03103077  0.02887502 ...  0.04018123 -0.09967508
  -0.10457633]
 [ 0.10594834  0.12933558 -0.11799856 ...  0.04667493 -0.04844757
   0.00779147]
 ...
 [-0.1550922   0.04216274  0.08293539 ... -0.11682776  0.08386099
  -0.0900319 ]
 [-0.04596374  0.09996535  0.05243661 ...  0.1531889  -0.05815145
  -0.07130518]
 [-0.02934577  0.08173876 -0.08019421 ... -0.10942626  0.14507154
   0.01984355]]
tensor_name:  TemporalFusionTransformer/time_distributed_83/kernel
[[-0.10058983 -0.00445958  0.05256511 ... -0.03350575  0.08379047
  -0.06575998]
 [-0.11302388 -0.14191039 -0.12161133 ... -0.09245285 -0.01223946
   0.00939707]
 [-0.00117222  0.03324782 -0.08258008 ...  0.10061     0.11290303
  -0.10495048]
 ...
 [-0.02199882 -0.0616811  -0.1419791  ...  0.09564658  0.02726215
  -0.11796956]
 [ 0.06945679 -0.1084563  -0.02721742 ...  0.01495322  0.09691973
   0.01471227]
 [-0.06771078 -0.05229672  0.02310392 ... -0.00179691  0.11466285
   0.04521281]]
tensor_name:  TemporalFusionTransformer/time_distributed_84/bias
[-4.76756552e-03  3.62199359e-02  2.54256418e-04 -8.51823948e-03
 -9.22292098e-03 -1.25999460e-02  5.14198793e-03 -2.85189436e-03
  1.40232975e-02  1.15643190e-02  1.03318803e-02 -3.39617790e-03
  6.37493376e-03  5.49731124e-03  1.85624545e-03 -4.05199407e-03
 -1.24695720e-02 -5.94982877e-03 -9.28147137e-03 -2.22057551e-02
 -1.23208379e-02 -5.21232840e-03  7.00996350e-03 -4.43867268e-03
  2.13219728e-02 -4.24413942e-03  3.96681624e-03  3.53048160e-03
  1.23577239e-02 -9.89885908e-03  1.42191108e-02 -7.98698142e-03
 -1.02070514e-02 -4.03171871e-03 -1.51705295e-02 -1.06739029e-02
  8.56518466e-03 -2.40903199e-02 -6.65279757e-03 -1.52766472e-02
  7.29292457e-04  5.86536480e-03 -1.39347115e-03  2.34904792e-02
  2.17884546e-03  3.67655838e-03 -7.10635632e-03 -2.27821209e-02
  6.66921446e-03  1.77951029e-03  3.05358716e-03  9.51852463e-03
 -7.36074895e-03  5.97434537e-03 -7.03661796e-03  2.70335265e-02
 -1.30545124e-02  2.88892747e-03 -4.01367014e-03  4.29959828e-03
 -1.21048442e-03 -2.88491752e-02  1.07830474e-02 -5.27229346e-03
  8.64930358e-03 -1.60781462e-02  1.56496223e-02 -1.28838792e-02
 -2.12241197e-03 -2.36118445e-03  2.45609060e-02  4.29116469e-03
 -1.03135966e-02 -6.00182032e-03 -1.85020212e-02 -1.46112628e-02
  7.88997021e-03  1.72760955e-03 -1.29691912e-02 -4.44471464e-03
  1.61465094e-03  6.23345422e-03  1.43851601e-02  2.73574307e-03
 -6.77603483e-03  7.21433526e-03  7.25114532e-03  1.75514584e-03
 -9.42620263e-03 -1.77283678e-02 -1.39129469e-02  1.58674791e-02
 -8.94138776e-03 -1.22020477e-02  7.17298314e-03  6.70637051e-03
 -5.26759168e-03  1.05463648e-02  1.50611252e-02 -2.92866747e-03
 -1.11999577e-02  1.48419031e-05 -1.37812151e-02  1.59522668e-02
 -1.50862150e-02 -1.91445015e-02  2.33824831e-02  9.09252744e-03
  5.61252981e-03 -9.51652974e-03 -3.61360726e-03 -2.28939559e-02
  1.30389137e-02 -2.65568262e-03 -8.21232237e-03 -2.07602046e-03
  4.53636469e-03  3.92472418e-03  2.25731448e-04  2.17380840e-03
  7.37751182e-03  1.71072618e-03 -3.42089729e-03  1.30914375e-02
  1.62191652e-02 -2.27644090e-02  8.75997450e-03 -1.34186419e-02
 -1.44129805e-03 -2.36334070e-03 -1.26042571e-02  8.57267063e-03
 -1.57539230e-02 -7.15825707e-03  4.96824039e-03 -8.70278850e-03
 -1.27550503e-02 -3.08865607e-02 -1.07278451e-02  1.43539708e-03
 -1.77480485e-02 -9.96376295e-03  7.26221409e-03 -4.28873394e-03
 -2.41330755e-03  1.85249243e-02  1.33181391e-02 -3.01168882e-03
  3.44375614e-03  3.80372046e-03 -1.46779083e-02  1.45204991e-04
  1.50523223e-02  7.97286071e-03 -6.60796463e-03 -7.70100765e-03
 -6.18895050e-03  5.56130009e-03  8.46787728e-03 -1.04962336e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_84/kernel
[[-0.08333742 -0.08152317  0.01970409 ...  0.11104469 -0.0004569
   0.0224591 ]
 [-0.13339143  0.07726716 -0.04603464 ...  0.11278908 -0.0258027
   0.09259421]
 [-0.06834281 -0.00161     0.03905152 ...  0.11356308 -0.09573753
  -0.0056082 ]
 ...
 [-0.12970147 -0.04619406 -0.00566678 ... -0.14428686 -0.06418142
  -0.00343114]
 [ 0.12624882 -0.09881632  0.04852854 ...  0.09425097  0.06326958
   0.00218486]
 [ 0.07146011 -0.08699165 -0.03474906 ...  0.05028649  0.11861332
  -0.03927282]]
tensor_name:  TemporalFusionTransformer/time_distributed_85/bias
[ 1.27901994e-02  1.01508740e-02 -8.82209372e-03 -2.86868983e-03
  9.58926231e-03  8.60425457e-03  4.86238813e-03 -6.52888324e-03
  1.42060744e-03  1.60935838e-02 -1.30454393e-03  1.62295089e-03
 -8.09933990e-04  4.69738065e-04  1.03384079e-02  1.19051179e-02
 -1.69781391e-02 -4.13957145e-03  1.59642205e-03 -5.84998121e-03
  1.09688770e-02  2.52664392e-03 -2.66922289e-03 -1.95228145e-03
 -1.55835375e-02  6.42263889e-03 -6.25751493e-03  7.38808012e-04
 -1.78569499e-02 -8.10609758e-03  3.24097835e-03 -1.90131087e-02
 -9.60685499e-03 -5.33736369e-04  1.26356259e-02  1.20129006e-03
  4.49138228e-03 -4.16379422e-03  1.02598695e-02 -3.72345501e-04
  7.95442052e-03  4.06276342e-03  4.04618168e-03 -9.87394154e-03
  1.66783202e-03 -1.20327494e-03  6.47483859e-03  3.53744510e-03
  7.32443947e-03 -5.01878886e-03 -7.90604483e-03  9.01897624e-03
  5.69264917e-03 -7.55058136e-03 -1.79647596e-03 -1.21842045e-02
 -9.77526791e-03 -2.17773998e-03 -6.91501098e-03  1.85799238e-03
 -1.83557812e-02  1.64208133e-02  9.75415314e-05  1.09636951e-02
 -1.13740955e-02 -2.41567511e-02 -5.32835163e-03  4.45849355e-03
 -1.20949317e-02 -9.57198814e-03 -1.05422949e-02 -1.06381634e-02
  4.75465553e-03 -1.27220759e-02 -6.65138243e-03  2.66494928e-03
 -8.29244684e-03 -3.24074063e-03  8.45088530e-03  6.85635349e-03
  3.81237781e-03  1.60717927e-02 -1.11489533e-03 -4.97364532e-03
 -2.58299778e-03 -4.19594208e-03  8.25707708e-03  5.01000509e-03
 -6.47683861e-03 -9.99864563e-03  9.49110743e-03  1.54343350e-02
 -7.36549962e-04 -6.06534630e-03 -6.37710188e-03  2.51516583e-04
 -9.65718995e-04  3.38268955e-03  1.60584424e-03 -3.52431531e-03
  1.49467979e-02  2.70570861e-03  1.64085533e-02  8.81646480e-03
 -7.77057000e-03  3.29216500e-03 -4.76489682e-03 -1.88369639e-02
  1.08461818e-02 -7.53542525e-04  2.51965411e-03 -4.42727515e-03
 -2.89238011e-03  8.21014494e-03  4.14203666e-03  9.07898042e-03
 -8.21344182e-03 -3.40873562e-03 -7.55690364e-03 -5.73575683e-03
  4.60490817e-03 -2.07841899e-02  6.91036833e-03  7.75028486e-03
  1.98783400e-03 -2.72159697e-04  2.59650289e-03  7.18930596e-03
  8.89080297e-03  3.92710743e-03  2.06393818e-03  2.31832452e-03
  3.36299813e-03  4.07933956e-03  8.30099639e-03  4.60501341e-03
 -8.99590272e-03  8.57444174e-05  3.12070269e-03 -6.92032184e-03
 -1.21592414e-02  2.59033521e-03  9.45149269e-03 -7.31539028e-03
  1.30692543e-02  6.13222225e-03 -2.65715504e-03  7.10019283e-03
  7.65377143e-03  1.62546430e-02  8.55807960e-03 -2.97645270e-03
  3.50477610e-04 -2.02184333e-03  1.31352327e-03  1.09427348e-02
 -1.17053315e-02  1.08823413e-02  9.61953960e-03 -5.19939745e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_85/kernel
[[ 0.00378011 -0.04367412 -0.02175777 ... -0.00885294  0.0812551
   0.10719074]
 [-0.04114567  0.10321393 -0.07241538 ... -0.07069814 -0.07495335
  -0.11065964]
 [ 0.1806331   0.06676477 -0.12628116 ... -0.03789936 -0.07755765
   0.13249399]
 ...
 [ 0.07174113  0.16784078 -0.12904592 ...  0.02684953  0.00451763
  -0.01138713]
 [-0.04244823  0.13041571 -0.09194531 ... -0.06427304  0.08402301
   0.14277951]
 [ 0.00107451 -0.04844178 -0.03670987 ...  0.0200162   0.05859223
  -0.06641302]]
tensor_name:  TemporalFusionTransformer/time_distributed_86/bias
[-0.02767398 -0.03914915 -0.02468015 -0.02291127 -0.01077469  0.00799636
 -0.01648318 -0.01695828 -0.02845223 -0.02267327 -0.02894998 -0.00560837
 -0.01713081 -0.00812957 -0.0033148  -0.02606313 -0.00042614 -0.03952398
 -0.01811684 -0.0149236   0.00140125 -0.01548551 -0.01514573 -0.02185289
 -0.01639228 -0.01351659 -0.02706742 -0.01056522 -0.01199609 -0.01685072
 -0.01081581 -0.01861071 -0.00843859  0.00262288  0.00534469 -0.01032017
  0.01068625 -0.02584347 -0.01145146 -0.02291142 -0.01294268 -0.01055707
 -0.03020224 -0.01340862 -0.00784265 -0.02071996 -0.00973427 -0.01567413
 -0.00989355 -0.0140132  -0.01633146 -0.03203502 -0.02594776 -0.00339406
 -0.02211525 -0.02882694  0.00080093 -0.0183424  -0.00208263 -0.02127196
 -0.02169478 -0.02391214 -0.02750892 -0.02305789 -0.01459553  0.00225745
 -0.01669001 -0.01574747 -0.02248413 -0.00633086 -0.01490652 -0.02279091
 -0.00794597 -0.00642941 -0.04404274 -0.01919558 -0.0074259   0.00347626
 -0.00852352 -0.01026959 -0.02315543 -0.01887252 -0.00913762 -0.00272279
 -0.02292293 -0.01009786 -0.02949447 -0.0111578  -0.01728406 -0.01678864
 -0.02764889 -0.01227479 -0.00936888 -0.00428557 -0.01611754 -0.01114234
  0.00379555 -0.02936975 -0.00621517 -0.00725324 -0.00400075 -0.01787979
  0.0122635  -0.01448917 -0.00737246  0.00327337 -0.01133319 -0.02203009
 -0.00519598 -0.03248848 -0.01423855 -0.00445849 -0.02811411 -0.00605017
 -0.03265548 -0.02239597 -0.02369511 -0.01653981 -0.02367355 -0.01670777
 -0.01050811 -0.01406232 -0.00354387 -0.03352351 -0.03500866 -0.01374868
  0.00190117 -0.00163771 -0.01504824 -0.02156153 -0.01101096 -0.00904096
 -0.01915923 -0.016393    0.00846755 -0.00867321  0.00563171 -0.0250297
 -0.0146867  -0.01584107 -0.01053086 -0.02536112 -0.00747589 -0.01657671
 -0.0070564  -0.02231838 -0.02756624 -0.02894059 -0.05004954 -0.01676417
 -0.01925743 -0.00466571 -0.01502264 -0.01454938 -0.0086384  -0.01573489
 -0.01430529 -0.0099753  -0.01498231 -0.02286864]
tensor_name:  TemporalFusionTransformer/time_distributed_86/kernel
[[ 0.04320746 -0.1097544  -0.04760092 ... -0.06262451 -0.07621715
  -0.11072039]
 [-0.13459271 -0.04260393  0.07252206 ...  0.00600414 -0.12089381
   0.07731656]
 [-0.00181327 -0.04017268  0.14997186 ... -0.06611264 -0.00949202
  -0.0091729 ]
 ...
 [ 0.11455128 -0.1434034  -0.07158592 ...  0.03142547  0.11854842
  -0.00551436]
 [-0.0885802  -0.0781946  -0.04940783 ... -0.09202861  0.03831658
  -0.07132266]
 [-0.09537243  0.08223257  0.01357812 ...  0.03275059  0.12193561
   0.16030347]]
tensor_name:  TemporalFusionTransformer/time_distributed_87/bias
[ 2.43200473e-02  1.12819197e-02 -5.51764434e-03 -7.05498457e-03
 -2.01298129e-02  1.94448512e-02  2.39936244e-02 -1.35043552e-02
 -3.01401392e-02 -2.64503807e-03 -2.50481535e-04  1.76471360e-02
 -2.05209642e-03  2.01577274e-03  7.85197131e-03  1.83012467e-02
 -3.05345375e-02  8.45401734e-03  5.54843619e-03 -8.61921720e-03
  3.53153534e-02  4.15683398e-03 -4.26464248e-03 -5.87542541e-04
 -1.45193413e-02  7.93156959e-03 -1.17758093e-02 -8.61707702e-03
 -1.62191652e-02 -8.85832682e-03 -1.74427796e-02 -3.12777646e-02
  9.31632519e-03 -1.45055521e-02  2.25846004e-02  8.34764505e-05
 -1.97853707e-03  2.03667651e-03  6.63914438e-03  1.11857764e-02
  2.10499242e-02  7.57593708e-03 -3.16246762e-03 -3.35969683e-03
 -3.55117675e-03  4.66076983e-03  1.28298411e-02  1.09312951e-03
  6.95441244e-03 -2.17840951e-02 -1.27760107e-02  9.56943259e-03
 -2.65062763e-03 -1.72553603e-02 -1.40306205e-02 -1.38505530e-02
 -4.81135026e-02 -6.79395348e-03 -1.25900190e-02 -4.61068656e-03
 -4.78179054e-03 -2.29748478e-03 -1.32877938e-02  2.36692838e-02
 -2.08145436e-02 -1.84429176e-02  2.19494719e-02 -6.08807709e-03
 -3.11108329e-03 -9.53881815e-03 -3.15123657e-03 -2.14791112e-02
 -8.10823590e-03 -8.02387390e-03  1.35088731e-02 -1.91789062e-03
 -1.49937021e-02 -6.74551725e-03  1.68603882e-02  1.07056433e-02
  3.04435892e-03  1.47479139e-02 -1.05659274e-04 -2.70462595e-02
 -2.83399294e-03 -1.81482709e-03 -5.95225533e-03  1.63122285e-02
 -9.95534379e-03 -3.20488662e-02  1.03649171e-03  2.44454183e-02
 -1.06005080e-03 -1.10806255e-02 -5.07542689e-04 -1.27584301e-02
 -1.48614701e-02  1.90414267e-03  8.35434347e-03 -1.45093156e-02
  2.13769432e-02 -7.38821877e-03  3.55887637e-02  1.91408116e-02
 -3.13096717e-02  1.88896749e-02  4.26989840e-03 -6.79999404e-03
  1.31939584e-02 -1.38591053e-02  6.85278140e-03  1.51783100e-03
  5.91586158e-03  2.03419179e-02 -8.83106887e-03  2.21681539e-02
 -8.46932642e-04  9.31289699e-03 -7.47900689e-04 -1.03792232e-02
  6.05731923e-03 -7.11480062e-03 -1.85592929e-04  1.25191575e-02
  9.71740205e-03  3.75133031e-03  1.70137355e-06 -2.42307689e-03
  1.27446121e-02 -2.13023406e-02  1.31634239e-03  1.04707135e-02
  4.24082428e-02  5.30787418e-03  2.78445613e-02 -7.31051294e-03
  5.09450096e-04 -1.20052823e-03 -1.23087782e-03 -1.46252438e-02
 -1.46746319e-02  1.05382493e-02  4.86955158e-02 -1.75718535e-02
  1.23003274e-02  2.24956069e-02  8.85450863e-05  2.47502252e-02
 -3.78450542e-03  3.13791744e-02  9.65959951e-03 -9.41620165e-05
 -2.11684871e-03 -7.27306213e-03  5.80223650e-03  1.07925222e-03
 -3.20000686e-02 -4.97681089e-03  5.99814393e-03 -9.61334351e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_87/kernel
[[-0.09093376 -0.11061467 -0.1058616  ...  0.13341297 -0.08826071
  -0.03556077]
 [-0.04615341  0.05724315  0.09475907 ...  0.00968121 -0.03070087
   0.08442876]
 [ 0.13688312  0.11608844 -0.03686865 ... -0.14487314  0.08842871
  -0.17774776]
 ...
 [ 0.06813689 -0.02422405  0.11947969 ...  0.06739255  0.06243184
   0.06262021]
 [-0.02646348 -0.07484516 -0.06388003 ... -0.06352246 -0.0344519
  -0.08734532]
 [ 0.12771764  0.0711899   0.12471317 ...  0.1011861   0.12693256
   0.0732386 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_88/bias
[-0.00259785 -0.01793931 -0.01200732 -0.01047941 -0.00238822 -0.01206928
  0.01083557 -0.00854686  0.0154109  -0.00338681 -0.00625829  0.00601745
  0.00630491 -0.00467681 -0.00402427  0.00423677  0.00908568  0.00643578
 -0.01137112 -0.01650375  0.01934662 -0.00574496 -0.01788726 -0.00719804
 -0.00933682 -0.0185503  -0.00856654 -0.00247192 -0.01354702 -0.01607488
 -0.00530865  0.00126532  0.00100215  0.00025693  0.00562458 -0.00995698
 -0.01796987  0.00271352 -0.00377256 -0.01090752  0.00761518  0.0198548
 -0.00646877 -0.02638293 -0.01284048 -0.00846943  0.011933    0.00370016
 -0.00125307 -0.00424018 -0.00536963 -0.02377475 -0.01143028 -0.00797403
 -0.00823712 -0.01674023  0.02720495 -0.02290643 -0.0215303  -0.00641237
 -0.00170743 -0.02187643  0.0045172   0.00845443 -0.01006143  0.00455726
  0.00030603  0.00633157 -0.00125942 -0.02639441 -0.00224386  0.01260078
 -0.01043379 -0.01336589  0.01327233 -0.0104825  -0.00113546 -0.02015315
  0.00424727 -0.01303213 -0.01047993 -0.01818699 -0.01165973  0.00054666
  0.0088316  -0.02120983 -0.00621633  0.00409979 -0.00086327  0.00414228
 -0.01360517  0.01526741  0.00697584 -0.03070107 -0.01043181 -0.01750206
  0.0016595  -0.02225429 -0.0127791   0.00288724  0.00041072 -0.02451223
  0.02288312 -0.01775781  0.02048179 -0.00415156 -0.01601306 -0.00329383
 -0.0211978   0.0070268  -0.00538078 -0.02308892 -0.00943961 -0.01671533
 -0.00248852  0.02052482 -0.00865213 -0.00803088 -0.01197386 -0.00420954
 -0.0095654   0.00508805 -0.00588016  0.002182   -0.00827782 -0.00647358
 -0.00778122 -0.00217663  0.00437593  0.01096258 -0.02480037 -0.0045664
  0.02144909 -0.01952051  0.00364648 -0.0006251  -0.01243096  0.00566327
 -0.00060381 -0.00849504 -0.00262437 -0.00941916  0.01046773 -0.00651563
  0.00105487  0.02529968 -0.00417592 -0.00553416 -0.02640481 -0.00479537
 -0.02106715 -0.02486571 -0.00492521 -0.00331349 -0.00756132 -0.00247215
 -0.0008602  -0.00087828  0.00152402  0.00307754]
tensor_name:  TemporalFusionTransformer/time_distributed_88/kernel
[[ 0.07417849  0.05735806 -0.07628486 ... -0.03375584  0.05804616
  -0.06529842]
 [ 0.11048929 -0.0755975   0.06621224 ...  0.16810356 -0.02303782
  -0.10755426]
 [ 0.00694057 -0.08828492 -0.05431038 ...  0.04700573 -0.09927735
  -0.10535772]
 ...
 [-0.14002259 -0.19555557 -0.04944807 ... -0.00699152  0.04453983
  -0.09285736]
 [ 0.12885037  0.0317743   0.02245414 ... -0.02878342 -0.06116813
  -0.05976747]
 [-0.03115598 -0.07950954  0.09636956 ... -0.14197198 -0.09099435
  -0.15241212]]
tensor_name:  TemporalFusionTransformer/time_distributed_89/bias
[ 3.72030982e-03 -1.64909512e-02 -8.32304079e-03 -1.77154616e-02
 -7.35141803e-03  1.25849107e-02 -6.52497681e-03 -7.58155715e-03
 -1.75534375e-02 -3.02623049e-03 -5.59167424e-03  7.72296265e-03
  3.84175708e-03 -1.00214398e-02  5.93642984e-03 -1.34985829e-02
 -5.63889276e-03  9.02642496e-03  1.46700246e-02 -1.19201560e-02
 -4.40270873e-03  1.59005995e-03 -5.64179523e-03  1.12213437e-02
  1.41076054e-02  9.04586352e-03  2.33256202e-02  1.40815200e-02
 -1.42767327e-04 -1.32507700e-02  7.52490014e-03 -2.48653498e-02
 -9.02093574e-03 -1.31773856e-02 -1.08739594e-02 -2.38148100e-03
  7.68066850e-03  3.30740679e-03 -7.27359299e-03 -1.51950191e-03
 -8.54530558e-03 -1.97313055e-02  1.79496072e-02  1.21931508e-02
  1.57608278e-03 -8.89211148e-03 -1.08113270e-02 -8.32570158e-03
  1.59968324e-02 -8.00008606e-03 -8.42472538e-03 -1.74909215e-02
  8.77999514e-03 -1.19898785e-02  5.77568263e-03  2.70772376e-04
  1.73475333e-02  1.03943171e-02 -2.49691103e-02  1.49600320e-02
  9.14701959e-05 -6.78648893e-03 -9.01683699e-03 -6.14631688e-03
  3.05100973e-03 -8.91122408e-03  3.18738166e-03  3.18443315e-04
 -1.49258552e-02  2.19302159e-02  2.91477190e-03 -2.25690585e-02
  8.11541360e-03 -9.83139779e-03 -2.93277446e-02 -6.53192541e-03
 -1.21917780e-02 -4.85150237e-03  1.00281760e-02 -1.11593921e-02
 -1.23359691e-02  1.18104927e-02 -1.87632740e-02 -6.02165423e-03
 -1.37178469e-02 -2.03451589e-02  2.82438332e-03  1.59388296e-02
 -3.91172944e-03 -1.08638569e-03  1.15172556e-02 -2.88758683e-03
  1.00723875e-03 -1.02643492e-02 -2.06795391e-02  2.11625192e-02
 -1.39470380e-02 -7.15650758e-03 -2.25556851e-03 -1.67354681e-02
 -1.65162496e-02 -9.36055183e-03 -1.00551546e-03 -6.08278962e-04
  5.60011202e-03  1.29076494e-02 -1.30089736e-02  1.89352920e-03
 -5.39937709e-03 -1.51245724e-02  2.07885411e-02 -3.14548891e-03
  6.34087902e-03  4.86901216e-03  1.77365448e-02 -3.36275809e-03
  7.32913800e-03  9.45532508e-03 -4.39734384e-03 -1.37099782e-02
  1.37422886e-02 -1.39360595e-02 -2.24104822e-02 -1.35054840e-02
 -1.79705564e-02 -2.94825062e-03 -9.87081323e-04 -1.30155997e-04
 -7.04265013e-03 -2.75932509e-03 -3.03000305e-02 -1.32276518e-02
 -9.97322612e-04  2.30775978e-02 -7.19216699e-03 -4.65619331e-03
  2.19636261e-02 -2.33887276e-03 -1.00253848e-02 -7.62464432e-03
  1.77490544e-02 -5.12195518e-03 -1.27599789e-02 -3.99167463e-03
  9.81581304e-03 -2.31106952e-03  3.48077132e-03 -2.15259520e-03
  2.81796753e-02  1.98122580e-02 -1.07780630e-02 -2.31788736e-02
  1.28227035e-02  7.64765730e-03  1.16253654e-02 -2.41527539e-02
 -1.62618048e-03  1.65879708e-02  1.62505414e-02 -1.03783356e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_89/kernel
[[ 0.06565404 -0.02435482  0.10227216 ...  0.05981486  0.13023366
  -0.11445328]
 [-0.1300171  -0.02453293 -0.10369508 ... -0.1057778   0.00600049
   0.12474529]
 [ 0.07276442  0.15148431  0.01435622 ...  0.05220643  0.13674405
   0.13104333]
 ...
 [ 0.06132508  0.05932491 -0.04879654 ...  0.04154893 -0.08701266
  -0.0771982 ]
 [ 0.01060575  0.04532669  0.08059328 ...  0.06536701 -0.01193855
   0.00450445]
 [-0.12848328  0.03027563 -0.10600447 ...  0.02068735  0.01611281
   0.08130974]]
tensor_name:  TemporalFusionTransformer/time_distributed_9/bias
[-0.00957767 -0.03940068  0.00403872  0.02912696 -0.05259736 -0.08208186
 -0.07602628 -0.06194508 -0.04259952 -0.00887012  0.06794001 -0.02148375
 -0.01001004  0.09310106  0.08812302  0.06326252  0.00532125 -0.02086745
 -0.07260456  0.05495534  0.03763473 -0.06736104  0.06079192  0.02080399
  0.0102633  -0.01338872 -0.006384   -0.01949006 -0.05972084  0.07036557
  0.00469539 -0.04697048 -0.03355863  0.01390026  0.02131627  0.0187608
  0.0161173  -0.05120338 -0.0023539   0.06121632 -0.02262376 -0.02187171
 -0.01852735 -0.01248473 -0.05367457  0.02736521 -0.10053312 -0.04572842
 -0.00339183 -0.01717307 -0.00913967 -0.04312079  0.05763074 -0.00605921
 -0.09220642 -0.05008752 -0.03225503 -0.00892535 -0.03389074 -0.01446838
 -0.01531544 -0.01791618 -0.01496516 -0.01881151 -0.05514057 -0.0719417
 -0.02367713 -0.07757644  0.01145237 -0.06356038  0.03758902  0.04372702
  0.04807921  0.00339109 -0.05669653  0.00728976  0.05763714  0.04326573
  0.06570012 -0.00685412 -0.06807082 -0.01161117  0.03443239  0.03318093
  0.05224687  0.06227874  0.05975702  0.02941125 -0.02519245  0.01596575
 -0.04867494  0.01742029 -0.03434649 -0.03027774 -0.04582883 -0.03678904
 -0.02081388  0.07814876 -0.08674581 -0.03390198 -0.07646224 -0.08885548
 -0.03029408 -0.04441605 -0.08676006  0.05014903 -0.02395323 -0.05009964
  0.01402258 -0.00516504 -0.02500576  0.05922313  0.03529977  0.00435401
 -0.0318201   0.00408982 -0.06680907 -0.00584678 -0.00355318  0.04046123
 -0.03107826 -0.03249395  0.04552922  0.05052629 -0.04494825 -0.07979178
 -0.01303323 -0.02073146  0.04169678  0.08306535  0.01953769 -0.0474054
 -0.00619612  0.03262926  0.02550921 -0.0847839  -0.08284317  0.10052051
  0.04959915 -0.01463261  0.00719121 -0.03560241 -0.00946426  0.00840935
  0.0326951  -0.02617124 -0.01360754  0.01141092 -0.02292393  0.00055999
  0.01309843  0.03988853 -0.0708954   0.03193604  0.07766993 -0.02179474
 -0.0293026  -0.01470712  0.04389708 -0.07554737]
tensor_name:  TemporalFusionTransformer/time_distributed_9/kernel
[[ 0.01818761 -0.04052912  0.07201458 ... -0.03709686 -0.03826757
  -0.02119413]
 [-0.00552321  0.06169503 -0.08430389 ...  0.00479323 -0.05666642
   0.00541095]
 [-0.01113085 -0.00536195  0.15248914 ...  0.02819631  0.05585318
  -0.03443508]
 ...
 [ 0.00086103 -0.08587239  0.05377771 ... -0.07039357  0.01605152
  -0.00144559]
 [ 0.04491434  0.00031712  0.05919201 ... -0.08817226 -0.05048179
  -0.02615381]
 [ 0.07757884  0.06929667  0.01101773 ... -0.00977835 -0.05874977
   0.02188557]]
tensor_name:  TemporalFusionTransformer/time_distributed_90/bias
[ 1.46220988e-02 -2.86488025e-03  2.86808150e-04 -1.42312394e-02
 -2.06507482e-02 -2.24358141e-02  1.39089711e-02  2.75725150e-03
 -2.83318236e-02 -2.89559364e-02 -2.68147644e-02  2.54763803e-03
 -2.08533332e-02 -2.19732188e-02 -2.85012554e-02  3.00801303e-02
 -2.17024400e-03 -2.11303700e-02  4.91415858e-02  1.90948043e-02
 -1.69560115e-03 -4.78624715e-04  7.55836081e-04  2.75728002e-04
 -9.06719267e-03 -1.05038434e-02 -2.05169730e-02  1.83899142e-02
  1.12800431e-02 -1.97816789e-02  1.22071570e-03 -2.84169763e-02
  7.07632955e-03 -2.82059493e-03  7.18996301e-03  4.59702173e-03
 -7.44143547e-03  1.08797208e-03  2.78155468e-02 -2.26819958e-03
 -1.30341379e-02  1.03338715e-02 -1.94749050e-02 -3.41786863e-03
  1.10338619e-02  3.47111467e-03 -1.11125205e-02  1.14697395e-02
 -1.89287364e-02 -2.92205177e-02 -1.38577120e-02  3.30628864e-02
 -4.91952582e-04  1.39625929e-02  1.75356306e-03  8.58581252e-03
 -1.88380666e-02  2.69162524e-02 -2.34153364e-02  1.04827704e-02
  6.69304840e-03  6.23896345e-03  1.39232967e-02  1.54770119e-02
 -4.20438917e-03 -1.04393112e-02 -1.58758145e-02  9.98175703e-04
 -9.47446562e-03 -1.67588200e-02  1.07107647e-02 -1.30198644e-02
  2.47281343e-02  2.23657750e-02 -2.02157665e-02  1.35420496e-02
 -1.35128507e-02  1.04834624e-02 -2.82498100e-03  1.41861243e-02
  9.66804661e-03  1.09080244e-02 -4.48720455e-02  1.49537728e-03
 -1.14790993e-02  1.02484003e-02  1.55711155e-02  1.80883557e-02
 -9.40742437e-03 -3.99547108e-02 -6.50430471e-03  1.05789835e-02
 -1.70709100e-02 -5.73763298e-03  1.59494281e-02 -6.59500621e-03
  3.04329917e-02 -6.61969185e-03 -2.49649584e-02 -3.90720461e-03
 -9.93170869e-03 -1.96568179e-03 -7.18410173e-03  1.61032788e-02
 -9.75879934e-03 -1.82997845e-02 -4.71359445e-03 -4.37367894e-03
 -3.31792831e-02 -4.97987680e-03 -1.14121055e-02 -7.83261564e-03
 -1.69968884e-02  1.63117833e-02  9.17899539e-04 -1.42775690e-02
  7.19344462e-05  7.30015663e-03  9.71113704e-03 -2.45357957e-02
  1.78255886e-02 -2.57059908e-03 -1.00529362e-02 -1.41541951e-03
 -7.59761268e-03 -1.46923568e-02  3.14296633e-02 -1.86213106e-02
 -1.80674028e-02  5.03051002e-03  1.35831060e-02 -3.93415423e-04
  1.22232046e-02  1.60139874e-02  1.32902758e-03 -2.16970071e-02
 -1.78331658e-02  1.46416863e-02 -1.64617077e-02  3.34875137e-02
  6.55652210e-03  3.92956706e-03 -4.22490202e-03  5.44982124e-03
 -3.47826071e-02 -3.20891626e-02  2.27241851e-02  7.61628198e-03
  2.73647858e-03  2.93334830e-03  1.13029676e-02  1.63387170e-03
 -1.18808902e-03 -2.34124553e-03 -4.57483158e-03 -1.09142922e-02
  1.07535319e-02 -9.71315429e-03 -2.27391720e-03 -2.31763870e-02]
tensor_name:  TemporalFusionTransformer/time_distributed_90/kernel
[[ 0.10537316  0.06994365 -0.00892388 ... -0.02785322 -0.1019315
   0.0647284 ]
 [ 0.01833999 -0.17418072 -0.01702122 ...  0.0535801  -0.14349923
  -0.08127505]
 [ 0.10922416 -0.04238999 -0.05708829 ... -0.14310087 -0.12079958
   0.01864284]
 ...
 [ 0.01988333 -0.09977068 -0.11740625 ... -0.00220198  0.12161437
   0.00067868]
 [ 0.05391231 -0.11941695 -0.09419965 ... -0.15260726 -0.11996233
  -0.12548399]
 [-0.03438925  0.07971957  0.14940834 ... -0.06664018  0.11083585
   0.1027483 ]]
tensor_name:  TemporalFusionTransformer/time_distributed_91/bias
[ 0.0562225   0.0099426   0.00631185 -0.00821469 -0.02603339  0.00569587
  0.01806056 -0.00879249 -0.01493564  0.00390177 -0.02291827  0.00698651
 -0.0049986   0.00994261  0.00041685  0.01673622 -0.02166858 -0.00068038
  0.01587782  0.00542582  0.02311684  0.01526524 -0.01718279 -0.00321338
 -0.03093923  0.00122511 -0.00974935 -0.00804887 -0.0106231  -0.01140425
 -0.01479405 -0.02705172  0.01210088 -0.0192435   0.00882098 -0.00128308
  0.00596983  0.0071969   0.00745661  0.02417832  0.01852136 -0.00970045
 -0.0113662  -0.00770806 -0.0094056   0.00377718  0.00753046 -0.02232397
  0.00771382 -0.02437504 -0.01973063  0.00639212  0.01580904 -0.01988203
 -0.03127031 -0.0242672  -0.02352296 -0.01142995 -0.00842379 -0.00464741
 -0.01691805  0.00070027 -0.04791224  0.03879257 -0.00815937 -0.0625505
  0.04908578 -0.01317241 -0.00720496 -0.01029436 -0.0099016  -0.06132835
 -0.01682989 -0.01116916  0.03548144  0.00860726 -0.01927326 -0.00764755
  0.00414349  0.04744965  0.00273012  0.0091548  -0.00213484 -0.01979318
 -0.00559675  0.00413142 -0.00317136  0.01712328 -0.01221122 -0.01253709
 -0.00214242  0.070887   -0.01374912  0.00183695  0.00311592 -0.02234548
 -0.00075323 -0.00103209 -0.00505588 -0.01512959  0.02578029 -0.0295398
  0.03204115  0.02372706 -0.04892739  0.01127288  0.00398435 -0.00619527
  0.01680861 -0.02100045  0.00955837  0.00753603 -0.00234338  0.01775083
 -0.00391008  0.04511286 -0.0001695   0.03124726 -0.00523097 -0.01333472
  0.0067892  -0.00903426  0.00313476  0.02160116  0.00908127  0.00449529
 -0.00889384  0.00457464  0.00818268 -0.03137556 -0.00181907 -0.00306553
  0.06567127 -0.0030635   0.02274218 -0.00469919  0.00529372 -0.00128162
 -0.00810397 -0.00932358 -0.01085878  0.02054778  0.05291288 -0.03408312
  0.01494243  0.04544726 -0.00886332  0.03208694 -0.0071799   0.07005285
 -0.01267937  0.00398148 -0.01999618 -0.03289988  0.00664497  0.00031623
 -0.04548234 -0.01037496 -0.00200315 -0.0285024 ]
tensor_name:  TemporalFusionTransformer/time_distributed_91/kernel
[[ 0.13288698 -0.0219786   0.08316619 ...  0.13381836 -0.07778213
  -0.07728952]
 [-0.14430717  0.13339859 -0.02957064 ...  0.08506023 -0.00731433
   0.15130718]
 [-0.00252844 -0.05873069 -0.13806203 ... -0.06571193  0.10046153
  -0.04843297]
 ...
 [-0.11121952 -0.09453722  0.04050886 ... -0.08537394 -0.07359071
   0.01694438]
 [-0.02637346  0.03010285 -0.06848448 ...  0.04636063 -0.01746828
  -0.03867331]
 [ 0.04555231 -0.02640256 -0.11312746 ...  0.01487591  0.11217719
  -0.08569355]]
tensor_name:  TemporalFusionTransformer/time_distributed_92/bias
[ 0.02849086 -0.01433734  0.00202709 -0.01296106  0.00534721  0.00495423
  0.01439116 -0.01024139 -0.01024942 -0.0132679   0.01838921 -0.01263794
 -0.0159205  -0.00858065 -0.01381695  0.00678266  0.00035602 -0.01326548
 -0.03455604 -0.03642655  0.01076018  0.01864105  0.01210324 -0.00860583
  0.01153613 -0.01088659 -0.01252258 -0.01282655  0.00580992 -0.01648072
  0.00045926  0.02395226 -0.01081532  0.00389343  0.00952872 -0.0137677
  0.00119727 -0.00369929  0.00172603  0.02692036 -0.00833016  0.01042001
  0.0029817  -0.01016449  0.00073353 -0.00510812  0.00365599  0.00626831
  0.00950762 -0.00865771  0.01990957 -0.02256666 -0.01569813  0.02453482
  0.01265803 -0.02236339  0.01564045 -0.00147183  0.00111512 -0.00105432
 -0.00334596 -0.00512034  0.02104496  0.01091833 -0.0182879   0.01457253
  0.00789835 -0.00427221 -0.01201803 -0.00429259  0.00178728  0.02895358
  0.00690034 -0.01076484  0.02803353  0.00857574 -0.01096844 -0.01361678
  0.01226997  0.01286906 -0.01153831 -0.00751343 -0.00168107 -0.02018159
 -0.00237212 -0.00406819 -0.02706588 -0.01542382 -0.00580466 -0.01511413
 -0.02055637  0.02727298 -0.01243497  0.00189103 -0.0240977   0.02412044
 -0.01159264 -0.00443158  0.00973661  0.0226021   0.03239989  0.00945804
  0.01979331  0.0239164   0.0214555  -0.01843963 -0.0090518  -0.02378047
 -0.03996211  0.01071848 -0.00594688 -0.00970523 -0.00897848 -0.00555802
 -0.00564694  0.02851852 -0.00856221  0.00959655  0.00172106 -0.00551772
  0.01125058  0.02031748 -0.0078283  -0.00900187 -0.0219677  -0.01315332
 -0.00146266 -0.0094723   0.00782525  0.0022188  -0.00405036 -0.01036699
  0.03097787 -0.02594422  0.00745329 -0.01389504 -0.01537142 -0.00422905
 -0.02412681 -0.01866907 -0.01117273 -0.01465937  0.01784564 -0.00298211
 -0.02039835  0.02097073 -0.01706114  0.0125277  -0.00731623  0.04527872
 -0.00158562 -0.02099298 -0.00038611 -0.01856365  0.00161246 -0.02412688
 -0.01653085 -0.01080172 -0.00555433  0.00255715]
tensor_name:  TemporalFusionTransformer/time_distributed_92/kernel
[[-0.02631095 -0.05834149  0.01464152 ...  0.02090625  0.00798924
   0.11706097]
 [-0.03117356  0.00536743  0.04856459 ... -0.05582335  0.02211623
  -0.10755764]
 [-0.03174261  0.00581872  0.05436145 ...  0.15675728  0.05613178
   0.04886379]
 ...
 [-0.06653596 -0.06298979 -0.04358402 ... -0.07917291 -0.0250493
  -0.0937002 ]
 [ 0.05088335 -0.08200692 -0.02359373 ...  0.08190104 -0.0347933
   0.09650227]
 [ 0.09827144  0.1692303  -0.05033921 ...  0.04806647 -0.01213868
  -0.05720973]]
tensor_name:  TemporalFusionTransformer/time_distributed_93/bias
[ 6.78115105e-03  2.00014278e-01  5.58667909e-03 -1.07130492e-02
 -7.20942207e-03  7.37073319e-03 -6.23810058e-03 -4.78427531e-03
  8.06306582e-03 -2.45760195e-02 -1.09522352e-02  3.10537382e-03
  6.89270161e-03 -1.56508572e-02 -1.27034821e-03 -4.23245318e-03
  8.04613065e-03 -1.11084210e-03 -8.53127055e-03  4.17328021e-03
  8.17180052e-02 -2.51205079e-02  1.46923969e-02  1.42721543e-02
  1.11150602e-02 -5.94086293e-03 -2.49679433e-03 -6.24396373e-03
 -3.98924248e-03  7.81599060e-03  1.55968172e-03 -1.90786552e-02
  5.06873149e-03 -1.05729792e-02 -1.66442059e-03 -1.39480606e-02
  1.30175073e-02 -1.34325204e-02  1.15030287e-02 -7.84272386e-04
 -7.82704875e-02  4.06944333e-03  8.78305361e-03  5.37188211e-03
 -3.24263121e-03  4.81007481e-03 -3.03101493e-03 -1.95579705e-04
  3.29472939e-03  3.53965312e-02 -4.13543917e-03 -1.50888339e-02
  7.17814732e-03  4.02206928e-03  1.22866011e-04  1.79350153e-01
  3.11898533e-03  7.80549506e-03 -7.55257951e-03  1.17131379e-02
 -1.16210862e-03 -5.57112508e-04  1.00247124e-02  3.10161114e-02
  1.54967178e-02  1.65424738e-02  2.02460401e-03  9.21668392e-03
 -2.44373502e-03 -6.39928132e-02  7.59436190e-02  6.53180527e-03
 -1.17792711e-02  1.34400344e-02 -7.67922541e-03  1.27234571e-02
  3.29707041e-02  5.37998695e-03 -1.20108817e-02 -3.09585012e-03
  2.95629650e-02 -6.01056870e-03 -1.64765690e-04  7.37113529e-04
  6.12894818e-03  1.06373020e-02 -1.42889824e-02 -3.53934360e-04
 -2.63396613e-02 -8.22073128e-03  1.23142144e-02  3.89984786e-03
  3.25414212e-03  1.05756978e-02 -6.70317467e-03  4.09454899e-03
  1.28852027e-02 -6.09702896e-03  1.36112925e-02 -1.23440735e-02
 -1.05757182e-02  2.08696094e-03 -8.87579401e-04  2.32978235e-03
 -1.54348286e-02  1.37016019e-02  3.27451178e-03 -2.19599642e-02
  7.60609191e-03  1.33686550e-02  3.67744337e-03  2.48298664e-02
  4.36375523e-03  4.35585156e-03 -6.03698008e-03  6.23967163e-02
  8.18752311e-03 -9.59399808e-03 -9.23159823e-04 -1.32105909e-02
  2.58873962e-03 -6.38214964e-03  1.44530199e-02  9.98868980e-03
  2.05282471e-03 -1.12842396e-02  2.96209310e-03 -2.77889473e-03
  3.33821005e-03 -3.37308086e-02  1.81128625e-02 -7.52030872e-04
  8.88574650e-05 -1.51260709e-02 -1.04874047e-03 -7.24921876e-04
  1.13038477e-02 -2.14584731e-03 -1.07096294e-02  1.33842994e-02
 -3.23423035e-02 -8.01893696e-03  1.08651789e-02 -5.31813875e-03
  8.14995356e-03  8.33962113e-03  4.75164095e-04 -6.60557125e-04
  1.15835853e-02  1.22698219e-02 -3.27088725e-04 -1.38349517e-03
 -4.73202253e-03 -1.87267080e-01 -5.05746156e-03  1.30641703e-02
 -1.12894299e-02 -3.13239079e-03 -8.01386219e-03 -4.36041225e-03]
tensor_name:  TemporalFusionTransformer/time_distributed_93/kernel
[[-0.00922581  0.32123756  0.01517738 ... -0.08994333 -0.00540613
   0.13394685]
 [-0.0215666   0.2321332  -0.02318139 ... -0.08102912  0.14020914
  -0.11479107]
 [-0.08389211  0.2482719   0.11815578 ... -0.02993919  0.03278796
  -0.09331241]
 ...
 [ 0.04757503  0.10673314 -0.11588328 ...  0.08659033  0.07164387
   0.09890805]
 [-0.04345814 -0.07542419  0.02508725 ...  0.07032962  0.03166746
  -0.09628449]
 [-0.05465837 -0.40505558  0.1014493  ...  0.11919475 -0.04442397
   0.06875449]]
tensor_name:  TemporalFusionTransformer/time_distributed_94/bias
[-0.04739418  0.06481375  0.00681447  0.01138819 -0.04045045  0.0034217
 -0.04306627  0.00024215 -0.0437607   0.0268787  -0.02218746  0.00734156
 -0.01267563 -0.01723074 -0.04814684 -0.00968869 -0.02943462 -0.03240915
 -0.05289109  0.01093158  0.08360943 -0.03683093 -0.04442526 -0.05031518
 -0.03574074 -0.05849132 -0.03046441 -0.00249747 -0.02993035 -0.02825711
 -0.04020009 -0.05477474 -0.02816206  0.02463692 -0.02459883 -0.02334857
 -0.03645475 -0.01673164 -0.02610779 -0.03483113  0.06987795 -0.01853906
 -0.03720104 -0.00581977 -0.01854352 -0.01811078 -0.02761484 -0.02042767
 -0.01006181  0.05101917 -0.01569453 -0.02309779 -0.01693776 -0.03139379
 -0.01155093  0.0828677  -0.01573816  0.02015724 -0.02086962 -0.03493435
 -0.00291494 -0.00900123 -0.03774577 -0.03883672 -0.03746193 -0.07771202
 -0.00713875 -0.03168881 -0.01471305  0.07977229  0.0785291  -0.0094308
 -0.02643275  0.02012846  0.00286364 -0.03184592 -0.04825519 -0.01625711
 -0.02014825 -0.03635183  0.02776483 -0.01687598 -0.03175197  0.00266873
 -0.03997907 -0.01245007  0.00560622 -0.03728548  0.01196172 -0.03211366
 -0.02064518  0.00411332 -0.03380811 -0.01216079 -0.00268098 -0.02904531
 -0.06860501  0.020627   -0.02553039 -0.01985809 -0.00833021 -0.0288803
 -0.00496622  0.01586121 -0.0239577  -0.02631665 -0.01271902 -0.05467971
 -0.04271419 -0.05916176 -0.03674805  0.00979581 -0.016879   -0.02916856
 -0.00579168  0.04218138  0.04249577 -0.04888052 -0.01928336 -0.00299914
 -0.0288879  -0.03339551  0.00765955 -0.05159042  0.00374416 -0.00290171
 -0.02136652 -0.02042543 -0.01623396 -0.03885517 -0.03282672 -0.00972843
 -0.00299123  0.01091129  0.00037097 -0.01723954 -0.0188544  -0.03700446
 -0.02192535 -0.02954462  0.01059002 -0.02185097 -0.02400949 -0.05883066
 -0.01666382 -0.0285207  -0.03513683 -0.0368956   0.03125498 -0.02111457
 -0.031452   -0.03935793 -0.01024297  0.10508754 -0.01344476 -0.00111636
 -0.04724955 -0.02471692 -0.00035074 -0.0306805 ]
tensor_name:  TemporalFusionTransformer/time_distributed_94/kernel
[[-0.00375137  0.05691698 -0.03138309 ...  0.01306299 -0.04774443
  -0.0493102 ]
 [ 0.05648739 -0.01514449  0.01496287 ...  0.03279224 -0.11260933
   0.10519362]
 [-0.04153384  0.15242338 -0.10038716 ...  0.04278651  0.01850393
   0.07634829]
 ...
 [ 0.09352557  0.12125611 -0.02380517 ... -0.05573804  0.08788583
   0.00912567]
 [ 0.1481235  -0.01648246 -0.0253769  ...  0.09128948  0.14035663
   0.07906456]
 [ 0.05749095 -0.23139119 -0.08829378 ... -0.08793832  0.09075818
  -0.06037278]]
tensor_name:  TemporalFusionTransformer/time_distributed_95/bias
[ 0.0247796   0.00404915 -0.00482447]
tensor_name:  TemporalFusionTransformer/time_distributed_95/kernel
[[-6.87980801e-02 -1.43510178e-01  4.81477715e-02]
 [-2.40262151e-02  3.52922566e-02  5.22439778e-02]
 [ 2.30074190e-02  2.37177685e-02  1.36356831e-01]
 [ 9.32827592e-02  3.35778631e-02 -1.22846827e-01]
 [ 2.17824476e-04  1.09715529e-01  8.90578085e-04]
 [-1.65537357e-01 -1.13012634e-01 -1.20975561e-01]
 [-3.61219384e-02  6.66622445e-02 -7.94765651e-02]
 [ 1.60262212e-01 -1.04053326e-01  1.04325237e-02]
 [ 1.01590864e-02 -1.05970696e-01  1.43478781e-01]
 [-2.40698680e-02  1.27570536e-02 -4.13426422e-02]
 [ 7.49546289e-02  2.65986044e-02 -7.44230151e-02]
 [ 5.31139337e-02 -9.90816057e-02 -9.84094664e-02]
 [ 3.26389819e-02 -1.20230459e-01 -1.32058471e-01]
 [ 9.50854868e-02 -1.56463590e-02 -3.02108154e-02]
 [ 2.99008214e-03 -3.31813470e-02 -3.94954383e-02]
 [-7.31916213e-03  5.84170222e-02  1.63333178e-01]
 [-1.31103173e-01  1.17722079e-01  1.01080522e-01]
 [ 6.98068589e-02  1.13733888e-01  9.33991671e-02]
 [ 7.04023764e-02  5.79169067e-03 -4.08229195e-02]
 [-1.09929495e-01  1.34845868e-01  1.04538053e-01]
 [-6.92903474e-02  9.90235433e-03  4.78053093e-02]
 [-2.21047346e-02 -1.60078972e-03 -8.04300755e-02]
 [-9.78449211e-02 -9.02019292e-02  8.98949653e-02]
 [-8.77239034e-02 -6.69636056e-02  7.70378932e-02]
 [-7.15365708e-02  1.19875707e-01  8.43693689e-02]
 [ 3.83899882e-02  1.63770188e-02 -3.86330076e-02]
 [ 3.20340432e-02 -4.54423996e-03  1.21931337e-01]
 [ 1.04361229e-01 -1.82607807e-02  1.79031547e-02]
 [ 1.14893995e-01  2.32614595e-02  1.68778762e-01]
 [-1.24808483e-01 -1.37640074e-01 -1.28183752e-01]
 [-6.90783141e-04 -1.52105868e-01  1.05676241e-01]
 [ 3.14220376e-02 -4.90799136e-02 -7.00419322e-02]
 [ 2.48179864e-02  7.20575303e-02  1.11924395e-01]
 [ 3.07359751e-02  5.38593195e-02 -8.61366987e-02]
 [-7.25567639e-02  1.46204695e-01 -8.77050832e-02]
 [ 1.00337394e-01  4.57477458e-02  1.47651676e-02]
 [-1.25304788e-01  6.75265118e-02 -8.40301290e-02]
 [-1.66200679e-02 -3.71520258e-02 -4.41872180e-02]
 [-1.01497583e-01  1.15286551e-01  4.58317511e-02]
 [-3.54770236e-02 -5.99621311e-02  7.75352269e-02]
 [ 1.11405484e-01  3.57843526e-02 -2.27511488e-02]
 [-1.23889185e-05  1.89825110e-02  8.57289732e-02]
 [-7.92307332e-02 -1.77748147e-02  2.70160325e-02]
 [-9.28892847e-03 -5.54122776e-02  1.00943059e-01]
 [ 9.69506577e-02 -1.36910528e-01  8.08355883e-02]
 [-3.87269184e-02 -1.24028757e-01  1.18072718e-01]
 [-5.98371401e-02 -8.29134583e-02 -1.40920714e-01]
 [ 2.40674950e-02  7.58375973e-02 -3.08807883e-02]
 [ 1.02153316e-01  1.67923316e-01 -8.26692283e-02]
 [ 1.06024429e-01 -1.46529078e-02  1.71317145e-01]
 [ 1.77395374e-01 -1.06279917e-01  6.05541952e-02]
 [-3.47285601e-03 -2.46615205e-02 -9.24410298e-02]
 [-1.22841503e-02 -3.49048264e-02 -3.89485657e-02]
 [-1.26895696e-01  7.36250654e-02 -1.61694616e-01]
 [ 6.81606904e-02 -1.52124420e-01 -7.57150874e-02]
 [-2.26015318e-02 -3.80952172e-02  5.95043413e-02]
 [-2.63300315e-02  9.78768021e-02 -7.98765849e-03]
 [-3.74950469e-03 -7.52252415e-02  1.87780280e-02]
 [ 1.63517576e-02 -8.36032853e-02 -2.52261925e-02]
 [-2.48997621e-02  1.67157963e-01 -4.25906852e-02]
 [ 3.34028751e-02 -4.38833535e-02  1.33916258e-03]
 [ 1.83907971e-02  1.37309745e-01 -1.08801596e-01]
 [-1.05204821e-01 -1.47699550e-01  1.06536150e-01]
 [-6.52568862e-02  5.37678264e-02  1.98433623e-02]
 [-9.97559428e-02  6.06324449e-02  1.46903470e-01]
 [-4.54669520e-02  7.94561300e-03  8.38860199e-02]
 [-5.79721369e-02 -5.05890138e-02 -1.42269313e-01]
 [-1.17263034e-01 -1.06533982e-01  7.39572495e-02]
 [ 1.00643486e-01  1.14417821e-01  1.31999508e-01]
 [-2.83039249e-02  4.93062753e-03 -9.22838971e-02]
 [-5.51058017e-02  2.67258342e-02  4.09590602e-02]
 [-4.00963202e-02 -1.34171262e-01  7.53570497e-02]
 [ 9.65957195e-02 -1.06233306e-01 -7.05210716e-02]
 [-8.33317563e-02  1.21876232e-01  2.93956343e-02]
 [ 2.59346403e-02  2.99650943e-03  2.53702775e-02]
 [ 1.66290253e-02  1.14886969e-01  9.49376076e-02]
 [-1.27523020e-01  5.68369702e-02  4.33534048e-02]
 [-7.21596032e-02  9.45891589e-02 -5.12610674e-02]
 [ 4.56862524e-02 -6.98593110e-02 -2.36509778e-02]
 [ 1.20978758e-01  1.77288540e-02  1.27242208e-01]
 [-1.55015662e-02 -6.68175146e-02  1.06516229e-02]
 [ 2.64796596e-02  3.98606881e-02 -9.03032944e-02]
 [ 9.38299298e-02  1.07915908e-01 -1.50436476e-01]
 [-1.39894620e-01  1.27545208e-01  5.64248860e-02]
 [ 8.44334066e-02  7.24654943e-02  4.91134590e-03]
 [ 9.41679403e-02 -1.50291875e-01  6.43881187e-02]
 [ 5.30954711e-02 -1.34468198e-01 -5.12832738e-02]
 [ 1.12893566e-01  1.10052548e-01  8.75317156e-02]
 [ 1.44291380e-02  1.24536477e-01 -1.62385199e-02]
 [-1.08109996e-01  1.08347967e-01 -8.29676837e-02]
 [ 1.33684475e-03 -3.06641348e-02  1.51107283e-02]
 [ 4.10086811e-02 -1.20664805e-01 -3.88221219e-02]
 [-8.85978118e-02 -1.50868163e-01  4.76627126e-02]
 [ 6.62074089e-02  4.25321423e-03  6.66691661e-02]
 [ 4.24862886e-03 -8.84399116e-02 -6.94713518e-02]
 [ 8.33619982e-02  1.69339523e-01 -2.29771603e-02]
 [-7.04022646e-02 -7.77809545e-02  1.05585590e-01]
 [ 6.81163371e-02 -9.48459804e-02 -4.37051319e-02]
 [-8.27363133e-02 -9.35740322e-02  3.11412532e-02]
 [ 2.39103269e-02 -3.25921141e-02  2.30366830e-02]
 [ 1.76560014e-01 -7.09047988e-02  7.84180090e-02]
 [-2.64671315e-02 -1.39507189e-01 -8.88899788e-02]
 [-3.88405249e-02  9.69279110e-02 -1.38924748e-01]
 [-7.08470270e-02  1.03129566e-01  9.55835283e-02]
 [ 8.99514332e-02  3.57879624e-02  3.14961486e-02]
 [-2.62145307e-02 -7.46009126e-02 -8.48288741e-03]
 [-4.48759422e-02 -1.12661205e-01  1.20597489e-01]
 [ 2.59414427e-02  7.84016326e-02 -8.57991576e-02]
 [-1.47704557e-01 -6.10289909e-02 -1.67222749e-02]
 [-9.99133214e-02  1.46485195e-01 -3.97481024e-02]
 [ 7.50149414e-02  1.45931005e-01  8.51777270e-02]
 [-2.68840883e-02 -9.65482295e-02 -1.25798807e-01]
 [-7.94663429e-02 -2.65657827e-02 -2.21894309e-02]
 [ 6.00040667e-02 -1.50649756e-01 -1.32969514e-01]
 [-4.89302985e-02 -1.61338933e-02 -1.06349878e-01]
 [-1.23131841e-01  1.72327105e-02 -1.98104326e-02]
 [-8.27583484e-03 -3.24984714e-02  9.70628951e-03]
 [ 1.20561734e-01  5.94053306e-02 -1.56389430e-01]
 [ 9.10149813e-02  1.84390754e-01  1.24979235e-01]
 [-3.08591500e-02 -7.79813007e-02  2.12003570e-02]
 [ 9.65981632e-02  1.47004742e-02  1.14470661e-01]
 [-3.35539170e-02 -8.56492203e-03 -8.09017345e-02]
 [-1.06810786e-01  5.22249453e-02  1.43367186e-01]
 [-7.11331442e-02  5.83942123e-02 -1.16393482e-03]
 [ 1.06430098e-01  2.55942047e-02  1.60708323e-01]
 [-4.02079662e-03  7.15224892e-02  3.06224488e-02]
 [-8.32047090e-02  1.15735568e-01 -6.05255887e-02]
 [-1.97731107e-02  1.40540347e-01  1.30749732e-01]
 [ 4.04317789e-02 -1.27311721e-01 -1.62233990e-02]
 [ 7.31650963e-02 -1.07123882e-01 -6.97928891e-02]
 [-3.75512801e-02  1.17356829e-01  9.87925977e-02]
 [ 7.48760700e-02 -4.37473729e-02  1.20311424e-01]
 [ 2.51192357e-02 -1.24625951e-01 -4.33339886e-02]
 [-1.15257896e-01  4.16251794e-02  6.52249232e-02]
 [ 9.42999497e-03  1.12013659e-02 -1.52683370e-02]
 [ 1.33663267e-01 -6.78349435e-02  1.39952555e-01]
 [-7.29071423e-02 -1.19414106e-01 -9.96391326e-02]
 [ 4.24428582e-02  1.27684548e-01  4.44081321e-04]
 [-2.85104085e-02  1.22118309e-01 -5.31530604e-02]
 [-7.00194808e-03 -5.18780621e-03  1.44700080e-01]
 [ 5.46835512e-02 -5.94682842e-02  7.93121010e-02]
 [-4.82071340e-02 -1.19093686e-01 -1.37625784e-01]
 [ 1.18901826e-01  1.04069583e-01  9.97143462e-02]
 [-1.68067846e-03 -1.49720162e-01  4.72415201e-02]
 [-9.40870121e-02 -1.53671741e-01  1.39395352e-02]
 [-1.05969291e-02  1.05014428e-01 -6.58456162e-02]
 [-1.12121142e-01 -4.28510047e-02 -1.13157004e-01]
 [ 7.58390352e-02  7.20299706e-02  2.50098985e-02]
 [-9.57145263e-03  3.68566555e-03  3.62436287e-03]
 [-7.84903951e-03  1.44480139e-01 -3.02704293e-02]
 [ 8.56155716e-03 -6.61851019e-02  2.02916972e-02]
 [-1.46869779e-01 -1.59654282e-02 -1.58807099e-01]
 [-3.46623957e-02  1.21306680e-01 -3.69099043e-02]
 [ 1.52459079e-02  5.22585679e-03 -3.24156228e-03]
 [-6.14574701e-02  9.54265613e-03 -1.22631036e-01]
 [-1.19650096e-01 -2.76298895e-02  1.25236735e-02]
 [ 1.31521570e-02 -1.24633692e-01  4.56386916e-02]
 [ 2.83035636e-02  5.84012568e-02  9.81542245e-02]
 [ 1.77303076e-01 -1.37598455e-01  1.30804464e-01]
 [-1.22676991e-01 -8.11331905e-03 -9.18644443e-02]]
# Total number of params: 3534803
WARNING:tensorflow:From /opt/BAA/TFT/libs/utils.py:199: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

Done.
Computing best validation loss
  32/2711 [..............................] - ETA: 15:24 - loss: 0.2205  96/2711 [>.............................] - ETA: 5:03 - loss: 0.2339  160/2711 [>.............................] - ETA: 2:59 - loss: 0.2083 192/2711 [=>............................] - ETA: 2:29 - loss: 0.2161 224/2711 [=>............................] - ETA: 2:07 - loss: 0.2183 256/2711 [=>............................] - ETA: 1:50 - loss: 0.2104 288/2711 [==>...........................] - ETA: 1:37 - loss: 0.2034 352/2711 [==>...........................] - ETA: 1:18 - loss: 0.1971 384/2711 [===>..........................] - ETA: 1:11 - loss: 0.1935 448/2711 [===>..........................] - ETA: 59s - loss: 0.1846  512/2711 [====>.........................] - ETA: 51s - loss: 0.1732 576/2711 [=====>........................] - ETA: 44s - loss: 0.1753 608/2711 [=====>........................] - ETA: 41s - loss: 0.1722 640/2711 [======>.......................] - ETA: 39s - loss: 0.1694 704/2711 [======>.......................] - ETA: 34s - loss: 0.1669 768/2711 [=======>......................] - ETA: 31s - loss: 0.1685 832/2711 [========>.....................] - ETA: 28s - loss: 0.1707 864/2711 [========>.....................] - ETA: 26s - loss: 0.1709 896/2711 [========>.....................] - ETA: 25s - loss: 0.1711 960/2711 [=========>....................] - ETA: 23s - loss: 0.1667 992/2711 [=========>....................] - ETA: 21s - loss: 0.16801024/2711 [==========>...................] - ETA: 21s - loss: 0.16781088/2711 [===========>..................] - ETA: 19s - loss: 0.16721120/2711 [===========>..................] - ETA: 18s - loss: 0.16891152/2711 [===========>..................] - ETA: 17s - loss: 0.16801216/2711 [============>.................] - ETA: 16s - loss: 0.16761248/2711 [============>.................] - ETA: 15s - loss: 0.16671280/2711 [=============>................] - ETA: 14s - loss: 0.16561312/2711 [=============>................] - ETA: 14s - loss: 0.16471376/2711 [==============>...............] - ETA: 12s - loss: 0.16561408/2711 [==============>...............] - ETA: 12s - loss: 0.16581440/2711 [==============>...............] - ETA: 11s - loss: 0.16451504/2711 [===============>..............] - ETA: 10s - loss: 0.16381536/2711 [===============>..............] - ETA: 10s - loss: 0.16291600/2711 [================>.............] - ETA: 9s - loss: 0.1622 1664/2711 [=================>............] - ETA: 8s - loss: 0.16191728/2711 [==================>...........] - ETA: 7s - loss: 0.16191760/2711 [==================>...........] - ETA: 7s - loss: 0.16171824/2711 [===================>..........] - ETA: 6s - loss: 0.16001888/2711 [===================>..........] - ETA: 6s - loss: 0.16221952/2711 [====================>.........] - ETA: 5s - loss: 0.16202016/2711 [=====================>........] - ETA: 4s - loss: 0.16012048/2711 [=====================>........] - ETA: 4s - loss: 0.16042080/2711 [======================>.......] - ETA: 4s - loss: 0.16272112/2711 [======================>.......] - ETA: 4s - loss: 0.16202176/2711 [=======================>......] - ETA: 3s - loss: 0.16112240/2711 [=======================>......] - ETA: 3s - loss: 0.16172304/2711 [========================>.....] - ETA: 2s - loss: 0.16192368/2711 [=========================>....] - ETA: 2s - loss: 0.16122400/2711 [=========================>....] - ETA: 1s - loss: 0.16942432/2711 [=========================>....] - ETA: 1s - loss: 0.17542496/2711 [==========================>...] - ETA: 1s - loss: 0.17442528/2711 [==========================>...] - ETA: 1s - loss: 0.17392560/2711 [===========================>..] - ETA: 0s - loss: 0.17492624/2711 [============================>.] - ETA: 0s - loss: 0.17462688/2711 [============================>.] - ETA: 0s - loss: 0.17322711/2711 [==============================] - 15s 6ms/sample - loss: 0.1728
Computing test loss
Training completed @ 2024-12-23 20:55:42.023180
Best validation loss = 0.17280841937851352
Params:
dropout_rate  =  0.3
hidden_layer_size  =  160
learning_rate  =  0.001
max_gradient_norm  =  0.01
minibatch_size  =  64
model_folder  =  /opt/BAA/TFT/models/training_fixed_parameters/day_60min/pod_just_wind_speed_day_60min/saved_models/visitors/fixed
num_heads  =  1
stack_size  =  1
total_time_steps  =  32
num_encoder_steps  =  24
num_epochs  =  100
early_stopping_patience  =  3
multiprocessing_workers  =  5
column_definition  =  [('dummy_id', <DataTypes.REAL_VALUED: 0>, <InputTypes.ID: 4>), ('date', <DataTypes.DATE: 2>, <InputTypes.TIME: 5>), ('minute_of_hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('hour_of_day', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('week_of_year', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('month_of_year', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_month', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('Wind Speed', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('visitors', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('region', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>)]
input_size  =  9
output_size  =  1
category_counts  =  [1]
input_obs_loc  =  [7]
static_input_loc  =  [8]
known_regular_inputs  =  [0, 1, 2, 3, 4, 5, 6]
known_categorical_inputs  =  [0]

Normalised Quantile Loss for Test Data: P50=0.17474590762984019, P90=0.09185279994900092
